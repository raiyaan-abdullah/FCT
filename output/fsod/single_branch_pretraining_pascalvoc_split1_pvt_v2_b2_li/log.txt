[01/29 16:17:08] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 16:17:08] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 16:17:08] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 16:17:08] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/29 16:17:08] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/29 16:17:08] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/29 16:17:08] d2.utils.env INFO: Using a generated random seed 8767476
[01/29 16:17:11] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/29 16:17:12] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/29 16:17:12] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/29 16:17:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/29 16:17:12] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 16:17:12] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/29 16:17:13] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/29 16:18:33] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 16:18:33] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 16:18:33] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 16:18:33] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/29 16:18:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/29 16:18:33] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/29 16:18:34] d2.utils.env INFO: Using a generated random seed 34073499
[01/29 16:18:36] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/29 16:18:37] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/29 16:18:37] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/29 16:18:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/29 16:18:37] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 16:18:37] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/29 16:18:38] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/29 16:18:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/29 16:21:36] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 16:21:37] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 16:21:37] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 16:21:37] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/29 16:21:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/29 16:21:37] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/29 16:21:37] d2.utils.env INFO: Using a generated random seed 37269718
[01/29 16:21:39] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/29 16:21:40] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/29 16:21:41] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/29 16:21:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/29 16:21:41] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 16:21:41] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/29 16:21:41] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/29 16:21:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/29 16:21:41] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[01/29 16:21:41] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  head.{bias, weight}
[01/29 16:21:41] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 16:21:46] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 163, in forward
    _, detector_losses = self.roi_heads(images, features, proposals, gt_instances)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/pvt_roi_heads.py", line 214, in forward
    [features[f] for f in self.in_features], proposal_boxes
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/pvt_roi_heads.py", line 189, in _shared_roi_transform
    x = blk(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/pvt_v2.py", line 173, in forward
    x = x + self.drop_path(self.mlp(self.norm2(x), H, W))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/pvt_v2.py", line 55, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/pvt_v2.py", line 443, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 23.70 GiB total capacity; 20.63 GiB already allocated; 432.69 MiB free; 20.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/29 16:21:46] d2.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[01/29 16:21:46] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21130M
[01/29 16:22:08] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 16:22:08] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 16:22:08] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 16:22:08] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/29 16:22:08] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/29 16:22:08] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/29 16:22:08] d2.utils.env INFO: Using a generated random seed 8984151
[01/29 16:22:11] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/29 16:22:12] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/29 16:22:12] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/29 16:22:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/29 16:22:12] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 16:22:12] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/29 16:22:12] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/29 16:22:13] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/29 16:22:13] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[01/29 16:22:13] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  head.{bias, weight}
[01/29 16:22:13] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 16:22:14] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 294, in run_step
    self.optimizer.step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 65, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/optim/adamw.py", line 148, in step
    eps=group['eps'])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/optim/_functional.py", line 125, in adamw
    param.mul_(1 - lr * weight_decay)
TypeError: unsupported operand type(s) for *: 'float' and 'NoneType'
[01/29 16:22:14] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/29 16:22:14] d2.utils.events INFO:  iter: 0  total_loss: 5.259  loss_cls: 4.506  loss_box_reg: 0.04254  loss_rpn_cls: 0.6914  loss_rpn_loc: 0.01915  data_time: 0.1304  lr: N/A  max_mem: 12004M
[01/29 16:26:59] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 16:27:00] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 16:27:00] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 16:27:00] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/29 16:27:00] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/29 16:27:00] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/29 16:27:00] d2.utils.env INFO: Using a generated random seed 190223
[01/29 16:27:02] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/29 16:27:03] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/29 16:27:03] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/29 16:27:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/29 16:27:03] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 16:27:03] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/29 16:27:04] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/29 16:27:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/29 16:27:04] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[01/29 16:27:04] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  head.{bias, weight}
[01/29 16:27:04] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 16:27:19] d2.utils.events INFO:  eta: 3:45:32  iter: 19  total_loss: 5.063  loss_cls: 4.09  loss_box_reg: 0.07538  loss_rpn_cls: 0.6917  loss_rpn_loc: 0.1298  time: 0.7511  data_time: 0.0075  lr: 3.8162e-05  max_mem: 15127M
[01/29 16:27:34] d2.utils.events INFO:  eta: 3:48:35  iter: 39  total_loss: 1.367  loss_cls: 0.3922  loss_box_reg: 0.09791  loss_rpn_cls: 0.6803  loss_rpn_loc: 0.1015  time: 0.7418  data_time: 0.0023  lr: 7.8122e-05  max_mem: 15127M
[01/29 16:27:48] d2.utils.events INFO:  eta: 3:39:17  iter: 59  total_loss: 1.159  loss_cls: 0.2829  loss_box_reg: 0.1395  loss_rpn_cls: 0.5746  loss_rpn_loc: 0.09579  time: 0.7220  data_time: 0.0022  lr: 0.00011808  max_mem: 15127M
[01/29 16:28:03] d2.utils.events INFO:  eta: 3:36:52  iter: 79  total_loss: 0.7566  loss_cls: 0.1766  loss_box_reg: 0.0882  loss_rpn_cls: 0.3241  loss_rpn_loc: 0.1226  time: 0.7262  data_time: 0.0024  lr: 0.00015804  max_mem: 15127M
[01/29 16:28:18] d2.utils.events INFO:  eta: 3:38:46  iter: 99  total_loss: 1.113  loss_cls: 0.2606  loss_box_reg: 0.1408  loss_rpn_cls: 0.3997  loss_rpn_loc: 0.1946  time: 0.7334  data_time: 0.0024  lr: 0.000198  max_mem: 15184M
[01/29 16:28:33] d2.utils.events INFO:  eta: 3:38:33  iter: 119  total_loss: 0.9025  loss_cls: 0.243  loss_box_reg: 0.1335  loss_rpn_cls: 0.3806  loss_rpn_loc: 0.1623  time: 0.7374  data_time: 0.0024  lr: 0.0002  max_mem: 15184M
[01/29 16:28:48] d2.utils.events INFO:  eta: 3:38:35  iter: 139  total_loss: 0.9357  loss_cls: 0.2418  loss_box_reg: 0.1297  loss_rpn_cls: 0.3218  loss_rpn_loc: 0.1185  time: 0.7347  data_time: 0.0021  lr: 0.0002  max_mem: 15184M
[01/29 16:29:01] d2.utils.events INFO:  eta: 3:36:51  iter: 159  total_loss: 0.7085  loss_cls: 0.1877  loss_box_reg: 0.09594  loss_rpn_cls: 0.3022  loss_rpn_loc: 0.1055  time: 0.7274  data_time: 0.0021  lr: 0.0002  max_mem: 15184M
[01/29 16:29:17] d2.utils.events INFO:  eta: 3:37:47  iter: 179  total_loss: 0.8315  loss_cls: 0.2686  loss_box_reg: 0.1528  loss_rpn_cls: 0.2739  loss_rpn_loc: 0.1148  time: 0.7329  data_time: 0.0027  lr: 0.0002  max_mem: 15184M
[01/29 16:29:32] d2.utils.events INFO:  eta: 3:38:31  iter: 199  total_loss: 0.9082  loss_cls: 0.2618  loss_box_reg: 0.1512  loss_rpn_cls: 0.3077  loss_rpn_loc: 0.1257  time: 0.7342  data_time: 0.0024  lr: 0.0002  max_mem: 15184M
[01/29 16:29:46] d2.utils.events INFO:  eta: 3:37:36  iter: 219  total_loss: 1.109  loss_cls: 0.4168  loss_box_reg: 0.2592  loss_rpn_cls: 0.3075  loss_rpn_loc: 0.1019  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15184M
[01/29 16:30:00] d2.utils.events INFO:  eta: 3:37:03  iter: 239  total_loss: 0.8112  loss_cls: 0.2503  loss_box_reg: 0.1301  loss_rpn_cls: 0.2621  loss_rpn_loc: 0.09932  time: 0.7299  data_time: 0.0025  lr: 0.0002  max_mem: 15184M
[01/29 16:30:14] d2.utils.events INFO:  eta: 3:36:48  iter: 259  total_loss: 0.8026  loss_cls: 0.2419  loss_box_reg: 0.1381  loss_rpn_cls: 0.2836  loss_rpn_loc: 0.1106  time: 0.7291  data_time: 0.0024  lr: 0.0002  max_mem: 15184M
[01/29 16:30:29] d2.utils.events INFO:  eta: 3:36:36  iter: 279  total_loss: 0.8334  loss_cls: 0.2604  loss_box_reg: 0.1606  loss_rpn_cls: 0.2451  loss_rpn_loc: 0.1709  time: 0.7304  data_time: 0.0023  lr: 0.0002  max_mem: 15184M
[01/29 16:30:44] d2.utils.events INFO:  eta: 3:36:49  iter: 299  total_loss: 0.7953  loss_cls: 0.2517  loss_box_reg: 0.1627  loss_rpn_cls: 0.2476  loss_rpn_loc: 0.1256  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15184M
[01/29 16:30:59] d2.utils.events INFO:  eta: 3:36:34  iter: 319  total_loss: 0.7574  loss_cls: 0.224  loss_box_reg: 0.1417  loss_rpn_cls: 0.234  loss_rpn_loc: 0.1004  time: 0.7300  data_time: 0.0024  lr: 0.0002  max_mem: 15184M
[01/29 16:31:13] d2.utils.events INFO:  eta: 3:36:08  iter: 339  total_loss: 0.9531  loss_cls: 0.2631  loss_box_reg: 0.1727  loss_rpn_cls: 0.2449  loss_rpn_loc: 0.1293  time: 0.7290  data_time: 0.0025  lr: 0.0002  max_mem: 15184M
[01/29 16:31:27] d2.utils.events INFO:  eta: 3:35:42  iter: 359  total_loss: 0.9327  loss_cls: 0.2801  loss_box_reg: 0.2019  loss_rpn_cls: 0.2462  loss_rpn_loc: 0.08288  time: 0.7285  data_time: 0.0025  lr: 0.0002  max_mem: 15184M
[01/29 16:31:42] d2.utils.events INFO:  eta: 3:35:27  iter: 379  total_loss: 0.7495  loss_cls: 0.2276  loss_box_reg: 0.1523  loss_rpn_cls: 0.2346  loss_rpn_loc: 0.1005  time: 0.7288  data_time: 0.0025  lr: 0.0002  max_mem: 15184M
[01/29 16:31:57] d2.utils.events INFO:  eta: 3:35:35  iter: 399  total_loss: 0.8217  loss_cls: 0.253  loss_box_reg: 0.1554  loss_rpn_cls: 0.2526  loss_rpn_loc: 0.138  time: 0.7302  data_time: 0.0023  lr: 0.0002  max_mem: 15184M
[01/29 16:32:12] d2.utils.events INFO:  eta: 3:34:58  iter: 419  total_loss: 0.7294  loss_cls: 0.2175  loss_box_reg: 0.1448  loss_rpn_cls: 0.1792  loss_rpn_loc: 0.1036  time: 0.7297  data_time: 0.0023  lr: 0.0002  max_mem: 15184M
[01/29 16:32:26] d2.utils.events INFO:  eta: 3:34:54  iter: 439  total_loss: 0.779  loss_cls: 0.2344  loss_box_reg: 0.1564  loss_rpn_cls: 0.2013  loss_rpn_loc: 0.103  time: 0.7294  data_time: 0.0024  lr: 0.0002  max_mem: 15184M
[01/29 16:32:41] d2.utils.events INFO:  eta: 3:34:28  iter: 459  total_loss: 0.77  loss_cls: 0.2819  loss_box_reg: 0.2001  loss_rpn_cls: 0.1962  loss_rpn_loc: 0.09839  time: 0.7289  data_time: 0.0024  lr: 0.0002  max_mem: 15184M
[01/29 16:32:56] d2.utils.events INFO:  eta: 3:34:25  iter: 479  total_loss: 0.7312  loss_cls: 0.259  loss_box_reg: 0.1739  loss_rpn_cls: 0.1831  loss_rpn_loc: 0.08798  time: 0.7295  data_time: 0.0023  lr: 0.0002  max_mem: 15184M
[01/29 16:33:10] d2.utils.events INFO:  eta: 3:34:10  iter: 499  total_loss: 0.6407  loss_cls: 0.2148  loss_box_reg: 0.1477  loss_rpn_cls: 0.1688  loss_rpn_loc: 0.07321  time: 0.7288  data_time: 0.0022  lr: 0.0002  max_mem: 15184M
[01/29 16:33:25] d2.utils.events INFO:  eta: 3:33:57  iter: 519  total_loss: 0.7323  loss_cls: 0.1955  loss_box_reg: 0.1665  loss_rpn_cls: 0.1992  loss_rpn_loc: 0.119  time: 0.7290  data_time: 0.0022  lr: 0.0002  max_mem: 15184M
[01/29 16:33:39] d2.utils.events INFO:  eta: 3:33:38  iter: 539  total_loss: 0.8137  loss_cls: 0.2248  loss_box_reg: 0.2137  loss_rpn_cls: 0.2003  loss_rpn_loc: 0.1267  time: 0.7289  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:33:53] d2.utils.events INFO:  eta: 3:33:15  iter: 559  total_loss: 0.6954  loss_cls: 0.2148  loss_box_reg: 0.1556  loss_rpn_cls: 0.1543  loss_rpn_loc: 0.1447  time: 0.7280  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:34:08] d2.utils.events INFO:  eta: 3:33:06  iter: 579  total_loss: 0.8775  loss_cls: 0.2289  loss_box_reg: 0.2045  loss_rpn_cls: 0.223  loss_rpn_loc: 0.1649  time: 0.7286  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:34:22] d2.utils.events INFO:  eta: 3:32:39  iter: 599  total_loss: 0.6945  loss_cls: 0.2438  loss_box_reg: 0.2103  loss_rpn_cls: 0.1822  loss_rpn_loc: 0.06065  time: 0.7266  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:34:36] d2.utils.events INFO:  eta: 3:32:24  iter: 619  total_loss: 0.8675  loss_cls: 0.251  loss_box_reg: 0.2431  loss_rpn_cls: 0.1863  loss_rpn_loc: 0.1713  time: 0.7265  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:34:52] d2.utils.events INFO:  eta: 3:32:22  iter: 639  total_loss: 0.9105  loss_cls: 0.3065  loss_box_reg: 0.1922  loss_rpn_cls: 0.2034  loss_rpn_loc: 0.1749  time: 0.7287  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:35:06] d2.utils.events INFO:  eta: 3:32:08  iter: 659  total_loss: 0.771  loss_cls: 0.2114  loss_box_reg: 0.1864  loss_rpn_cls: 0.1971  loss_rpn_loc: 0.1564  time: 0.7275  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:35:20] d2.utils.events INFO:  eta: 3:32:01  iter: 679  total_loss: 0.8254  loss_cls: 0.2395  loss_box_reg: 0.2267  loss_rpn_cls: 0.1994  loss_rpn_loc: 0.1413  time: 0.7271  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:35:34] d2.utils.events INFO:  eta: 3:31:46  iter: 699  total_loss: 0.5353  loss_cls: 0.1677  loss_box_reg: 0.1596  loss_rpn_cls: 0.1297  loss_rpn_loc: 0.08353  time: 0.7261  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:35:49] d2.utils.events INFO:  eta: 3:31:24  iter: 719  total_loss: 0.6862  loss_cls: 0.1718  loss_box_reg: 0.1738  loss_rpn_cls: 0.1411  loss_rpn_loc: 0.1357  time: 0.7263  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:36:04] d2.utils.events INFO:  eta: 3:31:27  iter: 739  total_loss: 0.6503  loss_cls: 0.1954  loss_box_reg: 0.2187  loss_rpn_cls: 0.1315  loss_rpn_loc: 0.07748  time: 0.7272  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:36:18] d2.utils.events INFO:  eta: 3:31:02  iter: 759  total_loss: 0.643  loss_cls: 0.2135  loss_box_reg: 0.2034  loss_rpn_cls: 0.1365  loss_rpn_loc: 0.1118  time: 0.7263  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:36:33] d2.utils.events INFO:  eta: 3:31:01  iter: 779  total_loss: 0.7891  loss_cls: 0.1924  loss_box_reg: 0.184  loss_rpn_cls: 0.1946  loss_rpn_loc: 0.1439  time: 0.7267  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:36:49] d2.utils.events INFO:  eta: 3:31:33  iter: 799  total_loss: 0.667  loss_cls: 0.1576  loss_box_reg: 0.1398  loss_rpn_cls: 0.162  loss_rpn_loc: 0.1673  time: 0.7287  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:37:03] d2.utils.events INFO:  eta: 3:30:40  iter: 819  total_loss: 0.6087  loss_cls: 0.1769  loss_box_reg: 0.1444  loss_rpn_cls: 0.157  loss_rpn_loc: 0.1041  time: 0.7282  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:37:18] d2.utils.events INFO:  eta: 3:30:25  iter: 839  total_loss: 0.7207  loss_cls: 0.1889  loss_box_reg: 0.2308  loss_rpn_cls: 0.1725  loss_rpn_loc: 0.09829  time: 0.7279  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:37:33] d2.utils.events INFO:  eta: 3:30:36  iter: 859  total_loss: 0.6922  loss_cls: 0.2127  loss_box_reg: 0.1934  loss_rpn_cls: 0.1611  loss_rpn_loc: 0.123  time: 0.7285  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:37:48] d2.utils.events INFO:  eta: 3:30:31  iter: 879  total_loss: 0.804  loss_cls: 0.2286  loss_box_reg: 0.2005  loss_rpn_cls: 0.1569  loss_rpn_loc: 0.1277  time: 0.7289  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 16:38:03] d2.utils.events INFO:  eta: 3:30:43  iter: 899  total_loss: 0.8312  loss_cls: 0.2122  loss_box_reg: 0.2592  loss_rpn_cls: 0.1589  loss_rpn_loc: 0.1363  time: 0.7300  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:38:18] d2.utils.events INFO:  eta: 3:30:36  iter: 919  total_loss: 0.6801  loss_cls: 0.1997  loss_box_reg: 0.1885  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.08342  time: 0.7301  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:38:32] d2.utils.events INFO:  eta: 3:30:00  iter: 939  total_loss: 0.5951  loss_cls: 0.1544  loss_box_reg: 0.174  loss_rpn_cls: 0.1506  loss_rpn_loc: 0.09134  time: 0.7295  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:38:46] d2.utils.events INFO:  eta: 3:29:32  iter: 959  total_loss: 0.6449  loss_cls: 0.1884  loss_box_reg: 0.1985  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.1213  time: 0.7291  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:39:02] d2.utils.events INFO:  eta: 3:29:41  iter: 979  total_loss: 0.6805  loss_cls: 0.2027  loss_box_reg: 0.2337  loss_rpn_cls: 0.1554  loss_rpn_loc: 0.1051  time: 0.7302  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:39:17] d2.utils.events INFO:  eta: 3:29:27  iter: 999  total_loss: 0.6807  loss_cls: 0.1803  loss_box_reg: 0.1757  loss_rpn_cls: 0.1324  loss_rpn_loc: 0.1137  time: 0.7304  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:39:31] d2.utils.events INFO:  eta: 3:28:47  iter: 1019  total_loss: 0.7407  loss_cls: 0.2212  loss_box_reg: 0.2362  loss_rpn_cls: 0.1386  loss_rpn_loc: 0.1107  time: 0.7300  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:39:45] d2.utils.events INFO:  eta: 3:28:00  iter: 1039  total_loss: 0.6583  loss_cls: 0.1783  loss_box_reg: 0.1806  loss_rpn_cls: 0.1497  loss_rpn_loc: 0.06972  time: 0.7295  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:40:00] d2.utils.events INFO:  eta: 3:28:31  iter: 1059  total_loss: 0.6043  loss_cls: 0.168  loss_box_reg: 0.1696  loss_rpn_cls: 0.1267  loss_rpn_loc: 0.09302  time: 0.7295  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:40:15] d2.utils.events INFO:  eta: 3:28:35  iter: 1079  total_loss: 0.7107  loss_cls: 0.2161  loss_box_reg: 0.1996  loss_rpn_cls: 0.147  loss_rpn_loc: 0.0941  time: 0.7297  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:40:30] d2.utils.events INFO:  eta: 3:28:25  iter: 1099  total_loss: 0.748  loss_cls: 0.2748  loss_box_reg: 0.2339  loss_rpn_cls: 0.1576  loss_rpn_loc: 0.09564  time: 0.7299  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:40:45] d2.utils.events INFO:  eta: 3:28:20  iter: 1119  total_loss: 0.7398  loss_cls: 0.241  loss_box_reg: 0.2256  loss_rpn_cls: 0.1673  loss_rpn_loc: 0.1373  time: 0.7308  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 16:41:00] d2.utils.events INFO:  eta: 3:28:16  iter: 1139  total_loss: 0.7039  loss_cls: 0.2164  loss_box_reg: 0.2233  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.1005  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:41:14] d2.utils.events INFO:  eta: 3:29:15  iter: 1159  total_loss: 0.6346  loss_cls: 0.1816  loss_box_reg: 0.2001  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.1131  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:41:29] d2.utils.events INFO:  eta: 3:28:22  iter: 1179  total_loss: 0.5798  loss_cls: 0.1502  loss_box_reg: 0.1918  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.07192  time: 0.7303  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:41:43] d2.utils.events INFO:  eta: 3:27:15  iter: 1199  total_loss: 0.6946  loss_cls: 0.2261  loss_box_reg: 0.2496  loss_rpn_cls: 0.1417  loss_rpn_loc: 0.1068  time: 0.7301  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:41:58] d2.utils.events INFO:  eta: 3:27:17  iter: 1219  total_loss: 0.6856  loss_cls: 0.1875  loss_box_reg: 0.2008  loss_rpn_cls: 0.1653  loss_rpn_loc: 0.1151  time: 0.7300  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:42:12] d2.utils.events INFO:  eta: 3:27:02  iter: 1239  total_loss: 0.7038  loss_cls: 0.2141  loss_box_reg: 0.1906  loss_rpn_cls: 0.1519  loss_rpn_loc: 0.1268  time: 0.7298  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:42:27] d2.utils.events INFO:  eta: 3:27:13  iter: 1259  total_loss: 0.6344  loss_cls: 0.1775  loss_box_reg: 0.1819  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.1305  time: 0.7301  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:42:42] d2.utils.events INFO:  eta: 3:27:07  iter: 1279  total_loss: 0.7229  loss_cls: 0.2146  loss_box_reg: 0.2452  loss_rpn_cls: 0.1269  loss_rpn_loc: 0.1096  time: 0.7301  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:42:56] d2.utils.events INFO:  eta: 3:26:38  iter: 1299  total_loss: 0.6182  loss_cls: 0.1544  loss_box_reg: 0.1728  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.1091  time: 0.7296  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:43:11] d2.utils.events INFO:  eta: 3:26:28  iter: 1319  total_loss: 0.5516  loss_cls: 0.1558  loss_box_reg: 0.1659  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.08738  time: 0.7299  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:43:25] d2.utils.events INFO:  eta: 3:26:36  iter: 1339  total_loss: 0.6501  loss_cls: 0.1773  loss_box_reg: 0.187  loss_rpn_cls: 0.1367  loss_rpn_loc: 0.09818  time: 0.7298  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:43:39] d2.utils.events INFO:  eta: 3:26:17  iter: 1359  total_loss: 0.6357  loss_cls: 0.1669  loss_box_reg: 0.163  loss_rpn_cls: 0.1312  loss_rpn_loc: 0.1248  time: 0.7293  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:43:55] d2.utils.events INFO:  eta: 3:26:16  iter: 1379  total_loss: 0.5814  loss_cls: 0.1817  loss_box_reg: 0.1985  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.08695  time: 0.7302  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:44:09] d2.utils.events INFO:  eta: 3:25:51  iter: 1399  total_loss: 0.5817  loss_cls: 0.1642  loss_box_reg: 0.2056  loss_rpn_cls: 0.08358  loss_rpn_loc: 0.1033  time: 0.7301  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:44:23] d2.utils.events INFO:  eta: 3:25:09  iter: 1419  total_loss: 0.6204  loss_cls: 0.1893  loss_box_reg: 0.204  loss_rpn_cls: 0.1247  loss_rpn_loc: 0.1107  time: 0.7295  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:44:38] d2.utils.events INFO:  eta: 3:25:08  iter: 1439  total_loss: 0.5994  loss_cls: 0.1568  loss_box_reg: 0.1765  loss_rpn_cls: 0.09367  loss_rpn_loc: 0.1186  time: 0.7296  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:44:53] d2.utils.events INFO:  eta: 3:25:16  iter: 1459  total_loss: 0.637  loss_cls: 0.1476  loss_box_reg: 0.1507  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1468  time: 0.7298  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:45:08] d2.utils.events INFO:  eta: 3:24:58  iter: 1479  total_loss: 0.6973  loss_cls: 0.1847  loss_box_reg: 0.1577  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.1723  time: 0.7298  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:45:22] d2.utils.events INFO:  eta: 3:24:43  iter: 1499  total_loss: 0.5912  loss_cls: 0.1692  loss_box_reg: 0.2048  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.06828  time: 0.7297  data_time: 0.0027  lr: 0.0002  max_mem: 15389M
[01/29 16:45:37] d2.utils.events INFO:  eta: 3:24:33  iter: 1519  total_loss: 0.632  loss_cls: 0.1685  loss_box_reg: 0.1852  loss_rpn_cls: 0.09369  loss_rpn_loc: 0.09866  time: 0.7297  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:45:52] d2.utils.events INFO:  eta: 3:24:58  iter: 1539  total_loss: 0.6456  loss_cls: 0.1995  loss_box_reg: 0.1507  loss_rpn_cls: 0.1559  loss_rpn_loc: 0.1265  time: 0.7302  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 16:46:06] d2.utils.events INFO:  eta: 3:24:51  iter: 1559  total_loss: 0.7315  loss_cls: 0.1802  loss_box_reg: 0.1847  loss_rpn_cls: 0.1241  loss_rpn_loc: 0.1241  time: 0.7298  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:46:22] d2.utils.events INFO:  eta: 3:24:54  iter: 1579  total_loss: 0.6917  loss_cls: 0.1828  loss_box_reg: 0.1653  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.1156  time: 0.7303  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 16:46:37] d2.utils.events INFO:  eta: 3:26:03  iter: 1599  total_loss: 0.5222  loss_cls: 0.1656  loss_box_reg: 0.156  loss_rpn_cls: 0.1158  loss_rpn_loc: 0.1174  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:46:51] d2.utils.events INFO:  eta: 3:25:51  iter: 1619  total_loss: 0.4891  loss_cls: 0.1216  loss_box_reg: 0.1279  loss_rpn_cls: 0.09718  loss_rpn_loc: 0.06937  time: 0.7303  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:47:05] d2.utils.events INFO:  eta: 3:25:28  iter: 1639  total_loss: 0.4863  loss_cls: 0.1557  loss_box_reg: 0.1346  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.0882  time: 0.7301  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:47:19] d2.utils.events INFO:  eta: 3:24:47  iter: 1659  total_loss: 0.527  loss_cls: 0.1547  loss_box_reg: 0.1714  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.1004  time: 0.7298  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:47:34] d2.utils.events INFO:  eta: 3:23:39  iter: 1679  total_loss: 0.6113  loss_cls: 0.1811  loss_box_reg: 0.1961  loss_rpn_cls: 0.1233  loss_rpn_loc: 0.0866  time: 0.7295  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:47:47] d2.utils.events INFO:  eta: 3:22:54  iter: 1699  total_loss: 0.6388  loss_cls: 0.1903  loss_box_reg: 0.1988  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.1031  time: 0.7290  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:48:03] d2.utils.events INFO:  eta: 3:23:03  iter: 1719  total_loss: 0.66  loss_cls: 0.1863  loss_box_reg: 0.2006  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.1379  time: 0.7294  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 16:48:17] d2.utils.events INFO:  eta: 3:21:58  iter: 1739  total_loss: 0.688  loss_cls: 0.1992  loss_box_reg: 0.1973  loss_rpn_cls: 0.1192  loss_rpn_loc: 0.1464  time: 0.7295  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:48:32] d2.utils.events INFO:  eta: 3:22:13  iter: 1759  total_loss: 0.5728  loss_cls: 0.1536  loss_box_reg: 0.1582  loss_rpn_cls: 0.1317  loss_rpn_loc: 0.09489  time: 0.7295  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:48:47] d2.utils.events INFO:  eta: 3:21:39  iter: 1779  total_loss: 0.7139  loss_cls: 0.193  loss_box_reg: 0.1737  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.11  time: 0.7294  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:49:01] d2.utils.events INFO:  eta: 3:20:27  iter: 1799  total_loss: 0.4993  loss_cls: 0.1547  loss_box_reg: 0.1748  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.06391  time: 0.7292  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:49:16] d2.utils.events INFO:  eta: 3:20:39  iter: 1819  total_loss: 0.585  loss_cls: 0.1775  loss_box_reg: 0.154  loss_rpn_cls: 0.09201  loss_rpn_loc: 0.09423  time: 0.7293  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:49:31] d2.utils.events INFO:  eta: 3:20:35  iter: 1839  total_loss: 0.5997  loss_cls: 0.1588  loss_box_reg: 0.1382  loss_rpn_cls: 0.08345  loss_rpn_loc: 0.1201  time: 0.7297  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:49:47] d2.utils.events INFO:  eta: 3:20:34  iter: 1859  total_loss: 0.6278  loss_cls: 0.1448  loss_box_reg: 0.1404  loss_rpn_cls: 0.11  loss_rpn_loc: 0.1283  time: 0.7303  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:50:01] d2.utils.events INFO:  eta: 3:20:19  iter: 1879  total_loss: 0.5729  loss_cls: 0.131  loss_box_reg: 0.1292  loss_rpn_cls: 0.1379  loss_rpn_loc: 0.1376  time: 0.7303  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:50:16] d2.utils.events INFO:  eta: 3:19:41  iter: 1899  total_loss: 0.6799  loss_cls: 0.1819  loss_box_reg: 0.2155  loss_rpn_cls: 0.1282  loss_rpn_loc: 0.07776  time: 0.7300  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:50:29] d2.utils.events INFO:  eta: 3:18:43  iter: 1919  total_loss: 0.6248  loss_cls: 0.1647  loss_box_reg: 0.1967  loss_rpn_cls: 0.1233  loss_rpn_loc: 0.1021  time: 0.7295  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:50:44] d2.utils.events INFO:  eta: 3:19:04  iter: 1939  total_loss: 0.614  loss_cls: 0.1626  loss_box_reg: 0.1842  loss_rpn_cls: 0.1303  loss_rpn_loc: 0.1124  time: 0.7297  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:50:59] d2.utils.events INFO:  eta: 3:19:00  iter: 1959  total_loss: 0.579  loss_cls: 0.1876  loss_box_reg: 0.2148  loss_rpn_cls: 0.09825  loss_rpn_loc: 0.1215  time: 0.7299  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:51:13] d2.utils.events INFO:  eta: 3:18:25  iter: 1979  total_loss: 0.7124  loss_cls: 0.1711  loss_box_reg: 0.275  loss_rpn_cls: 0.1223  loss_rpn_loc: 0.09238  time: 0.7296  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:51:28] d2.utils.events INFO:  eta: 3:18:27  iter: 1999  total_loss: 0.4585  loss_cls: 0.1525  loss_box_reg: 0.1419  loss_rpn_cls: 0.09387  loss_rpn_loc: 0.09379  time: 0.7298  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:51:44] d2.utils.events INFO:  eta: 3:18:46  iter: 2019  total_loss: 0.5115  loss_cls: 0.1363  loss_box_reg: 0.1491  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.1088  time: 0.7303  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:51:58] d2.utils.events INFO:  eta: 3:18:22  iter: 2039  total_loss: 0.5394  loss_cls: 0.1558  loss_box_reg: 0.1927  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.07785  time: 0.7299  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:52:13] d2.utils.events INFO:  eta: 3:18:25  iter: 2059  total_loss: 0.5657  loss_cls: 0.153  loss_box_reg: 0.2144  loss_rpn_cls: 0.08026  loss_rpn_loc: 0.0809  time: 0.7300  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:52:28] d2.utils.events INFO:  eta: 3:18:10  iter: 2079  total_loss: 0.5595  loss_cls: 0.1545  loss_box_reg: 0.1674  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.09859  time: 0.7302  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:52:42] d2.utils.events INFO:  eta: 3:17:35  iter: 2099  total_loss: 0.5348  loss_cls: 0.128  loss_box_reg: 0.1361  loss_rpn_cls: 0.08703  loss_rpn_loc: 0.1097  time: 0.7300  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:52:55] d2.utils.events INFO:  eta: 3:16:57  iter: 2119  total_loss: 0.5507  loss_cls: 0.125  loss_box_reg: 0.1686  loss_rpn_cls: 0.08893  loss_rpn_loc: 0.1163  time: 0.7293  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:53:10] d2.utils.events INFO:  eta: 3:16:27  iter: 2139  total_loss: 0.5565  loss_cls: 0.1319  loss_box_reg: 0.1649  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.08181  time: 0.7292  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:53:25] d2.utils.events INFO:  eta: 3:16:05  iter: 2159  total_loss: 0.5493  loss_cls: 0.1504  loss_box_reg: 0.1758  loss_rpn_cls: 0.09393  loss_rpn_loc: 0.101  time: 0.7294  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:53:39] d2.utils.events INFO:  eta: 3:16:09  iter: 2179  total_loss: 0.5881  loss_cls: 0.1586  loss_box_reg: 0.2022  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.0924  time: 0.7293  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:53:52] d2.utils.events INFO:  eta: 3:15:34  iter: 2199  total_loss: 0.5514  loss_cls: 0.172  loss_box_reg: 0.1684  loss_rpn_cls: 0.09659  loss_rpn_loc: 0.08976  time: 0.7287  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:54:06] d2.utils.events INFO:  eta: 3:14:54  iter: 2219  total_loss: 0.5202  loss_cls: 0.1407  loss_box_reg: 0.1635  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.08988  time: 0.7283  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:54:22] d2.utils.events INFO:  eta: 3:15:25  iter: 2239  total_loss: 0.461  loss_cls: 0.1228  loss_box_reg: 0.1177  loss_rpn_cls: 0.07155  loss_rpn_loc: 0.1274  time: 0.7290  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:54:37] d2.utils.events INFO:  eta: 3:14:46  iter: 2259  total_loss: 0.5163  loss_cls: 0.1437  loss_box_reg: 0.142  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.1322  time: 0.7289  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:54:51] d2.utils.events INFO:  eta: 3:14:25  iter: 2279  total_loss: 0.4856  loss_cls: 0.1247  loss_box_reg: 0.1344  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.09909  time: 0.7287  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:55:06] d2.utils.events INFO:  eta: 3:14:17  iter: 2299  total_loss: 0.622  loss_cls: 0.1312  loss_box_reg: 0.1332  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.1025  time: 0.7289  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:55:21] d2.utils.events INFO:  eta: 3:14:13  iter: 2319  total_loss: 0.499  loss_cls: 0.1178  loss_box_reg: 0.1019  loss_rpn_cls: 0.116  loss_rpn_loc: 0.08807  time: 0.7291  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:55:35] d2.utils.events INFO:  eta: 3:13:51  iter: 2339  total_loss: 0.6853  loss_cls: 0.191  loss_box_reg: 0.2132  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.1093  time: 0.7291  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 16:55:50] d2.utils.events INFO:  eta: 3:13:43  iter: 2359  total_loss: 0.5153  loss_cls: 0.1725  loss_box_reg: 0.1846  loss_rpn_cls: 0.101  loss_rpn_loc: 0.08285  time: 0.7290  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:56:04] d2.utils.events INFO:  eta: 3:13:18  iter: 2379  total_loss: 0.6079  loss_cls: 0.1577  loss_box_reg: 0.1946  loss_rpn_cls: 0.09905  loss_rpn_loc: 0.1321  time: 0.7289  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:56:20] d2.utils.events INFO:  eta: 3:13:06  iter: 2399  total_loss: 0.7062  loss_cls: 0.1912  loss_box_reg: 0.1848  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.1213  time: 0.7293  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:56:35] d2.utils.events INFO:  eta: 3:13:19  iter: 2419  total_loss: 0.5676  loss_cls: 0.1653  loss_box_reg: 0.1875  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.1058  time: 0.7293  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:56:50] d2.utils.events INFO:  eta: 3:13:27  iter: 2439  total_loss: 0.5527  loss_cls: 0.1429  loss_box_reg: 0.1535  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.107  time: 0.7297  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:57:04] d2.utils.events INFO:  eta: 3:12:59  iter: 2459  total_loss: 0.5346  loss_cls: 0.1687  loss_box_reg: 0.1389  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.1285  time: 0.7295  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:57:19] d2.utils.events INFO:  eta: 3:12:51  iter: 2479  total_loss: 0.5852  loss_cls: 0.1566  loss_box_reg: 0.1515  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.1173  time: 0.7296  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:57:34] d2.utils.events INFO:  eta: 3:12:48  iter: 2499  total_loss: 0.5791  loss_cls: 0.1432  loss_box_reg: 0.1808  loss_rpn_cls: 0.09846  loss_rpn_loc: 0.06189  time: 0.7297  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:57:49] d2.utils.events INFO:  eta: 3:12:33  iter: 2519  total_loss: 0.5301  loss_cls: 0.1418  loss_box_reg: 0.1698  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.07367  time: 0.7297  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:58:04] d2.utils.events INFO:  eta: 3:11:50  iter: 2539  total_loss: 0.6075  loss_cls: 0.1356  loss_box_reg: 0.1323  loss_rpn_cls: 0.09826  loss_rpn_loc: 0.111  time: 0.7298  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:58:19] d2.utils.events INFO:  eta: 3:12:09  iter: 2559  total_loss: 0.6633  loss_cls: 0.153  loss_box_reg: 0.1652  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.1133  time: 0.7301  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:58:34] d2.utils.events INFO:  eta: 3:11:45  iter: 2579  total_loss: 0.5165  loss_cls: 0.1543  loss_box_reg: 0.1418  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.1221  time: 0.7304  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 16:58:50] d2.utils.events INFO:  eta: 3:11:30  iter: 2599  total_loss: 0.7101  loss_cls: 0.1808  loss_box_reg: 0.1978  loss_rpn_cls: 0.1445  loss_rpn_loc: 0.1165  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:59:05] d2.utils.events INFO:  eta: 3:11:24  iter: 2619  total_loss: 0.5792  loss_cls: 0.1743  loss_box_reg: 0.1723  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.08958  time: 0.7309  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 16:59:20] d2.utils.events INFO:  eta: 3:11:03  iter: 2639  total_loss: 0.4779  loss_cls: 0.1329  loss_box_reg: 0.1577  loss_rpn_cls: 0.09957  loss_rpn_loc: 0.07762  time: 0.7310  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 16:59:34] d2.utils.events INFO:  eta: 3:10:48  iter: 2659  total_loss: 0.5271  loss_cls: 0.1394  loss_box_reg: 0.1408  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.08523  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 16:59:49] d2.utils.events INFO:  eta: 3:11:02  iter: 2679  total_loss: 0.5352  loss_cls: 0.1292  loss_box_reg: 0.1799  loss_rpn_cls: 0.08706  loss_rpn_loc: 0.1293  time: 0.7308  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:00:04] d2.utils.events INFO:  eta: 3:11:25  iter: 2699  total_loss: 0.5019  loss_cls: 0.1635  loss_box_reg: 0.1692  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.08123  time: 0.7310  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:00:17] d2.utils.events INFO:  eta: 3:10:33  iter: 2719  total_loss: 0.6347  loss_cls: 0.144  loss_box_reg: 0.1662  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1208  time: 0.7305  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 17:00:33] d2.utils.events INFO:  eta: 3:10:55  iter: 2739  total_loss: 0.548  loss_cls: 0.1546  loss_box_reg: 0.1962  loss_rpn_cls: 0.06792  loss_rpn_loc: 0.07956  time: 0.7309  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:00:47] d2.utils.events INFO:  eta: 3:10:17  iter: 2759  total_loss: 0.5676  loss_cls: 0.1736  loss_box_reg: 0.1762  loss_rpn_cls: 0.07998  loss_rpn_loc: 0.08013  time: 0.7308  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:01:02] d2.utils.events INFO:  eta: 3:10:21  iter: 2779  total_loss: 0.5551  loss_cls: 0.1245  loss_box_reg: 0.165  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.09269  time: 0.7309  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:01:17] d2.utils.events INFO:  eta: 3:10:06  iter: 2799  total_loss: 0.6477  loss_cls: 0.1934  loss_box_reg: 0.1886  loss_rpn_cls: 0.1241  loss_rpn_loc: 0.1438  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:01:31] d2.utils.events INFO:  eta: 3:09:32  iter: 2819  total_loss: 0.4903  loss_cls: 0.1314  loss_box_reg: 0.1453  loss_rpn_cls: 0.0765  loss_rpn_loc: 0.1167  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:01:47] d2.utils.events INFO:  eta: 3:09:17  iter: 2839  total_loss: 0.5903  loss_cls: 0.1693  loss_box_reg: 0.1709  loss_rpn_cls: 0.08506  loss_rpn_loc: 0.07465  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:02:01] d2.utils.events INFO:  eta: 3:08:30  iter: 2859  total_loss: 0.6488  loss_cls: 0.1973  loss_box_reg: 0.1995  loss_rpn_cls: 0.09194  loss_rpn_loc: 0.125  time: 0.7309  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:02:16] d2.utils.events INFO:  eta: 3:08:33  iter: 2879  total_loss: 0.4328  loss_cls: 0.09939  loss_box_reg: 0.1173  loss_rpn_cls: 0.05596  loss_rpn_loc: 0.1117  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:02:30] d2.utils.events INFO:  eta: 3:08:12  iter: 2899  total_loss: 0.4111  loss_cls: 0.1127  loss_box_reg: 0.1445  loss_rpn_cls: 0.07528  loss_rpn_loc: 0.06357  time: 0.7309  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:02:44] d2.utils.events INFO:  eta: 3:08:03  iter: 2919  total_loss: 0.5493  loss_cls: 0.1464  loss_box_reg: 0.1963  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.09268  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:02:59] d2.utils.events INFO:  eta: 3:07:48  iter: 2939  total_loss: 0.6508  loss_cls: 0.1622  loss_box_reg: 0.1874  loss_rpn_cls: 0.1303  loss_rpn_loc: 0.08338  time: 0.7307  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:03:14] d2.utils.events INFO:  eta: 3:07:27  iter: 2959  total_loss: 0.5773  loss_cls: 0.148  loss_box_reg: 0.1802  loss_rpn_cls: 0.09822  loss_rpn_loc: 0.1351  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:03:28] d2.utils.events INFO:  eta: 3:07:14  iter: 2979  total_loss: 0.5838  loss_cls: 0.1438  loss_box_reg: 0.1871  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.121  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:03:42] d2.utils.events INFO:  eta: 3:06:35  iter: 2999  total_loss: 0.5088  loss_cls: 0.1166  loss_box_reg: 0.1504  loss_rpn_cls: 0.09118  loss_rpn_loc: 0.1289  time: 0.7305  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:03:57] d2.utils.events INFO:  eta: 3:05:36  iter: 3019  total_loss: 0.5511  loss_cls: 0.1319  loss_box_reg: 0.1514  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.09092  time: 0.7304  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:04:11] d2.utils.events INFO:  eta: 3:05:59  iter: 3039  total_loss: 0.5207  loss_cls: 0.1396  loss_box_reg: 0.1613  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.1047  time: 0.7304  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:04:27] d2.utils.events INFO:  eta: 3:05:41  iter: 3059  total_loss: 0.6461  loss_cls: 0.1397  loss_box_reg: 0.1813  loss_rpn_cls: 0.08995  loss_rpn_loc: 0.1729  time: 0.7308  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:04:42] d2.utils.events INFO:  eta: 3:05:41  iter: 3079  total_loss: 0.5524  loss_cls: 0.1424  loss_box_reg: 0.183  loss_rpn_cls: 0.07437  loss_rpn_loc: 0.1164  time: 0.7309  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:04:57] d2.utils.events INFO:  eta: 3:05:44  iter: 3099  total_loss: 0.4782  loss_cls: 0.1299  loss_box_reg: 0.142  loss_rpn_cls: 0.09148  loss_rpn_loc: 0.09583  time: 0.7311  data_time: 0.0027  lr: 0.0002  max_mem: 15389M
[01/29 17:05:12] d2.utils.events INFO:  eta: 3:05:29  iter: 3119  total_loss: 0.5529  loss_cls: 0.1813  loss_box_reg: 0.1848  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.08523  time: 0.7310  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 17:05:27] d2.utils.events INFO:  eta: 3:05:25  iter: 3139  total_loss: 0.4478  loss_cls: 0.1018  loss_box_reg: 0.1473  loss_rpn_cls: 0.07924  loss_rpn_loc: 0.1024  time: 0.7311  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:05:42] d2.utils.events INFO:  eta: 3:05:34  iter: 3159  total_loss: 0.6713  loss_cls: 0.1775  loss_box_reg: 0.252  loss_rpn_cls: 0.09805  loss_rpn_loc: 0.1266  time: 0.7314  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:05:57] d2.utils.events INFO:  eta: 3:05:19  iter: 3179  total_loss: 0.5561  loss_cls: 0.1451  loss_box_reg: 0.2062  loss_rpn_cls: 0.0995  loss_rpn_loc: 0.06865  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:06:12] d2.utils.events INFO:  eta: 3:05:28  iter: 3199  total_loss: 0.6153  loss_cls: 0.1774  loss_box_reg: 0.1782  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.1174  time: 0.7314  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:06:27] d2.utils.events INFO:  eta: 3:05:21  iter: 3219  total_loss: 0.4665  loss_cls: 0.1257  loss_box_reg: 0.1477  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1043  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:06:42] d2.utils.events INFO:  eta: 3:04:57  iter: 3239  total_loss: 0.5737  loss_cls: 0.153  loss_box_reg: 0.1681  loss_rpn_cls: 0.0966  loss_rpn_loc: 0.07864  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:06:57] d2.utils.events INFO:  eta: 3:04:53  iter: 3259  total_loss: 0.442  loss_cls: 0.1091  loss_box_reg: 0.1751  loss_rpn_cls: 0.09834  loss_rpn_loc: 0.06156  time: 0.7317  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:07:12] d2.utils.events INFO:  eta: 3:04:55  iter: 3279  total_loss: 0.6501  loss_cls: 0.1151  loss_box_reg: 0.1568  loss_rpn_cls: 0.09259  loss_rpn_loc: 0.1671  time: 0.7319  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:07:27] d2.utils.events INFO:  eta: 3:04:35  iter: 3299  total_loss: 0.5686  loss_cls: 0.1362  loss_box_reg: 0.1684  loss_rpn_cls: 0.09641  loss_rpn_loc: 0.1049  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:07:42] d2.utils.events INFO:  eta: 3:04:05  iter: 3319  total_loss: 0.503  loss_cls: 0.1296  loss_box_reg: 0.1898  loss_rpn_cls: 0.08461  loss_rpn_loc: 0.1103  time: 0.7320  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:07:57] d2.utils.events INFO:  eta: 3:03:54  iter: 3339  total_loss: 0.4152  loss_cls: 0.1203  loss_box_reg: 0.1368  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.08523  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:08:11] d2.utils.events INFO:  eta: 3:03:45  iter: 3359  total_loss: 0.3829  loss_cls: 0.1177  loss_box_reg: 0.1322  loss_rpn_cls: 0.07731  loss_rpn_loc: 0.107  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:08:26] d2.utils.events INFO:  eta: 3:03:30  iter: 3379  total_loss: 0.5602  loss_cls: 0.1365  loss_box_reg: 0.1675  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.08305  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:08:41] d2.utils.events INFO:  eta: 3:03:15  iter: 3399  total_loss: 0.4228  loss_cls: 0.126  loss_box_reg: 0.1339  loss_rpn_cls: 0.05764  loss_rpn_loc: 0.08803  time: 0.7320  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:08:56] d2.utils.events INFO:  eta: 3:03:27  iter: 3419  total_loss: 0.6648  loss_cls: 0.1866  loss_box_reg: 0.1999  loss_rpn_cls: 0.09884  loss_rpn_loc: 0.1115  time: 0.7321  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:09:09] d2.utils.events INFO:  eta: 3:03:01  iter: 3439  total_loss: 0.452  loss_cls: 0.1243  loss_box_reg: 0.1602  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.07763  time: 0.7318  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:09:24] d2.utils.events INFO:  eta: 3:02:52  iter: 3459  total_loss: 0.5533  loss_cls: 0.1531  loss_box_reg: 0.2094  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.08443  time: 0.7318  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:09:38] d2.utils.events INFO:  eta: 3:02:35  iter: 3479  total_loss: 0.4675  loss_cls: 0.1314  loss_box_reg: 0.1378  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.09525  time: 0.7316  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 17:09:53] d2.utils.events INFO:  eta: 3:02:27  iter: 3499  total_loss: 0.4129  loss_cls: 0.1011  loss_box_reg: 0.1321  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.07982  time: 0.7318  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:10:08] d2.utils.events INFO:  eta: 3:02:12  iter: 3519  total_loss: 0.3817  loss_cls: 0.09715  loss_box_reg: 0.1287  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.05234  time: 0.7318  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:10:23] d2.utils.events INFO:  eta: 3:01:54  iter: 3539  total_loss: 0.5742  loss_cls: 0.1708  loss_box_reg: 0.229  loss_rpn_cls: 0.08553  loss_rpn_loc: 0.0862  time: 0.7318  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:10:38] d2.utils.events INFO:  eta: 3:01:31  iter: 3559  total_loss: 0.5323  loss_cls: 0.1351  loss_box_reg: 0.1711  loss_rpn_cls: 0.09046  loss_rpn_loc: 0.08733  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:10:53] d2.utils.events INFO:  eta: 3:01:08  iter: 3579  total_loss: 0.508  loss_cls: 0.1434  loss_box_reg: 0.1486  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.07067  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:11:07] d2.utils.events INFO:  eta: 3:00:27  iter: 3599  total_loss: 0.5318  loss_cls: 0.1279  loss_box_reg: 0.1433  loss_rpn_cls: 0.09144  loss_rpn_loc: 0.09651  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:11:22] d2.utils.events INFO:  eta: 2:59:52  iter: 3619  total_loss: 0.5239  loss_cls: 0.1315  loss_box_reg: 0.1924  loss_rpn_cls: 0.09578  loss_rpn_loc: 0.0625  time: 0.7320  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:11:37] d2.utils.events INFO:  eta: 2:59:56  iter: 3639  total_loss: 0.4151  loss_cls: 0.1137  loss_box_reg: 0.1657  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.06328  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:11:52] d2.utils.events INFO:  eta: 2:59:52  iter: 3659  total_loss: 0.4984  loss_cls: 0.1013  loss_box_reg: 0.177  loss_rpn_cls: 0.09547  loss_rpn_loc: 0.1346  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:12:07] d2.utils.events INFO:  eta: 2:59:34  iter: 3679  total_loss: 0.4802  loss_cls: 0.1054  loss_box_reg: 0.1748  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.09033  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:12:22] d2.utils.events INFO:  eta: 2:59:15  iter: 3699  total_loss: 0.3874  loss_cls: 0.08793  loss_box_reg: 0.1309  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.06035  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:12:37] d2.utils.events INFO:  eta: 2:59:13  iter: 3719  total_loss: 0.439  loss_cls: 0.1252  loss_box_reg: 0.1413  loss_rpn_cls: 0.08822  loss_rpn_loc: 0.08063  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:12:52] d2.utils.events INFO:  eta: 2:58:49  iter: 3739  total_loss: 0.5348  loss_cls: 0.1785  loss_box_reg: 0.1996  loss_rpn_cls: 0.08677  loss_rpn_loc: 0.1228  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:13:06] d2.utils.events INFO:  eta: 2:58:39  iter: 3759  total_loss: 0.5189  loss_cls: 0.1431  loss_box_reg: 0.1539  loss_rpn_cls: 0.12  loss_rpn_loc: 0.103  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:13:21] d2.utils.events INFO:  eta: 2:58:24  iter: 3779  total_loss: 0.7035  loss_cls: 0.1484  loss_box_reg: 0.1587  loss_rpn_cls: 0.125  loss_rpn_loc: 0.153  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:13:36] d2.utils.events INFO:  eta: 2:58:22  iter: 3799  total_loss: 0.5233  loss_cls: 0.1433  loss_box_reg: 0.1767  loss_rpn_cls: 0.1161  loss_rpn_loc: 0.1045  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:13:51] d2.utils.events INFO:  eta: 2:58:19  iter: 3819  total_loss: 0.5086  loss_cls: 0.1412  loss_box_reg: 0.1495  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.08164  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:14:05] d2.utils.events INFO:  eta: 2:57:34  iter: 3839  total_loss: 0.4155  loss_cls: 0.1077  loss_box_reg: 0.1401  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.07001  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:14:19] d2.utils.events INFO:  eta: 2:57:14  iter: 3859  total_loss: 0.5327  loss_cls: 0.1256  loss_box_reg: 0.1719  loss_rpn_cls: 0.07532  loss_rpn_loc: 0.1056  time: 0.7322  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:14:34] d2.utils.events INFO:  eta: 2:56:52  iter: 3879  total_loss: 0.4902  loss_cls: 0.1392  loss_box_reg: 0.1381  loss_rpn_cls: 0.106  loss_rpn_loc: 0.05067  time: 0.7322  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:14:49] d2.utils.events INFO:  eta: 2:56:44  iter: 3899  total_loss: 0.5577  loss_cls: 0.1283  loss_box_reg: 0.118  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.08963  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:15:03] d2.utils.events INFO:  eta: 2:56:34  iter: 3919  total_loss: 0.4958  loss_cls: 0.1257  loss_box_reg: 0.1803  loss_rpn_cls: 0.08107  loss_rpn_loc: 0.0737  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:15:18] d2.utils.events INFO:  eta: 2:56:14  iter: 3939  total_loss: 0.3824  loss_cls: 0.1336  loss_box_reg: 0.1527  loss_rpn_cls: 0.06036  loss_rpn_loc: 0.07092  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:15:32] d2.utils.events INFO:  eta: 2:55:59  iter: 3959  total_loss: 0.4999  loss_cls: 0.1191  loss_box_reg: 0.1713  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.0824  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:15:47] d2.utils.events INFO:  eta: 2:55:49  iter: 3979  total_loss: 0.4989  loss_cls: 0.115  loss_box_reg: 0.1497  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.09132  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:16:00] d2.utils.events INFO:  eta: 2:55:25  iter: 3999  total_loss: 0.453  loss_cls: 0.1004  loss_box_reg: 0.126  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.0616  time: 0.7318  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:16:14] d2.utils.events INFO:  eta: 2:55:00  iter: 4019  total_loss: 0.4166  loss_cls: 0.07265  loss_box_reg: 0.1268  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.09699  time: 0.7316  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:16:30] d2.utils.events INFO:  eta: 2:54:53  iter: 4039  total_loss: 0.4653  loss_cls: 0.0745  loss_box_reg: 0.1021  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.1371  time: 0.7317  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:16:43] d2.utils.events INFO:  eta: 2:54:12  iter: 4059  total_loss: 0.4424  loss_cls: 0.1106  loss_box_reg: 0.1586  loss_rpn_cls: 0.06008  loss_rpn_loc: 0.09603  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:16:58] d2.utils.events INFO:  eta: 2:53:46  iter: 4079  total_loss: 0.5752  loss_cls: 0.1368  loss_box_reg: 0.167  loss_rpn_cls: 0.09431  loss_rpn_loc: 0.1326  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:17:13] d2.utils.events INFO:  eta: 2:53:22  iter: 4099  total_loss: 0.5106  loss_cls: 0.1337  loss_box_reg: 0.1656  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.08854  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:17:27] d2.utils.events INFO:  eta: 2:52:56  iter: 4119  total_loss: 0.551  loss_cls: 0.1307  loss_box_reg: 0.1583  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.08241  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:17:41] d2.utils.events INFO:  eta: 2:52:31  iter: 4139  total_loss: 0.5169  loss_cls: 0.1299  loss_box_reg: 0.1922  loss_rpn_cls: 0.08977  loss_rpn_loc: 0.1  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:17:55] d2.utils.events INFO:  eta: 2:51:33  iter: 4159  total_loss: 0.3628  loss_cls: 0.1107  loss_box_reg: 0.1339  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.04943  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:18:09] d2.utils.events INFO:  eta: 2:50:37  iter: 4179  total_loss: 0.4421  loss_cls: 0.1191  loss_box_reg: 0.144  loss_rpn_cls: 0.08639  loss_rpn_loc: 0.08273  time: 0.7308  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:18:24] d2.utils.events INFO:  eta: 2:50:30  iter: 4199  total_loss: 0.5622  loss_cls: 0.131  loss_box_reg: 0.1514  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.09821  time: 0.7311  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:18:38] d2.utils.events INFO:  eta: 2:50:07  iter: 4219  total_loss: 0.414  loss_cls: 0.1143  loss_box_reg: 0.1469  loss_rpn_cls: 0.06988  loss_rpn_loc: 0.05459  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:18:53] d2.utils.events INFO:  eta: 2:49:30  iter: 4239  total_loss: 0.4138  loss_cls: 0.1156  loss_box_reg: 0.1167  loss_rpn_cls: 0.08482  loss_rpn_loc: 0.08919  time: 0.7310  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:19:07] d2.utils.events INFO:  eta: 2:48:43  iter: 4259  total_loss: 0.522  loss_cls: 0.1717  loss_box_reg: 0.1815  loss_rpn_cls: 0.07411  loss_rpn_loc: 0.1166  time: 0.7309  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:19:21] d2.utils.events INFO:  eta: 2:47:57  iter: 4279  total_loss: 0.5903  loss_cls: 0.1513  loss_box_reg: 0.1823  loss_rpn_cls: 0.09581  loss_rpn_loc: 0.08805  time: 0.7307  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:19:36] d2.utils.events INFO:  eta: 2:47:29  iter: 4299  total_loss: 0.422  loss_cls: 0.1155  loss_box_reg: 0.1256  loss_rpn_cls: 0.07469  loss_rpn_loc: 0.0938  time: 0.7306  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:19:51] d2.utils.events INFO:  eta: 2:47:20  iter: 4319  total_loss: 0.606  loss_cls: 0.1453  loss_box_reg: 0.2188  loss_rpn_cls: 0.09541  loss_rpn_loc: 0.09057  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:20:05] d2.utils.events INFO:  eta: 2:47:02  iter: 4339  total_loss: 0.3945  loss_cls: 0.1096  loss_box_reg: 0.1297  loss_rpn_cls: 0.08507  loss_rpn_loc: 0.06326  time: 0.7307  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:20:19] d2.utils.events INFO:  eta: 2:46:42  iter: 4359  total_loss: 0.6011  loss_cls: 0.1475  loss_box_reg: 0.1623  loss_rpn_cls: 0.1137  loss_rpn_loc: 0.08256  time: 0.7305  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:20:33] d2.utils.events INFO:  eta: 2:46:28  iter: 4379  total_loss: 0.5129  loss_cls: 0.129  loss_box_reg: 0.1591  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.0666  time: 0.7305  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:20:49] d2.utils.events INFO:  eta: 2:46:18  iter: 4399  total_loss: 0.5405  loss_cls: 0.1634  loss_box_reg: 0.1523  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.1181  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:21:03] d2.utils.events INFO:  eta: 2:45:51  iter: 4419  total_loss: 0.5681  loss_cls: 0.1507  loss_box_reg: 0.1957  loss_rpn_cls: 0.08727  loss_rpn_loc: 0.09658  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:21:18] d2.utils.events INFO:  eta: 2:45:49  iter: 4439  total_loss: 0.6303  loss_cls: 0.1176  loss_box_reg: 0.2068  loss_rpn_cls: 0.09166  loss_rpn_loc: 0.1277  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:21:32] d2.utils.events INFO:  eta: 2:45:22  iter: 4459  total_loss: 0.5863  loss_cls: 0.1455  loss_box_reg: 0.1887  loss_rpn_cls: 0.0825  loss_rpn_loc: 0.1099  time: 0.7305  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:21:46] d2.utils.events INFO:  eta: 2:45:05  iter: 4479  total_loss: 0.471  loss_cls: 0.1111  loss_box_reg: 0.1552  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.09219  time: 0.7303  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:22:00] d2.utils.events INFO:  eta: 2:44:44  iter: 4499  total_loss: 0.5456  loss_cls: 0.1406  loss_box_reg: 0.2026  loss_rpn_cls: 0.09505  loss_rpn_loc: 0.0992  time: 0.7302  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:22:15] d2.utils.events INFO:  eta: 2:44:29  iter: 4519  total_loss: 0.5329  loss_cls: 0.1616  loss_box_reg: 0.1934  loss_rpn_cls: 0.09857  loss_rpn_loc: 0.08795  time: 0.7302  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:22:30] d2.utils.events INFO:  eta: 2:44:21  iter: 4539  total_loss: 0.5243  loss_cls: 0.1435  loss_box_reg: 0.1695  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.1337  time: 0.7303  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:22:45] d2.utils.events INFO:  eta: 2:44:07  iter: 4559  total_loss: 0.5185  loss_cls: 0.1242  loss_box_reg: 0.1822  loss_rpn_cls: 0.05761  loss_rpn_loc: 0.09485  time: 0.7304  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:23:00] d2.utils.events INFO:  eta: 2:43:52  iter: 4579  total_loss: 0.4707  loss_cls: 0.1269  loss_box_reg: 0.13  loss_rpn_cls: 0.07541  loss_rpn_loc: 0.09308  time: 0.7304  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:23:15] d2.utils.events INFO:  eta: 2:43:49  iter: 4599  total_loss: 0.5295  loss_cls: 0.1243  loss_box_reg: 0.1556  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.1569  time: 0.7305  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:23:29] d2.utils.events INFO:  eta: 2:43:34  iter: 4619  total_loss: 0.4566  loss_cls: 0.1038  loss_box_reg: 0.1356  loss_rpn_cls: 0.09705  loss_rpn_loc: 0.1168  time: 0.7304  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:23:44] d2.utils.events INFO:  eta: 2:43:22  iter: 4639  total_loss: 0.5026  loss_cls: 0.126  loss_box_reg: 0.1684  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.09971  time: 0.7306  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:23:59] d2.utils.events INFO:  eta: 2:43:07  iter: 4659  total_loss: 0.512  loss_cls: 0.1493  loss_box_reg: 0.1798  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1062  time: 0.7306  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:24:14] d2.utils.events INFO:  eta: 2:42:46  iter: 4679  total_loss: 0.4588  loss_cls: 0.1257  loss_box_reg: 0.1471  loss_rpn_cls: 0.0856  loss_rpn_loc: 0.08455  time: 0.7305  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:24:29] d2.utils.events INFO:  eta: 2:42:25  iter: 4699  total_loss: 0.5216  loss_cls: 0.1232  loss_box_reg: 0.2003  loss_rpn_cls: 0.07785  loss_rpn_loc: 0.0996  time: 0.7307  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:24:44] d2.utils.events INFO:  eta: 2:42:21  iter: 4719  total_loss: 0.5167  loss_cls: 0.1186  loss_box_reg: 0.1462  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.116  time: 0.7308  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:24:59] d2.utils.events INFO:  eta: 2:42:06  iter: 4739  total_loss: 0.5162  loss_cls: 0.1405  loss_box_reg: 0.1896  loss_rpn_cls: 0.07416  loss_rpn_loc: 0.09995  time: 0.7308  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:25:14] d2.utils.events INFO:  eta: 2:41:56  iter: 4759  total_loss: 0.4683  loss_cls: 0.1187  loss_box_reg: 0.1164  loss_rpn_cls: 0.06557  loss_rpn_loc: 0.1107  time: 0.7308  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:25:29] d2.utils.events INFO:  eta: 2:41:51  iter: 4779  total_loss: 0.4186  loss_cls: 0.1191  loss_box_reg: 0.1698  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.1027  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:25:43] d2.utils.events INFO:  eta: 2:41:28  iter: 4799  total_loss: 0.5793  loss_cls: 0.159  loss_box_reg: 0.2016  loss_rpn_cls: 0.09802  loss_rpn_loc: 0.1222  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:25:57] d2.utils.events INFO:  eta: 2:41:07  iter: 4819  total_loss: 0.4704  loss_cls: 0.1127  loss_box_reg: 0.161  loss_rpn_cls: 0.06437  loss_rpn_loc: 0.07401  time: 0.7307  data_time: 0.0027  lr: 0.0002  max_mem: 15389M
[01/29 17:26:11] d2.utils.events INFO:  eta: 2:40:58  iter: 4839  total_loss: 0.3866  loss_cls: 0.08711  loss_box_reg: 0.1567  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.1061  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:26:25] d2.utils.events INFO:  eta: 2:40:44  iter: 4859  total_loss: 0.4443  loss_cls: 0.1113  loss_box_reg: 0.1393  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.09162  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:26:41] d2.utils.events INFO:  eta: 2:40:40  iter: 4879  total_loss: 0.599  loss_cls: 0.1448  loss_box_reg: 0.1995  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1106  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:26:56] d2.utils.events INFO:  eta: 2:40:23  iter: 4899  total_loss: 0.4657  loss_cls: 0.1007  loss_box_reg: 0.1341  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.1052  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:27:11] d2.utils.events INFO:  eta: 2:40:00  iter: 4919  total_loss: 0.581  loss_cls: 0.1304  loss_box_reg: 0.1526  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.1047  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:27:25] d2.utils.events INFO:  eta: 2:39:39  iter: 4939  total_loss: 0.5795  loss_cls: 0.167  loss_box_reg: 0.1838  loss_rpn_cls: 0.0955  loss_rpn_loc: 0.08359  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:27:39] d2.utils.events INFO:  eta: 2:39:25  iter: 4959  total_loss: 0.4159  loss_cls: 0.1183  loss_box_reg: 0.125  loss_rpn_cls: 0.092  loss_rpn_loc: 0.0778  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:27:54] d2.utils.events INFO:  eta: 2:39:10  iter: 4979  total_loss: 0.4821  loss_cls: 0.144  loss_box_reg: 0.1409  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.07528  time: 0.7306  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:28:08] d2.utils.events INFO:  eta: 2:39:06  iter: 4999  total_loss: 0.4126  loss_cls: 0.09502  loss_box_reg: 0.1471  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.07696  time: 0.7306  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:28:23] d2.utils.events INFO:  eta: 2:39:07  iter: 5019  total_loss: 0.5259  loss_cls: 0.1503  loss_box_reg: 0.1646  loss_rpn_cls: 0.07591  loss_rpn_loc: 0.08942  time: 0.7306  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:28:38] d2.utils.events INFO:  eta: 2:38:55  iter: 5039  total_loss: 0.4524  loss_cls: 0.1092  loss_box_reg: 0.1615  loss_rpn_cls: 0.08518  loss_rpn_loc: 0.1031  time: 0.7307  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:28:53] d2.utils.events INFO:  eta: 2:39:04  iter: 5059  total_loss: 0.5381  loss_cls: 0.174  loss_box_reg: 0.2089  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.1097  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:29:09] d2.utils.events INFO:  eta: 2:39:04  iter: 5079  total_loss: 0.5374  loss_cls: 0.1492  loss_box_reg: 0.1733  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.09088  time: 0.7309  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:29:23] d2.utils.events INFO:  eta: 2:38:41  iter: 5099  total_loss: 0.5714  loss_cls: 0.1513  loss_box_reg: 0.1793  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.08546  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:29:38] d2.utils.events INFO:  eta: 2:39:08  iter: 5119  total_loss: 0.6628  loss_cls: 0.1823  loss_box_reg: 0.2501  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.1044  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:29:52] d2.utils.events INFO:  eta: 2:38:54  iter: 5139  total_loss: 0.4717  loss_cls: 0.1614  loss_box_reg: 0.172  loss_rpn_cls: 0.09743  loss_rpn_loc: 0.1034  time: 0.7307  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:30:07] d2.utils.events INFO:  eta: 2:38:51  iter: 5159  total_loss: 0.5104  loss_cls: 0.09643  loss_box_reg: 0.1598  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.08486  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:30:22] d2.utils.events INFO:  eta: 2:39:13  iter: 5179  total_loss: 0.4911  loss_cls: 0.1292  loss_box_reg: 0.1384  loss_rpn_cls: 0.08278  loss_rpn_loc: 0.09006  time: 0.7309  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:30:37] d2.utils.events INFO:  eta: 2:39:14  iter: 5199  total_loss: 0.5425  loss_cls: 0.131  loss_box_reg: 0.1766  loss_rpn_cls: 0.09831  loss_rpn_loc: 0.1321  time: 0.7310  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:30:52] d2.utils.events INFO:  eta: 2:38:53  iter: 5219  total_loss: 0.4624  loss_cls: 0.09583  loss_box_reg: 0.1281  loss_rpn_cls: 0.06727  loss_rpn_loc: 0.07961  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:31:07] d2.utils.events INFO:  eta: 2:38:49  iter: 5239  total_loss: 0.4542  loss_cls: 0.1012  loss_box_reg: 0.1478  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.08613  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:31:21] d2.utils.events INFO:  eta: 2:38:23  iter: 5259  total_loss: 0.528  loss_cls: 0.09285  loss_box_reg: 0.1699  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.1123  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:31:36] d2.utils.events INFO:  eta: 2:38:25  iter: 5279  total_loss: 0.4294  loss_cls: 0.1052  loss_box_reg: 0.1216  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.09734  time: 0.7310  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:31:50] d2.utils.events INFO:  eta: 2:38:21  iter: 5299  total_loss: 0.4497  loss_cls: 0.1215  loss_box_reg: 0.1612  loss_rpn_cls: 0.06875  loss_rpn_loc: 0.05515  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:32:04] d2.utils.events INFO:  eta: 2:37:52  iter: 5319  total_loss: 0.5317  loss_cls: 0.1325  loss_box_reg: 0.1569  loss_rpn_cls: 0.06878  loss_rpn_loc: 0.1161  time: 0.7308  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:32:20] d2.utils.events INFO:  eta: 2:37:40  iter: 5339  total_loss: 0.5382  loss_cls: 0.1391  loss_box_reg: 0.1726  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.1355  time: 0.7310  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:32:34] d2.utils.events INFO:  eta: 2:37:51  iter: 5359  total_loss: 0.3324  loss_cls: 0.08664  loss_box_reg: 0.1291  loss_rpn_cls: 0.08866  loss_rpn_loc: 0.07483  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:32:49] d2.utils.events INFO:  eta: 2:37:37  iter: 5379  total_loss: 0.4979  loss_cls: 0.1178  loss_box_reg: 0.1815  loss_rpn_cls: 0.07344  loss_rpn_loc: 0.05625  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:33:05] d2.utils.events INFO:  eta: 2:37:18  iter: 5399  total_loss: 0.5212  loss_cls: 0.142  loss_box_reg: 0.1896  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.09474  time: 0.7312  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:33:19] d2.utils.events INFO:  eta: 2:36:37  iter: 5419  total_loss: 0.4492  loss_cls: 0.1423  loss_box_reg: 0.1373  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.06015  time: 0.7311  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:33:33] d2.utils.events INFO:  eta: 2:36:21  iter: 5439  total_loss: 0.6163  loss_cls: 0.1451  loss_box_reg: 0.1856  loss_rpn_cls: 0.0798  loss_rpn_loc: 0.1035  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:33:48] d2.utils.events INFO:  eta: 2:36:33  iter: 5459  total_loss: 0.4776  loss_cls: 0.1089  loss_box_reg: 0.1518  loss_rpn_cls: 0.0858  loss_rpn_loc: 0.06654  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:34:02] d2.utils.events INFO:  eta: 2:36:23  iter: 5479  total_loss: 0.4137  loss_cls: 0.101  loss_box_reg: 0.1424  loss_rpn_cls: 0.07187  loss_rpn_loc: 0.09053  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:34:17] d2.utils.events INFO:  eta: 2:36:21  iter: 5499  total_loss: 0.4059  loss_cls: 0.117  loss_box_reg: 0.1121  loss_rpn_cls: 0.08501  loss_rpn_loc: 0.08296  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:34:32] d2.utils.events INFO:  eta: 2:36:01  iter: 5519  total_loss: 0.4929  loss_cls: 0.1321  loss_box_reg: 0.1439  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.08988  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:34:47] d2.utils.events INFO:  eta: 2:35:51  iter: 5539  total_loss: 0.5914  loss_cls: 0.1317  loss_box_reg: 0.1413  loss_rpn_cls: 0.09261  loss_rpn_loc: 0.105  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:35:02] d2.utils.events INFO:  eta: 2:35:20  iter: 5559  total_loss: 0.4193  loss_cls: 0.09682  loss_box_reg: 0.1342  loss_rpn_cls: 0.09012  loss_rpn_loc: 0.05763  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:35:16] d2.utils.events INFO:  eta: 2:34:42  iter: 5579  total_loss: 0.4964  loss_cls: 0.122  loss_box_reg: 0.1534  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.1183  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:35:30] d2.utils.events INFO:  eta: 2:34:27  iter: 5599  total_loss: 0.485  loss_cls: 0.148  loss_box_reg: 0.163  loss_rpn_cls: 0.09423  loss_rpn_loc: 0.0796  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:35:45] d2.utils.events INFO:  eta: 2:34:11  iter: 5619  total_loss: 0.5373  loss_cls: 0.1201  loss_box_reg: 0.1648  loss_rpn_cls: 0.08604  loss_rpn_loc: 0.1023  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:35:59] d2.utils.events INFO:  eta: 2:33:31  iter: 5639  total_loss: 0.4276  loss_cls: 0.1088  loss_box_reg: 0.1674  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.06921  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:36:12] d2.utils.events INFO:  eta: 2:32:40  iter: 5659  total_loss: 0.5069  loss_cls: 0.1533  loss_box_reg: 0.1635  loss_rpn_cls: 0.08273  loss_rpn_loc: 0.08705  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:36:27] d2.utils.events INFO:  eta: 2:32:36  iter: 5679  total_loss: 0.6263  loss_cls: 0.1424  loss_box_reg: 0.2075  loss_rpn_cls: 0.07184  loss_rpn_loc: 0.1102  time: 0.7307  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:36:41] d2.utils.events INFO:  eta: 2:32:10  iter: 5699  total_loss: 0.5907  loss_cls: 0.1519  loss_box_reg: 0.1763  loss_rpn_cls: 0.107  loss_rpn_loc: 0.06727  time: 0.7306  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:36:56] d2.utils.events INFO:  eta: 2:31:55  iter: 5719  total_loss: 0.5686  loss_cls: 0.1629  loss_box_reg: 0.1875  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.104  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:37:11] d2.utils.events INFO:  eta: 2:31:44  iter: 5739  total_loss: 0.5279  loss_cls: 0.1355  loss_box_reg: 0.1808  loss_rpn_cls: 0.08639  loss_rpn_loc: 0.09762  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:37:25] d2.utils.events INFO:  eta: 2:31:21  iter: 5759  total_loss: 0.6279  loss_cls: 0.2089  loss_box_reg: 0.2257  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.06899  time: 0.7305  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:37:39] d2.utils.events INFO:  eta: 2:30:54  iter: 5779  total_loss: 0.4947  loss_cls: 0.1291  loss_box_reg: 0.159  loss_rpn_cls: 0.09165  loss_rpn_loc: 0.09526  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:37:54] d2.utils.events INFO:  eta: 2:30:50  iter: 5799  total_loss: 0.3587  loss_cls: 0.1013  loss_box_reg: 0.1047  loss_rpn_cls: 0.07233  loss_rpn_loc: 0.09382  time: 0.7306  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:38:09] d2.utils.events INFO:  eta: 2:30:36  iter: 5819  total_loss: 0.4836  loss_cls: 0.1271  loss_box_reg: 0.1713  loss_rpn_cls: 0.08442  loss_rpn_loc: 0.1013  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:38:24] d2.utils.events INFO:  eta: 2:30:22  iter: 5839  total_loss: 0.501  loss_cls: 0.1196  loss_box_reg: 0.1699  loss_rpn_cls: 0.08105  loss_rpn_loc: 0.08304  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:38:38] d2.utils.events INFO:  eta: 2:30:12  iter: 5859  total_loss: 0.429  loss_cls: 0.1077  loss_box_reg: 0.1371  loss_rpn_cls: 0.0837  loss_rpn_loc: 0.06755  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:38:53] d2.utils.events INFO:  eta: 2:29:48  iter: 5879  total_loss: 0.4035  loss_cls: 0.1158  loss_box_reg: 0.1495  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.09932  time: 0.7305  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:39:08] d2.utils.events INFO:  eta: 2:29:38  iter: 5899  total_loss: 0.4609  loss_cls: 0.1311  loss_box_reg: 0.1442  loss_rpn_cls: 0.06455  loss_rpn_loc: 0.09932  time: 0.7306  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:39:22] d2.utils.events INFO:  eta: 2:29:27  iter: 5919  total_loss: 0.391  loss_cls: 0.09422  loss_box_reg: 0.1504  loss_rpn_cls: 0.0659  loss_rpn_loc: 0.1185  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:39:37] d2.utils.events INFO:  eta: 2:29:34  iter: 5939  total_loss: 0.6046  loss_cls: 0.1451  loss_box_reg: 0.195  loss_rpn_cls: 0.08152  loss_rpn_loc: 0.09993  time: 0.7306  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:39:53] d2.utils.events INFO:  eta: 2:29:24  iter: 5959  total_loss: 0.5239  loss_cls: 0.1377  loss_box_reg: 0.1402  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.07203  time: 0.7307  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:40:08] d2.utils.events INFO:  eta: 2:29:23  iter: 5979  total_loss: 0.4595  loss_cls: 0.1196  loss_box_reg: 0.1756  loss_rpn_cls: 0.08833  loss_rpn_loc: 0.08112  time: 0.7309  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:40:23] d2.utils.events INFO:  eta: 2:29:13  iter: 5999  total_loss: 0.4337  loss_cls: 0.09752  loss_box_reg: 0.1146  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.06607  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:40:39] d2.utils.events INFO:  eta: 2:29:01  iter: 6019  total_loss: 0.3826  loss_cls: 0.1078  loss_box_reg: 0.1369  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.1128  time: 0.7311  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:40:54] d2.utils.events INFO:  eta: 2:28:46  iter: 6039  total_loss: 0.533  loss_cls: 0.1181  loss_box_reg: 0.149  loss_rpn_cls: 0.07773  loss_rpn_loc: 0.1281  time: 0.7311  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:41:08] d2.utils.events INFO:  eta: 2:28:15  iter: 6059  total_loss: 0.4656  loss_cls: 0.1312  loss_box_reg: 0.1474  loss_rpn_cls: 0.08119  loss_rpn_loc: 0.08807  time: 0.7310  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:41:22] d2.utils.events INFO:  eta: 2:27:24  iter: 6079  total_loss: 0.5085  loss_cls: 0.128  loss_box_reg: 0.1709  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.08185  time: 0.7309  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:41:36] d2.utils.events INFO:  eta: 2:26:45  iter: 6099  total_loss: 0.4541  loss_cls: 0.1072  loss_box_reg: 0.1291  loss_rpn_cls: 0.06973  loss_rpn_loc: 0.09832  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:41:50] d2.utils.events INFO:  eta: 2:26:28  iter: 6119  total_loss: 0.4437  loss_cls: 0.09711  loss_box_reg: 0.1491  loss_rpn_cls: 0.05316  loss_rpn_loc: 0.09859  time: 0.7308  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:42:04] d2.utils.events INFO:  eta: 2:26:11  iter: 6139  total_loss: 0.459  loss_cls: 0.08589  loss_box_reg: 0.1297  loss_rpn_cls: 0.08496  loss_rpn_loc: 0.1218  time: 0.7306  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:42:19] d2.utils.events INFO:  eta: 2:25:54  iter: 6159  total_loss: 0.3751  loss_cls: 0.1045  loss_box_reg: 0.1197  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.08504  time: 0.7307  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:42:34] d2.utils.events INFO:  eta: 2:25:40  iter: 6179  total_loss: 0.4704  loss_cls: 0.1081  loss_box_reg: 0.1372  loss_rpn_cls: 0.0807  loss_rpn_loc: 0.129  time: 0.7307  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:42:48] d2.utils.events INFO:  eta: 2:25:07  iter: 6199  total_loss: 0.4945  loss_cls: 0.1349  loss_box_reg: 0.1667  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.09034  time: 0.7307  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:43:03] d2.utils.events INFO:  eta: 2:24:58  iter: 6219  total_loss: 0.4986  loss_cls: 0.1171  loss_box_reg: 0.1375  loss_rpn_cls: 0.07875  loss_rpn_loc: 0.09097  time: 0.7308  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:43:19] d2.utils.events INFO:  eta: 2:24:43  iter: 6239  total_loss: 0.4694  loss_cls: 0.1564  loss_box_reg: 0.1624  loss_rpn_cls: 0.06919  loss_rpn_loc: 0.06229  time: 0.7309  data_time: 0.0027  lr: 0.0002  max_mem: 15389M
[01/29 17:43:33] d2.utils.events INFO:  eta: 2:24:44  iter: 6259  total_loss: 0.4513  loss_cls: 0.1227  loss_box_reg: 0.1508  loss_rpn_cls: 0.0717  loss_rpn_loc: 0.1086  time: 0.7309  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:43:49] d2.utils.events INFO:  eta: 2:24:33  iter: 6279  total_loss: 0.4196  loss_cls: 0.1056  loss_box_reg: 0.116  loss_rpn_cls: 0.08077  loss_rpn_loc: 0.06857  time: 0.7310  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:44:04] d2.utils.events INFO:  eta: 2:24:33  iter: 6299  total_loss: 0.3582  loss_cls: 0.08394  loss_box_reg: 0.1033  loss_rpn_cls: 0.05181  loss_rpn_loc: 0.0769  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:44:18] d2.utils.events INFO:  eta: 2:24:08  iter: 6319  total_loss: 0.5623  loss_cls: 0.1616  loss_box_reg: 0.1773  loss_rpn_cls: 0.07426  loss_rpn_loc: 0.07711  time: 0.7310  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:44:33] d2.utils.events INFO:  eta: 2:23:49  iter: 6339  total_loss: 0.4919  loss_cls: 0.1241  loss_box_reg: 0.1463  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.1267  time: 0.7310  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:44:47] d2.utils.events INFO:  eta: 2:23:30  iter: 6359  total_loss: 0.4039  loss_cls: 0.1072  loss_box_reg: 0.148  loss_rpn_cls: 0.06521  loss_rpn_loc: 0.09046  time: 0.7309  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:45:01] d2.utils.events INFO:  eta: 2:23:14  iter: 6379  total_loss: 0.4757  loss_cls: 0.134  loss_box_reg: 0.1454  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.08608  time: 0.7308  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:45:17] d2.utils.events INFO:  eta: 2:23:07  iter: 6399  total_loss: 0.3413  loss_cls: 0.07386  loss_box_reg: 0.1028  loss_rpn_cls: 0.07042  loss_rpn_loc: 0.07959  time: 0.7311  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:45:33] d2.utils.events INFO:  eta: 2:23:12  iter: 6419  total_loss: 0.4918  loss_cls: 0.09982  loss_box_reg: 0.1212  loss_rpn_cls: 0.06202  loss_rpn_loc: 0.09022  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:45:48] d2.utils.events INFO:  eta: 2:22:57  iter: 6439  total_loss: 0.5285  loss_cls: 0.1496  loss_box_reg: 0.1812  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.08903  time: 0.7312  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:46:03] d2.utils.events INFO:  eta: 2:22:43  iter: 6459  total_loss: 0.3275  loss_cls: 0.1005  loss_box_reg: 0.1064  loss_rpn_cls: 0.05335  loss_rpn_loc: 0.05731  time: 0.7313  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:46:18] d2.utils.events INFO:  eta: 2:22:50  iter: 6479  total_loss: 0.457  loss_cls: 0.1185  loss_box_reg: 0.1519  loss_rpn_cls: 0.05985  loss_rpn_loc: 0.09967  time: 0.7315  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:46:33] d2.utils.events INFO:  eta: 2:22:40  iter: 6499  total_loss: 0.4925  loss_cls: 0.1151  loss_box_reg: 0.1545  loss_rpn_cls: 0.09753  loss_rpn_loc: 0.1097  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:46:48] d2.utils.events INFO:  eta: 2:22:25  iter: 6519  total_loss: 0.3128  loss_cls: 0.08743  loss_box_reg: 0.1137  loss_rpn_cls: 0.05379  loss_rpn_loc: 0.05589  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:47:02] d2.utils.events INFO:  eta: 2:22:00  iter: 6539  total_loss: 0.3657  loss_cls: 0.1118  loss_box_reg: 0.1296  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.08823  time: 0.7314  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:47:16] d2.utils.events INFO:  eta: 2:21:29  iter: 6559  total_loss: 0.5103  loss_cls: 0.1262  loss_box_reg: 0.1613  loss_rpn_cls: 0.09231  loss_rpn_loc: 0.06623  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:47:31] d2.utils.events INFO:  eta: 2:21:36  iter: 6579  total_loss: 0.629  loss_cls: 0.1744  loss_box_reg: 0.2077  loss_rpn_cls: 0.09979  loss_rpn_loc: 0.1074  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:47:46] d2.utils.events INFO:  eta: 2:21:16  iter: 6599  total_loss: 0.4978  loss_cls: 0.1298  loss_box_reg: 0.1896  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.09606  time: 0.7314  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:48:00] d2.utils.events INFO:  eta: 2:20:49  iter: 6619  total_loss: 0.5114  loss_cls: 0.1362  loss_box_reg: 0.1968  loss_rpn_cls: 0.06614  loss_rpn_loc: 0.07588  time: 0.7313  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:48:15] d2.utils.events INFO:  eta: 2:20:56  iter: 6639  total_loss: 0.5064  loss_cls: 0.1472  loss_box_reg: 0.1722  loss_rpn_cls: 0.07649  loss_rpn_loc: 0.09206  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:48:29] d2.utils.events INFO:  eta: 2:20:45  iter: 6659  total_loss: 0.3948  loss_cls: 0.1061  loss_box_reg: 0.1352  loss_rpn_cls: 0.06846  loss_rpn_loc: 0.08019  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:48:45] d2.utils.events INFO:  eta: 2:20:31  iter: 6679  total_loss: 0.4253  loss_cls: 0.1088  loss_box_reg: 0.1387  loss_rpn_cls: 0.06184  loss_rpn_loc: 0.1132  time: 0.7314  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:49:01] d2.utils.events INFO:  eta: 2:20:25  iter: 6699  total_loss: 0.3736  loss_cls: 0.08626  loss_box_reg: 0.09832  loss_rpn_cls: 0.07285  loss_rpn_loc: 0.0737  time: 0.7316  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:49:15] d2.utils.events INFO:  eta: 2:20:08  iter: 6719  total_loss: 0.455  loss_cls: 0.105  loss_box_reg: 0.1478  loss_rpn_cls: 0.07865  loss_rpn_loc: 0.08745  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:49:30] d2.utils.events INFO:  eta: 2:19:46  iter: 6739  total_loss: 0.443  loss_cls: 0.1118  loss_box_reg: 0.1573  loss_rpn_cls: 0.05064  loss_rpn_loc: 0.1036  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:49:44] d2.utils.events INFO:  eta: 2:19:33  iter: 6759  total_loss: 0.4172  loss_cls: 0.09273  loss_box_reg: 0.1222  loss_rpn_cls: 0.05943  loss_rpn_loc: 0.09423  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:49:59] d2.utils.events INFO:  eta: 2:19:23  iter: 6779  total_loss: 0.5075  loss_cls: 0.1314  loss_box_reg: 0.1546  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.07935  time: 0.7316  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:50:14] d2.utils.events INFO:  eta: 2:19:09  iter: 6799  total_loss: 0.5256  loss_cls: 0.1299  loss_box_reg: 0.1682  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1095  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:50:29] d2.utils.events INFO:  eta: 2:19:15  iter: 6819  total_loss: 0.4743  loss_cls: 0.1194  loss_box_reg: 0.1376  loss_rpn_cls: 0.05921  loss_rpn_loc: 0.09866  time: 0.7317  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:50:43] d2.utils.events INFO:  eta: 2:18:45  iter: 6839  total_loss: 0.4916  loss_cls: 0.1254  loss_box_reg: 0.1758  loss_rpn_cls: 0.07939  loss_rpn_loc: 0.08668  time: 0.7316  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:50:58] d2.utils.events INFO:  eta: 2:18:35  iter: 6859  total_loss: 0.489  loss_cls: 0.1171  loss_box_reg: 0.1426  loss_rpn_cls: 0.07352  loss_rpn_loc: 0.09364  time: 0.7316  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:51:12] d2.utils.events INFO:  eta: 2:18:08  iter: 6879  total_loss: 0.4713  loss_cls: 0.1421  loss_box_reg: 0.1985  loss_rpn_cls: 0.06774  loss_rpn_loc: 0.08887  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:51:27] d2.utils.events INFO:  eta: 2:17:44  iter: 6899  total_loss: 0.4498  loss_cls: 0.1017  loss_box_reg: 0.1372  loss_rpn_cls: 0.06736  loss_rpn_loc: 0.08732  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:51:42] d2.utils.events INFO:  eta: 2:17:34  iter: 6919  total_loss: 0.475  loss_cls: 0.1392  loss_box_reg: 0.1631  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.09754  time: 0.7316  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:51:57] d2.utils.events INFO:  eta: 2:17:17  iter: 6939  total_loss: 0.4662  loss_cls: 0.126  loss_box_reg: 0.1308  loss_rpn_cls: 0.09152  loss_rpn_loc: 0.08044  time: 0.7316  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:52:11] d2.utils.events INFO:  eta: 2:17:00  iter: 6959  total_loss: 0.3723  loss_cls: 0.105  loss_box_reg: 0.1462  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.08866  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:52:25] d2.utils.events INFO:  eta: 2:16:12  iter: 6979  total_loss: 0.4166  loss_cls: 0.1415  loss_box_reg: 0.147  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.07338  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:52:40] d2.utils.events INFO:  eta: 2:15:46  iter: 6999  total_loss: 0.4262  loss_cls: 0.1156  loss_box_reg: 0.1477  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.07819  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:52:55] d2.utils.events INFO:  eta: 2:15:28  iter: 7019  total_loss: 0.4816  loss_cls: 0.1121  loss_box_reg: 0.1782  loss_rpn_cls: 0.07731  loss_rpn_loc: 0.08597  time: 0.7315  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:53:09] d2.utils.events INFO:  eta: 2:14:58  iter: 7039  total_loss: 0.3776  loss_cls: 0.09392  loss_box_reg: 0.1508  loss_rpn_cls: 0.08438  loss_rpn_loc: 0.0566  time: 0.7314  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:53:24] d2.utils.events INFO:  eta: 2:14:56  iter: 7059  total_loss: 0.4844  loss_cls: 0.1343  loss_box_reg: 0.1529  loss_rpn_cls: 0.08526  loss_rpn_loc: 0.08247  time: 0.7314  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:53:38] d2.utils.events INFO:  eta: 2:14:42  iter: 7079  total_loss: 0.504  loss_cls: 0.09075  loss_box_reg: 0.1544  loss_rpn_cls: 0.08078  loss_rpn_loc: 0.1007  time: 0.7313  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:53:52] d2.utils.events INFO:  eta: 2:14:31  iter: 7099  total_loss: 0.546  loss_cls: 0.1704  loss_box_reg: 0.1946  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.09194  time: 0.7312  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:54:06] d2.utils.events INFO:  eta: 2:14:19  iter: 7119  total_loss: 0.4443  loss_cls: 0.1139  loss_box_reg: 0.1609  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.0849  time: 0.7312  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:54:21] d2.utils.events INFO:  eta: 2:14:04  iter: 7139  total_loss: 0.5572  loss_cls: 0.1433  loss_box_reg: 0.1914  loss_rpn_cls: 0.08065  loss_rpn_loc: 0.1317  time: 0.7312  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:54:35] d2.utils.events INFO:  eta: 2:13:48  iter: 7159  total_loss: 0.4591  loss_cls: 0.1319  loss_box_reg: 0.1672  loss_rpn_cls: 0.07987  loss_rpn_loc: 0.1013  time: 0.7312  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:54:49] d2.utils.events INFO:  eta: 2:13:30  iter: 7179  total_loss: 0.4943  loss_cls: 0.1265  loss_box_reg: 0.1447  loss_rpn_cls: 0.086  loss_rpn_loc: 0.08453  time: 0.7310  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:55:05] d2.utils.events INFO:  eta: 2:13:17  iter: 7199  total_loss: 0.4229  loss_cls: 0.08817  loss_box_reg: 0.1396  loss_rpn_cls: 0.05769  loss_rpn_loc: 0.1116  time: 0.7312  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:55:20] d2.utils.events INFO:  eta: 2:12:51  iter: 7219  total_loss: 0.4822  loss_cls: 0.1044  loss_box_reg: 0.153  loss_rpn_cls: 0.08869  loss_rpn_loc: 0.07998  time: 0.7312  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:55:34] d2.utils.events INFO:  eta: 2:12:17  iter: 7239  total_loss: 0.4252  loss_cls: 0.1136  loss_box_reg: 0.1289  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.08564  time: 0.7312  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:55:49] d2.utils.events INFO:  eta: 2:11:41  iter: 7259  total_loss: 0.502  loss_cls: 0.1246  loss_box_reg: 0.1152  loss_rpn_cls: 0.08781  loss_rpn_loc: 0.09671  time: 0.7312  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:56:04] d2.utils.events INFO:  eta: 2:11:22  iter: 7279  total_loss: 0.4984  loss_cls: 0.1192  loss_box_reg: 0.1627  loss_rpn_cls: 0.0953  loss_rpn_loc: 0.0896  time: 0.7312  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:56:19] d2.utils.events INFO:  eta: 2:11:05  iter: 7299  total_loss: 0.6098  loss_cls: 0.1703  loss_box_reg: 0.2172  loss_rpn_cls: 0.08092  loss_rpn_loc: 0.08242  time: 0.7313  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 17:56:34] d2.utils.events INFO:  eta: 2:10:54  iter: 7319  total_loss: 0.5133  loss_cls: 0.1164  loss_box_reg: 0.1624  loss_rpn_cls: 0.09283  loss_rpn_loc: 0.09834  time: 0.7314  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:56:48] d2.utils.events INFO:  eta: 2:10:25  iter: 7339  total_loss: 0.527  loss_cls: 0.1238  loss_box_reg: 0.1763  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.1256  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:57:04] d2.utils.events INFO:  eta: 2:10:35  iter: 7359  total_loss: 0.3891  loss_cls: 0.1084  loss_box_reg: 0.1364  loss_rpn_cls: 0.06063  loss_rpn_loc: 0.07465  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:57:18] d2.utils.events INFO:  eta: 2:10:24  iter: 7379  total_loss: 0.3676  loss_cls: 0.101  loss_box_reg: 0.1205  loss_rpn_cls: 0.06215  loss_rpn_loc: 0.06372  time: 0.7314  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 17:57:32] d2.utils.events INFO:  eta: 2:09:51  iter: 7399  total_loss: 0.3062  loss_cls: 0.06829  loss_box_reg: 0.1107  loss_rpn_cls: 0.03634  loss_rpn_loc: 0.06101  time: 0.7313  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:57:46] d2.utils.events INFO:  eta: 2:09:24  iter: 7419  total_loss: 0.4361  loss_cls: 0.1173  loss_box_reg: 0.1888  loss_rpn_cls: 0.06  loss_rpn_loc: 0.0606  time: 0.7312  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 17:58:01] d2.utils.events INFO:  eta: 2:09:12  iter: 7439  total_loss: 0.5334  loss_cls: 0.1318  loss_box_reg: 0.176  loss_rpn_cls: 0.07986  loss_rpn_loc: 0.09716  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:58:16] d2.utils.events INFO:  eta: 2:08:51  iter: 7459  total_loss: 0.5002  loss_cls: 0.1433  loss_box_reg: 0.1707  loss_rpn_cls: 0.08244  loss_rpn_loc: 0.1087  time: 0.7313  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:58:32] d2.utils.events INFO:  eta: 2:08:36  iter: 7479  total_loss: 0.4436  loss_cls: 0.1101  loss_box_reg: 0.1548  loss_rpn_cls: 0.05249  loss_rpn_loc: 0.1213  time: 0.7314  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:58:47] d2.utils.events INFO:  eta: 2:08:25  iter: 7499  total_loss: 0.4825  loss_cls: 0.1107  loss_box_reg: 0.1838  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.1019  time: 0.7315  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 17:59:02] d2.utils.events INFO:  eta: 2:08:20  iter: 7519  total_loss: 0.4925  loss_cls: 0.1409  loss_box_reg: 0.2056  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.06879  time: 0.7316  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:59:17] d2.utils.events INFO:  eta: 2:08:09  iter: 7539  total_loss: 0.475  loss_cls: 0.1173  loss_box_reg: 0.1149  loss_rpn_cls: 0.06768  loss_rpn_loc: 0.1254  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 17:59:32] d2.utils.events INFO:  eta: 2:07:50  iter: 7559  total_loss: 0.4344  loss_cls: 0.1144  loss_box_reg: 0.1263  loss_rpn_cls: 0.07207  loss_rpn_loc: 0.1059  time: 0.7316  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 17:59:47] d2.utils.events INFO:  eta: 2:07:41  iter: 7579  total_loss: 0.461  loss_cls: 0.09235  loss_box_reg: 0.1401  loss_rpn_cls: 0.05248  loss_rpn_loc: 0.0823  time: 0.7317  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:00:03] d2.utils.events INFO:  eta: 2:07:30  iter: 7599  total_loss: 0.4293  loss_cls: 0.08276  loss_box_reg: 0.1308  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.1145  time: 0.7318  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:00:18] d2.utils.events INFO:  eta: 2:08:07  iter: 7619  total_loss: 0.4194  loss_cls: 0.09359  loss_box_reg: 0.1312  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.09812  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:00:33] d2.utils.events INFO:  eta: 2:07:52  iter: 7639  total_loss: 0.4746  loss_cls: 0.1232  loss_box_reg: 0.1707  loss_rpn_cls: 0.09742  loss_rpn_loc: 0.08572  time: 0.7319  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:00:48] d2.utils.events INFO:  eta: 2:07:41  iter: 7659  total_loss: 0.5733  loss_cls: 0.1611  loss_box_reg: 0.1877  loss_rpn_cls: 0.09803  loss_rpn_loc: 0.08684  time: 0.7320  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:01:03] d2.utils.events INFO:  eta: 2:07:22  iter: 7679  total_loss: 0.4259  loss_cls: 0.1296  loss_box_reg: 0.1805  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.08833  time: 0.7320  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:01:17] d2.utils.events INFO:  eta: 2:06:46  iter: 7699  total_loss: 0.4353  loss_cls: 0.1207  loss_box_reg: 0.1634  loss_rpn_cls: 0.0727  loss_rpn_loc: 0.09415  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:01:31] d2.utils.events INFO:  eta: 2:06:17  iter: 7719  total_loss: 0.4099  loss_cls: 0.08864  loss_box_reg: 0.1478  loss_rpn_cls: 0.0739  loss_rpn_loc: 0.1068  time: 0.7318  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:01:47] d2.utils.events INFO:  eta: 2:06:38  iter: 7739  total_loss: 0.4232  loss_cls: 0.1211  loss_box_reg: 0.1321  loss_rpn_cls: 0.06842  loss_rpn_loc: 0.08562  time: 0.7320  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:02:01] d2.utils.events INFO:  eta: 2:06:30  iter: 7759  total_loss: 0.453  loss_cls: 0.1065  loss_box_reg: 0.1435  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.09005  time: 0.7320  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:02:16] d2.utils.events INFO:  eta: 2:06:08  iter: 7779  total_loss: 0.4835  loss_cls: 0.1451  loss_box_reg: 0.1868  loss_rpn_cls: 0.08943  loss_rpn_loc: 0.07593  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:02:31] d2.utils.events INFO:  eta: 2:06:01  iter: 7799  total_loss: 0.4941  loss_cls: 0.1204  loss_box_reg: 0.1487  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.08927  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:02:46] d2.utils.events INFO:  eta: 2:05:24  iter: 7819  total_loss: 0.4187  loss_cls: 0.1239  loss_box_reg: 0.132  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.08186  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:03:01] d2.utils.events INFO:  eta: 2:05:43  iter: 7839  total_loss: 0.3966  loss_cls: 0.116  loss_box_reg: 0.1386  loss_rpn_cls: 0.05792  loss_rpn_loc: 0.05582  time: 0.7321  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:03:15] d2.utils.events INFO:  eta: 2:05:16  iter: 7859  total_loss: 0.4561  loss_cls: 0.1378  loss_box_reg: 0.1367  loss_rpn_cls: 0.06856  loss_rpn_loc: 0.0898  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:03:30] d2.utils.events INFO:  eta: 2:05:03  iter: 7879  total_loss: 0.4705  loss_cls: 0.08817  loss_box_reg: 0.1163  loss_rpn_cls: 0.08727  loss_rpn_loc: 0.09245  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:03:44] d2.utils.events INFO:  eta: 2:05:10  iter: 7899  total_loss: 0.3754  loss_cls: 0.1092  loss_box_reg: 0.1453  loss_rpn_cls: 0.07577  loss_rpn_loc: 0.066  time: 0.7320  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:04:00] d2.utils.events INFO:  eta: 2:05:19  iter: 7919  total_loss: 0.4139  loss_cls: 0.1119  loss_box_reg: 0.1534  loss_rpn_cls: 0.06727  loss_rpn_loc: 0.09915  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:04:14] d2.utils.events INFO:  eta: 2:05:09  iter: 7939  total_loss: 0.5247  loss_cls: 0.1708  loss_box_reg: 0.2117  loss_rpn_cls: 0.08393  loss_rpn_loc: 0.08147  time: 0.7321  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:04:29] d2.utils.events INFO:  eta: 2:04:58  iter: 7959  total_loss: 0.4848  loss_cls: 0.1141  loss_box_reg: 0.1024  loss_rpn_cls: 0.09034  loss_rpn_loc: 0.1073  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:04:44] d2.utils.events INFO:  eta: 2:04:52  iter: 7979  total_loss: 0.4496  loss_cls: 0.107  loss_box_reg: 0.1436  loss_rpn_cls: 0.07234  loss_rpn_loc: 0.09717  time: 0.7321  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:04:59] d2.utils.events INFO:  eta: 2:05:00  iter: 7999  total_loss: 0.513  loss_cls: 0.1139  loss_box_reg: 0.1415  loss_rpn_cls: 0.0734  loss_rpn_loc: 0.1068  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:05:13] d2.utils.events INFO:  eta: 2:04:45  iter: 8019  total_loss: 0.3933  loss_cls: 0.09597  loss_box_reg: 0.1563  loss_rpn_cls: 0.0595  loss_rpn_loc: 0.05248  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:05:29] d2.utils.events INFO:  eta: 2:04:43  iter: 8039  total_loss: 0.4548  loss_cls: 0.1187  loss_box_reg: 0.1359  loss_rpn_cls: 0.05932  loss_rpn_loc: 0.07743  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:05:44] d2.utils.events INFO:  eta: 2:04:43  iter: 8059  total_loss: 0.4044  loss_cls: 0.08721  loss_box_reg: 0.1287  loss_rpn_cls: 0.04216  loss_rpn_loc: 0.1048  time: 0.7322  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:05:58] d2.utils.events INFO:  eta: 2:04:35  iter: 8079  total_loss: 0.4719  loss_cls: 0.129  loss_box_reg: 0.1787  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.1019  time: 0.7322  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:06:13] d2.utils.events INFO:  eta: 2:04:32  iter: 8099  total_loss: 0.5536  loss_cls: 0.1396  loss_box_reg: 0.1903  loss_rpn_cls: 0.06652  loss_rpn_loc: 0.09587  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:06:27] d2.utils.events INFO:  eta: 2:04:12  iter: 8119  total_loss: 0.4859  loss_cls: 0.1395  loss_box_reg: 0.1884  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.07538  time: 0.7322  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:06:42] d2.utils.events INFO:  eta: 2:03:57  iter: 8139  total_loss: 0.5163  loss_cls: 0.1219  loss_box_reg: 0.1835  loss_rpn_cls: 0.05251  loss_rpn_loc: 0.1111  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:06:57] d2.utils.events INFO:  eta: 2:03:52  iter: 8159  total_loss: 0.5407  loss_cls: 0.1412  loss_box_reg: 0.1879  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.1299  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:07:11] d2.utils.events INFO:  eta: 2:03:43  iter: 8179  total_loss: 0.542  loss_cls: 0.1206  loss_box_reg: 0.1685  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.1038  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:07:26] d2.utils.events INFO:  eta: 2:03:15  iter: 8199  total_loss: 0.4362  loss_cls: 0.1078  loss_box_reg: 0.1353  loss_rpn_cls: 0.08134  loss_rpn_loc: 0.101  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:07:41] d2.utils.events INFO:  eta: 2:03:10  iter: 8219  total_loss: 0.442  loss_cls: 0.1141  loss_box_reg: 0.155  loss_rpn_cls: 0.05173  loss_rpn_loc: 0.0902  time: 0.7322  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:07:55] d2.utils.events INFO:  eta: 2:02:54  iter: 8239  total_loss: 0.4385  loss_cls: 0.09828  loss_box_reg: 0.1486  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.09076  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:08:10] d2.utils.events INFO:  eta: 2:02:43  iter: 8259  total_loss: 0.5108  loss_cls: 0.1221  loss_box_reg: 0.1792  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.06914  time: 0.7322  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:08:25] d2.utils.events INFO:  eta: 2:02:36  iter: 8279  total_loss: 0.432  loss_cls: 0.1202  loss_box_reg: 0.1428  loss_rpn_cls: 0.05649  loss_rpn_loc: 0.09366  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:08:41] d2.utils.events INFO:  eta: 2:02:27  iter: 8299  total_loss: 0.4856  loss_cls: 0.1245  loss_box_reg: 0.1757  loss_rpn_cls: 0.06387  loss_rpn_loc: 0.0743  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:08:55] d2.utils.events INFO:  eta: 2:02:01  iter: 8319  total_loss: 0.456  loss_cls: 0.1305  loss_box_reg: 0.17  loss_rpn_cls: 0.05776  loss_rpn_loc: 0.1012  time: 0.7323  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:09:10] d2.utils.events INFO:  eta: 2:01:54  iter: 8339  total_loss: 0.4687  loss_cls: 0.1205  loss_box_reg: 0.1825  loss_rpn_cls: 0.06237  loss_rpn_loc: 0.1105  time: 0.7323  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:09:25] d2.utils.events INFO:  eta: 2:01:28  iter: 8359  total_loss: 0.6024  loss_cls: 0.1584  loss_box_reg: 0.1998  loss_rpn_cls: 0.0751  loss_rpn_loc: 0.0915  time: 0.7323  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:09:41] d2.utils.events INFO:  eta: 2:01:31  iter: 8379  total_loss: 0.5542  loss_cls: 0.1088  loss_box_reg: 0.1893  loss_rpn_cls: 0.08517  loss_rpn_loc: 0.158  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:09:56] d2.utils.events INFO:  eta: 2:01:44  iter: 8399  total_loss: 0.4234  loss_cls: 0.1094  loss_box_reg: 0.1286  loss_rpn_cls: 0.06563  loss_rpn_loc: 0.1199  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:10:11] d2.utils.events INFO:  eta: 2:01:20  iter: 8419  total_loss: 0.4768  loss_cls: 0.1162  loss_box_reg: 0.1579  loss_rpn_cls: 0.05516  loss_rpn_loc: 0.09812  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:10:26] d2.utils.events INFO:  eta: 2:00:57  iter: 8439  total_loss: 0.4792  loss_cls: 0.1047  loss_box_reg: 0.1453  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.08472  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:10:40] d2.utils.events INFO:  eta: 2:00:39  iter: 8459  total_loss: 0.4375  loss_cls: 0.1326  loss_box_reg: 0.1499  loss_rpn_cls: 0.06194  loss_rpn_loc: 0.05547  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:10:55] d2.utils.events INFO:  eta: 2:00:22  iter: 8479  total_loss: 0.4199  loss_cls: 0.09731  loss_box_reg: 0.1374  loss_rpn_cls: 0.05788  loss_rpn_loc: 0.07561  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:11:10] d2.utils.events INFO:  eta: 1:59:59  iter: 8499  total_loss: 0.435  loss_cls: 0.0781  loss_box_reg: 0.1254  loss_rpn_cls: 0.06707  loss_rpn_loc: 0.1012  time: 0.7326  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:11:25] d2.utils.events INFO:  eta: 1:59:30  iter: 8519  total_loss: 0.5265  loss_cls: 0.1277  loss_box_reg: 0.1403  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.1075  time: 0.7327  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:11:40] d2.utils.events INFO:  eta: 1:59:19  iter: 8539  total_loss: 0.4583  loss_cls: 0.114  loss_box_reg: 0.1397  loss_rpn_cls: 0.08568  loss_rpn_loc: 0.1032  time: 0.7327  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:11:54] d2.utils.events INFO:  eta: 1:59:13  iter: 8559  total_loss: 0.5094  loss_cls: 0.1226  loss_box_reg: 0.1413  loss_rpn_cls: 0.06967  loss_rpn_loc: 0.08981  time: 0.7326  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:12:07] d2.utils.events INFO:  eta: 1:58:38  iter: 8579  total_loss: 0.3937  loss_cls: 0.07701  loss_box_reg: 0.08882  loss_rpn_cls: 0.07016  loss_rpn_loc: 0.05549  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:12:22] d2.utils.events INFO:  eta: 1:58:17  iter: 8599  total_loss: 0.3538  loss_cls: 0.083  loss_box_reg: 0.1261  loss_rpn_cls: 0.06247  loss_rpn_loc: 0.06809  time: 0.7324  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:12:36] d2.utils.events INFO:  eta: 1:57:38  iter: 8619  total_loss: 0.4299  loss_cls: 0.08832  loss_box_reg: 0.1376  loss_rpn_cls: 0.07471  loss_rpn_loc: 0.08504  time: 0.7324  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:12:51] d2.utils.events INFO:  eta: 1:57:19  iter: 8639  total_loss: 0.4141  loss_cls: 0.08208  loss_box_reg: 0.1652  loss_rpn_cls: 0.06534  loss_rpn_loc: 0.08009  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:13:06] d2.utils.events INFO:  eta: 1:57:01  iter: 8659  total_loss: 0.5128  loss_cls: 0.1248  loss_box_reg: 0.176  loss_rpn_cls: 0.05637  loss_rpn_loc: 0.07878  time: 0.7324  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:13:21] d2.utils.events INFO:  eta: 1:56:53  iter: 8679  total_loss: 0.5211  loss_cls: 0.1595  loss_box_reg: 0.1878  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.08986  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:13:36] d2.utils.events INFO:  eta: 1:56:49  iter: 8699  total_loss: 0.4945  loss_cls: 0.1063  loss_box_reg: 0.174  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.1222  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:13:50] d2.utils.events INFO:  eta: 1:56:31  iter: 8719  total_loss: 0.4169  loss_cls: 0.122  loss_box_reg: 0.1613  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.1098  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:14:05] d2.utils.events INFO:  eta: 1:56:04  iter: 8739  total_loss: 0.3671  loss_cls: 0.07227  loss_box_reg: 0.1142  loss_rpn_cls: 0.06251  loss_rpn_loc: 0.06875  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:14:20] d2.utils.events INFO:  eta: 1:55:57  iter: 8759  total_loss: 0.3738  loss_cls: 0.09599  loss_box_reg: 0.1315  loss_rpn_cls: 0.04927  loss_rpn_loc: 0.07857  time: 0.7325  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:14:35] d2.utils.events INFO:  eta: 1:55:51  iter: 8779  total_loss: 0.4023  loss_cls: 0.1058  loss_box_reg: 0.1351  loss_rpn_cls: 0.04938  loss_rpn_loc: 0.06624  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:14:50] d2.utils.events INFO:  eta: 1:55:27  iter: 8799  total_loss: 0.3699  loss_cls: 0.1147  loss_box_reg: 0.1394  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.07384  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:15:05] d2.utils.events INFO:  eta: 1:55:21  iter: 8819  total_loss: 0.4784  loss_cls: 0.1231  loss_box_reg: 0.1591  loss_rpn_cls: 0.05806  loss_rpn_loc: 0.09943  time: 0.7326  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:15:20] d2.utils.events INFO:  eta: 1:54:54  iter: 8839  total_loss: 0.3822  loss_cls: 0.09034  loss_box_reg: 0.11  loss_rpn_cls: 0.06113  loss_rpn_loc: 0.08562  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:15:35] d2.utils.events INFO:  eta: 1:54:54  iter: 8859  total_loss: 0.3893  loss_cls: 0.1006  loss_box_reg: 0.1314  loss_rpn_cls: 0.0685  loss_rpn_loc: 0.07387  time: 0.7326  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:15:50] d2.utils.events INFO:  eta: 1:54:44  iter: 8879  total_loss: 0.3816  loss_cls: 0.08966  loss_box_reg: 0.1008  loss_rpn_cls: 0.05641  loss_rpn_loc: 0.07657  time: 0.7327  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:16:05] d2.utils.events INFO:  eta: 1:54:33  iter: 8899  total_loss: 0.4681  loss_cls: 0.1127  loss_box_reg: 0.1191  loss_rpn_cls: 0.07973  loss_rpn_loc: 0.08445  time: 0.7327  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:16:19] d2.utils.events INFO:  eta: 1:54:09  iter: 8919  total_loss: 0.4315  loss_cls: 0.1171  loss_box_reg: 0.1387  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.08504  time: 0.7327  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:16:34] d2.utils.events INFO:  eta: 1:53:47  iter: 8939  total_loss: 0.6537  loss_cls: 0.1844  loss_box_reg: 0.2135  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.07146  time: 0.7327  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:16:49] d2.utils.events INFO:  eta: 1:53:27  iter: 8959  total_loss: 0.5252  loss_cls: 0.1573  loss_box_reg: 0.1946  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.09785  time: 0.7327  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:17:03] d2.utils.events INFO:  eta: 1:53:06  iter: 8979  total_loss: 0.5012  loss_cls: 0.1292  loss_box_reg: 0.185  loss_rpn_cls: 0.07761  loss_rpn_loc: 0.0666  time: 0.7326  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:17:17] d2.utils.events INFO:  eta: 1:52:42  iter: 8999  total_loss: 0.4092  loss_cls: 0.1144  loss_box_reg: 0.1466  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.07301  time: 0.7326  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:17:31] d2.utils.events INFO:  eta: 1:52:33  iter: 9019  total_loss: 0.4332  loss_cls: 0.1248  loss_box_reg: 0.1496  loss_rpn_cls: 0.07584  loss_rpn_loc: 0.0952  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:17:46] d2.utils.events INFO:  eta: 1:52:07  iter: 9039  total_loss: 0.3937  loss_cls: 0.09725  loss_box_reg: 0.1252  loss_rpn_cls: 0.06779  loss_rpn_loc: 0.07216  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:18:00] d2.utils.events INFO:  eta: 1:51:50  iter: 9059  total_loss: 0.4865  loss_cls: 0.1111  loss_box_reg: 0.1201  loss_rpn_cls: 0.08277  loss_rpn_loc: 0.1016  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:18:15] d2.utils.events INFO:  eta: 1:51:35  iter: 9079  total_loss: 0.5309  loss_cls: 0.1458  loss_box_reg: 0.2009  loss_rpn_cls: 0.08564  loss_rpn_loc: 0.09711  time: 0.7325  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:18:31] d2.utils.events INFO:  eta: 1:51:22  iter: 9099  total_loss: 0.4674  loss_cls: 0.1086  loss_box_reg: 0.1411  loss_rpn_cls: 0.08125  loss_rpn_loc: 0.1173  time: 0.7326  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:18:46] d2.utils.events INFO:  eta: 1:51:12  iter: 9119  total_loss: 0.4508  loss_cls: 0.1095  loss_box_reg: 0.1412  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.07822  time: 0.7327  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:19:02] d2.utils.events INFO:  eta: 1:51:26  iter: 9139  total_loss: 0.4274  loss_cls: 0.1048  loss_box_reg: 0.1527  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.09702  time: 0.7328  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:19:16] d2.utils.events INFO:  eta: 1:50:56  iter: 9159  total_loss: 0.4064  loss_cls: 0.0929  loss_box_reg: 0.1515  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.0926  time: 0.7328  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:19:31] d2.utils.events INFO:  eta: 1:50:42  iter: 9179  total_loss: 0.4323  loss_cls: 0.1247  loss_box_reg: 0.1898  loss_rpn_cls: 0.05907  loss_rpn_loc: 0.07078  time: 0.7328  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:19:45] d2.utils.events INFO:  eta: 1:50:41  iter: 9199  total_loss: 0.4512  loss_cls: 0.1026  loss_box_reg: 0.1415  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.08947  time: 0.7327  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:20:00] d2.utils.events INFO:  eta: 1:50:25  iter: 9219  total_loss: 0.4278  loss_cls: 0.1026  loss_box_reg: 0.1648  loss_rpn_cls: 0.08333  loss_rpn_loc: 0.1107  time: 0.7327  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:20:14] d2.utils.events INFO:  eta: 1:50:12  iter: 9239  total_loss: 0.4611  loss_cls: 0.09523  loss_box_reg: 0.134  loss_rpn_cls: 0.0634  loss_rpn_loc: 0.08935  time: 0.7327  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:20:28] d2.utils.events INFO:  eta: 1:49:48  iter: 9259  total_loss: 0.3962  loss_cls: 0.08572  loss_box_reg: 0.1538  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.07917  time: 0.7326  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:20:42] d2.utils.events INFO:  eta: 1:49:06  iter: 9279  total_loss: 0.5538  loss_cls: 0.1129  loss_box_reg: 0.1855  loss_rpn_cls: 0.07409  loss_rpn_loc: 0.0843  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:20:56] d2.utils.events INFO:  eta: 1:48:41  iter: 9299  total_loss: 0.5849  loss_cls: 0.1232  loss_box_reg: 0.2125  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.1041  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:21:11] d2.utils.events INFO:  eta: 1:48:28  iter: 9319  total_loss: 0.3866  loss_cls: 0.1244  loss_box_reg: 0.1417  loss_rpn_cls: 0.06598  loss_rpn_loc: 0.05189  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:21:25] d2.utils.events INFO:  eta: 1:48:11  iter: 9339  total_loss: 0.5076  loss_cls: 0.1724  loss_box_reg: 0.1781  loss_rpn_cls: 0.07868  loss_rpn_loc: 0.07759  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:21:39] d2.utils.events INFO:  eta: 1:47:50  iter: 9359  total_loss: 0.5285  loss_cls: 0.1225  loss_box_reg: 0.1446  loss_rpn_cls: 0.079  loss_rpn_loc: 0.09389  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:21:54] d2.utils.events INFO:  eta: 1:47:18  iter: 9379  total_loss: 0.3905  loss_cls: 0.09655  loss_box_reg: 0.1219  loss_rpn_cls: 0.07493  loss_rpn_loc: 0.1223  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:22:08] d2.utils.events INFO:  eta: 1:46:34  iter: 9399  total_loss: 0.4012  loss_cls: 0.1158  loss_box_reg: 0.1429  loss_rpn_cls: 0.08468  loss_rpn_loc: 0.07565  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:22:23] d2.utils.events INFO:  eta: 1:46:48  iter: 9419  total_loss: 0.4318  loss_cls: 0.1105  loss_box_reg: 0.1255  loss_rpn_cls: 0.05723  loss_rpn_loc: 0.1064  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:22:38] d2.utils.events INFO:  eta: 1:46:26  iter: 9439  total_loss: 0.5567  loss_cls: 0.1467  loss_box_reg: 0.2202  loss_rpn_cls: 0.08804  loss_rpn_loc: 0.1079  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:22:53] d2.utils.events INFO:  eta: 1:46:15  iter: 9459  total_loss: 0.4483  loss_cls: 0.1144  loss_box_reg: 0.1568  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.1259  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:23:07] d2.utils.events INFO:  eta: 1:45:15  iter: 9479  total_loss: 0.326  loss_cls: 0.08074  loss_box_reg: 0.1023  loss_rpn_cls: 0.05606  loss_rpn_loc: 0.07575  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:23:23] d2.utils.events INFO:  eta: 1:45:05  iter: 9499  total_loss: 0.6385  loss_cls: 0.1497  loss_box_reg: 0.1723  loss_rpn_cls: 0.09634  loss_rpn_loc: 0.1305  time: 0.7324  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:23:37] d2.utils.events INFO:  eta: 1:44:50  iter: 9519  total_loss: 0.4549  loss_cls: 0.1069  loss_box_reg: 0.1463  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.06958  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:23:52] d2.utils.events INFO:  eta: 1:44:42  iter: 9539  total_loss: 0.4395  loss_cls: 0.1069  loss_box_reg: 0.1743  loss_rpn_cls: 0.06924  loss_rpn_loc: 0.06753  time: 0.7324  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:24:06] d2.utils.events INFO:  eta: 1:44:20  iter: 9559  total_loss: 0.4251  loss_cls: 0.104  loss_box_reg: 0.1207  loss_rpn_cls: 0.06616  loss_rpn_loc: 0.07568  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:24:20] d2.utils.events INFO:  eta: 1:44:06  iter: 9579  total_loss: 0.427  loss_cls: 0.1088  loss_box_reg: 0.1757  loss_rpn_cls: 0.06059  loss_rpn_loc: 0.06515  time: 0.7322  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:24:36] d2.utils.events INFO:  eta: 1:44:26  iter: 9599  total_loss: 0.568  loss_cls: 0.1425  loss_box_reg: 0.1781  loss_rpn_cls: 0.07878  loss_rpn_loc: 0.09403  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:24:51] d2.utils.events INFO:  eta: 1:44:33  iter: 9619  total_loss: 0.5413  loss_cls: 0.1265  loss_box_reg: 0.1921  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1043  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:25:06] d2.utils.events INFO:  eta: 1:44:11  iter: 9639  total_loss: 0.4922  loss_cls: 0.1015  loss_box_reg: 0.1637  loss_rpn_cls: 0.07532  loss_rpn_loc: 0.1052  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:25:21] d2.utils.events INFO:  eta: 1:43:56  iter: 9659  total_loss: 0.542  loss_cls: 0.1264  loss_box_reg: 0.2098  loss_rpn_cls: 0.07364  loss_rpn_loc: 0.05568  time: 0.7325  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:25:36] d2.utils.events INFO:  eta: 1:43:49  iter: 9679  total_loss: 0.4239  loss_cls: 0.08864  loss_box_reg: 0.1476  loss_rpn_cls: 0.06324  loss_rpn_loc: 0.09227  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:25:52] d2.utils.events INFO:  eta: 1:43:38  iter: 9699  total_loss: 0.484  loss_cls: 0.1305  loss_box_reg: 0.1694  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.1085  time: 0.7326  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:26:07] d2.utils.events INFO:  eta: 1:43:33  iter: 9719  total_loss: 0.5226  loss_cls: 0.125  loss_box_reg: 0.1741  loss_rpn_cls: 0.06444  loss_rpn_loc: 0.1529  time: 0.7327  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:26:21] d2.utils.events INFO:  eta: 1:43:14  iter: 9739  total_loss: 0.4454  loss_cls: 0.121  loss_box_reg: 0.1555  loss_rpn_cls: 0.07692  loss_rpn_loc: 0.06318  time: 0.7326  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:26:35] d2.utils.events INFO:  eta: 1:42:45  iter: 9759  total_loss: 0.387  loss_cls: 0.08681  loss_box_reg: 0.1589  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.06591  time: 0.7325  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:26:50] d2.utils.events INFO:  eta: 1:42:26  iter: 9779  total_loss: 0.5452  loss_cls: 0.1351  loss_box_reg: 0.2217  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.101  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:27:05] d2.utils.events INFO:  eta: 1:42:15  iter: 9799  total_loss: 0.4127  loss_cls: 0.1165  loss_box_reg: 0.1472  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.09154  time: 0.7325  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:27:19] d2.utils.events INFO:  eta: 1:41:53  iter: 9819  total_loss: 0.3438  loss_cls: 0.07986  loss_box_reg: 0.1213  loss_rpn_cls: 0.05316  loss_rpn_loc: 0.0723  time: 0.7326  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:27:35] d2.utils.events INFO:  eta: 1:41:38  iter: 9839  total_loss: 0.5063  loss_cls: 0.1298  loss_box_reg: 0.1822  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.105  time: 0.7326  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:27:49] d2.utils.events INFO:  eta: 1:41:22  iter: 9859  total_loss: 0.397  loss_cls: 0.09098  loss_box_reg: 0.1207  loss_rpn_cls: 0.08968  loss_rpn_loc: 0.067  time: 0.7326  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:28:03] d2.utils.events INFO:  eta: 1:40:27  iter: 9879  total_loss: 0.3558  loss_cls: 0.08641  loss_box_reg: 0.1285  loss_rpn_cls: 0.04927  loss_rpn_loc: 0.06018  time: 0.7325  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:28:16] d2.utils.events INFO:  eta: 1:39:39  iter: 9899  total_loss: 0.3365  loss_cls: 0.09393  loss_box_reg: 0.1146  loss_rpn_cls: 0.07375  loss_rpn_loc: 0.09739  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:28:30] d2.utils.events INFO:  eta: 1:39:15  iter: 9919  total_loss: 0.5172  loss_cls: 0.08979  loss_box_reg: 0.1493  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.112  time: 0.7323  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:28:46] d2.utils.events INFO:  eta: 1:39:26  iter: 9939  total_loss: 0.4103  loss_cls: 0.08917  loss_box_reg: 0.1407  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.1124  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:29:01] d2.utils.events INFO:  eta: 1:39:18  iter: 9959  total_loss: 0.4914  loss_cls: 0.1263  loss_box_reg: 0.1547  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.08162  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:29:15] d2.utils.events INFO:  eta: 1:39:03  iter: 9979  total_loss: 0.3226  loss_cls: 0.08965  loss_box_reg: 0.1069  loss_rpn_cls: 0.05898  loss_rpn_loc: 0.1014  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:29:30] d2.utils.events INFO:  eta: 1:39:04  iter: 9999  total_loss: 0.4382  loss_cls: 0.11  loss_box_reg: 0.1443  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.07984  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:29:45] d2.utils.events INFO:  eta: 1:38:52  iter: 10019  total_loss: 0.3944  loss_cls: 0.1032  loss_box_reg: 0.1188  loss_rpn_cls: 0.05442  loss_rpn_loc: 0.08218  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:29:59] d2.utils.events INFO:  eta: 1:38:24  iter: 10039  total_loss: 0.4346  loss_cls: 0.1046  loss_box_reg: 0.1517  loss_rpn_cls: 0.06012  loss_rpn_loc: 0.09067  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:30:13] d2.utils.events INFO:  eta: 1:37:41  iter: 10059  total_loss: 0.4495  loss_cls: 0.1124  loss_box_reg: 0.172  loss_rpn_cls: 0.07213  loss_rpn_loc: 0.07445  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:30:28] d2.utils.events INFO:  eta: 1:37:16  iter: 10079  total_loss: 0.4946  loss_cls: 0.1061  loss_box_reg: 0.1605  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1038  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:30:42] d2.utils.events INFO:  eta: 1:36:35  iter: 10099  total_loss: 0.4273  loss_cls: 0.09971  loss_box_reg: 0.1461  loss_rpn_cls: 0.05545  loss_rpn_loc: 0.07228  time: 0.7322  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:30:57] d2.utils.events INFO:  eta: 1:36:14  iter: 10119  total_loss: 0.5772  loss_cls: 0.1491  loss_box_reg: 0.2181  loss_rpn_cls: 0.06545  loss_rpn_loc: 0.0936  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:31:12] d2.utils.events INFO:  eta: 1:35:50  iter: 10139  total_loss: 0.5254  loss_cls: 0.1304  loss_box_reg: 0.1481  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.1378  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:31:27] d2.utils.events INFO:  eta: 1:35:45  iter: 10159  total_loss: 0.5048  loss_cls: 0.1253  loss_box_reg: 0.1693  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.1079  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:31:42] d2.utils.events INFO:  eta: 1:35:48  iter: 10179  total_loss: 0.4174  loss_cls: 0.1103  loss_box_reg: 0.158  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.08097  time: 0.7324  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:31:57] d2.utils.events INFO:  eta: 1:35:36  iter: 10199  total_loss: 0.4594  loss_cls: 0.1289  loss_box_reg: 0.2054  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.06759  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:32:11] d2.utils.events INFO:  eta: 1:35:19  iter: 10219  total_loss: 0.3358  loss_cls: 0.083  loss_box_reg: 0.1061  loss_rpn_cls: 0.0506  loss_rpn_loc: 0.07378  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:32:26] d2.utils.events INFO:  eta: 1:35:28  iter: 10239  total_loss: 0.3814  loss_cls: 0.08024  loss_box_reg: 0.1192  loss_rpn_cls: 0.04103  loss_rpn_loc: 0.0776  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:32:41] d2.utils.events INFO:  eta: 1:35:14  iter: 10259  total_loss: 0.4653  loss_cls: 0.13  loss_box_reg: 0.1793  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.08927  time: 0.7324  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:32:55] d2.utils.events INFO:  eta: 1:35:02  iter: 10279  total_loss: 0.4969  loss_cls: 0.1182  loss_box_reg: 0.1614  loss_rpn_cls: 0.07955  loss_rpn_loc: 0.0955  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:33:10] d2.utils.events INFO:  eta: 1:34:55  iter: 10299  total_loss: 0.6227  loss_cls: 0.2089  loss_box_reg: 0.2438  loss_rpn_cls: 0.08062  loss_rpn_loc: 0.1206  time: 0.7323  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:33:25] d2.utils.events INFO:  eta: 1:35:02  iter: 10319  total_loss: 0.4264  loss_cls: 0.1141  loss_box_reg: 0.1201  loss_rpn_cls: 0.09688  loss_rpn_loc: 0.08258  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:33:39] d2.utils.events INFO:  eta: 1:34:52  iter: 10339  total_loss: 0.3966  loss_cls: 0.1116  loss_box_reg: 0.1161  loss_rpn_cls: 0.05219  loss_rpn_loc: 0.05543  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:33:55] d2.utils.events INFO:  eta: 1:34:54  iter: 10359  total_loss: 0.4738  loss_cls: 0.1157  loss_box_reg: 0.1317  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.07706  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:34:09] d2.utils.events INFO:  eta: 1:34:33  iter: 10379  total_loss: 0.4305  loss_cls: 0.1068  loss_box_reg: 0.1837  loss_rpn_cls: 0.04275  loss_rpn_loc: 0.07298  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:34:23] d2.utils.events INFO:  eta: 1:34:28  iter: 10399  total_loss: 0.436  loss_cls: 0.1028  loss_box_reg: 0.1526  loss_rpn_cls: 0.0479  loss_rpn_loc: 0.08567  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:34:38] d2.utils.events INFO:  eta: 1:34:13  iter: 10419  total_loss: 0.4567  loss_cls: 0.1259  loss_box_reg: 0.1374  loss_rpn_cls: 0.05162  loss_rpn_loc: 0.09945  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:34:53] d2.utils.events INFO:  eta: 1:33:58  iter: 10439  total_loss: 0.4252  loss_cls: 0.1113  loss_box_reg: 0.1396  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.1219  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:35:08] d2.utils.events INFO:  eta: 1:33:33  iter: 10459  total_loss: 0.4422  loss_cls: 0.1337  loss_box_reg: 0.1665  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.1101  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:35:22] d2.utils.events INFO:  eta: 1:33:28  iter: 10479  total_loss: 0.3794  loss_cls: 0.103  loss_box_reg: 0.1318  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.06479  time: 0.7324  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:35:37] d2.utils.events INFO:  eta: 1:32:53  iter: 10499  total_loss: 0.5227  loss_cls: 0.1187  loss_box_reg: 0.1752  loss_rpn_cls: 0.07637  loss_rpn_loc: 0.1138  time: 0.7324  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:35:52] d2.utils.events INFO:  eta: 1:32:53  iter: 10519  total_loss: 0.6174  loss_cls: 0.142  loss_box_reg: 0.2639  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.1057  time: 0.7324  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:36:07] d2.utils.events INFO:  eta: 1:32:25  iter: 10539  total_loss: 0.5047  loss_cls: 0.1183  loss_box_reg: 0.1605  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.07967  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:36:21] d2.utils.events INFO:  eta: 1:32:11  iter: 10559  total_loss: 0.3465  loss_cls: 0.08961  loss_box_reg: 0.1079  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.08306  time: 0.7324  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:36:35] d2.utils.events INFO:  eta: 1:32:08  iter: 10579  total_loss: 0.3767  loss_cls: 0.1078  loss_box_reg: 0.1534  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.08145  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:36:50] d2.utils.events INFO:  eta: 1:31:44  iter: 10599  total_loss: 0.37  loss_cls: 0.09133  loss_box_reg: 0.1457  loss_rpn_cls: 0.0442  loss_rpn_loc: 0.06307  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:37:04] d2.utils.events INFO:  eta: 1:31:19  iter: 10619  total_loss: 0.4771  loss_cls: 0.1156  loss_box_reg: 0.1592  loss_rpn_cls: 0.05788  loss_rpn_loc: 0.05125  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:37:19] d2.utils.events INFO:  eta: 1:30:57  iter: 10639  total_loss: 0.4957  loss_cls: 0.1448  loss_box_reg: 0.1879  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.07949  time: 0.7323  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:37:34] d2.utils.events INFO:  eta: 1:30:52  iter: 10659  total_loss: 0.4256  loss_cls: 0.123  loss_box_reg: 0.1299  loss_rpn_cls: 0.04054  loss_rpn_loc: 0.0958  time: 0.7323  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:37:48] d2.utils.events INFO:  eta: 1:30:19  iter: 10679  total_loss: 0.3609  loss_cls: 0.09729  loss_box_reg: 0.1403  loss_rpn_cls: 0.04266  loss_rpn_loc: 0.07654  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:38:02] d2.utils.events INFO:  eta: 1:29:56  iter: 10699  total_loss: 0.3877  loss_cls: 0.09334  loss_box_reg: 0.124  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.07722  time: 0.7322  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:38:17] d2.utils.events INFO:  eta: 1:29:39  iter: 10719  total_loss: 0.4171  loss_cls: 0.1127  loss_box_reg: 0.1467  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.07702  time: 0.7322  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:38:32] d2.utils.events INFO:  eta: 1:29:26  iter: 10739  total_loss: 0.4432  loss_cls: 0.1042  loss_box_reg: 0.1274  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.08414  time: 0.7322  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:38:46] d2.utils.events INFO:  eta: 1:29:18  iter: 10759  total_loss: 0.4241  loss_cls: 0.1086  loss_box_reg: 0.169  loss_rpn_cls: 0.04891  loss_rpn_loc: 0.05977  time: 0.7322  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:39:01] d2.utils.events INFO:  eta: 1:29:03  iter: 10779  total_loss: 0.4467  loss_cls: 0.1122  loss_box_reg: 0.1515  loss_rpn_cls: 0.07485  loss_rpn_loc: 0.1125  time: 0.7322  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:39:16] d2.utils.events INFO:  eta: 1:28:48  iter: 10799  total_loss: 0.448  loss_cls: 0.0944  loss_box_reg: 0.1652  loss_rpn_cls: 0.05646  loss_rpn_loc: 0.06819  time: 0.7322  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:39:30] d2.utils.events INFO:  eta: 1:28:35  iter: 10819  total_loss: 0.5704  loss_cls: 0.1346  loss_box_reg: 0.1775  loss_rpn_cls: 0.09736  loss_rpn_loc: 0.1106  time: 0.7322  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:39:45] d2.utils.events INFO:  eta: 1:28:21  iter: 10839  total_loss: 0.5479  loss_cls: 0.1256  loss_box_reg: 0.1724  loss_rpn_cls: 0.08043  loss_rpn_loc: 0.07414  time: 0.7322  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:39:59] d2.utils.events INFO:  eta: 1:27:57  iter: 10859  total_loss: 0.3453  loss_cls: 0.1049  loss_box_reg: 0.127  loss_rpn_cls: 0.04144  loss_rpn_loc: 0.08152  time: 0.7321  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:40:13] d2.utils.events INFO:  eta: 1:27:46  iter: 10879  total_loss: 0.3981  loss_cls: 0.1066  loss_box_reg: 0.1421  loss_rpn_cls: 0.08896  loss_rpn_loc: 0.09461  time: 0.7321  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:40:27] d2.utils.events INFO:  eta: 1:27:38  iter: 10899  total_loss: 0.4152  loss_cls: 0.1001  loss_box_reg: 0.1436  loss_rpn_cls: 0.07472  loss_rpn_loc: 0.09568  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:40:42] d2.utils.events INFO:  eta: 1:27:30  iter: 10919  total_loss: 0.3895  loss_cls: 0.0852  loss_box_reg: 0.1363  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.1015  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:40:56] d2.utils.events INFO:  eta: 1:27:06  iter: 10939  total_loss: 0.5049  loss_cls: 0.1249  loss_box_reg: 0.1381  loss_rpn_cls: 0.07702  loss_rpn_loc: 0.0967  time: 0.7320  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:41:11] d2.utils.events INFO:  eta: 1:26:47  iter: 10959  total_loss: 0.3481  loss_cls: 0.07463  loss_box_reg: 0.1176  loss_rpn_cls: 0.09914  loss_rpn_loc: 0.06325  time: 0.7320  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:41:27] d2.utils.events INFO:  eta: 1:26:37  iter: 10979  total_loss: 0.5766  loss_cls: 0.1417  loss_box_reg: 0.1964  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.1183  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:41:41] d2.utils.events INFO:  eta: 1:26:20  iter: 10999  total_loss: 0.4426  loss_cls: 0.109  loss_box_reg: 0.1518  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.0788  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:41:55] d2.utils.events INFO:  eta: 1:25:58  iter: 11019  total_loss: 0.5342  loss_cls: 0.1471  loss_box_reg: 0.1783  loss_rpn_cls: 0.09763  loss_rpn_loc: 0.05717  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:42:10] d2.utils.events INFO:  eta: 1:25:51  iter: 11039  total_loss: 0.4405  loss_cls: 0.09755  loss_box_reg: 0.1501  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.08647  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:42:24] d2.utils.events INFO:  eta: 1:25:39  iter: 11059  total_loss: 0.5079  loss_cls: 0.1357  loss_box_reg: 0.2173  loss_rpn_cls: 0.06204  loss_rpn_loc: 0.06061  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:42:39] d2.utils.events INFO:  eta: 1:25:24  iter: 11079  total_loss: 0.3391  loss_cls: 0.09531  loss_box_reg: 0.1126  loss_rpn_cls: 0.06736  loss_rpn_loc: 0.08478  time: 0.7320  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:42:55] d2.utils.events INFO:  eta: 1:25:46  iter: 11099  total_loss: 0.5016  loss_cls: 0.1315  loss_box_reg: 0.166  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.09626  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:43:09] d2.utils.events INFO:  eta: 1:25:22  iter: 11119  total_loss: 0.3972  loss_cls: 0.08529  loss_box_reg: 0.1129  loss_rpn_cls: 0.06829  loss_rpn_loc: 0.1017  time: 0.7321  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:43:24] d2.utils.events INFO:  eta: 1:24:54  iter: 11139  total_loss: 0.4566  loss_cls: 0.1158  loss_box_reg: 0.138  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.09516  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:43:39] d2.utils.events INFO:  eta: 1:24:39  iter: 11159  total_loss: 0.4389  loss_cls: 0.113  loss_box_reg: 0.1349  loss_rpn_cls: 0.07349  loss_rpn_loc: 0.1014  time: 0.7321  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:43:53] d2.utils.events INFO:  eta: 1:24:19  iter: 11179  total_loss: 0.5913  loss_cls: 0.1436  loss_box_reg: 0.1996  loss_rpn_cls: 0.09271  loss_rpn_loc: 0.118  time: 0.7321  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:44:07] d2.utils.events INFO:  eta: 1:23:59  iter: 11199  total_loss: 0.4542  loss_cls: 0.1173  loss_box_reg: 0.1587  loss_rpn_cls: 0.07154  loss_rpn_loc: 0.09689  time: 0.7320  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:44:21] d2.utils.events INFO:  eta: 1:23:39  iter: 11219  total_loss: 0.3935  loss_cls: 0.0965  loss_box_reg: 0.1316  loss_rpn_cls: 0.07132  loss_rpn_loc: 0.09602  time: 0.7319  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:44:35] d2.utils.events INFO:  eta: 1:23:15  iter: 11239  total_loss: 0.5018  loss_cls: 0.1154  loss_box_reg: 0.1885  loss_rpn_cls: 0.07582  loss_rpn_loc: 0.07809  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:44:50] d2.utils.events INFO:  eta: 1:23:08  iter: 11259  total_loss: 0.389  loss_cls: 0.08796  loss_box_reg: 0.1199  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.08509  time: 0.7319  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:45:04] d2.utils.events INFO:  eta: 1:22:49  iter: 11279  total_loss: 0.3034  loss_cls: 0.07832  loss_box_reg: 0.1261  loss_rpn_cls: 0.06648  loss_rpn_loc: 0.07021  time: 0.7318  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:45:18] d2.utils.events INFO:  eta: 1:22:30  iter: 11299  total_loss: 0.4099  loss_cls: 0.08608  loss_box_reg: 0.1256  loss_rpn_cls: 0.05314  loss_rpn_loc: 0.07232  time: 0.7318  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:45:33] d2.utils.events INFO:  eta: 1:22:00  iter: 11319  total_loss: 0.3962  loss_cls: 0.08649  loss_box_reg: 0.1172  loss_rpn_cls: 0.07926  loss_rpn_loc: 0.08839  time: 0.7318  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:45:47] d2.utils.events INFO:  eta: 1:21:45  iter: 11339  total_loss: 0.533  loss_cls: 0.1056  loss_box_reg: 0.1798  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.09382  time: 0.7317  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:46:01] d2.utils.events INFO:  eta: 1:21:28  iter: 11359  total_loss: 0.3291  loss_cls: 0.0715  loss_box_reg: 0.1004  loss_rpn_cls: 0.04434  loss_rpn_loc: 0.05244  time: 0.7317  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:46:16] d2.utils.events INFO:  eta: 1:21:15  iter: 11379  total_loss: 0.4062  loss_cls: 0.1039  loss_box_reg: 0.1294  loss_rpn_cls: 0.05128  loss_rpn_loc: 0.09376  time: 0.7317  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:46:30] d2.utils.events INFO:  eta: 1:20:59  iter: 11399  total_loss: 0.3698  loss_cls: 0.08128  loss_box_reg: 0.1125  loss_rpn_cls: 0.05149  loss_rpn_loc: 0.1164  time: 0.7317  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:46:44] d2.utils.events INFO:  eta: 1:20:45  iter: 11419  total_loss: 0.3674  loss_cls: 0.1119  loss_box_reg: 0.1283  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.06741  time: 0.7316  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:46:59] d2.utils.events INFO:  eta: 1:20:31  iter: 11439  total_loss: 0.5471  loss_cls: 0.1146  loss_box_reg: 0.169  loss_rpn_cls: 0.07904  loss_rpn_loc: 0.09367  time: 0.7317  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:47:14] d2.utils.events INFO:  eta: 1:20:27  iter: 11459  total_loss: 0.4318  loss_cls: 0.1157  loss_box_reg: 0.1268  loss_rpn_cls: 0.0858  loss_rpn_loc: 0.07201  time: 0.7317  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:47:29] d2.utils.events INFO:  eta: 1:20:17  iter: 11479  total_loss: 0.4198  loss_cls: 0.09627  loss_box_reg: 0.1607  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.0637  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:47:43] d2.utils.events INFO:  eta: 1:20:06  iter: 11499  total_loss: 0.5182  loss_cls: 0.1406  loss_box_reg: 0.2076  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.1042  time: 0.7317  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:47:58] d2.utils.events INFO:  eta: 1:19:32  iter: 11519  total_loss: 0.43  loss_cls: 0.1285  loss_box_reg: 0.1925  loss_rpn_cls: 0.05702  loss_rpn_loc: 0.06989  time: 0.7316  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:48:12] d2.utils.events INFO:  eta: 1:19:14  iter: 11539  total_loss: 0.3969  loss_cls: 0.1172  loss_box_reg: 0.1298  loss_rpn_cls: 0.06669  loss_rpn_loc: 0.08711  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:48:26] d2.utils.events INFO:  eta: 1:18:49  iter: 11559  total_loss: 0.3957  loss_cls: 0.1163  loss_box_reg: 0.1597  loss_rpn_cls: 0.04888  loss_rpn_loc: 0.05657  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:48:41] d2.utils.events INFO:  eta: 1:18:48  iter: 11579  total_loss: 0.466  loss_cls: 0.1119  loss_box_reg: 0.1843  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1008  time: 0.7316  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:48:56] d2.utils.events INFO:  eta: 1:18:38  iter: 11599  total_loss: 0.3972  loss_cls: 0.08305  loss_box_reg: 0.1176  loss_rpn_cls: 0.06335  loss_rpn_loc: 0.08815  time: 0.7316  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:49:10] d2.utils.events INFO:  eta: 1:18:19  iter: 11619  total_loss: 0.3712  loss_cls: 0.09194  loss_box_reg: 0.1391  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.08316  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:49:25] d2.utils.events INFO:  eta: 1:18:16  iter: 11639  total_loss: 0.4383  loss_cls: 0.1153  loss_box_reg: 0.1521  loss_rpn_cls: 0.05469  loss_rpn_loc: 0.08597  time: 0.7315  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:49:39] d2.utils.events INFO:  eta: 1:17:50  iter: 11659  total_loss: 0.4381  loss_cls: 0.1061  loss_box_reg: 0.1122  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.1117  time: 0.7315  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:49:54] d2.utils.events INFO:  eta: 1:17:39  iter: 11679  total_loss: 0.4131  loss_cls: 0.1129  loss_box_reg: 0.1693  loss_rpn_cls: 0.07574  loss_rpn_loc: 0.06545  time: 0.7315  data_time: 0.0022  lr: 0.0002  max_mem: 15389M
[01/29 18:50:08] d2.utils.events INFO:  eta: 1:17:32  iter: 11699  total_loss: 0.4227  loss_cls: 0.1062  loss_box_reg: 0.1458  loss_rpn_cls: 0.03802  loss_rpn_loc: 0.0772  time: 0.7315  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:50:23] d2.utils.events INFO:  eta: 1:17:16  iter: 11719  total_loss: 0.4829  loss_cls: 0.1173  loss_box_reg: 0.14  loss_rpn_cls: 0.07419  loss_rpn_loc: 0.09408  time: 0.7315  data_time: 0.0026  lr: 0.0002  max_mem: 15389M
[01/29 18:50:37] d2.utils.events INFO:  eta: 1:16:53  iter: 11739  total_loss: 0.5382  loss_cls: 0.1232  loss_box_reg: 0.162  loss_rpn_cls: 0.08157  loss_rpn_loc: 0.08341  time: 0.7314  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:50:51] d2.utils.events INFO:  eta: 1:16:35  iter: 11759  total_loss: 0.4171  loss_cls: 0.1307  loss_box_reg: 0.1507  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.05737  time: 0.7314  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:51:06] d2.utils.events INFO:  eta: 1:16:14  iter: 11779  total_loss: 0.3932  loss_cls: 0.09329  loss_box_reg: 0.1121  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.0831  time: 0.7314  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:51:20] d2.utils.events INFO:  eta: 1:15:53  iter: 11799  total_loss: 0.43  loss_cls: 0.1243  loss_box_reg: 0.1449  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.07251  time: 0.7314  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:51:34] d2.utils.events INFO:  eta: 1:15:33  iter: 11819  total_loss: 0.4137  loss_cls: 0.09737  loss_box_reg: 0.1488  loss_rpn_cls: 0.05531  loss_rpn_loc: 0.1073  time: 0.7314  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:51:49] d2.utils.events INFO:  eta: 1:15:19  iter: 11839  total_loss: 0.3763  loss_cls: 0.08262  loss_box_reg: 0.1346  loss_rpn_cls: 0.03233  loss_rpn_loc: 0.1082  time: 0.7314  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:52:05] d2.utils.events INFO:  eta: 1:15:22  iter: 11859  total_loss: 0.3626  loss_cls: 0.1  loss_box_reg: 0.1063  loss_rpn_cls: 0.06112  loss_rpn_loc: 0.08237  time: 0.7314  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:52:20] d2.utils.events INFO:  eta: 1:15:19  iter: 11879  total_loss: 0.4166  loss_cls: 0.1103  loss_box_reg: 0.1267  loss_rpn_cls: 0.06385  loss_rpn_loc: 0.07106  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:52:35] d2.utils.events INFO:  eta: 1:15:07  iter: 11899  total_loss: 0.4071  loss_cls: 0.08494  loss_box_reg: 0.1474  loss_rpn_cls: 0.05879  loss_rpn_loc: 0.0807  time: 0.7315  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:52:48] d2.utils.events INFO:  eta: 1:14:50  iter: 11919  total_loss: 0.3821  loss_cls: 0.1021  loss_box_reg: 0.1377  loss_rpn_cls: 0.04826  loss_rpn_loc: 0.0597  time: 0.7314  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:53:04] d2.utils.events INFO:  eta: 1:14:40  iter: 11939  total_loss: 0.4395  loss_cls: 0.1324  loss_box_reg: 0.164  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.0475  time: 0.7314  data_time: 0.0024  lr: 0.0002  max_mem: 15389M
[01/29 18:53:17] d2.utils.events INFO:  eta: 1:14:19  iter: 11959  total_loss: 0.3935  loss_cls: 0.1095  loss_box_reg: 0.1695  loss_rpn_cls: 0.06214  loss_rpn_loc: 0.08075  time: 0.7313  data_time: 0.0021  lr: 0.0002  max_mem: 15389M
[01/29 18:53:32] d2.utils.events INFO:  eta: 1:13:56  iter: 11979  total_loss: 0.3883  loss_cls: 0.1129  loss_box_reg: 0.165  loss_rpn_cls: 0.07069  loss_rpn_loc: 0.09063  time: 0.7313  data_time: 0.0023  lr: 0.0002  max_mem: 15389M
[01/29 18:53:46] d2.utils.events INFO:  eta: 1:13:47  iter: 11999  total_loss: 0.4204  loss_cls: 0.1078  loss_box_reg: 0.1266  loss_rpn_cls: 0.06773  loss_rpn_loc: 0.08565  time: 0.7313  data_time: 0.0025  lr: 0.0002  max_mem: 15389M
[01/29 18:54:01] d2.utils.events INFO:  eta: 1:13:35  iter: 12019  total_loss: 0.3502  loss_cls: 0.07612  loss_box_reg: 0.1256  loss_rpn_cls: 0.0452  loss_rpn_loc: 0.09196  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:54:16] d2.utils.events INFO:  eta: 1:13:26  iter: 12039  total_loss: 0.3704  loss_cls: 0.08277  loss_box_reg: 0.1079  loss_rpn_cls: 0.05224  loss_rpn_loc: 0.1039  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:54:31] d2.utils.events INFO:  eta: 1:13:19  iter: 12059  total_loss: 0.3549  loss_cls: 0.09542  loss_box_reg: 0.1145  loss_rpn_cls: 0.05194  loss_rpn_loc: 0.08255  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:54:46] d2.utils.events INFO:  eta: 1:13:12  iter: 12079  total_loss: 0.4444  loss_cls: 0.07815  loss_box_reg: 0.1333  loss_rpn_cls: 0.0547  loss_rpn_loc: 0.07254  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 18:55:00] d2.utils.events INFO:  eta: 1:12:30  iter: 12099  total_loss: 0.3821  loss_cls: 0.0874  loss_box_reg: 0.1477  loss_rpn_cls: 0.06552  loss_rpn_loc: 0.08397  time: 0.7314  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 18:55:15] d2.utils.events INFO:  eta: 1:12:16  iter: 12119  total_loss: 0.3846  loss_cls: 0.08768  loss_box_reg: 0.1325  loss_rpn_cls: 0.05755  loss_rpn_loc: 0.09487  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 18:55:30] d2.utils.events INFO:  eta: 1:12:06  iter: 12139  total_loss: 0.4982  loss_cls: 0.07962  loss_box_reg: 0.1194  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.08696  time: 0.7314  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 18:55:45] d2.utils.events INFO:  eta: 1:11:53  iter: 12159  total_loss: 0.4267  loss_cls: 0.1146  loss_box_reg: 0.1587  loss_rpn_cls: 0.05196  loss_rpn_loc: 0.08867  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:56:00] d2.utils.events INFO:  eta: 1:11:40  iter: 12179  total_loss: 0.4547  loss_cls: 0.1049  loss_box_reg: 0.1708  loss_rpn_cls: 0.06929  loss_rpn_loc: 0.1026  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:56:16] d2.utils.events INFO:  eta: 1:11:47  iter: 12199  total_loss: 0.4557  loss_cls: 0.09638  loss_box_reg: 0.1136  loss_rpn_cls: 0.05688  loss_rpn_loc: 0.1102  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 18:56:30] d2.utils.events INFO:  eta: 1:11:41  iter: 12219  total_loss: 0.3769  loss_cls: 0.09134  loss_box_reg: 0.1263  loss_rpn_cls: 0.04065  loss_rpn_loc: 0.06764  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:56:43] d2.utils.events INFO:  eta: 1:11:15  iter: 12239  total_loss: 0.4838  loss_cls: 0.1166  loss_box_reg: 0.1817  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.1137  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 18:56:58] d2.utils.events INFO:  eta: 1:11:00  iter: 12259  total_loss: 0.3805  loss_cls: 0.08725  loss_box_reg: 0.1093  loss_rpn_cls: 0.06919  loss_rpn_loc: 0.08255  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:57:12] d2.utils.events INFO:  eta: 1:10:48  iter: 12279  total_loss: 0.5124  loss_cls: 0.1153  loss_box_reg: 0.2072  loss_rpn_cls: 0.05098  loss_rpn_loc: 0.09362  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:57:27] d2.utils.events INFO:  eta: 1:10:39  iter: 12299  total_loss: 0.362  loss_cls: 0.09181  loss_box_reg: 0.1295  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.07474  time: 0.7314  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 18:57:42] d2.utils.events INFO:  eta: 1:10:30  iter: 12319  total_loss: 0.4099  loss_cls: 0.08996  loss_box_reg: 0.1388  loss_rpn_cls: 0.05814  loss_rpn_loc: 0.09666  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 18:57:57] d2.utils.events INFO:  eta: 1:10:15  iter: 12339  total_loss: 0.3703  loss_cls: 0.09036  loss_box_reg: 0.126  loss_rpn_cls: 0.05242  loss_rpn_loc: 0.09081  time: 0.7314  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 18:58:11] d2.utils.events INFO:  eta: 1:09:56  iter: 12359  total_loss: 0.4087  loss_cls: 0.1067  loss_box_reg: 0.1564  loss_rpn_cls: 0.04967  loss_rpn_loc: 0.05695  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:58:27] d2.utils.events INFO:  eta: 1:09:47  iter: 12379  total_loss: 0.3718  loss_cls: 0.08031  loss_box_reg: 0.1427  loss_rpn_cls: 0.05701  loss_rpn_loc: 0.07382  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:58:41] d2.utils.events INFO:  eta: 1:09:28  iter: 12399  total_loss: 0.3076  loss_cls: 0.07355  loss_box_reg: 0.0829  loss_rpn_cls: 0.03982  loss_rpn_loc: 0.0633  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:58:56] d2.utils.events INFO:  eta: 1:09:04  iter: 12419  total_loss: 0.3887  loss_cls: 0.08547  loss_box_reg: 0.1921  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.06791  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:59:10] d2.utils.events INFO:  eta: 1:08:48  iter: 12439  total_loss: 0.4292  loss_cls: 0.1192  loss_box_reg: 0.161  loss_rpn_cls: 0.059  loss_rpn_loc: 0.06604  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 18:59:25] d2.utils.events INFO:  eta: 1:08:30  iter: 12459  total_loss: 0.4818  loss_cls: 0.1548  loss_box_reg: 0.1687  loss_rpn_cls: 0.05487  loss_rpn_loc: 0.06793  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 18:59:40] d2.utils.events INFO:  eta: 1:08:18  iter: 12479  total_loss: 0.4099  loss_cls: 0.09656  loss_box_reg: 0.1597  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.07796  time: 0.7315  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 18:59:56] d2.utils.events INFO:  eta: 1:08:12  iter: 12499  total_loss: 0.4369  loss_cls: 0.119  loss_box_reg: 0.1418  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.07077  time: 0.7315  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:00:11] d2.utils.events INFO:  eta: 1:07:59  iter: 12519  total_loss: 0.4544  loss_cls: 0.1275  loss_box_reg: 0.1902  loss_rpn_cls: 0.0497  loss_rpn_loc: 0.08095  time: 0.7316  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:00:24] d2.utils.events INFO:  eta: 1:07:44  iter: 12539  total_loss: 0.3986  loss_cls: 0.09872  loss_box_reg: 0.1644  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.05667  time: 0.7315  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:00:39] d2.utils.events INFO:  eta: 1:07:50  iter: 12559  total_loss: 0.2944  loss_cls: 0.06583  loss_box_reg: 0.1095  loss_rpn_cls: 0.0382  loss_rpn_loc: 0.06452  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:00:54] d2.utils.events INFO:  eta: 1:07:22  iter: 12579  total_loss: 0.3915  loss_cls: 0.1098  loss_box_reg: 0.1317  loss_rpn_cls: 0.0535  loss_rpn_loc: 0.06759  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:01:08] d2.utils.events INFO:  eta: 1:07:04  iter: 12599  total_loss: 0.4176  loss_cls: 0.09733  loss_box_reg: 0.1214  loss_rpn_cls: 0.06676  loss_rpn_loc: 0.1101  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:01:24] d2.utils.events INFO:  eta: 1:07:13  iter: 12619  total_loss: 0.3993  loss_cls: 0.1079  loss_box_reg: 0.1465  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.09357  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:01:38] d2.utils.events INFO:  eta: 1:06:34  iter: 12639  total_loss: 0.307  loss_cls: 0.07148  loss_box_reg: 0.1014  loss_rpn_cls: 0.03926  loss_rpn_loc: 0.08091  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:01:53] d2.utils.events INFO:  eta: 1:06:28  iter: 12659  total_loss: 0.3151  loss_cls: 0.07461  loss_box_reg: 0.09477  loss_rpn_cls: 0.05379  loss_rpn_loc: 0.08893  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:02:07] d2.utils.events INFO:  eta: 1:06:06  iter: 12679  total_loss: 0.3645  loss_cls: 0.07697  loss_box_reg: 0.1168  loss_rpn_cls: 0.05232  loss_rpn_loc: 0.07213  time: 0.7315  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:02:22] d2.utils.events INFO:  eta: 1:05:48  iter: 12699  total_loss: 0.3608  loss_cls: 0.07875  loss_box_reg: 0.1326  loss_rpn_cls: 0.04596  loss_rpn_loc: 0.07353  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:02:35] d2.utils.events INFO:  eta: 1:05:27  iter: 12719  total_loss: 0.447  loss_cls: 0.1019  loss_box_reg: 0.1695  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.0677  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:02:50] d2.utils.events INFO:  eta: 1:05:13  iter: 12739  total_loss: 0.3551  loss_cls: 0.0762  loss_box_reg: 0.1398  loss_rpn_cls: 0.05129  loss_rpn_loc: 0.0728  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:03:04] d2.utils.events INFO:  eta: 1:05:03  iter: 12759  total_loss: 0.3686  loss_cls: 0.08266  loss_box_reg: 0.1274  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.06306  time: 0.7313  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:03:19] d2.utils.events INFO:  eta: 1:04:49  iter: 12779  total_loss: 0.4017  loss_cls: 0.1016  loss_box_reg: 0.1558  loss_rpn_cls: 0.06671  loss_rpn_loc: 0.07601  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:03:34] d2.utils.events INFO:  eta: 1:04:34  iter: 12799  total_loss: 0.4161  loss_cls: 0.09307  loss_box_reg: 0.1479  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.0851  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:03:48] d2.utils.events INFO:  eta: 1:04:21  iter: 12819  total_loss: 0.4278  loss_cls: 0.08619  loss_box_reg: 0.1558  loss_rpn_cls: 0.06294  loss_rpn_loc: 0.07978  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:04:03] d2.utils.events INFO:  eta: 1:04:04  iter: 12839  total_loss: 0.3977  loss_cls: 0.0996  loss_box_reg: 0.1228  loss_rpn_cls: 0.05335  loss_rpn_loc: 0.05991  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:04:18] d2.utils.events INFO:  eta: 1:03:46  iter: 12859  total_loss: 0.4311  loss_cls: 0.1354  loss_box_reg: 0.1546  loss_rpn_cls: 0.0468  loss_rpn_loc: 0.07673  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:04:32] d2.utils.events INFO:  eta: 1:03:31  iter: 12879  total_loss: 0.4221  loss_cls: 0.1057  loss_box_reg: 0.1642  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.05234  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:04:47] d2.utils.events INFO:  eta: 1:03:13  iter: 12899  total_loss: 0.3244  loss_cls: 0.06601  loss_box_reg: 0.1132  loss_rpn_cls: 0.03861  loss_rpn_loc: 0.08882  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:05:02] d2.utils.events INFO:  eta: 1:03:05  iter: 12919  total_loss: 0.4393  loss_cls: 0.09009  loss_box_reg: 0.1359  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.08613  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:05:17] d2.utils.events INFO:  eta: 1:02:50  iter: 12939  total_loss: 0.3197  loss_cls: 0.08041  loss_box_reg: 0.1313  loss_rpn_cls: 0.04092  loss_rpn_loc: 0.06544  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:05:31] d2.utils.events INFO:  eta: 1:02:36  iter: 12959  total_loss: 0.3122  loss_cls: 0.06717  loss_box_reg: 0.1182  loss_rpn_cls: 0.03857  loss_rpn_loc: 0.08304  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:05:47] d2.utils.events INFO:  eta: 1:02:35  iter: 12979  total_loss: 0.498  loss_cls: 0.1144  loss_box_reg: 0.1654  loss_rpn_cls: 0.05577  loss_rpn_loc: 0.1171  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:06:01] d2.utils.events INFO:  eta: 1:02:07  iter: 12999  total_loss: 0.3383  loss_cls: 0.07025  loss_box_reg: 0.1181  loss_rpn_cls: 0.04151  loss_rpn_loc: 0.07188  time: 0.7314  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:06:16] d2.utils.events INFO:  eta: 1:01:52  iter: 13019  total_loss: 0.3693  loss_cls: 0.09005  loss_box_reg: 0.1254  loss_rpn_cls: 0.03974  loss_rpn_loc: 0.07727  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:06:30] d2.utils.events INFO:  eta: 1:01:33  iter: 13039  total_loss: 0.2959  loss_cls: 0.06326  loss_box_reg: 0.09094  loss_rpn_cls: 0.04783  loss_rpn_loc: 0.07854  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:06:45] d2.utils.events INFO:  eta: 1:01:20  iter: 13059  total_loss: 0.4057  loss_cls: 0.1018  loss_box_reg: 0.135  loss_rpn_cls: 0.04745  loss_rpn_loc: 0.09992  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:07:00] d2.utils.events INFO:  eta: 1:01:05  iter: 13079  total_loss: 0.3822  loss_cls: 0.1002  loss_box_reg: 0.1353  loss_rpn_cls: 0.04314  loss_rpn_loc: 0.06174  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:07:14] d2.utils.events INFO:  eta: 1:00:51  iter: 13099  total_loss: 0.3471  loss_cls: 0.09387  loss_box_reg: 0.1707  loss_rpn_cls: 0.03553  loss_rpn_loc: 0.06448  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:07:29] d2.utils.events INFO:  eta: 1:00:39  iter: 13119  total_loss: 0.4877  loss_cls: 0.1227  loss_box_reg: 0.1901  loss_rpn_cls: 0.0399  loss_rpn_loc: 0.08762  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:07:44] d2.utils.events INFO:  eta: 1:00:24  iter: 13139  total_loss: 0.4097  loss_cls: 0.09156  loss_box_reg: 0.1469  loss_rpn_cls: 0.04745  loss_rpn_loc: 0.08219  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:07:58] d2.utils.events INFO:  eta: 1:00:06  iter: 13159  total_loss: 0.3747  loss_cls: 0.1188  loss_box_reg: 0.1278  loss_rpn_cls: 0.03472  loss_rpn_loc: 0.05435  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:08:13] d2.utils.events INFO:  eta: 0:59:48  iter: 13179  total_loss: 0.5088  loss_cls: 0.1136  loss_box_reg: 0.1881  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.0742  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:08:29] d2.utils.events INFO:  eta: 0:59:34  iter: 13199  total_loss: 0.4688  loss_cls: 0.08839  loss_box_reg: 0.1564  loss_rpn_cls: 0.04701  loss_rpn_loc: 0.1135  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:08:43] d2.utils.events INFO:  eta: 0:59:21  iter: 13219  total_loss: 0.4146  loss_cls: 0.09356  loss_box_reg: 0.1404  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.06623  time: 0.7315  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:08:58] d2.utils.events INFO:  eta: 0:59:17  iter: 13239  total_loss: 0.3887  loss_cls: 0.09257  loss_box_reg: 0.1233  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.11  time: 0.7315  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:09:14] d2.utils.events INFO:  eta: 0:59:02  iter: 13259  total_loss: 0.4524  loss_cls: 0.1112  loss_box_reg: 0.1599  loss_rpn_cls: 0.04986  loss_rpn_loc: 0.09169  time: 0.7316  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:09:28] d2.utils.events INFO:  eta: 0:58:49  iter: 13279  total_loss: 0.3985  loss_cls: 0.112  loss_box_reg: 0.1483  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.08222  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:09:43] d2.utils.events INFO:  eta: 0:58:33  iter: 13299  total_loss: 0.4407  loss_cls: 0.08417  loss_box_reg: 0.1491  loss_rpn_cls: 0.03887  loss_rpn_loc: 0.09001  time: 0.7316  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:09:57] d2.utils.events INFO:  eta: 0:58:13  iter: 13319  total_loss: 0.3877  loss_cls: 0.1064  loss_box_reg: 0.1529  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.07738  time: 0.7315  data_time: 0.0027  lr: 2e-05  max_mem: 15389M
[01/29 19:10:13] d2.utils.events INFO:  eta: 0:58:05  iter: 13339  total_loss: 0.2927  loss_cls: 0.06236  loss_box_reg: 0.09282  loss_rpn_cls: 0.04196  loss_rpn_loc: 0.06966  time: 0.7316  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:10:27] d2.utils.events INFO:  eta: 0:57:51  iter: 13359  total_loss: 0.445  loss_cls: 0.09656  loss_box_reg: 0.1686  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.09344  time: 0.7316  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:10:43] d2.utils.events INFO:  eta: 0:57:33  iter: 13379  total_loss: 0.499  loss_cls: 0.1306  loss_box_reg: 0.17  loss_rpn_cls: 0.05214  loss_rpn_loc: 0.1185  time: 0.7316  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:10:57] d2.utils.events INFO:  eta: 0:57:21  iter: 13399  total_loss: 0.3168  loss_cls: 0.06559  loss_box_reg: 0.08482  loss_rpn_cls: 0.04545  loss_rpn_loc: 0.06724  time: 0.7316  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:11:11] d2.utils.events INFO:  eta: 0:57:10  iter: 13419  total_loss: 0.3889  loss_cls: 0.09439  loss_box_reg: 0.1563  loss_rpn_cls: 0.04556  loss_rpn_loc: 0.05786  time: 0.7316  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:11:27] d2.utils.events INFO:  eta: 0:57:05  iter: 13439  total_loss: 0.404  loss_cls: 0.08916  loss_box_reg: 0.121  loss_rpn_cls: 0.05901  loss_rpn_loc: 0.07536  time: 0.7317  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:11:42] d2.utils.events INFO:  eta: 0:56:52  iter: 13459  total_loss: 0.45  loss_cls: 0.1127  loss_box_reg: 0.1794  loss_rpn_cls: 0.05673  loss_rpn_loc: 0.1189  time: 0.7317  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:11:56] d2.utils.events INFO:  eta: 0:56:32  iter: 13479  total_loss: 0.4061  loss_cls: 0.08546  loss_box_reg: 0.1555  loss_rpn_cls: 0.03883  loss_rpn_loc: 0.08969  time: 0.7317  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:12:11] d2.utils.events INFO:  eta: 0:56:13  iter: 13499  total_loss: 0.4909  loss_cls: 0.1326  loss_box_reg: 0.182  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.1203  time: 0.7317  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:12:25] d2.utils.events INFO:  eta: 0:56:00  iter: 13519  total_loss: 0.3349  loss_cls: 0.05971  loss_box_reg: 0.1076  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.08176  time: 0.7317  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:12:39] d2.utils.events INFO:  eta: 0:55:43  iter: 13539  total_loss: 0.3222  loss_cls: 0.08095  loss_box_reg: 0.1272  loss_rpn_cls: 0.03146  loss_rpn_loc: 0.07269  time: 0.7316  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:12:54] d2.utils.events INFO:  eta: 0:55:21  iter: 13559  total_loss: 0.3953  loss_cls: 0.1274  loss_box_reg: 0.1495  loss_rpn_cls: 0.0582  loss_rpn_loc: 0.06506  time: 0.7316  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:13:08] d2.utils.events INFO:  eta: 0:55:04  iter: 13579  total_loss: 0.4113  loss_cls: 0.08448  loss_box_reg: 0.1284  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.09013  time: 0.7316  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:13:23] d2.utils.events INFO:  eta: 0:54:50  iter: 13599  total_loss: 0.3715  loss_cls: 0.0761  loss_box_reg: 0.1298  loss_rpn_cls: 0.04587  loss_rpn_loc: 0.07566  time: 0.7316  data_time: 0.0027  lr: 2e-05  max_mem: 15389M
[01/29 19:13:37] d2.utils.events INFO:  eta: 0:54:31  iter: 13619  total_loss: 0.3568  loss_cls: 0.08572  loss_box_reg: 0.144  loss_rpn_cls: 0.07024  loss_rpn_loc: 0.07252  time: 0.7315  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:13:52] d2.utils.events INFO:  eta: 0:54:21  iter: 13639  total_loss: 0.4188  loss_cls: 0.1029  loss_box_reg: 0.159  loss_rpn_cls: 0.04809  loss_rpn_loc: 0.07563  time: 0.7315  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:14:06] d2.utils.events INFO:  eta: 0:54:05  iter: 13659  total_loss: 0.445  loss_cls: 0.1253  loss_box_reg: 0.1862  loss_rpn_cls: 0.03201  loss_rpn_loc: 0.07501  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:14:22] d2.utils.events INFO:  eta: 0:53:55  iter: 13679  total_loss: 0.4089  loss_cls: 0.08857  loss_box_reg: 0.1282  loss_rpn_cls: 0.06744  loss_rpn_loc: 0.08019  time: 0.7316  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:14:36] d2.utils.events INFO:  eta: 0:53:42  iter: 13699  total_loss: 0.4382  loss_cls: 0.1093  loss_box_reg: 0.163  loss_rpn_cls: 0.06706  loss_rpn_loc: 0.1199  time: 0.7315  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:14:51] d2.utils.events INFO:  eta: 0:53:32  iter: 13719  total_loss: 0.4256  loss_cls: 0.09674  loss_box_reg: 0.1409  loss_rpn_cls: 0.06351  loss_rpn_loc: 0.06514  time: 0.7316  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:15:05] d2.utils.events INFO:  eta: 0:53:20  iter: 13739  total_loss: 0.4643  loss_cls: 0.1011  loss_box_reg: 0.1453  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.05762  time: 0.7315  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:15:20] d2.utils.events INFO:  eta: 0:53:02  iter: 13759  total_loss: 0.2448  loss_cls: 0.0659  loss_box_reg: 0.1013  loss_rpn_cls: 0.02739  loss_rpn_loc: 0.06247  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:15:35] d2.utils.events INFO:  eta: 0:52:47  iter: 13779  total_loss: 0.4355  loss_cls: 0.1058  loss_box_reg: 0.1897  loss_rpn_cls: 0.04801  loss_rpn_loc: 0.08201  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:15:49] d2.utils.events INFO:  eta: 0:52:31  iter: 13799  total_loss: 0.4166  loss_cls: 0.105  loss_box_reg: 0.1639  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.07878  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:16:03] d2.utils.events INFO:  eta: 0:52:12  iter: 13819  total_loss: 0.3278  loss_cls: 0.07185  loss_box_reg: 0.1527  loss_rpn_cls: 0.04307  loss_rpn_loc: 0.06021  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:16:18] d2.utils.events INFO:  eta: 0:51:57  iter: 13839  total_loss: 0.3592  loss_cls: 0.1059  loss_box_reg: 0.1309  loss_rpn_cls: 0.04672  loss_rpn_loc: 0.04063  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:16:32] d2.utils.events INFO:  eta: 0:51:42  iter: 13859  total_loss: 0.3466  loss_cls: 0.08117  loss_box_reg: 0.09912  loss_rpn_cls: 0.05026  loss_rpn_loc: 0.08644  time: 0.7315  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:16:46] d2.utils.events INFO:  eta: 0:51:27  iter: 13879  total_loss: 0.3905  loss_cls: 0.119  loss_box_reg: 0.162  loss_rpn_cls: 0.04163  loss_rpn_loc: 0.06287  time: 0.7314  data_time: 0.0021  lr: 2e-05  max_mem: 15389M
[01/29 19:17:01] d2.utils.events INFO:  eta: 0:51:12  iter: 13899  total_loss: 0.3652  loss_cls: 0.103  loss_box_reg: 0.12  loss_rpn_cls: 0.05928  loss_rpn_loc: 0.05614  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:17:16] d2.utils.events INFO:  eta: 0:50:55  iter: 13919  total_loss: 0.363  loss_cls: 0.09504  loss_box_reg: 0.1258  loss_rpn_cls: 0.04057  loss_rpn_loc: 0.09909  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:17:30] d2.utils.events INFO:  eta: 0:50:36  iter: 13939  total_loss: 0.3751  loss_cls: 0.08469  loss_box_reg: 0.1295  loss_rpn_cls: 0.05796  loss_rpn_loc: 0.1099  time: 0.7314  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:17:46] d2.utils.events INFO:  eta: 0:50:23  iter: 13959  total_loss: 0.3469  loss_cls: 0.07845  loss_box_reg: 0.1222  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.06537  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:18:01] d2.utils.events INFO:  eta: 0:50:06  iter: 13979  total_loss: 0.4039  loss_cls: 0.1026  loss_box_reg: 0.1293  loss_rpn_cls: 0.05416  loss_rpn_loc: 0.09198  time: 0.7315  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:18:15] d2.utils.events INFO:  eta: 0:49:50  iter: 13999  total_loss: 0.4276  loss_cls: 0.1007  loss_box_reg: 0.148  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.06705  time: 0.7315  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:18:30] d2.utils.events INFO:  eta: 0:49:35  iter: 14019  total_loss: 0.4233  loss_cls: 0.1056  loss_box_reg: 0.1327  loss_rpn_cls: 0.07001  loss_rpn_loc: 0.06335  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:18:44] d2.utils.events INFO:  eta: 0:49:21  iter: 14039  total_loss: 0.3634  loss_cls: 0.09188  loss_box_reg: 0.1348  loss_rpn_cls: 0.05133  loss_rpn_loc: 0.07159  time: 0.7315  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:18:59] d2.utils.events INFO:  eta: 0:49:05  iter: 14059  total_loss: 0.4557  loss_cls: 0.1081  loss_box_reg: 0.1433  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.06938  time: 0.7315  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:19:15] d2.utils.events INFO:  eta: 0:48:51  iter: 14079  total_loss: 0.5652  loss_cls: 0.148  loss_box_reg: 0.2078  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.07595  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:19:29] d2.utils.events INFO:  eta: 0:48:38  iter: 14099  total_loss: 0.3481  loss_cls: 0.08671  loss_box_reg: 0.0993  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.08181  time: 0.7315  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:19:45] d2.utils.events INFO:  eta: 0:48:27  iter: 14119  total_loss: 0.4112  loss_cls: 0.1029  loss_box_reg: 0.1573  loss_rpn_cls: 0.05157  loss_rpn_loc: 0.1081  time: 0.7316  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:19:59] d2.utils.events INFO:  eta: 0:48:08  iter: 14139  total_loss: 0.3892  loss_cls: 0.09571  loss_box_reg: 0.1237  loss_rpn_cls: 0.04838  loss_rpn_loc: 0.08109  time: 0.7316  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:20:12] d2.utils.events INFO:  eta: 0:47:50  iter: 14159  total_loss: 0.4737  loss_cls: 0.1087  loss_box_reg: 0.146  loss_rpn_cls: 0.04721  loss_rpn_loc: 0.0828  time: 0.7315  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:20:27] d2.utils.events INFO:  eta: 0:47:35  iter: 14179  total_loss: 0.4913  loss_cls: 0.1163  loss_box_reg: 0.2319  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.0997  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:20:42] d2.utils.events INFO:  eta: 0:47:19  iter: 14199  total_loss: 0.3514  loss_cls: 0.07723  loss_box_reg: 0.1082  loss_rpn_cls: 0.0417  loss_rpn_loc: 0.07057  time: 0.7315  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:20:57] d2.utils.events INFO:  eta: 0:47:04  iter: 14219  total_loss: 0.3394  loss_cls: 0.06996  loss_box_reg: 0.131  loss_rpn_cls: 0.03471  loss_rpn_loc: 0.09308  time: 0.7315  data_time: 0.0027  lr: 2e-05  max_mem: 15389M
[01/29 19:21:11] d2.utils.events INFO:  eta: 0:46:45  iter: 14239  total_loss: 0.3847  loss_cls: 0.09826  loss_box_reg: 0.1544  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.06482  time: 0.7314  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:21:25] d2.utils.events INFO:  eta: 0:46:23  iter: 14259  total_loss: 0.4385  loss_cls: 0.09772  loss_box_reg: 0.1612  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.08018  time: 0.7314  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:21:39] d2.utils.events INFO:  eta: 0:46:01  iter: 14279  total_loss: 0.4443  loss_cls: 0.1182  loss_box_reg: 0.1859  loss_rpn_cls: 0.04986  loss_rpn_loc: 0.08043  time: 0.7313  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:21:54] d2.utils.events INFO:  eta: 0:45:49  iter: 14299  total_loss: 0.4501  loss_cls: 0.1148  loss_box_reg: 0.1567  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.09903  time: 0.7314  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:22:08] d2.utils.events INFO:  eta: 0:45:32  iter: 14319  total_loss: 0.4326  loss_cls: 0.09444  loss_box_reg: 0.1186  loss_rpn_cls: 0.05546  loss_rpn_loc: 0.1168  time: 0.7313  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:22:23] d2.utils.events INFO:  eta: 0:45:08  iter: 14339  total_loss: 0.3643  loss_cls: 0.08131  loss_box_reg: 0.1065  loss_rpn_cls: 0.03787  loss_rpn_loc: 0.1117  time: 0.7313  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:22:37] d2.utils.events INFO:  eta: 0:44:50  iter: 14359  total_loss: 0.365  loss_cls: 0.0961  loss_box_reg: 0.1611  loss_rpn_cls: 0.05109  loss_rpn_loc: 0.07564  time: 0.7313  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:22:51] d2.utils.events INFO:  eta: 0:44:34  iter: 14379  total_loss: 0.4199  loss_cls: 0.08941  loss_box_reg: 0.1584  loss_rpn_cls: 0.05685  loss_rpn_loc: 0.08497  time: 0.7313  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:23:05] d2.utils.events INFO:  eta: 0:44:11  iter: 14399  total_loss: 0.406  loss_cls: 0.1112  loss_box_reg: 0.1944  loss_rpn_cls: 0.04856  loss_rpn_loc: 0.05171  time: 0.7312  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:23:20] d2.utils.events INFO:  eta: 0:43:56  iter: 14419  total_loss: 0.4019  loss_cls: 0.0944  loss_box_reg: 0.1315  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.09178  time: 0.7312  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:23:35] d2.utils.events INFO:  eta: 0:43:27  iter: 14439  total_loss: 0.3813  loss_cls: 0.1137  loss_box_reg: 0.1496  loss_rpn_cls: 0.04962  loss_rpn_loc: 0.08599  time: 0.7312  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:23:49] d2.utils.events INFO:  eta: 0:43:10  iter: 14459  total_loss: 0.2979  loss_cls: 0.07204  loss_box_reg: 0.1131  loss_rpn_cls: 0.04039  loss_rpn_loc: 0.06718  time: 0.7312  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:24:03] d2.utils.events INFO:  eta: 0:42:58  iter: 14479  total_loss: 0.2982  loss_cls: 0.07035  loss_box_reg: 0.1134  loss_rpn_cls: 0.04292  loss_rpn_loc: 0.06553  time: 0.7312  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:24:18] d2.utils.events INFO:  eta: 0:42:38  iter: 14499  total_loss: 0.302  loss_cls: 0.05104  loss_box_reg: 0.103  loss_rpn_cls: 0.03859  loss_rpn_loc: 0.08692  time: 0.7312  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:24:32] d2.utils.events INFO:  eta: 0:42:19  iter: 14519  total_loss: 0.2388  loss_cls: 0.05148  loss_box_reg: 0.08425  loss_rpn_cls: 0.02905  loss_rpn_loc: 0.0457  time: 0.7311  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:24:47] d2.utils.events INFO:  eta: 0:42:10  iter: 14539  total_loss: 0.3006  loss_cls: 0.07766  loss_box_reg: 0.1005  loss_rpn_cls: 0.04101  loss_rpn_loc: 0.06663  time: 0.7312  data_time: 0.0027  lr: 2e-05  max_mem: 15389M
[01/29 19:25:02] d2.utils.events INFO:  eta: 0:42:01  iter: 14559  total_loss: 0.5135  loss_cls: 0.1127  loss_box_reg: 0.1914  loss_rpn_cls: 0.04306  loss_rpn_loc: 0.08603  time: 0.7312  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:25:16] d2.utils.events INFO:  eta: 0:41:45  iter: 14579  total_loss: 0.3175  loss_cls: 0.08996  loss_box_reg: 0.1184  loss_rpn_cls: 0.0461  loss_rpn_loc: 0.05895  time: 0.7311  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:25:31] d2.utils.events INFO:  eta: 0:41:30  iter: 14599  total_loss: 0.3999  loss_cls: 0.08696  loss_box_reg: 0.1434  loss_rpn_cls: 0.04355  loss_rpn_loc: 0.08066  time: 0.7312  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:25:45] d2.utils.events INFO:  eta: 0:41:17  iter: 14619  total_loss: 0.3147  loss_cls: 0.05352  loss_box_reg: 0.1136  loss_rpn_cls: 0.04581  loss_rpn_loc: 0.08603  time: 0.7311  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:25:58] d2.utils.events INFO:  eta: 0:40:49  iter: 14639  total_loss: 0.2804  loss_cls: 0.07629  loss_box_reg: 0.1068  loss_rpn_cls: 0.04879  loss_rpn_loc: 0.04669  time: 0.7310  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:26:13] d2.utils.events INFO:  eta: 0:40:39  iter: 14659  total_loss: 0.3525  loss_cls: 0.07451  loss_box_reg: 0.123  loss_rpn_cls: 0.03594  loss_rpn_loc: 0.07289  time: 0.7310  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:26:28] d2.utils.events INFO:  eta: 0:40:25  iter: 14679  total_loss: 0.4588  loss_cls: 0.1001  loss_box_reg: 0.1625  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.08495  time: 0.7311  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:26:42] d2.utils.events INFO:  eta: 0:40:05  iter: 14699  total_loss: 0.3027  loss_cls: 0.08771  loss_box_reg: 0.11  loss_rpn_cls: 0.02779  loss_rpn_loc: 0.0582  time: 0.7310  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:26:56] d2.utils.events INFO:  eta: 0:39:45  iter: 14719  total_loss: 0.3577  loss_cls: 0.08329  loss_box_reg: 0.1302  loss_rpn_cls: 0.04624  loss_rpn_loc: 0.05583  time: 0.7309  data_time: 0.0021  lr: 2e-05  max_mem: 15389M
[01/29 19:27:10] d2.utils.events INFO:  eta: 0:39:34  iter: 14739  total_loss: 0.2737  loss_cls: 0.07911  loss_box_reg: 0.1068  loss_rpn_cls: 0.03683  loss_rpn_loc: 0.06513  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:27:24] d2.utils.events INFO:  eta: 0:39:21  iter: 14759  total_loss: 0.4681  loss_cls: 0.09162  loss_box_reg: 0.1857  loss_rpn_cls: 0.05278  loss_rpn_loc: 0.1264  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:27:39] d2.utils.events INFO:  eta: 0:39:07  iter: 14779  total_loss: 0.4525  loss_cls: 0.1034  loss_box_reg: 0.1499  loss_rpn_cls: 0.04584  loss_rpn_loc: 0.08925  time: 0.7309  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:27:54] d2.utils.events INFO:  eta: 0:38:57  iter: 14799  total_loss: 0.3316  loss_cls: 0.08545  loss_box_reg: 0.1093  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.07752  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:28:08] d2.utils.events INFO:  eta: 0:38:40  iter: 14819  total_loss: 0.413  loss_cls: 0.08821  loss_box_reg: 0.1362  loss_rpn_cls: 0.03923  loss_rpn_loc: 0.0798  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:28:24] d2.utils.events INFO:  eta: 0:38:29  iter: 14839  total_loss: 0.3359  loss_cls: 0.06938  loss_box_reg: 0.1232  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.09718  time: 0.7310  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:28:38] d2.utils.events INFO:  eta: 0:38:13  iter: 14859  total_loss: 0.355  loss_cls: 0.07532  loss_box_reg: 0.1281  loss_rpn_cls: 0.04569  loss_rpn_loc: 0.07659  time: 0.7309  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:28:53] d2.utils.events INFO:  eta: 0:38:02  iter: 14879  total_loss: 0.3852  loss_cls: 0.1036  loss_box_reg: 0.1501  loss_rpn_cls: 0.04265  loss_rpn_loc: 0.08448  time: 0.7310  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:29:09] d2.utils.events INFO:  eta: 0:37:51  iter: 14899  total_loss: 0.3605  loss_cls: 0.09485  loss_box_reg: 0.1249  loss_rpn_cls: 0.05215  loss_rpn_loc: 0.06696  time: 0.7310  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:29:24] d2.utils.events INFO:  eta: 0:37:37  iter: 14919  total_loss: 0.2579  loss_cls: 0.05005  loss_box_reg: 0.1014  loss_rpn_cls: 0.05213  loss_rpn_loc: 0.06971  time: 0.7311  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:29:38] d2.utils.events INFO:  eta: 0:37:23  iter: 14939  total_loss: 0.3166  loss_cls: 0.0862  loss_box_reg: 0.1299  loss_rpn_cls: 0.02843  loss_rpn_loc: 0.06718  time: 0.7310  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:29:52] d2.utils.events INFO:  eta: 0:37:06  iter: 14959  total_loss: 0.3277  loss_cls: 0.06079  loss_box_reg: 0.1312  loss_rpn_cls: 0.04921  loss_rpn_loc: 0.07259  time: 0.7310  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:30:07] d2.utils.events INFO:  eta: 0:36:54  iter: 14979  total_loss: 0.3694  loss_cls: 0.0826  loss_box_reg: 0.1387  loss_rpn_cls: 0.03441  loss_rpn_loc: 0.1098  time: 0.7310  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:30:22] d2.utils.events INFO:  eta: 0:36:41  iter: 14999  total_loss: 0.5408  loss_cls: 0.1276  loss_box_reg: 0.2145  loss_rpn_cls: 0.07541  loss_rpn_loc: 0.09561  time: 0.7310  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:30:36] d2.utils.events INFO:  eta: 0:36:25  iter: 15019  total_loss: 0.4333  loss_cls: 0.08568  loss_box_reg: 0.131  loss_rpn_cls: 0.04203  loss_rpn_loc: 0.07739  time: 0.7310  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:30:51] d2.utils.events INFO:  eta: 0:36:14  iter: 15039  total_loss: 0.4251  loss_cls: 0.09343  loss_box_reg: 0.1397  loss_rpn_cls: 0.0386  loss_rpn_loc: 0.07814  time: 0.7310  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:31:05] d2.utils.events INFO:  eta: 0:35:57  iter: 15059  total_loss: 0.2812  loss_cls: 0.07106  loss_box_reg: 0.0925  loss_rpn_cls: 0.05481  loss_rpn_loc: 0.0531  time: 0.7310  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:31:20] d2.utils.events INFO:  eta: 0:35:41  iter: 15079  total_loss: 0.3223  loss_cls: 0.07904  loss_box_reg: 0.1139  loss_rpn_cls: 0.04882  loss_rpn_loc: 0.0584  time: 0.7310  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:31:34] d2.utils.events INFO:  eta: 0:35:25  iter: 15099  total_loss: 0.4501  loss_cls: 0.09976  loss_box_reg: 0.1617  loss_rpn_cls: 0.05211  loss_rpn_loc: 0.08485  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:31:48] d2.utils.events INFO:  eta: 0:35:08  iter: 15119  total_loss: 0.3133  loss_cls: 0.08227  loss_box_reg: 0.102  loss_rpn_cls: 0.03114  loss_rpn_loc: 0.068  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:32:02] d2.utils.events INFO:  eta: 0:34:54  iter: 15139  total_loss: 0.3982  loss_cls: 0.1013  loss_box_reg: 0.1554  loss_rpn_cls: 0.04343  loss_rpn_loc: 0.06027  time: 0.7308  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:32:17] d2.utils.events INFO:  eta: 0:34:45  iter: 15159  total_loss: 0.2831  loss_cls: 0.06008  loss_box_reg: 0.1042  loss_rpn_cls: 0.04378  loss_rpn_loc: 0.03906  time: 0.7309  data_time: 0.0027  lr: 2e-05  max_mem: 15389M
[01/29 19:32:32] d2.utils.events INFO:  eta: 0:34:32  iter: 15179  total_loss: 0.2972  loss_cls: 0.0739  loss_box_reg: 0.1012  loss_rpn_cls: 0.04142  loss_rpn_loc: 0.05096  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:32:47] d2.utils.events INFO:  eta: 0:34:14  iter: 15199  total_loss: 0.4164  loss_cls: 0.0874  loss_box_reg: 0.1245  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1259  time: 0.7309  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:33:00] d2.utils.events INFO:  eta: 0:33:59  iter: 15219  total_loss: 0.2472  loss_cls: 0.06447  loss_box_reg: 0.1142  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.05106  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:33:15] d2.utils.events INFO:  eta: 0:33:45  iter: 15239  total_loss: 0.3402  loss_cls: 0.07241  loss_box_reg: 0.1071  loss_rpn_cls: 0.05465  loss_rpn_loc: 0.08766  time: 0.7308  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:33:30] d2.utils.events INFO:  eta: 0:33:35  iter: 15259  total_loss: 0.4141  loss_cls: 0.07492  loss_box_reg: 0.1344  loss_rpn_cls: 0.05296  loss_rpn_loc: 0.1011  time: 0.7309  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:33:45] d2.utils.events INFO:  eta: 0:33:22  iter: 15279  total_loss: 0.3624  loss_cls: 0.08893  loss_box_reg: 0.1448  loss_rpn_cls: 0.04212  loss_rpn_loc: 0.06082  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:34:00] d2.utils.events INFO:  eta: 0:33:06  iter: 15299  total_loss: 0.3394  loss_cls: 0.07603  loss_box_reg: 0.09666  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.0944  time: 0.7309  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:34:14] d2.utils.events INFO:  eta: 0:32:53  iter: 15319  total_loss: 0.2983  loss_cls: 0.06983  loss_box_reg: 0.1182  loss_rpn_cls: 0.03365  loss_rpn_loc: 0.05561  time: 0.7309  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:34:29] d2.utils.events INFO:  eta: 0:32:44  iter: 15339  total_loss: 0.3547  loss_cls: 0.08361  loss_box_reg: 0.1433  loss_rpn_cls: 0.04283  loss_rpn_loc: 0.05959  time: 0.7309  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:34:43] d2.utils.events INFO:  eta: 0:32:29  iter: 15359  total_loss: 0.3818  loss_cls: 0.09326  loss_box_reg: 0.1448  loss_rpn_cls: 0.03897  loss_rpn_loc: 0.06366  time: 0.7308  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:34:57] d2.utils.events INFO:  eta: 0:32:12  iter: 15379  total_loss: 0.3552  loss_cls: 0.07427  loss_box_reg: 0.1415  loss_rpn_cls: 0.04502  loss_rpn_loc: 0.09189  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:35:12] d2.utils.events INFO:  eta: 0:32:02  iter: 15399  total_loss: 0.3469  loss_cls: 0.06926  loss_box_reg: 0.1503  loss_rpn_cls: 0.03677  loss_rpn_loc: 0.03967  time: 0.7308  data_time: 0.0027  lr: 2e-05  max_mem: 15389M
[01/29 19:35:27] d2.utils.events INFO:  eta: 0:31:43  iter: 15419  total_loss: 0.3508  loss_cls: 0.09342  loss_box_reg: 0.1758  loss_rpn_cls: 0.03464  loss_rpn_loc: 0.07211  time: 0.7308  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:35:41] d2.utils.events INFO:  eta: 0:31:26  iter: 15439  total_loss: 0.2918  loss_cls: 0.07726  loss_box_reg: 0.09355  loss_rpn_cls: 0.03171  loss_rpn_loc: 0.0544  time: 0.7308  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:35:56] d2.utils.events INFO:  eta: 0:31:15  iter: 15459  total_loss: 0.3844  loss_cls: 0.1111  loss_box_reg: 0.1698  loss_rpn_cls: 0.05365  loss_rpn_loc: 0.06291  time: 0.7308  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:36:10] d2.utils.events INFO:  eta: 0:30:58  iter: 15479  total_loss: 0.4321  loss_cls: 0.1031  loss_box_reg: 0.1856  loss_rpn_cls: 0.05452  loss_rpn_loc: 0.06805  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:36:25] d2.utils.events INFO:  eta: 0:30:45  iter: 15499  total_loss: 0.4066  loss_cls: 0.1111  loss_box_reg: 0.1705  loss_rpn_cls: 0.04798  loss_rpn_loc: 0.07543  time: 0.7308  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:36:40] d2.utils.events INFO:  eta: 0:30:35  iter: 15519  total_loss: 0.4311  loss_cls: 0.1026  loss_box_reg: 0.1453  loss_rpn_cls: 0.0365  loss_rpn_loc: 0.07086  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:36:53] d2.utils.events INFO:  eta: 0:30:13  iter: 15539  total_loss: 0.3439  loss_cls: 0.07303  loss_box_reg: 0.1221  loss_rpn_cls: 0.05531  loss_rpn_loc: 0.0759  time: 0.7307  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:37:09] d2.utils.events INFO:  eta: 0:30:00  iter: 15559  total_loss: 0.3775  loss_cls: 0.08183  loss_box_reg: 0.146  loss_rpn_cls: 0.04796  loss_rpn_loc: 0.08951  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:37:24] d2.utils.events INFO:  eta: 0:29:45  iter: 15579  total_loss: 0.355  loss_cls: 0.1047  loss_box_reg: 0.08492  loss_rpn_cls: 0.04778  loss_rpn_loc: 0.07605  time: 0.7308  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:37:39] d2.utils.events INFO:  eta: 0:29:36  iter: 15599  total_loss: 0.4241  loss_cls: 0.1052  loss_box_reg: 0.1806  loss_rpn_cls: 0.03373  loss_rpn_loc: 0.09428  time: 0.7309  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:37:53] d2.utils.events INFO:  eta: 0:29:22  iter: 15619  total_loss: 0.3389  loss_cls: 0.07947  loss_box_reg: 0.1007  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.0678  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:38:07] d2.utils.events INFO:  eta: 0:29:08  iter: 15639  total_loss: 0.3381  loss_cls: 0.07336  loss_box_reg: 0.1492  loss_rpn_cls: 0.03568  loss_rpn_loc: 0.07447  time: 0.7308  data_time: 0.0022  lr: 2e-05  max_mem: 15389M
[01/29 19:38:22] d2.utils.events INFO:  eta: 0:28:55  iter: 15659  total_loss: 0.359  loss_cls: 0.08066  loss_box_reg: 0.1358  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.07081  time: 0.7308  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:38:37] d2.utils.events INFO:  eta: 0:28:38  iter: 15679  total_loss: 0.4284  loss_cls: 0.1095  loss_box_reg: 0.1743  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.09459  time: 0.7308  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:38:52] d2.utils.events INFO:  eta: 0:28:24  iter: 15699  total_loss: 0.3491  loss_cls: 0.07871  loss_box_reg: 0.1148  loss_rpn_cls: 0.04255  loss_rpn_loc: 0.07512  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:39:06] d2.utils.events INFO:  eta: 0:28:11  iter: 15719  total_loss: 0.2709  loss_cls: 0.06117  loss_box_reg: 0.08844  loss_rpn_cls: 0.03608  loss_rpn_loc: 0.06299  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:39:21] d2.utils.events INFO:  eta: 0:27:55  iter: 15739  total_loss: 0.3746  loss_cls: 0.08605  loss_box_reg: 0.1357  loss_rpn_cls: 0.05181  loss_rpn_loc: 0.1029  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:39:35] d2.utils.events INFO:  eta: 0:27:42  iter: 15759  total_loss: 0.424  loss_cls: 0.1106  loss_box_reg: 0.1382  loss_rpn_cls: 0.04554  loss_rpn_loc: 0.08846  time: 0.7308  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:39:51] d2.utils.events INFO:  eta: 0:27:27  iter: 15779  total_loss: 0.3436  loss_cls: 0.06243  loss_box_reg: 0.09089  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.08344  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:40:06] d2.utils.events INFO:  eta: 0:27:14  iter: 15799  total_loss: 0.3151  loss_cls: 0.08225  loss_box_reg: 0.1442  loss_rpn_cls: 0.0546  loss_rpn_loc: 0.05801  time: 0.7308  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:40:20] d2.utils.events INFO:  eta: 0:27:02  iter: 15819  total_loss: 0.4018  loss_cls: 0.0877  loss_box_reg: 0.1304  loss_rpn_cls: 0.03414  loss_rpn_loc: 0.08868  time: 0.7309  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:40:36] d2.utils.events INFO:  eta: 0:26:48  iter: 15839  total_loss: 0.4352  loss_cls: 0.1109  loss_box_reg: 0.1603  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.08016  time: 0.7309  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:40:52] d2.utils.events INFO:  eta: 0:26:36  iter: 15859  total_loss: 0.3876  loss_cls: 0.09026  loss_box_reg: 0.1684  loss_rpn_cls: 0.03237  loss_rpn_loc: 0.07343  time: 0.7310  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:41:06] d2.utils.events INFO:  eta: 0:26:19  iter: 15879  total_loss: 0.3786  loss_cls: 0.0825  loss_box_reg: 0.1529  loss_rpn_cls: 0.03942  loss_rpn_loc: 0.09388  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:41:20] d2.utils.events INFO:  eta: 0:26:00  iter: 15899  total_loss: 0.3689  loss_cls: 0.07459  loss_box_reg: 0.146  loss_rpn_cls: 0.04459  loss_rpn_loc: 0.07061  time: 0.7309  data_time: 0.0024  lr: 2e-05  max_mem: 15389M
[01/29 19:41:34] d2.utils.events INFO:  eta: 0:25:43  iter: 15919  total_loss: 0.3314  loss_cls: 0.06154  loss_box_reg: 0.1181  loss_rpn_cls: 0.03785  loss_rpn_loc: 0.0861  time: 0.7309  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:41:49] d2.utils.events INFO:  eta: 0:25:29  iter: 15939  total_loss: 0.284  loss_cls: 0.07037  loss_box_reg: 0.1173  loss_rpn_cls: 0.02763  loss_rpn_loc: 0.06198  time: 0.7309  data_time: 0.0026  lr: 2e-05  max_mem: 15389M
[01/29 19:42:04] d2.utils.events INFO:  eta: 0:25:16  iter: 15959  total_loss: 0.3859  loss_cls: 0.09929  loss_box_reg: 0.1529  loss_rpn_cls: 0.0409  loss_rpn_loc: 0.05465  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:42:18] d2.utils.events INFO:  eta: 0:24:58  iter: 15979  total_loss: 0.3205  loss_cls: 0.08135  loss_box_reg: 0.1331  loss_rpn_cls: 0.02726  loss_rpn_loc: 0.06681  time: 0.7309  data_time: 0.0025  lr: 2e-05  max_mem: 15389M
[01/29 19:42:33] d2.utils.events INFO:  eta: 0:24:43  iter: 15999  total_loss: 0.3612  loss_cls: 0.08675  loss_box_reg: 0.1547  loss_rpn_cls: 0.0433  loss_rpn_loc: 0.0709  time: 0.7309  data_time: 0.0023  lr: 2e-05  max_mem: 15389M
[01/29 19:42:47] d2.utils.events INFO:  eta: 0:24:28  iter: 16019  total_loss: 0.4068  loss_cls: 0.1069  loss_box_reg: 0.1508  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.06953  time: 0.7309  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:43:03] d2.utils.events INFO:  eta: 0:24:18  iter: 16039  total_loss: 0.4059  loss_cls: 0.09112  loss_box_reg: 0.1441  loss_rpn_cls: 0.03544  loss_rpn_loc: 0.1004  time: 0.7309  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:43:17] d2.utils.events INFO:  eta: 0:24:06  iter: 16059  total_loss: 0.3389  loss_cls: 0.07614  loss_box_reg: 0.1283  loss_rpn_cls: 0.03823  loss_rpn_loc: 0.08483  time: 0.7309  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:43:32] d2.utils.events INFO:  eta: 0:23:50  iter: 16079  total_loss: 0.388  loss_cls: 0.09111  loss_box_reg: 0.1634  loss_rpn_cls: 0.05315  loss_rpn_loc: 0.07596  time: 0.7309  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:43:46] d2.utils.events INFO:  eta: 0:23:36  iter: 16099  total_loss: 0.3248  loss_cls: 0.07811  loss_box_reg: 0.1005  loss_rpn_cls: 0.05645  loss_rpn_loc: 0.06489  time: 0.7309  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:44:01] d2.utils.events INFO:  eta: 0:23:24  iter: 16119  total_loss: 0.3007  loss_cls: 0.07736  loss_box_reg: 0.1021  loss_rpn_cls: 0.03062  loss_rpn_loc: 0.09126  time: 0.7309  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:44:16] d2.utils.events INFO:  eta: 0:23:11  iter: 16139  total_loss: 0.3628  loss_cls: 0.09198  loss_box_reg: 0.1186  loss_rpn_cls: 0.03803  loss_rpn_loc: 0.06469  time: 0.7309  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:44:31] d2.utils.events INFO:  eta: 0:22:55  iter: 16159  total_loss: 0.3619  loss_cls: 0.08714  loss_box_reg: 0.1597  loss_rpn_cls: 0.03947  loss_rpn_loc: 0.07438  time: 0.7309  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:44:45] d2.utils.events INFO:  eta: 0:22:41  iter: 16179  total_loss: 0.49  loss_cls: 0.1105  loss_box_reg: 0.1806  loss_rpn_cls: 0.05833  loss_rpn_loc: 0.1004  time: 0.7309  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:45:01] d2.utils.events INFO:  eta: 0:22:27  iter: 16199  total_loss: 0.3424  loss_cls: 0.07552  loss_box_reg: 0.1152  loss_rpn_cls: 0.04944  loss_rpn_loc: 0.07874  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:45:15] d2.utils.events INFO:  eta: 0:22:15  iter: 16219  total_loss: 0.412  loss_cls: 0.0949  loss_box_reg: 0.1341  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.08809  time: 0.7310  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:45:30] d2.utils.events INFO:  eta: 0:22:01  iter: 16239  total_loss: 0.4553  loss_cls: 0.09834  loss_box_reg: 0.171  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.07204  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:45:46] d2.utils.events INFO:  eta: 0:21:44  iter: 16259  total_loss: 0.3354  loss_cls: 0.0794  loss_box_reg: 0.1113  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.08195  time: 0.7310  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:46:00] d2.utils.events INFO:  eta: 0:21:29  iter: 16279  total_loss: 0.347  loss_cls: 0.06778  loss_box_reg: 0.09998  loss_rpn_cls: 0.03985  loss_rpn_loc: 0.06396  time: 0.7310  data_time: 0.0022  lr: 2e-06  max_mem: 15389M
[01/29 19:46:15] d2.utils.events INFO:  eta: 0:21:15  iter: 16299  total_loss: 0.2709  loss_cls: 0.05854  loss_box_reg: 0.1036  loss_rpn_cls: 0.02377  loss_rpn_loc: 0.08499  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:46:29] d2.utils.events INFO:  eta: 0:21:00  iter: 16319  total_loss: 0.3134  loss_cls: 0.08171  loss_box_reg: 0.1493  loss_rpn_cls: 0.03897  loss_rpn_loc: 0.05748  time: 0.7310  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:46:44] d2.utils.events INFO:  eta: 0:20:42  iter: 16339  total_loss: 0.3524  loss_cls: 0.08259  loss_box_reg: 0.1264  loss_rpn_cls: 0.0391  loss_rpn_loc: 0.069  time: 0.7310  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:46:58] d2.utils.events INFO:  eta: 0:20:29  iter: 16359  total_loss: 0.3149  loss_cls: 0.08408  loss_box_reg: 0.1233  loss_rpn_cls: 0.0365  loss_rpn_loc: 0.08528  time: 0.7310  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:47:14] d2.utils.events INFO:  eta: 0:20:17  iter: 16379  total_loss: 0.3019  loss_cls: 0.06635  loss_box_reg: 0.1174  loss_rpn_cls: 0.03581  loss_rpn_loc: 0.08344  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:47:29] d2.utils.events INFO:  eta: 0:20:03  iter: 16399  total_loss: 0.3435  loss_cls: 0.08594  loss_box_reg: 0.149  loss_rpn_cls: 0.03723  loss_rpn_loc: 0.1016  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:47:43] d2.utils.events INFO:  eta: 0:19:47  iter: 16419  total_loss: 0.3579  loss_cls: 0.08563  loss_box_reg: 0.1587  loss_rpn_cls: 0.02901  loss_rpn_loc: 0.05676  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:47:57] d2.utils.events INFO:  eta: 0:19:32  iter: 16439  total_loss: 0.4276  loss_cls: 0.1146  loss_box_reg: 0.1976  loss_rpn_cls: 0.03706  loss_rpn_loc: 0.0623  time: 0.7310  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:48:12] d2.utils.events INFO:  eta: 0:19:16  iter: 16459  total_loss: 0.5119  loss_cls: 0.1003  loss_box_reg: 0.1833  loss_rpn_cls: 0.04928  loss_rpn_loc: 0.09398  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:48:26] d2.utils.events INFO:  eta: 0:18:59  iter: 16479  total_loss: 0.3708  loss_cls: 0.08281  loss_box_reg: 0.1181  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.1045  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:48:41] d2.utils.events INFO:  eta: 0:18:46  iter: 16499  total_loss: 0.2875  loss_cls: 0.06696  loss_box_reg: 0.1117  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.06385  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:48:56] d2.utils.events INFO:  eta: 0:18:31  iter: 16519  total_loss: 0.3756  loss_cls: 0.07823  loss_box_reg: 0.1039  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.09724  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:49:11] d2.utils.events INFO:  eta: 0:18:19  iter: 16539  total_loss: 0.3759  loss_cls: 0.09151  loss_box_reg: 0.1445  loss_rpn_cls: 0.04971  loss_rpn_loc: 0.07637  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:49:25] d2.utils.events INFO:  eta: 0:18:01  iter: 16559  total_loss: 0.2886  loss_cls: 0.05646  loss_box_reg: 0.1094  loss_rpn_cls: 0.03746  loss_rpn_loc: 0.05345  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:49:39] d2.utils.events INFO:  eta: 0:17:46  iter: 16579  total_loss: 0.3711  loss_cls: 0.07032  loss_box_reg: 0.1432  loss_rpn_cls: 0.04374  loss_rpn_loc: 0.06449  time: 0.7310  data_time: 0.0027  lr: 2e-06  max_mem: 15389M
[01/29 19:49:54] d2.utils.events INFO:  eta: 0:17:29  iter: 16599  total_loss: 0.3054  loss_cls: 0.06894  loss_box_reg: 0.1109  loss_rpn_cls: 0.03502  loss_rpn_loc: 0.05733  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:50:10] d2.utils.events INFO:  eta: 0:17:15  iter: 16619  total_loss: 0.3021  loss_cls: 0.08181  loss_box_reg: 0.122  loss_rpn_cls: 0.04044  loss_rpn_loc: 0.07337  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:50:24] d2.utils.events INFO:  eta: 0:17:00  iter: 16639  total_loss: 0.39  loss_cls: 0.12  loss_box_reg: 0.1606  loss_rpn_cls: 0.04905  loss_rpn_loc: 0.06239  time: 0.7310  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:50:39] d2.utils.events INFO:  eta: 0:16:46  iter: 16659  total_loss: 0.3874  loss_cls: 0.08587  loss_box_reg: 0.1439  loss_rpn_cls: 0.03611  loss_rpn_loc: 0.07722  time: 0.7310  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:50:54] d2.utils.events INFO:  eta: 0:16:34  iter: 16679  total_loss: 0.3512  loss_cls: 0.09412  loss_box_reg: 0.141  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.07022  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:51:09] d2.utils.events INFO:  eta: 0:16:21  iter: 16699  total_loss: 0.3703  loss_cls: 0.08722  loss_box_reg: 0.1209  loss_rpn_cls: 0.05221  loss_rpn_loc: 0.09214  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:51:24] d2.utils.events INFO:  eta: 0:16:06  iter: 16719  total_loss: 0.3868  loss_cls: 0.1063  loss_box_reg: 0.204  loss_rpn_cls: 0.04085  loss_rpn_loc: 0.06453  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:51:38] d2.utils.events INFO:  eta: 0:15:51  iter: 16739  total_loss: 0.3052  loss_cls: 0.08191  loss_box_reg: 0.1249  loss_rpn_cls: 0.03446  loss_rpn_loc: 0.07087  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:51:53] d2.utils.events INFO:  eta: 0:15:36  iter: 16759  total_loss: 0.5218  loss_cls: 0.1017  loss_box_reg: 0.1607  loss_rpn_cls: 0.05609  loss_rpn_loc: 0.09219  time: 0.7311  data_time: 0.0028  lr: 2e-06  max_mem: 15389M
[01/29 19:52:09] d2.utils.events INFO:  eta: 0:15:20  iter: 16779  total_loss: 0.3597  loss_cls: 0.08474  loss_box_reg: 0.1441  loss_rpn_cls: 0.03965  loss_rpn_loc: 0.08936  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:52:23] d2.utils.events INFO:  eta: 0:15:05  iter: 16799  total_loss: 0.385  loss_cls: 0.08569  loss_box_reg: 0.1592  loss_rpn_cls: 0.03106  loss_rpn_loc: 0.06366  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:52:37] d2.utils.events INFO:  eta: 0:14:48  iter: 16819  total_loss: 0.2936  loss_cls: 0.04913  loss_box_reg: 0.09814  loss_rpn_cls: 0.03389  loss_rpn_loc: 0.0898  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:52:52] d2.utils.events INFO:  eta: 0:14:31  iter: 16839  total_loss: 0.5149  loss_cls: 0.1274  loss_box_reg: 0.2111  loss_rpn_cls: 0.05428  loss_rpn_loc: 0.07817  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:53:07] d2.utils.events INFO:  eta: 0:14:16  iter: 16859  total_loss: 0.3843  loss_cls: 0.09835  loss_box_reg: 0.1153  loss_rpn_cls: 0.04009  loss_rpn_loc: 0.08216  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:53:21] d2.utils.events INFO:  eta: 0:14:01  iter: 16879  total_loss: 0.3654  loss_cls: 0.07957  loss_box_reg: 0.1278  loss_rpn_cls: 0.03388  loss_rpn_loc: 0.07168  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:53:36] d2.utils.events INFO:  eta: 0:13:46  iter: 16899  total_loss: 0.348  loss_cls: 0.06925  loss_box_reg: 0.1267  loss_rpn_cls: 0.03345  loss_rpn_loc: 0.05718  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:53:51] d2.utils.events INFO:  eta: 0:13:33  iter: 16919  total_loss: 0.3248  loss_cls: 0.06942  loss_box_reg: 0.09762  loss_rpn_cls: 0.0318  loss_rpn_loc: 0.0692  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:54:06] d2.utils.events INFO:  eta: 0:13:16  iter: 16939  total_loss: 0.4044  loss_cls: 0.1021  loss_box_reg: 0.1696  loss_rpn_cls: 0.05005  loss_rpn_loc: 0.06261  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:54:21] d2.utils.events INFO:  eta: 0:13:01  iter: 16959  total_loss: 0.4283  loss_cls: 0.09  loss_box_reg: 0.1736  loss_rpn_cls: 0.0577  loss_rpn_loc: 0.07545  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:54:36] d2.utils.events INFO:  eta: 0:12:47  iter: 16979  total_loss: 0.314  loss_cls: 0.07446  loss_box_reg: 0.1217  loss_rpn_cls: 0.05095  loss_rpn_loc: 0.0629  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:54:51] d2.utils.events INFO:  eta: 0:12:32  iter: 16999  total_loss: 0.3833  loss_cls: 0.09891  loss_box_reg: 0.1144  loss_rpn_cls: 0.04176  loss_rpn_loc: 0.08065  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:55:06] d2.utils.events INFO:  eta: 0:12:19  iter: 17019  total_loss: 0.3653  loss_cls: 0.1041  loss_box_reg: 0.1316  loss_rpn_cls: 0.04742  loss_rpn_loc: 0.06707  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:55:21] d2.utils.events INFO:  eta: 0:12:02  iter: 17039  total_loss: 0.2774  loss_cls: 0.06004  loss_box_reg: 0.102  loss_rpn_cls: 0.04218  loss_rpn_loc: 0.04101  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:55:35] d2.utils.events INFO:  eta: 0:11:45  iter: 17059  total_loss: 0.3451  loss_cls: 0.079  loss_box_reg: 0.1431  loss_rpn_cls: 0.03409  loss_rpn_loc: 0.06666  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:55:51] d2.utils.events INFO:  eta: 0:11:32  iter: 17079  total_loss: 0.2873  loss_cls: 0.06689  loss_box_reg: 0.1084  loss_rpn_cls: 0.03895  loss_rpn_loc: 0.0827  time: 0.7313  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:56:05] d2.utils.events INFO:  eta: 0:11:18  iter: 17099  total_loss: 0.3282  loss_cls: 0.0813  loss_box_reg: 0.1383  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.04745  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:56:20] d2.utils.events INFO:  eta: 0:11:01  iter: 17119  total_loss: 0.4124  loss_cls: 0.115  loss_box_reg: 0.1634  loss_rpn_cls: 0.04107  loss_rpn_loc: 0.0771  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:56:34] d2.utils.events INFO:  eta: 0:10:45  iter: 17139  total_loss: 0.3498  loss_cls: 0.0872  loss_box_reg: 0.1263  loss_rpn_cls: 0.03711  loss_rpn_loc: 0.06157  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:56:48] d2.utils.events INFO:  eta: 0:10:30  iter: 17159  total_loss: 0.3278  loss_cls: 0.08404  loss_box_reg: 0.131  loss_rpn_cls: 0.04003  loss_rpn_loc: 0.08571  time: 0.7312  data_time: 0.0027  lr: 2e-06  max_mem: 15389M
[01/29 19:57:02] d2.utils.events INFO:  eta: 0:10:14  iter: 17179  total_loss: 0.5335  loss_cls: 0.1339  loss_box_reg: 0.2194  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.07718  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:57:16] d2.utils.events INFO:  eta: 0:09:57  iter: 17199  total_loss: 0.374  loss_cls: 0.08275  loss_box_reg: 0.1625  loss_rpn_cls: 0.03652  loss_rpn_loc: 0.08001  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:57:31] d2.utils.events INFO:  eta: 0:09:43  iter: 17219  total_loss: 0.331  loss_cls: 0.09222  loss_box_reg: 0.14  loss_rpn_cls: 0.03788  loss_rpn_loc: 0.05189  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 19:57:45] d2.utils.events INFO:  eta: 0:09:26  iter: 17239  total_loss: 0.3544  loss_cls: 0.07724  loss_box_reg: 0.1214  loss_rpn_cls: 0.02904  loss_rpn_loc: 0.0793  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 19:57:59] d2.utils.events INFO:  eta: 0:09:11  iter: 17259  total_loss: 0.3694  loss_cls: 0.09153  loss_box_reg: 0.1442  loss_rpn_cls: 0.0477  loss_rpn_loc: 0.07965  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:58:15] d2.utils.events INFO:  eta: 0:08:56  iter: 17279  total_loss: 0.2966  loss_cls: 0.07397  loss_box_reg: 0.1062  loss_rpn_cls: 0.04092  loss_rpn_loc: 0.05327  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:58:30] d2.utils.events INFO:  eta: 0:08:43  iter: 17299  total_loss: 0.3734  loss_cls: 0.06963  loss_box_reg: 0.1392  loss_rpn_cls: 0.03612  loss_rpn_loc: 0.07239  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:58:44] d2.utils.events INFO:  eta: 0:08:28  iter: 17319  total_loss: 0.3038  loss_cls: 0.06941  loss_box_reg: 0.1059  loss_rpn_cls: 0.0378  loss_rpn_loc: 0.05599  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:58:59] d2.utils.events INFO:  eta: 0:08:14  iter: 17339  total_loss: 0.4041  loss_cls: 0.0777  loss_box_reg: 0.1438  loss_rpn_cls: 0.04235  loss_rpn_loc: 0.1074  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 19:59:15] d2.utils.events INFO:  eta: 0:08:00  iter: 17359  total_loss: 0.4345  loss_cls: 0.09238  loss_box_reg: 0.1393  loss_rpn_cls: 0.04673  loss_rpn_loc: 0.07438  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:59:30] d2.utils.events INFO:  eta: 0:07:44  iter: 17379  total_loss: 0.2946  loss_cls: 0.06492  loss_box_reg: 0.1386  loss_rpn_cls: 0.0498  loss_rpn_loc: 0.07094  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 19:59:45] d2.utils.events INFO:  eta: 0:07:29  iter: 17399  total_loss: 0.417  loss_cls: 0.1001  loss_box_reg: 0.157  loss_rpn_cls: 0.05229  loss_rpn_loc: 0.07303  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:00:00] d2.utils.events INFO:  eta: 0:07:15  iter: 17419  total_loss: 0.4086  loss_cls: 0.1011  loss_box_reg: 0.1728  loss_rpn_cls: 0.05683  loss_rpn_loc: 0.05719  time: 0.7313  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:00:14] d2.utils.events INFO:  eta: 0:07:00  iter: 17439  total_loss: 0.3391  loss_cls: 0.07945  loss_box_reg: 0.1503  loss_rpn_cls: 0.037  loss_rpn_loc: 0.07957  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:00:29] d2.utils.events INFO:  eta: 0:06:45  iter: 17459  total_loss: 0.337  loss_cls: 0.08632  loss_box_reg: 0.1538  loss_rpn_cls: 0.03149  loss_rpn_loc: 0.08255  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:00:43] d2.utils.events INFO:  eta: 0:06:30  iter: 17479  total_loss: 0.3198  loss_cls: 0.08396  loss_box_reg: 0.1155  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.06784  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:00:58] d2.utils.events INFO:  eta: 0:06:14  iter: 17499  total_loss: 0.3444  loss_cls: 0.07289  loss_box_reg: 0.1297  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.06515  time: 0.7312  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:01:12] d2.utils.events INFO:  eta: 0:05:59  iter: 17519  total_loss: 0.3515  loss_cls: 0.09836  loss_box_reg: 0.1353  loss_rpn_cls: 0.04919  loss_rpn_loc: 0.05225  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:01:27] d2.utils.events INFO:  eta: 0:05:43  iter: 17539  total_loss: 0.301  loss_cls: 0.07288  loss_box_reg: 0.1148  loss_rpn_cls: 0.03295  loss_rpn_loc: 0.04813  time: 0.7312  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:01:41] d2.utils.events INFO:  eta: 0:05:29  iter: 17559  total_loss: 0.3416  loss_cls: 0.08804  loss_box_reg: 0.1361  loss_rpn_cls: 0.04879  loss_rpn_loc: 0.06638  time: 0.7312  data_time: 0.0027  lr: 2e-06  max_mem: 15389M
[01/29 20:01:57] d2.utils.events INFO:  eta: 0:05:15  iter: 17579  total_loss: 0.3046  loss_cls: 0.06697  loss_box_reg: 0.1087  loss_rpn_cls: 0.03853  loss_rpn_loc: 0.07998  time: 0.7312  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 20:02:12] d2.utils.events INFO:  eta: 0:05:00  iter: 17599  total_loss: 0.329  loss_cls: 0.07706  loss_box_reg: 0.1389  loss_rpn_cls: 0.0346  loss_rpn_loc: 0.08525  time: 0.7313  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:02:26] d2.utils.events INFO:  eta: 0:04:45  iter: 17619  total_loss: 0.4124  loss_cls: 0.09517  loss_box_reg: 0.1378  loss_rpn_cls: 0.05592  loss_rpn_loc: 0.06753  time: 0.7312  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 20:02:40] d2.utils.events INFO:  eta: 0:04:30  iter: 17639  total_loss: 0.3182  loss_cls: 0.05893  loss_box_reg: 0.1109  loss_rpn_cls: 0.03282  loss_rpn_loc: 0.07071  time: 0.7312  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:02:55] d2.utils.events INFO:  eta: 0:04:13  iter: 17659  total_loss: 0.3253  loss_cls: 0.07224  loss_box_reg: 0.1317  loss_rpn_cls: 0.04042  loss_rpn_loc: 0.08227  time: 0.7312  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 20:03:08] d2.utils.events INFO:  eta: 0:03:57  iter: 17679  total_loss: 0.366  loss_cls: 0.09342  loss_box_reg: 0.1665  loss_rpn_cls: 0.05028  loss_rpn_loc: 0.0733  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:03:23] d2.utils.events INFO:  eta: 0:03:42  iter: 17699  total_loss: 0.3143  loss_cls: 0.06794  loss_box_reg: 0.09684  loss_rpn_cls: 0.05063  loss_rpn_loc: 0.06191  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:03:37] d2.utils.events INFO:  eta: 0:03:27  iter: 17719  total_loss: 0.3445  loss_cls: 0.07322  loss_box_reg: 0.1514  loss_rpn_cls: 0.0301  loss_rpn_loc: 0.07968  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:03:51] d2.utils.events INFO:  eta: 0:03:12  iter: 17739  total_loss: 0.293  loss_cls: 0.0749  loss_box_reg: 0.1208  loss_rpn_cls: 0.04415  loss_rpn_loc: 0.05946  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:04:05] d2.utils.events INFO:  eta: 0:02:57  iter: 17759  total_loss: 0.4175  loss_cls: 0.09261  loss_box_reg: 0.1301  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.08328  time: 0.7310  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:04:21] d2.utils.events INFO:  eta: 0:02:42  iter: 17779  total_loss: 0.4194  loss_cls: 0.07666  loss_box_reg: 0.125  loss_rpn_cls: 0.03849  loss_rpn_loc: 0.07533  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 20:04:36] d2.utils.events INFO:  eta: 0:02:27  iter: 17799  total_loss: 0.3017  loss_cls: 0.07944  loss_box_reg: 0.126  loss_rpn_cls: 0.03495  loss_rpn_loc: 0.06086  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:04:51] d2.utils.events INFO:  eta: 0:02:12  iter: 17819  total_loss: 0.2956  loss_cls: 0.06984  loss_box_reg: 0.1003  loss_rpn_cls: 0.04027  loss_rpn_loc: 0.06102  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:05:05] d2.utils.events INFO:  eta: 0:01:58  iter: 17839  total_loss: 0.3699  loss_cls: 0.07416  loss_box_reg: 0.1478  loss_rpn_cls: 0.04605  loss_rpn_loc: 0.07616  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:05:20] d2.utils.events INFO:  eta: 0:01:43  iter: 17859  total_loss: 0.3135  loss_cls: 0.07024  loss_box_reg: 0.1011  loss_rpn_cls: 0.04198  loss_rpn_loc: 0.07416  time: 0.7311  data_time: 0.0025  lr: 2e-06  max_mem: 15389M
[01/29 20:05:35] d2.utils.events INFO:  eta: 0:01:28  iter: 17879  total_loss: 0.3717  loss_cls: 0.106  loss_box_reg: 0.1205  loss_rpn_cls: 0.05176  loss_rpn_loc: 0.09122  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:05:49] d2.utils.events INFO:  eta: 0:01:13  iter: 17899  total_loss: 0.3087  loss_cls: 0.07217  loss_box_reg: 0.1048  loss_rpn_cls: 0.03197  loss_rpn_loc: 0.055  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:06:03] d2.utils.events INFO:  eta: 0:00:58  iter: 17919  total_loss: 0.2553  loss_cls: 0.04859  loss_box_reg: 0.0843  loss_rpn_cls: 0.02937  loss_rpn_loc: 0.06698  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:06:18] d2.utils.events INFO:  eta: 0:00:44  iter: 17939  total_loss: 0.4196  loss_cls: 0.08921  loss_box_reg: 0.1024  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1096  time: 0.7311  data_time: 0.0023  lr: 2e-06  max_mem: 15389M
[01/29 20:06:34] d2.utils.events INFO:  eta: 0:00:29  iter: 17959  total_loss: 0.4058  loss_cls: 0.09847  loss_box_reg: 0.154  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.08565  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 20:06:49] d2.utils.events INFO:  eta: 0:00:14  iter: 17979  total_loss: 0.3787  loss_cls: 0.09105  loss_box_reg: 0.1239  loss_rpn_cls: 0.0391  loss_rpn_loc: 0.07326  time: 0.7311  data_time: 0.0026  lr: 2e-06  max_mem: 15389M
[01/29 20:07:03] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_0017999.pth
[01/29 20:07:03] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[01/29 20:07:03] d2.utils.events INFO:  eta: 0:00:00  iter: 17999  total_loss: 0.4491  loss_cls: 0.1085  loss_box_reg: 0.1805  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.09063  time: 0.7311  data_time: 0.0024  lr: 2e-06  max_mem: 15389M
[01/29 20:07:03] d2.engine.hooks INFO: Overall training speed: 17998 iterations in 3:39:18 (0.7311 s / it)
[01/29 20:07:03] d2.engine.hooks INFO: Total training time: 3:39:57 (0:00:38 on hooks)
[01/30 00:55:33] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 00:55:34] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 00:55:34] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/30 00:55:34] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18
  STEPS: (12, 16)
  MAX_ITER: 18
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/30 00:55:34] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12
  - 16
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 00:55:34] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 00:55:34] d2.utils.env INFO: Using a generated random seed 34462310
[01/30 00:55:37] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/30 00:55:38] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 00:55:38] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 00:55:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/30 00:55:38] d2.data.build INFO: Using training sampler TrainingSampler
[01/30 00:55:38] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/30 00:55:38] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/30 00:55:38] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/30 00:55:38] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[01/30 00:55:38] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  head.{bias, weight}
[01/30 00:55:38] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 00:55:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_0000017.pth
[01/30 00:55:52] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[01/30 00:55:53] d2.utils.events INFO:  eta: 0:00:00  iter: 17  total_loss: 5.198  loss_cls: 4.357  loss_box_reg: 0.09285  loss_rpn_cls: 0.6895  loss_rpn_loc: 0.0727  time: 0.7351  data_time: 0.0081  lr: 1.9e-06  max_mem: 14076M
[01/30 00:55:53] d2.engine.hooks INFO: Overall training speed: 16 iterations in 0:00:11 (0.7351 s / it)
[01/30 00:55:53] d2.engine.hooks INFO: Total training time: 0:00:12 (0:00:01 on hooks)
[01/30 00:55:54] d2.data.build INFO: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 285          |   bicycle   | 337          |    boat     | 263          |
|   bottle   | 469          |     car     | 1201         |     cat     | 358          |
|   chair    | 756          | diningtable | 206          |     dog     | 489          |
|   horse    | 348          |   person    | 4528         | pottedplant | 480          |
|   sheep    | 242          |    train    | 282          |  tvmonitor  | 308          |
|    bird    | 459          |     bus     | 213          |     cow     | 244          |
| motorbike  | 325          |    sofa     | 239          |             |              |
|   total    | 12032        |             |              |             |              |
[01/30 00:55:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[01/30 00:55:54] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[01/30 00:55:54] d2.data.common INFO: Serialized dataset takes 2.12 MiB
[01/30 00:55:54] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[01/30 00:55:55] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0005 s/iter. Inference: 0.1123 s/iter. Eval: 0.0000 s/iter. Total: 0.1129 s/iter. ETA=0:09:17
[01/30 00:56:00] d2.evaluation.evaluator INFO: Inference done 55/4952. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 0.0000 s/iter. Total: 0.1142 s/iter. ETA=0:09:19
[01/30 00:56:05] d2.evaluation.evaluator INFO: Inference done 100/4952. Dataloading: 0.0008 s/iter. Inference: 0.1129 s/iter. Eval: 0.0000 s/iter. Total: 0.1138 s/iter. ETA=0:09:12
[01/30 00:56:10] d2.evaluation.evaluator INFO: Inference done 144/4952. Dataloading: 0.0008 s/iter. Inference: 0.1131 s/iter. Eval: 0.0000 s/iter. Total: 0.1139 s/iter. ETA=0:09:07
[01/30 00:56:15] d2.evaluation.evaluator INFO: Inference done 188/4952. Dataloading: 0.0008 s/iter. Inference: 0.1132 s/iter. Eval: 0.0000 s/iter. Total: 0.1141 s/iter. ETA=0:09:03
[01/30 00:56:20] d2.evaluation.evaluator INFO: Inference done 231/4952. Dataloading: 0.0008 s/iter. Inference: 0.1137 s/iter. Eval: 0.0000 s/iter. Total: 0.1146 s/iter. ETA=0:09:00
[01/30 00:56:25] d2.evaluation.evaluator INFO: Inference done 276/4952. Dataloading: 0.0008 s/iter. Inference: 0.1135 s/iter. Eval: 0.0000 s/iter. Total: 0.1143 s/iter. ETA=0:08:54
[01/30 00:56:30] d2.evaluation.evaluator INFO: Inference done 320/4952. Dataloading: 0.0008 s/iter. Inference: 0.1135 s/iter. Eval: 0.0000 s/iter. Total: 0.1144 s/iter. ETA=0:08:49
[01/30 00:56:35] d2.evaluation.evaluator INFO: Inference done 364/4952. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 0.0000 s/iter. Total: 0.1143 s/iter. ETA=0:08:44
[01/30 00:56:41] d2.evaluation.evaluator INFO: Inference done 408/4952. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 0.0000 s/iter. Total: 0.1143 s/iter. ETA=0:08:39
[01/30 00:56:46] d2.evaluation.evaluator INFO: Inference done 452/4952. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 0.0000 s/iter. Total: 0.1143 s/iter. ETA=0:08:34
[01/30 00:56:51] d2.evaluation.evaluator INFO: Inference done 496/4952. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 0.0000 s/iter. Total: 0.1143 s/iter. ETA=0:08:29
[01/30 00:56:56] d2.evaluation.evaluator INFO: Inference done 540/4952. Dataloading: 0.0008 s/iter. Inference: 0.1134 s/iter. Eval: 0.0000 s/iter. Total: 0.1143 s/iter. ETA=0:08:24
[01/30 00:57:01] d2.evaluation.evaluator INFO: Inference done 584/4952. Dataloading: 0.0008 s/iter. Inference: 0.1135 s/iter. Eval: 0.0000 s/iter. Total: 0.1144 s/iter. ETA=0:08:19
[01/30 00:57:06] d2.evaluation.evaluator INFO: Inference done 628/4952. Dataloading: 0.0008 s/iter. Inference: 0.1136 s/iter. Eval: 0.0000 s/iter. Total: 0.1145 s/iter. ETA=0:08:15
[01/30 00:57:11] d2.evaluation.evaluator INFO: Inference done 672/4952. Dataloading: 0.0008 s/iter. Inference: 0.1135 s/iter. Eval: 0.0000 s/iter. Total: 0.1144 s/iter. ETA=0:08:09
[01/30 00:57:16] d2.evaluation.evaluator INFO: Inference done 716/4952. Dataloading: 0.0008 s/iter. Inference: 0.1136 s/iter. Eval: 0.0000 s/iter. Total: 0.1145 s/iter. ETA=0:08:05
[01/30 00:57:21] d2.evaluation.evaluator INFO: Inference done 760/4952. Dataloading: 0.0008 s/iter. Inference: 0.1136 s/iter. Eval: 0.0000 s/iter. Total: 0.1145 s/iter. ETA=0:08:00
[01/30 00:57:26] d2.evaluation.evaluator INFO: Inference done 804/4952. Dataloading: 0.0008 s/iter. Inference: 0.1136 s/iter. Eval: 0.0000 s/iter. Total: 0.1145 s/iter. ETA=0:07:54
[01/30 00:57:31] d2.evaluation.evaluator INFO: Inference done 848/4952. Dataloading: 0.0008 s/iter. Inference: 0.1136 s/iter. Eval: 0.0000 s/iter. Total: 0.1145 s/iter. ETA=0:07:49
[01/30 00:57:36] d2.evaluation.evaluator INFO: Inference done 891/4952. Dataloading: 0.0008 s/iter. Inference: 0.1137 s/iter. Eval: 0.0000 s/iter. Total: 0.1146 s/iter. ETA=0:07:45
[01/30 00:57:41] d2.evaluation.evaluator INFO: Inference done 935/4952. Dataloading: 0.0008 s/iter. Inference: 0.1138 s/iter. Eval: 0.0000 s/iter. Total: 0.1147 s/iter. ETA=0:07:40
[01/30 00:57:46] d2.evaluation.evaluator INFO: Inference done 979/4952. Dataloading: 0.0008 s/iter. Inference: 0.1138 s/iter. Eval: 0.0000 s/iter. Total: 0.1147 s/iter. ETA=0:07:35
[01/30 00:57:51] d2.evaluation.evaluator INFO: Inference done 1023/4952. Dataloading: 0.0008 s/iter. Inference: 0.1138 s/iter. Eval: 0.0000 s/iter. Total: 0.1147 s/iter. ETA=0:07:30
[01/30 00:57:56] d2.evaluation.evaluator INFO: Inference done 1067/4952. Dataloading: 0.0008 s/iter. Inference: 0.1138 s/iter. Eval: 0.0000 s/iter. Total: 0.1147 s/iter. ETA=0:07:25
[01/30 00:58:01] d2.evaluation.evaluator INFO: Inference done 1111/4952. Dataloading: 0.0008 s/iter. Inference: 0.1138 s/iter. Eval: 0.0000 s/iter. Total: 0.1147 s/iter. ETA=0:07:20
[01/30 00:58:06] d2.evaluation.evaluator INFO: Inference done 1155/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:07:15
[01/30 00:58:12] d2.evaluation.evaluator INFO: Inference done 1199/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:07:10
[01/30 00:58:17] d2.evaluation.evaluator INFO: Inference done 1243/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:07:05
[01/30 00:58:22] d2.evaluation.evaluator INFO: Inference done 1287/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:07:00
[01/30 00:58:27] d2.evaluation.evaluator INFO: Inference done 1331/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:06:55
[01/30 00:58:32] d2.evaluation.evaluator INFO: Inference done 1375/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:06:50
[01/30 00:58:37] d2.evaluation.evaluator INFO: Inference done 1419/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:06:45
[01/30 00:58:42] d2.evaluation.evaluator INFO: Inference done 1463/4952. Dataloading: 0.0008 s/iter. Inference: 0.1139 s/iter. Eval: 0.0000 s/iter. Total: 0.1148 s/iter. ETA=0:06:40
[01/30 00:58:47] d2.evaluation.evaluator INFO: Inference done 1507/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:06:35
[01/30 00:58:52] d2.evaluation.evaluator INFO: Inference done 1551/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:06:30
[01/30 00:58:57] d2.evaluation.evaluator INFO: Inference done 1594/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:06:26
[01/30 00:59:02] d2.evaluation.evaluator INFO: Inference done 1638/4952. Dataloading: 0.0008 s/iter. Inference: 0.1141 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:06:21
[01/30 00:59:07] d2.evaluation.evaluator INFO: Inference done 1682/4952. Dataloading: 0.0008 s/iter. Inference: 0.1141 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:06:15
[01/30 00:59:12] d2.evaluation.evaluator INFO: Inference done 1726/4952. Dataloading: 0.0008 s/iter. Inference: 0.1141 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:06:10
[01/30 00:59:17] d2.evaluation.evaluator INFO: Inference done 1770/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:06:05
[01/30 00:59:22] d2.evaluation.evaluator INFO: Inference done 1814/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:06:00
[01/30 00:59:27] d2.evaluation.evaluator INFO: Inference done 1858/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:55
[01/30 00:59:32] d2.evaluation.evaluator INFO: Inference done 1902/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:50
[01/30 00:59:37] d2.evaluation.evaluator INFO: Inference done 1946/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:45
[01/30 00:59:43] d2.evaluation.evaluator INFO: Inference done 1990/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:40
[01/30 00:59:48] d2.evaluation.evaluator INFO: Inference done 2034/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:35
[01/30 00:59:53] d2.evaluation.evaluator INFO: Inference done 2078/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:30
[01/30 00:59:58] d2.evaluation.evaluator INFO: Inference done 2122/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:25
[01/30 01:00:03] d2.evaluation.evaluator INFO: Inference done 2166/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:20
[01/30 01:00:08] d2.evaluation.evaluator INFO: Inference done 2210/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:15
[01/30 01:00:13] d2.evaluation.evaluator INFO: Inference done 2254/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:10
[01/30 01:00:18] d2.evaluation.evaluator INFO: Inference done 2298/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:05:05
[01/30 01:00:23] d2.evaluation.evaluator INFO: Inference done 2342/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:59
[01/30 01:00:28] d2.evaluation.evaluator INFO: Inference done 2386/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:54
[01/30 01:00:33] d2.evaluation.evaluator INFO: Inference done 2430/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:49
[01/30 01:00:38] d2.evaluation.evaluator INFO: Inference done 2474/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:44
[01/30 01:00:43] d2.evaluation.evaluator INFO: Inference done 2518/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:39
[01/30 01:00:48] d2.evaluation.evaluator INFO: Inference done 2562/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:34
[01/30 01:00:53] d2.evaluation.evaluator INFO: Inference done 2606/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:29
[01/30 01:00:58] d2.evaluation.evaluator INFO: Inference done 2650/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:24
[01/30 01:01:04] d2.evaluation.evaluator INFO: Inference done 2694/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:19
[01/30 01:01:09] d2.evaluation.evaluator INFO: Inference done 2738/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:14
[01/30 01:01:14] d2.evaluation.evaluator INFO: Inference done 2782/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:09
[01/30 01:01:19] d2.evaluation.evaluator INFO: Inference done 2826/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:04:04
[01/30 01:01:24] d2.evaluation.evaluator INFO: Inference done 2870/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:59
[01/30 01:01:29] d2.evaluation.evaluator INFO: Inference done 2913/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:54
[01/30 01:01:34] d2.evaluation.evaluator INFO: Inference done 2957/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:49
[01/30 01:01:39] d2.evaluation.evaluator INFO: Inference done 3001/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:44
[01/30 01:01:44] d2.evaluation.evaluator INFO: Inference done 3045/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:39
[01/30 01:01:49] d2.evaluation.evaluator INFO: Inference done 3089/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:34
[01/30 01:01:54] d2.evaluation.evaluator INFO: Inference done 3133/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:29
[01/30 01:01:59] d2.evaluation.evaluator INFO: Inference done 3177/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:24
[01/30 01:02:04] d2.evaluation.evaluator INFO: Inference done 3221/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:18
[01/30 01:02:09] d2.evaluation.evaluator INFO: Inference done 3265/4952. Dataloading: 0.0008 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:13
[01/30 01:02:14] d2.evaluation.evaluator INFO: Inference done 3309/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:08
[01/30 01:02:19] d2.evaluation.evaluator INFO: Inference done 3353/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:03:03
[01/30 01:02:24] d2.evaluation.evaluator INFO: Inference done 3397/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:58
[01/30 01:02:29] d2.evaluation.evaluator INFO: Inference done 3441/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:02:53
[01/30 01:02:34] d2.evaluation.evaluator INFO: Inference done 3485/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:02:48
[01/30 01:02:40] d2.evaluation.evaluator INFO: Inference done 3529/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:02:43
[01/30 01:02:45] d2.evaluation.evaluator INFO: Inference done 3573/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:38
[01/30 01:02:50] d2.evaluation.evaluator INFO: Inference done 3617/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:02:33
[01/30 01:02:55] d2.evaluation.evaluator INFO: Inference done 3661/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:28
[01/30 01:03:00] d2.evaluation.evaluator INFO: Inference done 3705/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:23
[01/30 01:03:05] d2.evaluation.evaluator INFO: Inference done 3749/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:18
[01/30 01:03:10] d2.evaluation.evaluator INFO: Inference done 3793/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:13
[01/30 01:03:15] d2.evaluation.evaluator INFO: Inference done 3837/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:02:08
[01/30 01:03:20] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:02:03
[01/30 01:03:25] d2.evaluation.evaluator INFO: Inference done 3925/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:58
[01/30 01:03:30] d2.evaluation.evaluator INFO: Inference done 3969/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:53
[01/30 01:03:35] d2.evaluation.evaluator INFO: Inference done 4012/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:48
[01/30 01:03:40] d2.evaluation.evaluator INFO: Inference done 4056/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:43
[01/30 01:03:45] d2.evaluation.evaluator INFO: Inference done 4100/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:37
[01/30 01:03:50] d2.evaluation.evaluator INFO: Inference done 4144/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:32
[01/30 01:03:55] d2.evaluation.evaluator INFO: Inference done 4188/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:27
[01/30 01:04:00] d2.evaluation.evaluator INFO: Inference done 4232/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:22
[01/30 01:04:05] d2.evaluation.evaluator INFO: Inference done 4276/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:17
[01/30 01:04:11] d2.evaluation.evaluator INFO: Inference done 4320/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:12
[01/30 01:04:16] d2.evaluation.evaluator INFO: Inference done 4364/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:07
[01/30 01:04:21] d2.evaluation.evaluator INFO: Inference done 4408/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:01:02
[01/30 01:04:26] d2.evaluation.evaluator INFO: Inference done 4452/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:00:57
[01/30 01:04:31] d2.evaluation.evaluator INFO: Inference done 4496/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:00:52
[01/30 01:04:36] d2.evaluation.evaluator INFO: Inference done 4540/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1150 s/iter. ETA=0:00:47
[01/30 01:04:41] d2.evaluation.evaluator INFO: Inference done 4584/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:42
[01/30 01:04:46] d2.evaluation.evaluator INFO: Inference done 4628/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:37
[01/30 01:04:51] d2.evaluation.evaluator INFO: Inference done 4672/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:32
[01/30 01:04:56] d2.evaluation.evaluator INFO: Inference done 4716/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:27
[01/30 01:05:01] d2.evaluation.evaluator INFO: Inference done 4760/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:22
[01/30 01:05:06] d2.evaluation.evaluator INFO: Inference done 4804/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:17
[01/30 01:05:11] d2.evaluation.evaluator INFO: Inference done 4848/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:11
[01/30 01:05:16] d2.evaluation.evaluator INFO: Inference done 4892/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:06
[01/30 01:05:21] d2.evaluation.evaluator INFO: Inference done 4936/4952. Dataloading: 0.0009 s/iter. Inference: 0.1140 s/iter. Eval: 0.0000 s/iter. Total: 0.1149 s/iter. ETA=0:00:01
[01/30 01:05:23] d2.evaluation.evaluator INFO: Total inference time: 0:09:28.719644 (0.114963 s / iter per device, on 1 devices)
[01/30 01:05:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:09:23 (0.114006 s / iter per device, on 1 devices)
[01/30 01:05:23] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[01/30 01:05:33] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car  |  cat  |  chair  |  diningtable  |  dog  |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow  |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:-----:|:-----:|:-------:|:-------------:|:-----:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:-----:|:-----------:|:------:|
|    0.000    |   0.000   | 0.000  |  0.000   | 0.000 | 0.000 |  0.000  |     0.000     | 0.000 |  0.000  |  0.000   |     0.000     |  0.000  |  0.000  |    0.000    | 0.000  | 0.000 | 0.000 |    0.000    | 0.000  |
[01/30 01:05:33] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|  AP   |  AP50  |  AP75  |  bAP  |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:-----:|:------:|:------:|:-----:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 0.000 | 0.000  | 0.000  | 0.000 |  0.000  |  0.000  | 0.000 |  0.000  |  0.000  |
[01/30 01:05:33] d2.engine.defaults INFO: Evaluation results for voc_2007_test_all1 in csv format:
[01/30 01:05:33] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/30 01:05:33] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[01/30 01:05:33] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[01/30 01:23:32] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 01:23:32] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 01:23:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/30 01:23:32] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/30 01:23:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 01:23:33] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 01:23:33] d2.utils.env INFO: Using a generated random seed 33171222
[01/30 01:23:35] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/30 01:23:36] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 01:23:37] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 01:23:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/30 01:23:37] d2.data.build INFO: Using training sampler TrainingSampler
[01/30 01:23:37] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/30 01:23:37] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/30 01:23:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/30 01:23:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[01/30 01:23:37] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  head.{bias, weight}
[01/30 01:23:37] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 01:23:52] d2.utils.events INFO:  eta: 3:36:50  iter: 19  total_loss: 5.013  loss_cls: 4.135  loss_box_reg: 0.07205  loss_rpn_cls: 0.6919  loss_rpn_loc: 0.08791  time: 0.7105  data_time: 0.0083  lr: 3.8162e-05  max_mem: 14763M
[01/30 01:24:06] d2.utils.events INFO:  eta: 3:36:36  iter: 39  total_loss: 1.405  loss_cls: 0.41  loss_box_reg: 0.08647  loss_rpn_cls: 0.6873  loss_rpn_loc: 0.1274  time: 0.7098  data_time: 0.0021  lr: 7.8122e-05  max_mem: 14887M
[01/30 01:24:21] d2.utils.events INFO:  eta: 3:39:30  iter: 59  total_loss: 1.163  loss_cls: 0.2561  loss_box_reg: 0.1262  loss_rpn_cls: 0.6435  loss_rpn_loc: 0.1126  time: 0.7181  data_time: 0.0020  lr: 0.00011808  max_mem: 14887M
[01/30 01:24:35] d2.utils.events INFO:  eta: 3:32:20  iter: 79  total_loss: 0.806  loss_cls: 0.1671  loss_box_reg: 0.0834  loss_rpn_cls: 0.3729  loss_rpn_loc: 0.1697  time: 0.7074  data_time: 0.0020  lr: 0.00015804  max_mem: 14887M
[01/30 01:24:49] d2.utils.events INFO:  eta: 3:31:36  iter: 99  total_loss: 0.9464  loss_cls: 0.2344  loss_box_reg: 0.1347  loss_rpn_cls: 0.3552  loss_rpn_loc: 0.1445  time: 0.7082  data_time: 0.0021  lr: 0.000198  max_mem: 14887M
[01/30 01:25:04] d2.utils.events INFO:  eta: 3:32:19  iter: 119  total_loss: 0.8867  loss_cls: 0.2228  loss_box_reg: 0.1388  loss_rpn_cls: 0.3262  loss_rpn_loc: 0.1465  time: 0.7163  data_time: 0.0020  lr: 0.0002  max_mem: 14887M
[01/30 01:25:18] d2.utils.events INFO:  eta: 3:31:37  iter: 139  total_loss: 0.9024  loss_cls: 0.2977  loss_box_reg: 0.1855  loss_rpn_cls: 0.3243  loss_rpn_loc: 0.1412  time: 0.7155  data_time: 0.0020  lr: 0.0002  max_mem: 14887M
[01/30 01:25:33] d2.utils.events INFO:  eta: 3:31:23  iter: 159  total_loss: 0.853  loss_cls: 0.235  loss_box_reg: 0.133  loss_rpn_cls: 0.3041  loss_rpn_loc: 0.1253  time: 0.7165  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:25:48] d2.utils.events INFO:  eta: 3:32:01  iter: 179  total_loss: 0.8105  loss_cls: 0.2517  loss_box_reg: 0.1394  loss_rpn_cls: 0.2831  loss_rpn_loc: 0.1201  time: 0.7203  data_time: 0.0022  lr: 0.0002  max_mem: 14887M
[01/30 01:26:03] d2.utils.events INFO:  eta: 3:31:38  iter: 199  total_loss: 0.7939  loss_cls: 0.2733  loss_box_reg: 0.1567  loss_rpn_cls: 0.2431  loss_rpn_loc: 0.1076  time: 0.7237  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:26:17] d2.utils.events INFO:  eta: 3:29:56  iter: 219  total_loss: 0.9377  loss_cls: 0.3136  loss_box_reg: 0.2031  loss_rpn_cls: 0.2368  loss_rpn_loc: 0.1039  time: 0.7199  data_time: 0.0022  lr: 0.0002  max_mem: 14887M
[01/30 01:26:31] d2.utils.events INFO:  eta: 3:28:25  iter: 239  total_loss: 0.84  loss_cls: 0.3005  loss_box_reg: 0.1955  loss_rpn_cls: 0.2337  loss_rpn_loc: 0.1059  time: 0.7183  data_time: 0.0020  lr: 0.0002  max_mem: 14887M
[01/30 01:26:45] d2.utils.events INFO:  eta: 3:26:48  iter: 259  total_loss: 0.9885  loss_cls: 0.2731  loss_box_reg: 0.1819  loss_rpn_cls: 0.2619  loss_rpn_loc: 0.2066  time: 0.7162  data_time: 0.0020  lr: 0.0002  max_mem: 14887M
[01/30 01:26:59] d2.utils.events INFO:  eta: 3:26:32  iter: 279  total_loss: 0.8585  loss_cls: 0.2436  loss_box_reg: 0.1542  loss_rpn_cls: 0.2712  loss_rpn_loc: 0.1517  time: 0.7148  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:27:13] d2.utils.events INFO:  eta: 3:27:20  iter: 299  total_loss: 0.8032  loss_cls: 0.2551  loss_box_reg: 0.1344  loss_rpn_cls: 0.2457  loss_rpn_loc: 0.1162  time: 0.7169  data_time: 0.0020  lr: 0.0002  max_mem: 14887M
[01/30 01:27:29] d2.utils.events INFO:  eta: 3:30:11  iter: 319  total_loss: 0.9741  loss_cls: 0.3312  loss_box_reg: 0.1979  loss_rpn_cls: 0.2614  loss_rpn_loc: 0.1255  time: 0.7195  data_time: 0.0022  lr: 0.0002  max_mem: 14887M
[01/30 01:27:43] d2.utils.events INFO:  eta: 3:29:49  iter: 339  total_loss: 0.7013  loss_cls: 0.2241  loss_box_reg: 0.1368  loss_rpn_cls: 0.2431  loss_rpn_loc: 0.08582  time: 0.7180  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:27:57] d2.utils.events INFO:  eta: 3:29:35  iter: 359  total_loss: 0.7034  loss_cls: 0.2232  loss_box_reg: 0.1559  loss_rpn_cls: 0.1902  loss_rpn_loc: 0.09577  time: 0.7169  data_time: 0.0020  lr: 0.0002  max_mem: 14887M
[01/30 01:28:11] d2.utils.events INFO:  eta: 3:29:21  iter: 379  total_loss: 0.8226  loss_cls: 0.2704  loss_box_reg: 0.1995  loss_rpn_cls: 0.2001  loss_rpn_loc: 0.1161  time: 0.7165  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:28:25] d2.utils.events INFO:  eta: 3:28:38  iter: 399  total_loss: 0.6173  loss_cls: 0.1761  loss_box_reg: 0.1275  loss_rpn_cls: 0.209  loss_rpn_loc: 0.09524  time: 0.7150  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:28:39] d2.utils.events INFO:  eta: 3:28:11  iter: 419  total_loss: 0.9561  loss_cls: 0.2795  loss_box_reg: 0.2364  loss_rpn_cls: 0.2039  loss_rpn_loc: 0.0971  time: 0.7149  data_time: 0.0022  lr: 0.0002  max_mem: 14887M
[01/30 01:28:54] d2.utils.events INFO:  eta: 3:27:57  iter: 439  total_loss: 0.7888  loss_cls: 0.2538  loss_box_reg: 0.1784  loss_rpn_cls: 0.2102  loss_rpn_loc: 0.1664  time: 0.7159  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:29:08] d2.utils.events INFO:  eta: 3:27:37  iter: 459  total_loss: 0.9427  loss_cls: 0.3446  loss_box_reg: 0.2105  loss_rpn_cls: 0.2168  loss_rpn_loc: 0.1808  time: 0.7146  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:29:21] d2.utils.events INFO:  eta: 3:26:52  iter: 479  total_loss: 0.7988  loss_cls: 0.2375  loss_box_reg: 0.176  loss_rpn_cls: 0.1752  loss_rpn_loc: 0.1353  time: 0.7125  data_time: 0.0021  lr: 0.0002  max_mem: 14887M
[01/30 01:29:34] d2.utils.events INFO:  eta: 3:26:05  iter: 499  total_loss: 0.7837  loss_cls: 0.2514  loss_box_reg: 0.1985  loss_rpn_cls: 0.2002  loss_rpn_loc: 0.09564  time: 0.7101  data_time: 0.0021  lr: 0.0002  max_mem: 14924M
[01/30 01:29:48] d2.utils.events INFO:  eta: 3:25:51  iter: 519  total_loss: 0.6797  loss_cls: 0.2235  loss_box_reg: 0.1843  loss_rpn_cls: 0.1766  loss_rpn_loc: 0.08192  time: 0.7103  data_time: 0.0021  lr: 0.0002  max_mem: 14924M
[01/30 01:30:03] d2.utils.events INFO:  eta: 3:25:26  iter: 539  total_loss: 0.7714  loss_cls: 0.2456  loss_box_reg: 0.1836  loss_rpn_cls: 0.1665  loss_rpn_loc: 0.1275  time: 0.7109  data_time: 0.0022  lr: 0.0002  max_mem: 15246M
[01/30 01:30:17] d2.utils.events INFO:  eta: 3:25:22  iter: 559  total_loss: 0.7445  loss_cls: 0.211  loss_box_reg: 0.1898  loss_rpn_cls: 0.1527  loss_rpn_loc: 0.1057  time: 0.7105  data_time: 0.0021  lr: 0.0002  max_mem: 15246M
[01/30 01:30:31] d2.utils.events INFO:  eta: 3:25:08  iter: 579  total_loss: 0.8198  loss_cls: 0.2663  loss_box_reg: 0.2298  loss_rpn_cls: 0.18  loss_rpn_loc: 0.137  time: 0.7097  data_time: 0.0020  lr: 0.0002  max_mem: 15246M
[01/30 01:30:45] d2.utils.events INFO:  eta: 3:24:44  iter: 599  total_loss: 0.6964  loss_cls: 0.1854  loss_box_reg: 0.2017  loss_rpn_cls: 0.1349  loss_rpn_loc: 0.1075  time: 0.7101  data_time: 0.0020  lr: 0.0002  max_mem: 15246M
[01/30 01:31:00] d2.utils.events INFO:  eta: 3:24:59  iter: 619  total_loss: 0.8594  loss_cls: 0.2911  loss_box_reg: 0.2401  loss_rpn_cls: 0.1438  loss_rpn_loc: 0.07551  time: 0.7102  data_time: 0.0021  lr: 0.0002  max_mem: 15246M
[01/30 01:31:14] d2.utils.events INFO:  eta: 3:25:10  iter: 639  total_loss: 0.7572  loss_cls: 0.257  loss_box_reg: 0.1928  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.1196  time: 0.7108  data_time: 0.0021  lr: 0.0002  max_mem: 15256M
[01/30 01:31:28] d2.utils.events INFO:  eta: 3:24:44  iter: 659  total_loss: 0.6965  loss_cls: 0.199  loss_box_reg: 0.1841  loss_rpn_cls: 0.1638  loss_rpn_loc: 0.1091  time: 0.7100  data_time: 0.0023  lr: 0.0002  max_mem: 15256M
[01/30 01:31:42] d2.utils.events INFO:  eta: 3:24:42  iter: 679  total_loss: 0.6335  loss_cls: 0.2145  loss_box_reg: 0.1647  loss_rpn_cls: 0.18  loss_rpn_loc: 0.09505  time: 0.7095  data_time: 0.0021  lr: 0.0002  max_mem: 15256M
[01/30 01:31:56] d2.utils.events INFO:  eta: 3:24:39  iter: 699  total_loss: 0.7255  loss_cls: 0.2344  loss_box_reg: 0.1836  loss_rpn_cls: 0.1766  loss_rpn_loc: 0.08668  time: 0.7096  data_time: 0.0022  lr: 0.0002  max_mem: 15256M
[01/30 01:32:11] d2.utils.events INFO:  eta: 3:24:25  iter: 719  total_loss: 0.6877  loss_cls: 0.1702  loss_box_reg: 0.156  loss_rpn_cls: 0.1926  loss_rpn_loc: 0.1501  time: 0.7098  data_time: 0.0021  lr: 0.0002  max_mem: 15256M
[01/30 01:32:25] d2.utils.events INFO:  eta: 3:24:14  iter: 739  total_loss: 0.7487  loss_cls: 0.2036  loss_box_reg: 0.1884  loss_rpn_cls: 0.1906  loss_rpn_loc: 0.08957  time: 0.7096  data_time: 0.0021  lr: 0.0002  max_mem: 15256M
[01/30 01:32:38] d2.utils.events INFO:  eta: 3:23:59  iter: 759  total_loss: 0.8089  loss_cls: 0.2248  loss_box_reg: 0.247  loss_rpn_cls: 0.1538  loss_rpn_loc: 0.1378  time: 0.7090  data_time: 0.0021  lr: 0.0002  max_mem: 15256M
[01/30 01:32:52] d2.utils.events INFO:  eta: 3:23:42  iter: 779  total_loss: 0.6967  loss_cls: 0.1909  loss_box_reg: 0.1735  loss_rpn_cls: 0.14  loss_rpn_loc: 0.1236  time: 0.7085  data_time: 0.0020  lr: 0.0002  max_mem: 15256M
[01/30 01:33:07] d2.utils.events INFO:  eta: 3:23:40  iter: 799  total_loss: 0.7863  loss_cls: 0.2296  loss_box_reg: 0.1751  loss_rpn_cls: 0.1752  loss_rpn_loc: 0.1182  time: 0.7086  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:33:21] d2.utils.events INFO:  eta: 3:23:26  iter: 819  total_loss: 0.6901  loss_cls: 0.1841  loss_box_reg: 0.191  loss_rpn_cls: 0.1587  loss_rpn_loc: 0.1555  time: 0.7083  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:33:34] d2.utils.events INFO:  eta: 3:23:12  iter: 839  total_loss: 0.7796  loss_cls: 0.2282  loss_box_reg: 0.2388  loss_rpn_cls: 0.1392  loss_rpn_loc: 0.1044  time: 0.7078  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:33:48] d2.utils.events INFO:  eta: 3:22:48  iter: 859  total_loss: 0.8045  loss_cls: 0.2359  loss_box_reg: 0.2568  loss_rpn_cls: 0.1613  loss_rpn_loc: 0.08917  time: 0.7069  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:34:02] d2.utils.events INFO:  eta: 3:22:08  iter: 879  total_loss: 0.7381  loss_cls: 0.2434  loss_box_reg: 0.2564  loss_rpn_cls: 0.1334  loss_rpn_loc: 0.1065  time: 0.7067  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:34:16] d2.utils.events INFO:  eta: 3:21:41  iter: 899  total_loss: 0.6337  loss_cls: 0.1897  loss_box_reg: 0.205  loss_rpn_cls: 0.1612  loss_rpn_loc: 0.09371  time: 0.7064  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:34:30] d2.utils.events INFO:  eta: 3:21:26  iter: 919  total_loss: 0.6234  loss_cls: 0.1809  loss_box_reg: 0.1767  loss_rpn_cls: 0.1209  loss_rpn_loc: 0.121  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:34:44] d2.utils.events INFO:  eta: 3:21:52  iter: 939  total_loss: 0.6373  loss_cls: 0.1722  loss_box_reg: 0.1801  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.1223  time: 0.7065  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:34:59] d2.utils.events INFO:  eta: 3:21:37  iter: 959  total_loss: 0.7253  loss_cls: 0.1902  loss_box_reg: 0.2071  loss_rpn_cls: 0.1634  loss_rpn_loc: 0.1371  time: 0.7067  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:35:13] d2.utils.events INFO:  eta: 3:21:32  iter: 979  total_loss: 0.6055  loss_cls: 0.1911  loss_box_reg: 0.1949  loss_rpn_cls: 0.1429  loss_rpn_loc: 0.1073  time: 0.7067  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:35:27] d2.utils.events INFO:  eta: 3:21:21  iter: 999  total_loss: 0.6531  loss_cls: 0.1843  loss_box_reg: 0.1803  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.1363  time: 0.7072  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:35:41] d2.utils.events INFO:  eta: 3:20:55  iter: 1019  total_loss: 0.7304  loss_cls: 0.219  loss_box_reg: 0.2528  loss_rpn_cls: 0.1333  loss_rpn_loc: 0.09558  time: 0.7063  data_time: 0.0019  lr: 0.0002  max_mem: 15387M
[01/30 01:35:55] d2.utils.events INFO:  eta: 3:20:47  iter: 1039  total_loss: 0.7611  loss_cls: 0.2078  loss_box_reg: 0.2129  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.1649  time: 0.7070  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:36:10] d2.utils.events INFO:  eta: 3:20:01  iter: 1059  total_loss: 0.5183  loss_cls: 0.1451  loss_box_reg: 0.1749  loss_rpn_cls: 0.1376  loss_rpn_loc: 0.101  time: 0.7069  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:36:23] d2.utils.events INFO:  eta: 3:20:15  iter: 1079  total_loss: 0.5969  loss_cls: 0.189  loss_box_reg: 0.1658  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.09986  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:36:37] d2.utils.events INFO:  eta: 3:20:01  iter: 1099  total_loss: 0.585  loss_cls: 0.1624  loss_box_reg: 0.1828  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.08642  time: 0.7059  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:36:52] d2.utils.events INFO:  eta: 3:19:53  iter: 1119  total_loss: 0.8431  loss_cls: 0.1754  loss_box_reg: 0.1625  loss_rpn_cls: 0.135  loss_rpn_loc: 0.1243  time: 0.7067  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:37:07] d2.utils.events INFO:  eta: 3:20:03  iter: 1139  total_loss: 0.7816  loss_cls: 0.2382  loss_box_reg: 0.2079  loss_rpn_cls: 0.1463  loss_rpn_loc: 0.163  time: 0.7071  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:37:20] d2.utils.events INFO:  eta: 3:19:34  iter: 1159  total_loss: 0.5637  loss_cls: 0.1657  loss_box_reg: 0.1691  loss_rpn_cls: 0.1495  loss_rpn_loc: 0.07852  time: 0.7068  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:37:35] d2.utils.events INFO:  eta: 3:19:16  iter: 1179  total_loss: 0.6646  loss_cls: 0.2009  loss_box_reg: 0.2044  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.1102  time: 0.7073  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:37:50] d2.utils.events INFO:  eta: 3:19:20  iter: 1199  total_loss: 0.6897  loss_cls: 0.2074  loss_box_reg: 0.1934  loss_rpn_cls: 0.1259  loss_rpn_loc: 0.1279  time: 0.7076  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:38:05] d2.utils.events INFO:  eta: 3:19:39  iter: 1219  total_loss: 0.6139  loss_cls: 0.1549  loss_box_reg: 0.1734  loss_rpn_cls: 0.1244  loss_rpn_loc: 0.1547  time: 0.7084  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 01:38:19] d2.utils.events INFO:  eta: 3:19:25  iter: 1239  total_loss: 0.6569  loss_cls: 0.1825  loss_box_reg: 0.2035  loss_rpn_cls: 0.137  loss_rpn_loc: 0.1229  time: 0.7082  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:38:33] d2.utils.events INFO:  eta: 3:19:25  iter: 1259  total_loss: 0.6745  loss_cls: 0.1952  loss_box_reg: 0.195  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.09094  time: 0.7084  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:38:48] d2.utils.events INFO:  eta: 3:19:17  iter: 1279  total_loss: 0.7402  loss_cls: 0.2143  loss_box_reg: 0.2322  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.1235  time: 0.7090  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:39:02] d2.utils.events INFO:  eta: 3:19:01  iter: 1299  total_loss: 0.6108  loss_cls: 0.1909  loss_box_reg: 0.1794  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.1493  time: 0.7087  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:39:16] d2.utils.events INFO:  eta: 3:18:28  iter: 1319  total_loss: 0.5915  loss_cls: 0.1687  loss_box_reg: 0.1898  loss_rpn_cls: 0.1386  loss_rpn_loc: 0.0959  time: 0.7083  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 01:39:30] d2.utils.events INFO:  eta: 3:18:14  iter: 1339  total_loss: 0.6062  loss_cls: 0.147  loss_box_reg: 0.2026  loss_rpn_cls: 0.1365  loss_rpn_loc: 0.1005  time: 0.7082  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:39:44] d2.utils.events INFO:  eta: 3:18:13  iter: 1359  total_loss: 0.5872  loss_cls: 0.1575  loss_box_reg: 0.182  loss_rpn_cls: 0.1064  loss_rpn_loc: 0.1239  time: 0.7083  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:39:59] d2.utils.events INFO:  eta: 3:18:01  iter: 1379  total_loss: 0.6784  loss_cls: 0.1814  loss_box_reg: 0.1855  loss_rpn_cls: 0.1452  loss_rpn_loc: 0.1475  time: 0.7085  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:40:12] d2.utils.events INFO:  eta: 3:17:47  iter: 1399  total_loss: 0.5918  loss_cls: 0.1869  loss_box_reg: 0.1576  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.0997  time: 0.7082  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:40:26] d2.utils.events INFO:  eta: 3:17:30  iter: 1419  total_loss: 0.8078  loss_cls: 0.2342  loss_box_reg: 0.2849  loss_rpn_cls: 0.1508  loss_rpn_loc: 0.1241  time: 0.7076  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:40:40] d2.utils.events INFO:  eta: 3:17:21  iter: 1439  total_loss: 0.5439  loss_cls: 0.1383  loss_box_reg: 0.1231  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.1252  time: 0.7077  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:40:54] d2.utils.events INFO:  eta: 3:17:08  iter: 1459  total_loss: 0.649  loss_cls: 0.1804  loss_box_reg: 0.1746  loss_rpn_cls: 0.1442  loss_rpn_loc: 0.1104  time: 0.7075  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:41:08] d2.utils.events INFO:  eta: 3:17:11  iter: 1479  total_loss: 0.6647  loss_cls: 0.1936  loss_box_reg: 0.212  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1003  time: 0.7074  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:41:23] d2.utils.events INFO:  eta: 3:17:11  iter: 1499  total_loss: 0.5227  loss_cls: 0.1466  loss_box_reg: 0.1636  loss_rpn_cls: 0.08681  loss_rpn_loc: 0.1058  time: 0.7075  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:41:36] d2.utils.events INFO:  eta: 3:16:48  iter: 1519  total_loss: 0.5799  loss_cls: 0.1926  loss_box_reg: 0.1549  loss_rpn_cls: 0.1219  loss_rpn_loc: 0.07619  time: 0.7070  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:41:51] d2.utils.events INFO:  eta: 3:16:55  iter: 1539  total_loss: 0.53  loss_cls: 0.1415  loss_box_reg: 0.1102  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.09758  time: 0.7077  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:42:04] d2.utils.events INFO:  eta: 3:16:33  iter: 1559  total_loss: 0.6423  loss_cls: 0.2031  loss_box_reg: 0.2455  loss_rpn_cls: 0.1173  loss_rpn_loc: 0.09146  time: 0.7071  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:42:18] d2.utils.events INFO:  eta: 3:16:00  iter: 1579  total_loss: 0.6399  loss_cls: 0.1551  loss_box_reg: 0.1575  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.1099  time: 0.7066  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:42:33] d2.utils.events INFO:  eta: 3:16:12  iter: 1599  total_loss: 0.5678  loss_cls: 0.1714  loss_box_reg: 0.1889  loss_rpn_cls: 0.108  loss_rpn_loc: 0.08666  time: 0.7074  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:42:48] d2.utils.events INFO:  eta: 3:16:03  iter: 1619  total_loss: 0.5412  loss_cls: 0.1529  loss_box_reg: 0.1498  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.14  time: 0.7076  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:43:02] d2.utils.events INFO:  eta: 3:15:44  iter: 1639  total_loss: 0.6042  loss_cls: 0.1571  loss_box_reg: 0.2214  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.1252  time: 0.7077  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:43:15] d2.utils.events INFO:  eta: 3:15:12  iter: 1659  total_loss: 0.7067  loss_cls: 0.1673  loss_box_reg: 0.2425  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.0962  time: 0.7071  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 01:43:30] d2.utils.events INFO:  eta: 3:15:03  iter: 1679  total_loss: 0.6422  loss_cls: 0.1715  loss_box_reg: 0.2094  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.1196  time: 0.7072  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:43:43] d2.utils.events INFO:  eta: 3:14:27  iter: 1699  total_loss: 0.5523  loss_cls: 0.1593  loss_box_reg: 0.1684  loss_rpn_cls: 0.1213  loss_rpn_loc: 0.1295  time: 0.7069  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:43:57] d2.utils.events INFO:  eta: 3:14:05  iter: 1719  total_loss: 0.5354  loss_cls: 0.1729  loss_box_reg: 0.179  loss_rpn_cls: 0.09776  loss_rpn_loc: 0.08092  time: 0.7064  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:44:10] d2.utils.events INFO:  eta: 3:13:44  iter: 1739  total_loss: 0.5679  loss_cls: 0.1614  loss_box_reg: 0.166  loss_rpn_cls: 0.1385  loss_rpn_loc: 0.1207  time: 0.7061  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:44:24] d2.utils.events INFO:  eta: 3:13:27  iter: 1759  total_loss: 0.6121  loss_cls: 0.169  loss_box_reg: 0.1825  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1083  time: 0.7060  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:44:39] d2.utils.events INFO:  eta: 3:13:17  iter: 1779  total_loss: 0.501  loss_cls: 0.1347  loss_box_reg: 0.1314  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.11  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:44:53] d2.utils.events INFO:  eta: 3:13:03  iter: 1799  total_loss: 0.6987  loss_cls: 0.1783  loss_box_reg: 0.2495  loss_rpn_cls: 0.1608  loss_rpn_loc: 0.1205  time: 0.7064  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:45:07] d2.utils.events INFO:  eta: 3:12:47  iter: 1819  total_loss: 0.467  loss_cls: 0.1546  loss_box_reg: 0.1554  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.0812  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:45:21] d2.utils.events INFO:  eta: 3:12:32  iter: 1839  total_loss: 0.5087  loss_cls: 0.1585  loss_box_reg: 0.1624  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.07107  time: 0.7060  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:45:35] d2.utils.events INFO:  eta: 3:12:04  iter: 1859  total_loss: 0.5888  loss_cls: 0.1508  loss_box_reg: 0.1614  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.07178  time: 0.7057  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:45:49] d2.utils.events INFO:  eta: 3:12:04  iter: 1879  total_loss: 0.5861  loss_cls: 0.1566  loss_box_reg: 0.1455  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.1215  time: 0.7060  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:46:04] d2.utils.events INFO:  eta: 3:11:50  iter: 1899  total_loss: 0.5981  loss_cls: 0.1728  loss_box_reg: 0.1985  loss_rpn_cls: 0.1164  loss_rpn_loc: 0.08301  time: 0.7061  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:46:18] d2.utils.events INFO:  eta: 3:11:35  iter: 1919  total_loss: 0.5688  loss_cls: 0.1767  loss_box_reg: 0.199  loss_rpn_cls: 0.09459  loss_rpn_loc: 0.06595  time: 0.7061  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:46:31] d2.utils.events INFO:  eta: 3:11:07  iter: 1939  total_loss: 0.6253  loss_cls: 0.1713  loss_box_reg: 0.1888  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.08426  time: 0.7057  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:46:45] d2.utils.events INFO:  eta: 3:11:06  iter: 1959  total_loss: 0.6346  loss_cls: 0.1256  loss_box_reg: 0.1868  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.1212  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:46:59] d2.utils.events INFO:  eta: 3:10:27  iter: 1979  total_loss: 0.5717  loss_cls: 0.1517  loss_box_reg: 0.1812  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.1016  time: 0.7056  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:47:13] d2.utils.events INFO:  eta: 3:09:59  iter: 1999  total_loss: 0.6023  loss_cls: 0.1421  loss_box_reg: 0.1915  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.1625  time: 0.7056  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:47:27] d2.utils.events INFO:  eta: 3:09:47  iter: 2019  total_loss: 0.5428  loss_cls: 0.1433  loss_box_reg: 0.1781  loss_rpn_cls: 0.09067  loss_rpn_loc: 0.07221  time: 0.7054  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:47:41] d2.utils.events INFO:  eta: 3:09:28  iter: 2039  total_loss: 0.5627  loss_cls: 0.135  loss_box_reg: 0.1964  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.1105  time: 0.7050  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:47:55] d2.utils.events INFO:  eta: 3:09:16  iter: 2059  total_loss: 0.5906  loss_cls: 0.1564  loss_box_reg: 0.1994  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.07849  time: 0.7052  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:48:09] d2.utils.events INFO:  eta: 3:09:07  iter: 2079  total_loss: 0.4923  loss_cls: 0.1108  loss_box_reg: 0.1025  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.08552  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:48:24] d2.utils.events INFO:  eta: 3:08:56  iter: 2099  total_loss: 0.5428  loss_cls: 0.1238  loss_box_reg: 0.1519  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.06069  time: 0.7053  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:48:38] d2.utils.events INFO:  eta: 3:08:36  iter: 2119  total_loss: 0.5648  loss_cls: 0.1494  loss_box_reg: 0.1858  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.07102  time: 0.7055  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:48:52] d2.utils.events INFO:  eta: 3:08:17  iter: 2139  total_loss: 0.5335  loss_cls: 0.1286  loss_box_reg: 0.1382  loss_rpn_cls: 0.09243  loss_rpn_loc: 0.1271  time: 0.7055  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:49:08] d2.utils.events INFO:  eta: 3:08:18  iter: 2159  total_loss: 0.563  loss_cls: 0.1269  loss_box_reg: 0.1381  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.1509  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:49:22] d2.utils.events INFO:  eta: 3:08:06  iter: 2179  total_loss: 0.5137  loss_cls: 0.1378  loss_box_reg: 0.1427  loss_rpn_cls: 0.08986  loss_rpn_loc: 0.1404  time: 0.7063  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:49:36] d2.utils.events INFO:  eta: 3:07:41  iter: 2199  total_loss: 0.4916  loss_cls: 0.1189  loss_box_reg: 0.1752  loss_rpn_cls: 0.09964  loss_rpn_loc: 0.1046  time: 0.7063  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 01:49:50] d2.utils.events INFO:  eta: 3:07:16  iter: 2219  total_loss: 0.4  loss_cls: 0.09794  loss_box_reg: 0.114  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.08705  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:50:04] d2.utils.events INFO:  eta: 3:07:06  iter: 2239  total_loss: 0.4495  loss_cls: 0.1191  loss_box_reg: 0.1422  loss_rpn_cls: 0.08622  loss_rpn_loc: 0.08215  time: 0.7061  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:50:18] d2.utils.events INFO:  eta: 3:06:51  iter: 2259  total_loss: 0.5841  loss_cls: 0.154  loss_box_reg: 0.1661  loss_rpn_cls: 0.08546  loss_rpn_loc: 0.1147  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:50:32] d2.utils.events INFO:  eta: 3:06:18  iter: 2279  total_loss: 0.5719  loss_cls: 0.1625  loss_box_reg: 0.177  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.09798  time: 0.7058  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:50:46] d2.utils.events INFO:  eta: 3:06:10  iter: 2299  total_loss: 0.5122  loss_cls: 0.1381  loss_box_reg: 0.1429  loss_rpn_cls: 0.09897  loss_rpn_loc: 0.1632  time: 0.7059  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:51:01] d2.utils.events INFO:  eta: 3:06:09  iter: 2319  total_loss: 0.7168  loss_cls: 0.1957  loss_box_reg: 0.2056  loss_rpn_cls: 0.1631  loss_rpn_loc: 0.1192  time: 0.7063  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:51:15] d2.utils.events INFO:  eta: 3:05:55  iter: 2339  total_loss: 0.5671  loss_cls: 0.1487  loss_box_reg: 0.1697  loss_rpn_cls: 0.1187  loss_rpn_loc: 0.06525  time: 0.7061  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:51:29] d2.utils.events INFO:  eta: 3:05:21  iter: 2359  total_loss: 0.5253  loss_cls: 0.1481  loss_box_reg: 0.1718  loss_rpn_cls: 0.09142  loss_rpn_loc: 0.1108  time: 0.7059  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:51:42] d2.utils.events INFO:  eta: 3:05:04  iter: 2379  total_loss: 0.5832  loss_cls: 0.1419  loss_box_reg: 0.139  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.1439  time: 0.7055  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:51:56] d2.utils.events INFO:  eta: 3:04:52  iter: 2399  total_loss: 0.4921  loss_cls: 0.1191  loss_box_reg: 0.1903  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.1012  time: 0.7055  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:52:09] d2.utils.events INFO:  eta: 3:04:38  iter: 2419  total_loss: 0.5438  loss_cls: 0.1773  loss_box_reg: 0.2001  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1024  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:52:24] d2.utils.events INFO:  eta: 3:04:20  iter: 2439  total_loss: 0.5374  loss_cls: 0.1126  loss_box_reg: 0.1484  loss_rpn_cls: 0.07449  loss_rpn_loc: 0.1175  time: 0.7052  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:52:37] d2.utils.events INFO:  eta: 3:04:00  iter: 2459  total_loss: 0.6283  loss_cls: 0.1613  loss_box_reg: 0.1648  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.1371  time: 0.7049  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:52:52] d2.utils.events INFO:  eta: 3:03:51  iter: 2479  total_loss: 0.5838  loss_cls: 0.1415  loss_box_reg: 0.1704  loss_rpn_cls: 0.122  loss_rpn_loc: 0.1085  time: 0.7053  data_time: 0.0026  lr: 0.0002  max_mem: 15387M
[01/30 01:53:06] d2.utils.events INFO:  eta: 3:03:21  iter: 2499  total_loss: 0.621  loss_cls: 0.1906  loss_box_reg: 0.1744  loss_rpn_cls: 0.1146  loss_rpn_loc: 0.0811  time: 0.7053  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:53:21] d2.utils.events INFO:  eta: 3:03:24  iter: 2519  total_loss: 0.511  loss_cls: 0.1362  loss_box_reg: 0.1583  loss_rpn_cls: 0.08826  loss_rpn_loc: 0.07301  time: 0.7053  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:53:36] d2.utils.events INFO:  eta: 3:03:10  iter: 2539  total_loss: 0.4102  loss_cls: 0.1111  loss_box_reg: 0.1082  loss_rpn_cls: 0.09388  loss_rpn_loc: 0.1167  time: 0.7057  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:53:50] d2.utils.events INFO:  eta: 3:02:59  iter: 2559  total_loss: 0.5658  loss_cls: 0.1547  loss_box_reg: 0.1527  loss_rpn_cls: 0.09305  loss_rpn_loc: 0.06294  time: 0.7057  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:54:04] d2.utils.events INFO:  eta: 3:03:04  iter: 2579  total_loss: 0.6226  loss_cls: 0.1484  loss_box_reg: 0.1813  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.1477  time: 0.7058  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 01:54:19] d2.utils.events INFO:  eta: 3:02:45  iter: 2599  total_loss: 0.5645  loss_cls: 0.1358  loss_box_reg: 0.1894  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.09231  time: 0.7059  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:54:33] d2.utils.events INFO:  eta: 3:02:14  iter: 2619  total_loss: 0.5824  loss_cls: 0.1508  loss_box_reg: 0.183  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.112  time: 0.7059  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:54:47] d2.utils.events INFO:  eta: 3:02:02  iter: 2639  total_loss: 0.5921  loss_cls: 0.1632  loss_box_reg: 0.1821  loss_rpn_cls: 0.1346  loss_rpn_loc: 0.07467  time: 0.7060  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:55:01] d2.utils.events INFO:  eta: 3:02:07  iter: 2659  total_loss: 0.4513  loss_cls: 0.1109  loss_box_reg: 0.1111  loss_rpn_cls: 0.09602  loss_rpn_loc: 0.07658  time: 0.7059  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:55:15] d2.utils.events INFO:  eta: 3:01:46  iter: 2679  total_loss: 0.3612  loss_cls: 0.1104  loss_box_reg: 0.1187  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.06937  time: 0.7057  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:55:30] d2.utils.events INFO:  eta: 3:01:42  iter: 2699  total_loss: 0.5051  loss_cls: 0.1227  loss_box_reg: 0.153  loss_rpn_cls: 0.09173  loss_rpn_loc: 0.1755  time: 0.7059  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:55:44] d2.utils.events INFO:  eta: 3:01:30  iter: 2719  total_loss: 0.5675  loss_cls: 0.1436  loss_box_reg: 0.1829  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.09841  time: 0.7059  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:55:58] d2.utils.events INFO:  eta: 3:01:16  iter: 2739  total_loss: 0.5839  loss_cls: 0.1444  loss_box_reg: 0.2043  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.1099  time: 0.7059  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:56:12] d2.utils.events INFO:  eta: 3:01:14  iter: 2759  total_loss: 0.5486  loss_cls: 0.1387  loss_box_reg: 0.1979  loss_rpn_cls: 0.09502  loss_rpn_loc: 0.09426  time: 0.7059  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 01:56:27] d2.utils.events INFO:  eta: 3:00:51  iter: 2779  total_loss: 0.6496  loss_cls: 0.1379  loss_box_reg: 0.1251  loss_rpn_cls: 0.1252  loss_rpn_loc: 0.1348  time: 0.7060  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:56:40] d2.utils.events INFO:  eta: 3:00:31  iter: 2799  total_loss: 0.6345  loss_cls: 0.1868  loss_box_reg: 0.2316  loss_rpn_cls: 0.1219  loss_rpn_loc: 0.1105  time: 0.7058  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:56:55] d2.utils.events INFO:  eta: 3:00:27  iter: 2819  total_loss: 0.5145  loss_cls: 0.1309  loss_box_reg: 0.142  loss_rpn_cls: 0.09759  loss_rpn_loc: 0.1116  time: 0.7061  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:57:09] d2.utils.events INFO:  eta: 3:00:24  iter: 2839  total_loss: 0.5233  loss_cls: 0.1137  loss_box_reg: 0.1703  loss_rpn_cls: 0.08156  loss_rpn_loc: 0.08251  time: 0.7061  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:57:24] d2.utils.events INFO:  eta: 3:00:23  iter: 2859  total_loss: 0.5796  loss_cls: 0.1581  loss_box_reg: 0.1708  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.09527  time: 0.7062  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 01:57:38] d2.utils.events INFO:  eta: 2:59:55  iter: 2879  total_loss: 0.6306  loss_cls: 0.1469  loss_box_reg: 0.1985  loss_rpn_cls: 0.1275  loss_rpn_loc: 0.1119  time: 0.7061  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:57:52] d2.utils.events INFO:  eta: 2:59:54  iter: 2899  total_loss: 0.5977  loss_cls: 0.153  loss_box_reg: 0.1783  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.1563  time: 0.7062  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 01:58:06] d2.utils.events INFO:  eta: 2:59:45  iter: 2919  total_loss: 0.5342  loss_cls: 0.1259  loss_box_reg: 0.1442  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.09581  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:58:21] d2.utils.events INFO:  eta: 2:59:40  iter: 2939  total_loss: 0.536  loss_cls: 0.1215  loss_box_reg: 0.1407  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.09996  time: 0.7064  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 01:58:36] d2.utils.events INFO:  eta: 2:59:24  iter: 2959  total_loss: 0.4449  loss_cls: 0.1269  loss_box_reg: 0.1125  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.1231  time: 0.7065  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:58:49] d2.utils.events INFO:  eta: 2:59:16  iter: 2979  total_loss: 0.4882  loss_cls: 0.1343  loss_box_reg: 0.1959  loss_rpn_cls: 0.07869  loss_rpn_loc: 0.07174  time: 0.7064  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:59:05] d2.utils.events INFO:  eta: 2:59:21  iter: 2999  total_loss: 0.5475  loss_cls: 0.129  loss_box_reg: 0.1435  loss_rpn_cls: 0.09439  loss_rpn_loc: 0.09502  time: 0.7068  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:59:19] d2.utils.events INFO:  eta: 2:59:15  iter: 3019  total_loss: 0.5503  loss_cls: 0.1391  loss_box_reg: 0.1881  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.08618  time: 0.7067  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 01:59:32] d2.utils.events INFO:  eta: 2:58:57  iter: 3039  total_loss: 0.5581  loss_cls: 0.1419  loss_box_reg: 0.1812  loss_rpn_cls: 0.103  loss_rpn_loc: 0.1035  time: 0.7064  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 01:59:46] d2.utils.events INFO:  eta: 2:58:38  iter: 3059  total_loss: 0.6419  loss_cls: 0.18  loss_box_reg: 0.2018  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.1081  time: 0.7065  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:00:00] d2.utils.events INFO:  eta: 2:58:20  iter: 3079  total_loss: 0.3936  loss_cls: 0.1007  loss_box_reg: 0.1498  loss_rpn_cls: 0.065  loss_rpn_loc: 0.07903  time: 0.7063  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:00:13] d2.utils.events INFO:  eta: 2:57:50  iter: 3099  total_loss: 0.6863  loss_cls: 0.1736  loss_box_reg: 0.2978  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.1054  time: 0.7060  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:00:27] d2.utils.events INFO:  eta: 2:57:28  iter: 3119  total_loss: 0.616  loss_cls: 0.1381  loss_box_reg: 0.1888  loss_rpn_cls: 0.08795  loss_rpn_loc: 0.09467  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:00:40] d2.utils.events INFO:  eta: 2:57:09  iter: 3139  total_loss: 0.4625  loss_cls: 0.1176  loss_box_reg: 0.1609  loss_rpn_cls: 0.06565  loss_rpn_loc: 0.1054  time: 0.7056  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:00:56] d2.utils.events INFO:  eta: 2:56:55  iter: 3159  total_loss: 0.5641  loss_cls: 0.145  loss_box_reg: 0.1719  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.09283  time: 0.7061  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:01:10] d2.utils.events INFO:  eta: 2:56:29  iter: 3179  total_loss: 0.5002  loss_cls: 0.1056  loss_box_reg: 0.1981  loss_rpn_cls: 0.07702  loss_rpn_loc: 0.09612  time: 0.7059  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:01:24] d2.utils.events INFO:  eta: 2:56:23  iter: 3199  total_loss: 0.5985  loss_cls: 0.1653  loss_box_reg: 0.1952  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.07705  time: 0.7061  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 02:01:39] d2.utils.events INFO:  eta: 2:56:18  iter: 3219  total_loss: 0.5159  loss_cls: 0.1406  loss_box_reg: 0.1439  loss_rpn_cls: 0.08936  loss_rpn_loc: 0.06738  time: 0.7063  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:01:53] d2.utils.events INFO:  eta: 2:56:03  iter: 3239  total_loss: 0.4465  loss_cls: 0.1225  loss_box_reg: 0.1405  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.09875  time: 0.7062  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:02:08] d2.utils.events INFO:  eta: 2:55:56  iter: 3259  total_loss: 0.4143  loss_cls: 0.126  loss_box_reg: 0.1543  loss_rpn_cls: 0.04197  loss_rpn_loc: 0.09214  time: 0.7063  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:02:22] d2.utils.events INFO:  eta: 2:55:41  iter: 3279  total_loss: 0.4716  loss_cls: 0.1191  loss_box_reg: 0.1644  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.08664  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:02:36] d2.utils.events INFO:  eta: 2:55:21  iter: 3299  total_loss: 0.5375  loss_cls: 0.1411  loss_box_reg: 0.1826  loss_rpn_cls: 0.07246  loss_rpn_loc: 0.131  time: 0.7062  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:02:50] d2.utils.events INFO:  eta: 2:55:03  iter: 3319  total_loss: 0.5131  loss_cls: 0.1495  loss_box_reg: 0.1696  loss_rpn_cls: 0.08431  loss_rpn_loc: 0.08805  time: 0.7063  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:03:05] d2.utils.events INFO:  eta: 2:55:07  iter: 3339  total_loss: 0.4647  loss_cls: 0.1273  loss_box_reg: 0.1587  loss_rpn_cls: 0.08228  loss_rpn_loc: 0.09631  time: 0.7065  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:03:20] d2.utils.events INFO:  eta: 2:55:09  iter: 3359  total_loss: 0.4784  loss_cls: 0.1314  loss_box_reg: 0.147  loss_rpn_cls: 0.08427  loss_rpn_loc: 0.1008  time: 0.7067  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:03:34] d2.utils.events INFO:  eta: 2:54:54  iter: 3379  total_loss: 0.4468  loss_cls: 0.1119  loss_box_reg: 0.1738  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.06006  time: 0.7067  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:03:49] d2.utils.events INFO:  eta: 2:54:45  iter: 3399  total_loss: 0.5458  loss_cls: 0.1155  loss_box_reg: 0.118  loss_rpn_cls: 0.0877  loss_rpn_loc: 0.1234  time: 0.7069  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:04:03] d2.utils.events INFO:  eta: 2:54:32  iter: 3419  total_loss: 0.5046  loss_cls: 0.1356  loss_box_reg: 0.1643  loss_rpn_cls: 0.08917  loss_rpn_loc: 0.08573  time: 0.7069  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:04:16] d2.utils.events INFO:  eta: 2:54:15  iter: 3439  total_loss: 0.5632  loss_cls: 0.1571  loss_box_reg: 0.2171  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.1273  time: 0.7067  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:04:31] d2.utils.events INFO:  eta: 2:54:04  iter: 3459  total_loss: 0.5121  loss_cls: 0.1195  loss_box_reg: 0.1625  loss_rpn_cls: 0.08157  loss_rpn_loc: 0.09689  time: 0.7068  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:04:46] d2.utils.events INFO:  eta: 2:54:02  iter: 3479  total_loss: 0.5476  loss_cls: 0.116  loss_box_reg: 0.1521  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.1367  time: 0.7071  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:05:00] d2.utils.events INFO:  eta: 2:54:08  iter: 3499  total_loss: 0.5506  loss_cls: 0.1279  loss_box_reg: 0.1414  loss_rpn_cls: 0.09104  loss_rpn_loc: 0.1581  time: 0.7071  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:05:14] d2.utils.events INFO:  eta: 2:53:48  iter: 3519  total_loss: 0.5927  loss_cls: 0.1281  loss_box_reg: 0.162  loss_rpn_cls: 0.09903  loss_rpn_loc: 0.09502  time: 0.7069  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:05:28] d2.utils.events INFO:  eta: 2:53:04  iter: 3539  total_loss: 0.5335  loss_cls: 0.1162  loss_box_reg: 0.1225  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.124  time: 0.7069  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:05:43] d2.utils.events INFO:  eta: 2:52:51  iter: 3559  total_loss: 0.5088  loss_cls: 0.1377  loss_box_reg: 0.1453  loss_rpn_cls: 0.07501  loss_rpn_loc: 0.09792  time: 0.7070  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:05:56] d2.utils.events INFO:  eta: 2:52:28  iter: 3579  total_loss: 0.4791  loss_cls: 0.1349  loss_box_reg: 0.1514  loss_rpn_cls: 0.07705  loss_rpn_loc: 0.1057  time: 0.7067  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:06:10] d2.utils.events INFO:  eta: 2:52:10  iter: 3599  total_loss: 0.6631  loss_cls: 0.1974  loss_box_reg: 0.1803  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.1264  time: 0.7067  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:06:24] d2.utils.events INFO:  eta: 2:51:58  iter: 3619  total_loss: 0.5797  loss_cls: 0.1292  loss_box_reg: 0.1567  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1315  time: 0.7067  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:06:39] d2.utils.events INFO:  eta: 2:51:44  iter: 3639  total_loss: 0.5254  loss_cls: 0.1409  loss_box_reg: 0.1292  loss_rpn_cls: 0.08678  loss_rpn_loc: 0.1065  time: 0.7069  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:06:53] d2.utils.events INFO:  eta: 2:51:35  iter: 3659  total_loss: 0.4972  loss_cls: 0.143  loss_box_reg: 0.1859  loss_rpn_cls: 0.08864  loss_rpn_loc: 0.05872  time: 0.7068  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:07:06] d2.utils.events INFO:  eta: 2:51:26  iter: 3679  total_loss: 0.5514  loss_cls: 0.1441  loss_box_reg: 0.2334  loss_rpn_cls: 0.07815  loss_rpn_loc: 0.08847  time: 0.7066  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:07:21] d2.utils.events INFO:  eta: 2:51:01  iter: 3699  total_loss: 0.5981  loss_cls: 0.1531  loss_box_reg: 0.2074  loss_rpn_cls: 0.09619  loss_rpn_loc: 0.08656  time: 0.7067  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:07:34] d2.utils.events INFO:  eta: 2:50:38  iter: 3719  total_loss: 0.555  loss_cls: 0.1284  loss_box_reg: 0.2322  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.09768  time: 0.7066  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:07:49] d2.utils.events INFO:  eta: 2:50:32  iter: 3739  total_loss: 0.458  loss_cls: 0.1394  loss_box_reg: 0.1654  loss_rpn_cls: 0.07879  loss_rpn_loc: 0.0887  time: 0.7067  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:08:02] d2.utils.events INFO:  eta: 2:49:54  iter: 3759  total_loss: 0.5954  loss_cls: 0.1861  loss_box_reg: 0.2435  loss_rpn_cls: 0.08646  loss_rpn_loc: 0.06486  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:08:16] d2.utils.events INFO:  eta: 2:49:47  iter: 3779  total_loss: 0.5767  loss_cls: 0.1423  loss_box_reg: 0.1497  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.08978  time: 0.7064  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:08:30] d2.utils.events INFO:  eta: 2:49:25  iter: 3799  total_loss: 0.5841  loss_cls: 0.1625  loss_box_reg: 0.1793  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.1381  time: 0.7061  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:08:43] d2.utils.events INFO:  eta: 2:48:54  iter: 3819  total_loss: 0.4156  loss_cls: 0.1026  loss_box_reg: 0.1185  loss_rpn_cls: 0.09605  loss_rpn_loc: 0.06729  time: 0.7059  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:08:57] d2.utils.events INFO:  eta: 2:48:44  iter: 3839  total_loss: 0.562  loss_cls: 0.1356  loss_box_reg: 0.1616  loss_rpn_cls: 0.08813  loss_rpn_loc: 0.142  time: 0.7060  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:09:12] d2.utils.events INFO:  eta: 2:48:34  iter: 3859  total_loss: 0.5893  loss_cls: 0.1422  loss_box_reg: 0.172  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.1244  time: 0.7060  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:09:27] d2.utils.events INFO:  eta: 2:48:50  iter: 3879  total_loss: 0.517  loss_cls: 0.137  loss_box_reg: 0.173  loss_rpn_cls: 0.08598  loss_rpn_loc: 0.1158  time: 0.7063  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:09:41] d2.utils.events INFO:  eta: 2:48:09  iter: 3899  total_loss: 0.592  loss_cls: 0.1386  loss_box_reg: 0.2111  loss_rpn_cls: 0.0828  loss_rpn_loc: 0.1154  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:09:55] d2.utils.events INFO:  eta: 2:47:51  iter: 3919  total_loss: 0.4597  loss_cls: 0.1021  loss_box_reg: 0.1186  loss_rpn_cls: 0.102  loss_rpn_loc: 0.09939  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:10:10] d2.utils.events INFO:  eta: 2:47:37  iter: 3939  total_loss: 0.5604  loss_cls: 0.1173  loss_box_reg: 0.1404  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.1082  time: 0.7064  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:10:24] d2.utils.events INFO:  eta: 2:47:26  iter: 3959  total_loss: 0.486  loss_cls: 0.1199  loss_box_reg: 0.1301  loss_rpn_cls: 0.0889  loss_rpn_loc: 0.1158  time: 0.7064  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:10:38] d2.utils.events INFO:  eta: 2:47:11  iter: 3979  total_loss: 0.5316  loss_cls: 0.1108  loss_box_reg: 0.1199  loss_rpn_cls: 0.08711  loss_rpn_loc: 0.117  time: 0.7063  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:10:52] d2.utils.events INFO:  eta: 2:46:49  iter: 3999  total_loss: 0.4774  loss_cls: 0.1194  loss_box_reg: 0.1501  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.08385  time: 0.7064  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:11:06] d2.utils.events INFO:  eta: 2:46:30  iter: 4019  total_loss: 0.5645  loss_cls: 0.1602  loss_box_reg: 0.1793  loss_rpn_cls: 0.08405  loss_rpn_loc: 0.1046  time: 0.7062  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:11:20] d2.utils.events INFO:  eta: 2:46:29  iter: 4039  total_loss: 0.4733  loss_cls: 0.1157  loss_box_reg: 0.1779  loss_rpn_cls: 0.08923  loss_rpn_loc: 0.06965  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:11:34] d2.utils.events INFO:  eta: 2:46:15  iter: 4059  total_loss: 0.5041  loss_cls: 0.1092  loss_box_reg: 0.1575  loss_rpn_cls: 0.09094  loss_rpn_loc: 0.1211  time: 0.7063  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:11:48] d2.utils.events INFO:  eta: 2:45:59  iter: 4079  total_loss: 0.5393  loss_cls: 0.1319  loss_box_reg: 0.1807  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.1187  time: 0.7062  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:12:02] d2.utils.events INFO:  eta: 2:45:49  iter: 4099  total_loss: 0.5933  loss_cls: 0.1187  loss_box_reg: 0.1771  loss_rpn_cls: 0.09762  loss_rpn_loc: 0.1078  time: 0.7062  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:12:17] d2.utils.events INFO:  eta: 2:45:38  iter: 4119  total_loss: 0.5137  loss_cls: 0.1559  loss_box_reg: 0.1907  loss_rpn_cls: 0.09707  loss_rpn_loc: 0.09003  time: 0.7063  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:12:32] d2.utils.events INFO:  eta: 2:45:45  iter: 4139  total_loss: 0.4691  loss_cls: 0.1065  loss_box_reg: 0.1477  loss_rpn_cls: 0.0807  loss_rpn_loc: 0.1071  time: 0.7065  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:12:46] d2.utils.events INFO:  eta: 2:45:11  iter: 4159  total_loss: 0.4172  loss_cls: 0.1092  loss_box_reg: 0.1506  loss_rpn_cls: 0.08082  loss_rpn_loc: 0.08476  time: 0.7065  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:13:00] d2.utils.events INFO:  eta: 2:44:59  iter: 4179  total_loss: 0.508  loss_cls: 0.1374  loss_box_reg: 0.1775  loss_rpn_cls: 0.07477  loss_rpn_loc: 0.08733  time: 0.7065  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:13:14] d2.utils.events INFO:  eta: 2:44:39  iter: 4199  total_loss: 0.4594  loss_cls: 0.1117  loss_box_reg: 0.1364  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.1108  time: 0.7064  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:13:28] d2.utils.events INFO:  eta: 2:44:10  iter: 4219  total_loss: 0.5985  loss_cls: 0.1173  loss_box_reg: 0.1708  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1079  time: 0.7063  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:13:42] d2.utils.events INFO:  eta: 2:44:12  iter: 4239  total_loss: 0.6379  loss_cls: 0.1957  loss_box_reg: 0.2114  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.108  time: 0.7063  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:13:55] d2.utils.events INFO:  eta: 2:43:45  iter: 4259  total_loss: 0.4012  loss_cls: 0.1225  loss_box_reg: 0.1143  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.07985  time: 0.7062  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:14:09] d2.utils.events INFO:  eta: 2:43:24  iter: 4279  total_loss: 0.5372  loss_cls: 0.1582  loss_box_reg: 0.1704  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.07706  time: 0.7061  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:14:23] d2.utils.events INFO:  eta: 2:43:07  iter: 4299  total_loss: 0.4461  loss_cls: 0.09465  loss_box_reg: 0.1156  loss_rpn_cls: 0.07346  loss_rpn_loc: 0.1252  time: 0.7059  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:14:37] d2.utils.events INFO:  eta: 2:42:53  iter: 4319  total_loss: 0.4183  loss_cls: 0.09622  loss_box_reg: 0.1041  loss_rpn_cls: 0.0532  loss_rpn_loc: 0.09898  time: 0.7060  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:14:51] d2.utils.events INFO:  eta: 2:42:22  iter: 4339  total_loss: 0.393  loss_cls: 0.1015  loss_box_reg: 0.1237  loss_rpn_cls: 0.05227  loss_rpn_loc: 0.07436  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:15:04] d2.utils.events INFO:  eta: 2:42:02  iter: 4359  total_loss: 0.3875  loss_cls: 0.1025  loss_box_reg: 0.1379  loss_rpn_cls: 0.05916  loss_rpn_loc: 0.06642  time: 0.7056  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:15:19] d2.utils.events INFO:  eta: 2:41:50  iter: 4379  total_loss: 0.4957  loss_cls: 0.1045  loss_box_reg: 0.1371  loss_rpn_cls: 0.0719  loss_rpn_loc: 0.09271  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:15:33] d2.utils.events INFO:  eta: 2:41:37  iter: 4399  total_loss: 0.4585  loss_cls: 0.1035  loss_box_reg: 0.1667  loss_rpn_cls: 0.08017  loss_rpn_loc: 0.109  time: 0.7059  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:15:48] d2.utils.events INFO:  eta: 2:41:25  iter: 4419  total_loss: 0.5005  loss_cls: 0.1228  loss_box_reg: 0.1218  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.0941  time: 0.7059  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:16:02] d2.utils.events INFO:  eta: 2:41:17  iter: 4439  total_loss: 0.6153  loss_cls: 0.168  loss_box_reg: 0.1893  loss_rpn_cls: 0.1  loss_rpn_loc: 0.1279  time: 0.7060  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:16:16] d2.utils.events INFO:  eta: 2:40:57  iter: 4459  total_loss: 0.5861  loss_cls: 0.158  loss_box_reg: 0.2449  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.0763  time: 0.7059  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:16:30] d2.utils.events INFO:  eta: 2:40:40  iter: 4479  total_loss: 0.4906  loss_cls: 0.1522  loss_box_reg: 0.1479  loss_rpn_cls: 0.09279  loss_rpn_loc: 0.08653  time: 0.7058  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:16:44] d2.utils.events INFO:  eta: 2:40:23  iter: 4499  total_loss: 0.4418  loss_cls: 0.1326  loss_box_reg: 0.1572  loss_rpn_cls: 0.07394  loss_rpn_loc: 0.0653  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:16:58] d2.utils.events INFO:  eta: 2:40:06  iter: 4519  total_loss: 0.5899  loss_cls: 0.1391  loss_box_reg: 0.2364  loss_rpn_cls: 0.09289  loss_rpn_loc: 0.09518  time: 0.7057  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:17:11] d2.utils.events INFO:  eta: 2:39:55  iter: 4539  total_loss: 0.5339  loss_cls: 0.118  loss_box_reg: 0.1482  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.09977  time: 0.7056  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:17:25] d2.utils.events INFO:  eta: 2:39:36  iter: 4559  total_loss: 0.6124  loss_cls: 0.1397  loss_box_reg: 0.2159  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.07356  time: 0.7054  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:17:39] d2.utils.events INFO:  eta: 2:39:25  iter: 4579  total_loss: 0.4528  loss_cls: 0.1074  loss_box_reg: 0.152  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.08117  time: 0.7054  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:17:53] d2.utils.events INFO:  eta: 2:39:13  iter: 4599  total_loss: 0.4702  loss_cls: 0.1351  loss_box_reg: 0.1501  loss_rpn_cls: 0.07064  loss_rpn_loc: 0.07279  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:18:07] d2.utils.events INFO:  eta: 2:39:02  iter: 4619  total_loss: 0.506  loss_cls: 0.1179  loss_box_reg: 0.1541  loss_rpn_cls: 0.09441  loss_rpn_loc: 0.06842  time: 0.7055  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:18:21] d2.utils.events INFO:  eta: 2:38:43  iter: 4639  total_loss: 0.4758  loss_cls: 0.1455  loss_box_reg: 0.1935  loss_rpn_cls: 0.08837  loss_rpn_loc: 0.08817  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:18:35] d2.utils.events INFO:  eta: 2:38:27  iter: 4659  total_loss: 0.5286  loss_cls: 0.1398  loss_box_reg: 0.177  loss_rpn_cls: 0.08842  loss_rpn_loc: 0.08365  time: 0.7053  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:18:49] d2.utils.events INFO:  eta: 2:38:01  iter: 4679  total_loss: 0.4674  loss_cls: 0.1414  loss_box_reg: 0.1468  loss_rpn_cls: 0.08691  loss_rpn_loc: 0.1122  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:19:03] d2.utils.events INFO:  eta: 2:37:35  iter: 4699  total_loss: 0.5307  loss_cls: 0.1461  loss_box_reg: 0.1575  loss_rpn_cls: 0.08245  loss_rpn_loc: 0.1009  time: 0.7053  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:19:17] d2.utils.events INFO:  eta: 2:37:46  iter: 4719  total_loss: 0.4775  loss_cls: 0.1036  loss_box_reg: 0.1114  loss_rpn_cls: 0.08295  loss_rpn_loc: 0.08658  time: 0.7053  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:19:31] d2.utils.events INFO:  eta: 2:37:18  iter: 4739  total_loss: 0.5336  loss_cls: 0.125  loss_box_reg: 0.1829  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.09407  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:19:45] d2.utils.events INFO:  eta: 2:37:17  iter: 4759  total_loss: 0.5117  loss_cls: 0.1258  loss_box_reg: 0.1669  loss_rpn_cls: 0.0981  loss_rpn_loc: 0.0932  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:20:00] d2.utils.events INFO:  eta: 2:37:06  iter: 4779  total_loss: 0.502  loss_cls: 0.1164  loss_box_reg: 0.1354  loss_rpn_cls: 0.0829  loss_rpn_loc: 0.1231  time: 0.7054  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:20:14] d2.utils.events INFO:  eta: 2:36:54  iter: 4799  total_loss: 0.5872  loss_cls: 0.1444  loss_box_reg: 0.1905  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.131  time: 0.7053  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:20:28] d2.utils.events INFO:  eta: 2:36:47  iter: 4819  total_loss: 0.5625  loss_cls: 0.1274  loss_box_reg: 0.1676  loss_rpn_cls: 0.0853  loss_rpn_loc: 0.1226  time: 0.7053  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:20:42] d2.utils.events INFO:  eta: 2:36:26  iter: 4839  total_loss: 0.5965  loss_cls: 0.1085  loss_box_reg: 0.1751  loss_rpn_cls: 0.08516  loss_rpn_loc: 0.09011  time: 0.7053  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:20:57] d2.utils.events INFO:  eta: 2:36:12  iter: 4859  total_loss: 0.5309  loss_cls: 0.1363  loss_box_reg: 0.1871  loss_rpn_cls: 0.09685  loss_rpn_loc: 0.09496  time: 0.7054  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:21:11] d2.utils.events INFO:  eta: 2:35:58  iter: 4879  total_loss: 0.5096  loss_cls: 0.1442  loss_box_reg: 0.1538  loss_rpn_cls: 0.1177  loss_rpn_loc: 0.07758  time: 0.7055  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:21:26] d2.utils.events INFO:  eta: 2:35:46  iter: 4899  total_loss: 0.4517  loss_cls: 0.1244  loss_box_reg: 0.1438  loss_rpn_cls: 0.08569  loss_rpn_loc: 0.1222  time: 0.7055  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:21:41] d2.utils.events INFO:  eta: 2:35:36  iter: 4919  total_loss: 0.5097  loss_cls: 0.1162  loss_box_reg: 0.1592  loss_rpn_cls: 0.09051  loss_rpn_loc: 0.1112  time: 0.7057  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:21:54] d2.utils.events INFO:  eta: 2:35:18  iter: 4939  total_loss: 0.5454  loss_cls: 0.138  loss_box_reg: 0.2155  loss_rpn_cls: 0.09691  loss_rpn_loc: 0.1067  time: 0.7056  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:22:09] d2.utils.events INFO:  eta: 2:35:02  iter: 4959  total_loss: 0.5895  loss_cls: 0.1412  loss_box_reg: 0.2088  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.09948  time: 0.7057  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:22:23] d2.utils.events INFO:  eta: 2:34:51  iter: 4979  total_loss: 0.4744  loss_cls: 0.1174  loss_box_reg: 0.1402  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.1031  time: 0.7058  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:22:38] d2.utils.events INFO:  eta: 2:34:37  iter: 4999  total_loss: 0.4778  loss_cls: 0.1145  loss_box_reg: 0.1281  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.09158  time: 0.7058  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:22:52] d2.utils.events INFO:  eta: 2:34:24  iter: 5019  total_loss: 0.6124  loss_cls: 0.1543  loss_box_reg: 0.2141  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.1073  time: 0.7058  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:23:06] d2.utils.events INFO:  eta: 2:34:08  iter: 5039  total_loss: 0.5645  loss_cls: 0.126  loss_box_reg: 0.1981  loss_rpn_cls: 0.06811  loss_rpn_loc: 0.1062  time: 0.7057  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:23:19] d2.utils.events INFO:  eta: 2:33:51  iter: 5059  total_loss: 0.3758  loss_cls: 0.1036  loss_box_reg: 0.1275  loss_rpn_cls: 0.06755  loss_rpn_loc: 0.07454  time: 0.7056  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:23:33] d2.utils.events INFO:  eta: 2:33:36  iter: 5079  total_loss: 0.4067  loss_cls: 0.0885  loss_box_reg: 0.118  loss_rpn_cls: 0.06963  loss_rpn_loc: 0.06762  time: 0.7055  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:23:47] d2.utils.events INFO:  eta: 2:33:23  iter: 5099  total_loss: 0.4852  loss_cls: 0.1484  loss_box_reg: 0.187  loss_rpn_cls: 0.08848  loss_rpn_loc: 0.07871  time: 0.7055  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:24:01] d2.utils.events INFO:  eta: 2:33:06  iter: 5119  total_loss: 0.5413  loss_cls: 0.1603  loss_box_reg: 0.1976  loss_rpn_cls: 0.1107  loss_rpn_loc: 0.09292  time: 0.7054  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:24:14] d2.utils.events INFO:  eta: 2:32:35  iter: 5139  total_loss: 0.4788  loss_cls: 0.1392  loss_box_reg: 0.1563  loss_rpn_cls: 0.09062  loss_rpn_loc: 0.06401  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:24:29] d2.utils.events INFO:  eta: 2:32:27  iter: 5159  total_loss: 0.4953  loss_cls: 0.1562  loss_box_reg: 0.186  loss_rpn_cls: 0.06557  loss_rpn_loc: 0.08787  time: 0.7055  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:24:43] d2.utils.events INFO:  eta: 2:32:00  iter: 5179  total_loss: 0.6036  loss_cls: 0.1715  loss_box_reg: 0.2122  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.08534  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:24:57] d2.utils.events INFO:  eta: 2:31:46  iter: 5199  total_loss: 0.5132  loss_cls: 0.136  loss_box_reg: 0.1881  loss_rpn_cls: 0.07676  loss_rpn_loc: 0.09121  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:25:11] d2.utils.events INFO:  eta: 2:31:31  iter: 5219  total_loss: 0.5449  loss_cls: 0.1422  loss_box_reg: 0.1826  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.09948  time: 0.7054  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:25:25] d2.utils.events INFO:  eta: 2:30:58  iter: 5239  total_loss: 0.6926  loss_cls: 0.2012  loss_box_reg: 0.1909  loss_rpn_cls: 0.09675  loss_rpn_loc: 0.1008  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:25:39] d2.utils.events INFO:  eta: 2:30:44  iter: 5259  total_loss: 0.4674  loss_cls: 0.1132  loss_box_reg: 0.1274  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.07748  time: 0.7052  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:25:53] d2.utils.events INFO:  eta: 2:30:38  iter: 5279  total_loss: 0.5276  loss_cls: 0.1094  loss_box_reg: 0.1483  loss_rpn_cls: 0.09144  loss_rpn_loc: 0.1109  time: 0.7052  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:26:07] d2.utils.events INFO:  eta: 2:30:36  iter: 5299  total_loss: 0.518  loss_cls: 0.1566  loss_box_reg: 0.1974  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.1039  time: 0.7052  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:26:21] d2.utils.events INFO:  eta: 2:30:17  iter: 5319  total_loss: 0.4594  loss_cls: 0.1257  loss_box_reg: 0.1835  loss_rpn_cls: 0.09051  loss_rpn_loc: 0.09313  time: 0.7051  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:26:35] d2.utils.events INFO:  eta: 2:30:10  iter: 5339  total_loss: 0.4937  loss_cls: 0.1381  loss_box_reg: 0.155  loss_rpn_cls: 0.06598  loss_rpn_loc: 0.08643  time: 0.7052  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:26:48] d2.utils.events INFO:  eta: 2:29:53  iter: 5359  total_loss: 0.4856  loss_cls: 0.1192  loss_box_reg: 0.167  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.08213  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:27:03] d2.utils.events INFO:  eta: 2:29:39  iter: 5379  total_loss: 0.3977  loss_cls: 0.1255  loss_box_reg: 0.1546  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.08285  time: 0.7050  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:27:17] d2.utils.events INFO:  eta: 2:29:24  iter: 5399  total_loss: 0.3521  loss_cls: 0.1016  loss_box_reg: 0.1258  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.08611  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:27:31] d2.utils.events INFO:  eta: 2:29:09  iter: 5419  total_loss: 0.5327  loss_cls: 0.1548  loss_box_reg: 0.1896  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.09761  time: 0.7051  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:27:45] d2.utils.events INFO:  eta: 2:28:35  iter: 5439  total_loss: 0.4844  loss_cls: 0.1279  loss_box_reg: 0.1606  loss_rpn_cls: 0.07789  loss_rpn_loc: 0.07031  time: 0.7049  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:27:58] d2.utils.events INFO:  eta: 2:28:18  iter: 5459  total_loss: 0.4018  loss_cls: 0.132  loss_box_reg: 0.1204  loss_rpn_cls: 0.07405  loss_rpn_loc: 0.07853  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:28:13] d2.utils.events INFO:  eta: 2:28:16  iter: 5479  total_loss: 0.4656  loss_cls: 0.1203  loss_box_reg: 0.1155  loss_rpn_cls: 0.08312  loss_rpn_loc: 0.08883  time: 0.7050  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:28:28] d2.utils.events INFO:  eta: 2:28:09  iter: 5499  total_loss: 0.3685  loss_cls: 0.08322  loss_box_reg: 0.1038  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.06857  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:28:42] d2.utils.events INFO:  eta: 2:28:02  iter: 5519  total_loss: 0.437  loss_cls: 0.1126  loss_box_reg: 0.1373  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.08524  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:28:55] d2.utils.events INFO:  eta: 2:27:43  iter: 5539  total_loss: 0.4383  loss_cls: 0.1011  loss_box_reg: 0.1551  loss_rpn_cls: 0.06981  loss_rpn_loc: 0.06715  time: 0.7049  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:29:10] d2.utils.events INFO:  eta: 2:27:29  iter: 5559  total_loss: 0.4831  loss_cls: 0.1236  loss_box_reg: 0.1427  loss_rpn_cls: 0.09614  loss_rpn_loc: 0.08672  time: 0.7050  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:29:23] d2.utils.events INFO:  eta: 2:27:04  iter: 5579  total_loss: 0.4552  loss_cls: 0.1298  loss_box_reg: 0.1554  loss_rpn_cls: 0.06984  loss_rpn_loc: 0.08702  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:29:37] d2.utils.events INFO:  eta: 2:26:35  iter: 5599  total_loss: 0.3635  loss_cls: 0.1134  loss_box_reg: 0.1567  loss_rpn_cls: 0.04937  loss_rpn_loc: 0.03865  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:29:51] d2.utils.events INFO:  eta: 2:26:12  iter: 5619  total_loss: 0.5784  loss_cls: 0.1371  loss_box_reg: 0.1801  loss_rpn_cls: 0.08529  loss_rpn_loc: 0.1426  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:30:06] d2.utils.events INFO:  eta: 2:26:21  iter: 5639  total_loss: 0.5571  loss_cls: 0.1291  loss_box_reg: 0.1203  loss_rpn_cls: 0.08638  loss_rpn_loc: 0.08191  time: 0.7049  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:30:20] d2.utils.events INFO:  eta: 2:26:10  iter: 5659  total_loss: 0.4694  loss_cls: 0.1505  loss_box_reg: 0.1211  loss_rpn_cls: 0.09153  loss_rpn_loc: 0.0693  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:30:35] d2.utils.events INFO:  eta: 2:26:05  iter: 5679  total_loss: 0.4908  loss_cls: 0.1324  loss_box_reg: 0.1523  loss_rpn_cls: 0.09493  loss_rpn_loc: 0.1127  time: 0.7050  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:30:49] d2.utils.events INFO:  eta: 2:25:50  iter: 5699  total_loss: 0.4975  loss_cls: 0.09959  loss_box_reg: 0.1379  loss_rpn_cls: 0.06494  loss_rpn_loc: 0.1113  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:31:04] d2.utils.events INFO:  eta: 2:25:35  iter: 5719  total_loss: 0.5146  loss_cls: 0.09842  loss_box_reg: 0.1313  loss_rpn_cls: 0.092  loss_rpn_loc: 0.1481  time: 0.7052  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:31:18] d2.utils.events INFO:  eta: 2:25:28  iter: 5739  total_loss: 0.4494  loss_cls: 0.09085  loss_box_reg: 0.1198  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.1231  time: 0.7052  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:31:33] d2.utils.events INFO:  eta: 2:25:30  iter: 5759  total_loss: 0.5531  loss_cls: 0.1622  loss_box_reg: 0.1796  loss_rpn_cls: 0.113  loss_rpn_loc: 0.1052  time: 0.7053  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:31:48] d2.utils.events INFO:  eta: 2:25:10  iter: 5779  total_loss: 0.5788  loss_cls: 0.1597  loss_box_reg: 0.1734  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.0808  time: 0.7054  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:32:01] d2.utils.events INFO:  eta: 2:24:55  iter: 5799  total_loss: 0.4303  loss_cls: 0.1196  loss_box_reg: 0.1568  loss_rpn_cls: 0.08338  loss_rpn_loc: 0.07781  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:32:16] d2.utils.events INFO:  eta: 2:24:41  iter: 5819  total_loss: 0.5218  loss_cls: 0.1064  loss_box_reg: 0.1376  loss_rpn_cls: 0.1039  loss_rpn_loc: 0.1348  time: 0.7054  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:32:30] d2.utils.events INFO:  eta: 2:24:23  iter: 5839  total_loss: 0.42  loss_cls: 0.09434  loss_box_reg: 0.122  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.09187  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:32:44] d2.utils.events INFO:  eta: 2:24:05  iter: 5859  total_loss: 0.5689  loss_cls: 0.1364  loss_box_reg: 0.1689  loss_rpn_cls: 0.09479  loss_rpn_loc: 0.09833  time: 0.7054  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:32:58] d2.utils.events INFO:  eta: 2:23:43  iter: 5879  total_loss: 0.399  loss_cls: 0.0855  loss_box_reg: 0.1619  loss_rpn_cls: 0.06044  loss_rpn_loc: 0.09186  time: 0.7053  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:33:12] d2.utils.events INFO:  eta: 2:23:31  iter: 5899  total_loss: 0.5306  loss_cls: 0.1369  loss_box_reg: 0.1511  loss_rpn_cls: 0.09196  loss_rpn_loc: 0.09956  time: 0.7054  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:33:27] d2.utils.events INFO:  eta: 2:23:14  iter: 5919  total_loss: 0.4576  loss_cls: 0.1033  loss_box_reg: 0.1519  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.09649  time: 0.7055  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:33:41] d2.utils.events INFO:  eta: 2:23:00  iter: 5939  total_loss: 0.4043  loss_cls: 0.1022  loss_box_reg: 0.1679  loss_rpn_cls: 0.05166  loss_rpn_loc: 0.0899  time: 0.7054  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:33:55] d2.utils.events INFO:  eta: 2:22:46  iter: 5959  total_loss: 0.428  loss_cls: 0.09812  loss_box_reg: 0.155  loss_rpn_cls: 0.09176  loss_rpn_loc: 0.08755  time: 0.7053  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:34:08] d2.utils.events INFO:  eta: 2:22:26  iter: 5979  total_loss: 0.4914  loss_cls: 0.1428  loss_box_reg: 0.1619  loss_rpn_cls: 0.09259  loss_rpn_loc: 0.09012  time: 0.7052  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:34:22] d2.utils.events INFO:  eta: 2:22:03  iter: 5999  total_loss: 0.4255  loss_cls: 0.1184  loss_box_reg: 0.1384  loss_rpn_cls: 0.08474  loss_rpn_loc: 0.07466  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:34:36] d2.utils.events INFO:  eta: 2:21:58  iter: 6019  total_loss: 0.5396  loss_cls: 0.1449  loss_box_reg: 0.2188  loss_rpn_cls: 0.08408  loss_rpn_loc: 0.08163  time: 0.7052  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:34:50] d2.utils.events INFO:  eta: 2:21:44  iter: 6039  total_loss: 0.5046  loss_cls: 0.1004  loss_box_reg: 0.1518  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.07509  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:35:03] d2.utils.events INFO:  eta: 2:21:21  iter: 6059  total_loss: 0.5164  loss_cls: 0.1257  loss_box_reg: 0.1904  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.08827  time: 0.7050  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:35:18] d2.utils.events INFO:  eta: 2:21:23  iter: 6079  total_loss: 0.4879  loss_cls: 0.1126  loss_box_reg: 0.1635  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.107  time: 0.7050  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:35:32] d2.utils.events INFO:  eta: 2:21:14  iter: 6099  total_loss: 0.4865  loss_cls: 0.1094  loss_box_reg: 0.1377  loss_rpn_cls: 0.0746  loss_rpn_loc: 0.1332  time: 0.7051  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:35:46] d2.utils.events INFO:  eta: 2:21:02  iter: 6119  total_loss: 0.4048  loss_cls: 0.1054  loss_box_reg: 0.1429  loss_rpn_cls: 0.05888  loss_rpn_loc: 0.08877  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:36:00] d2.utils.events INFO:  eta: 2:20:48  iter: 6139  total_loss: 0.5235  loss_cls: 0.1291  loss_box_reg: 0.1646  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.09818  time: 0.7049  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:36:14] d2.utils.events INFO:  eta: 2:20:31  iter: 6159  total_loss: 0.5346  loss_cls: 0.1545  loss_box_reg: 0.1989  loss_rpn_cls: 0.08233  loss_rpn_loc: 0.1141  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:36:28] d2.utils.events INFO:  eta: 2:20:20  iter: 6179  total_loss: 0.4547  loss_cls: 0.1347  loss_box_reg: 0.1654  loss_rpn_cls: 0.07179  loss_rpn_loc: 0.06513  time: 0.7049  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:36:42] d2.utils.events INFO:  eta: 2:20:06  iter: 6199  total_loss: 0.555  loss_cls: 0.1386  loss_box_reg: 0.1512  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.08302  time: 0.7049  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:36:55] d2.utils.events INFO:  eta: 2:19:46  iter: 6219  total_loss: 0.4192  loss_cls: 0.1178  loss_box_reg: 0.1332  loss_rpn_cls: 0.06629  loss_rpn_loc: 0.05657  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:37:09] d2.utils.events INFO:  eta: 2:19:32  iter: 6239  total_loss: 0.6069  loss_cls: 0.1524  loss_box_reg: 0.2023  loss_rpn_cls: 0.09248  loss_rpn_loc: 0.07791  time: 0.7047  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:37:23] d2.utils.events INFO:  eta: 2:19:18  iter: 6259  total_loss: 0.417  loss_cls: 0.1096  loss_box_reg: 0.1424  loss_rpn_cls: 0.0996  loss_rpn_loc: 0.07925  time: 0.7048  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:37:37] d2.utils.events INFO:  eta: 2:19:01  iter: 6279  total_loss: 0.3901  loss_cls: 0.1147  loss_box_reg: 0.1523  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.06981  time: 0.7046  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:37:50] d2.utils.events INFO:  eta: 2:18:43  iter: 6299  total_loss: 0.4937  loss_cls: 0.1263  loss_box_reg: 0.1752  loss_rpn_cls: 0.08808  loss_rpn_loc: 0.1025  time: 0.7046  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:38:04] d2.utils.events INFO:  eta: 2:18:28  iter: 6319  total_loss: 0.3978  loss_cls: 0.1102  loss_box_reg: 0.1516  loss_rpn_cls: 0.05548  loss_rpn_loc: 0.1012  time: 0.7045  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:38:18] d2.utils.events INFO:  eta: 2:17:55  iter: 6339  total_loss: 0.4787  loss_cls: 0.1231  loss_box_reg: 0.156  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.06972  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:38:32] d2.utils.events INFO:  eta: 2:18:00  iter: 6359  total_loss: 0.3575  loss_cls: 0.0851  loss_box_reg: 0.1061  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.07937  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:38:46] d2.utils.events INFO:  eta: 2:17:42  iter: 6379  total_loss: 0.611  loss_cls: 0.1463  loss_box_reg: 0.2242  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.1074  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:39:00] d2.utils.events INFO:  eta: 2:17:20  iter: 6399  total_loss: 0.5007  loss_cls: 0.1194  loss_box_reg: 0.1935  loss_rpn_cls: 0.07823  loss_rpn_loc: 0.0975  time: 0.7044  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 02:39:15] d2.utils.events INFO:  eta: 2:17:13  iter: 6419  total_loss: 0.5162  loss_cls: 0.1497  loss_box_reg: 0.132  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.07586  time: 0.7045  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:39:29] d2.utils.events INFO:  eta: 2:17:10  iter: 6439  total_loss: 0.5108  loss_cls: 0.1395  loss_box_reg: 0.1499  loss_rpn_cls: 0.08794  loss_rpn_loc: 0.09786  time: 0.7046  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:39:43] d2.utils.events INFO:  eta: 2:17:01  iter: 6459  total_loss: 0.6647  loss_cls: 0.168  loss_box_reg: 0.2004  loss_rpn_cls: 0.0968  loss_rpn_loc: 0.1029  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:39:58] d2.utils.events INFO:  eta: 2:16:47  iter: 6479  total_loss: 0.5879  loss_cls: 0.1295  loss_box_reg: 0.1585  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1144  time: 0.7046  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:40:12] d2.utils.events INFO:  eta: 2:16:31  iter: 6499  total_loss: 0.4838  loss_cls: 0.136  loss_box_reg: 0.1561  loss_rpn_cls: 0.07542  loss_rpn_loc: 0.1063  time: 0.7046  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:40:26] d2.utils.events INFO:  eta: 2:16:13  iter: 6519  total_loss: 0.4219  loss_cls: 0.1177  loss_box_reg: 0.145  loss_rpn_cls: 0.07552  loss_rpn_loc: 0.06379  time: 0.7046  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:40:40] d2.utils.events INFO:  eta: 2:16:01  iter: 6539  total_loss: 0.4643  loss_cls: 0.1064  loss_box_reg: 0.1683  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.09285  time: 0.7045  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:40:53] d2.utils.events INFO:  eta: 2:15:48  iter: 6559  total_loss: 0.5856  loss_cls: 0.1357  loss_box_reg: 0.1878  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1099  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:41:07] d2.utils.events INFO:  eta: 2:15:39  iter: 6579  total_loss: 0.4043  loss_cls: 0.08997  loss_box_reg: 0.1173  loss_rpn_cls: 0.06773  loss_rpn_loc: 0.1175  time: 0.7044  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:41:20] d2.utils.events INFO:  eta: 2:15:25  iter: 6599  total_loss: 0.4311  loss_cls: 0.1012  loss_box_reg: 0.1266  loss_rpn_cls: 0.06937  loss_rpn_loc: 0.09054  time: 0.7042  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:41:34] d2.utils.events INFO:  eta: 2:15:10  iter: 6619  total_loss: 0.373  loss_cls: 0.08976  loss_box_reg: 0.1228  loss_rpn_cls: 0.06489  loss_rpn_loc: 0.05974  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:41:49] d2.utils.events INFO:  eta: 2:14:54  iter: 6639  total_loss: 0.4718  loss_cls: 0.1397  loss_box_reg: 0.168  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.1055  time: 0.7043  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:42:02] d2.utils.events INFO:  eta: 2:14:33  iter: 6659  total_loss: 0.3953  loss_cls: 0.104  loss_box_reg: 0.1505  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.08905  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:42:16] d2.utils.events INFO:  eta: 2:14:06  iter: 6679  total_loss: 0.5294  loss_cls: 0.1273  loss_box_reg: 0.1702  loss_rpn_cls: 0.124  loss_rpn_loc: 0.1097  time: 0.7042  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 02:42:30] d2.utils.events INFO:  eta: 2:14:02  iter: 6699  total_loss: 0.5517  loss_cls: 0.1373  loss_box_reg: 0.1884  loss_rpn_cls: 0.07717  loss_rpn_loc: 0.08343  time: 0.7042  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:42:45] d2.utils.events INFO:  eta: 2:13:48  iter: 6719  total_loss: 0.447  loss_cls: 0.1151  loss_box_reg: 0.1461  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.1237  time: 0.7043  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:42:59] d2.utils.events INFO:  eta: 2:13:23  iter: 6739  total_loss: 0.4479  loss_cls: 0.106  loss_box_reg: 0.1474  loss_rpn_cls: 0.08243  loss_rpn_loc: 0.0869  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:43:13] d2.utils.events INFO:  eta: 2:12:40  iter: 6759  total_loss: 0.4161  loss_cls: 0.08965  loss_box_reg: 0.1403  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.1  time: 0.7042  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:43:27] d2.utils.events INFO:  eta: 2:12:19  iter: 6779  total_loss: 0.5625  loss_cls: 0.1429  loss_box_reg: 0.1851  loss_rpn_cls: 0.09284  loss_rpn_loc: 0.1429  time: 0.7042  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:43:42] d2.utils.events INFO:  eta: 2:12:14  iter: 6799  total_loss: 0.4315  loss_cls: 0.1094  loss_box_reg: 0.1456  loss_rpn_cls: 0.08959  loss_rpn_loc: 0.1142  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:43:55] d2.utils.events INFO:  eta: 2:11:51  iter: 6819  total_loss: 0.5795  loss_cls: 0.1306  loss_box_reg: 0.1898  loss_rpn_cls: 0.08915  loss_rpn_loc: 0.09253  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:44:10] d2.utils.events INFO:  eta: 2:11:40  iter: 6839  total_loss: 0.5394  loss_cls: 0.126  loss_box_reg: 0.1766  loss_rpn_cls: 0.09577  loss_rpn_loc: 0.09253  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:44:24] d2.utils.events INFO:  eta: 2:11:26  iter: 6859  total_loss: 0.4889  loss_cls: 0.1115  loss_box_reg: 0.1648  loss_rpn_cls: 0.07344  loss_rpn_loc: 0.1033  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:44:38] d2.utils.events INFO:  eta: 2:11:11  iter: 6879  total_loss: 0.5389  loss_cls: 0.1437  loss_box_reg: 0.1878  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.09621  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:44:52] d2.utils.events INFO:  eta: 2:10:27  iter: 6899  total_loss: 0.3649  loss_cls: 0.09937  loss_box_reg: 0.1201  loss_rpn_cls: 0.04862  loss_rpn_loc: 0.114  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:45:06] d2.utils.events INFO:  eta: 2:09:55  iter: 6919  total_loss: 0.5971  loss_cls: 0.1468  loss_box_reg: 0.2183  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.09794  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:45:20] d2.utils.events INFO:  eta: 2:09:30  iter: 6939  total_loss: 0.4367  loss_cls: 0.1133  loss_box_reg: 0.1545  loss_rpn_cls: 0.06602  loss_rpn_loc: 0.08968  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:45:34] d2.utils.events INFO:  eta: 2:09:16  iter: 6959  total_loss: 0.5587  loss_cls: 0.1616  loss_box_reg: 0.1721  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.08428  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:45:48] d2.utils.events INFO:  eta: 2:09:26  iter: 6979  total_loss: 0.5217  loss_cls: 0.1202  loss_box_reg: 0.1695  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.06023  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:46:02] d2.utils.events INFO:  eta: 2:09:12  iter: 6999  total_loss: 0.4472  loss_cls: 0.1071  loss_box_reg: 0.1507  loss_rpn_cls: 0.08138  loss_rpn_loc: 0.08386  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:46:16] d2.utils.events INFO:  eta: 2:09:03  iter: 7019  total_loss: 0.5145  loss_cls: 0.1465  loss_box_reg: 0.1564  loss_rpn_cls: 0.07617  loss_rpn_loc: 0.1186  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:46:31] d2.utils.events INFO:  eta: 2:08:51  iter: 7039  total_loss: 0.504  loss_cls: 0.1398  loss_box_reg: 0.1814  loss_rpn_cls: 0.06759  loss_rpn_loc: 0.074  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:46:45] d2.utils.events INFO:  eta: 2:09:36  iter: 7059  total_loss: 0.4814  loss_cls: 0.1335  loss_box_reg: 0.193  loss_rpn_cls: 0.07223  loss_rpn_loc: 0.07645  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:46:58] d2.utils.events INFO:  eta: 2:08:42  iter: 7079  total_loss: 0.4544  loss_cls: 0.1057  loss_box_reg: 0.1273  loss_rpn_cls: 0.08512  loss_rpn_loc: 0.08265  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:47:12] d2.utils.events INFO:  eta: 2:07:56  iter: 7099  total_loss: 0.5149  loss_cls: 0.1232  loss_box_reg: 0.1596  loss_rpn_cls: 0.07246  loss_rpn_loc: 0.1198  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:47:26] d2.utils.events INFO:  eta: 2:07:42  iter: 7119  total_loss: 0.4795  loss_cls: 0.1031  loss_box_reg: 0.1552  loss_rpn_cls: 0.05813  loss_rpn_loc: 0.09268  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:47:40] d2.utils.events INFO:  eta: 2:07:26  iter: 7139  total_loss: 0.4852  loss_cls: 0.1273  loss_box_reg: 0.1477  loss_rpn_cls: 0.05649  loss_rpn_loc: 0.09448  time: 0.7039  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:47:53] d2.utils.events INFO:  eta: 2:07:06  iter: 7159  total_loss: 0.4517  loss_cls: 0.1047  loss_box_reg: 0.1335  loss_rpn_cls: 0.07836  loss_rpn_loc: 0.1031  time: 0.7038  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:48:07] d2.utils.events INFO:  eta: 2:06:41  iter: 7179  total_loss: 0.5579  loss_cls: 0.138  loss_box_reg: 0.1644  loss_rpn_cls: 0.0908  loss_rpn_loc: 0.1002  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:48:21] d2.utils.events INFO:  eta: 2:06:44  iter: 7199  total_loss: 0.4852  loss_cls: 0.1167  loss_box_reg: 0.1557  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1366  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:48:36] d2.utils.events INFO:  eta: 2:07:03  iter: 7219  total_loss: 0.509  loss_cls: 0.1076  loss_box_reg: 0.1494  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.09134  time: 0.7039  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:48:49] d2.utils.events INFO:  eta: 2:06:38  iter: 7239  total_loss: 0.4766  loss_cls: 0.1225  loss_box_reg: 0.1676  loss_rpn_cls: 0.08034  loss_rpn_loc: 0.09861  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:49:04] d2.utils.events INFO:  eta: 2:06:40  iter: 7259  total_loss: 0.4802  loss_cls: 0.1436  loss_box_reg: 0.179  loss_rpn_cls: 0.09933  loss_rpn_loc: 0.07027  time: 0.7038  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:49:17] d2.utils.events INFO:  eta: 2:06:30  iter: 7279  total_loss: 0.3989  loss_cls: 0.1146  loss_box_reg: 0.1369  loss_rpn_cls: 0.06951  loss_rpn_loc: 0.09756  time: 0.7038  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:49:32] d2.utils.events INFO:  eta: 2:06:16  iter: 7299  total_loss: 0.4554  loss_cls: 0.1473  loss_box_reg: 0.1533  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.08031  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:49:46] d2.utils.events INFO:  eta: 2:06:41  iter: 7319  total_loss: 0.5035  loss_cls: 0.1511  loss_box_reg: 0.1576  loss_rpn_cls: 0.07673  loss_rpn_loc: 0.08413  time: 0.7039  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:50:00] d2.utils.events INFO:  eta: 2:06:34  iter: 7339  total_loss: 0.3955  loss_cls: 0.09996  loss_box_reg: 0.1516  loss_rpn_cls: 0.06341  loss_rpn_loc: 0.09027  time: 0.7039  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:50:14] d2.utils.events INFO:  eta: 2:06:22  iter: 7359  total_loss: 0.486  loss_cls: 0.1334  loss_box_reg: 0.1641  loss_rpn_cls: 0.05343  loss_rpn_loc: 0.07378  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:50:27] d2.utils.events INFO:  eta: 2:05:59  iter: 7379  total_loss: 0.4488  loss_cls: 0.1068  loss_box_reg: 0.1145  loss_rpn_cls: 0.07676  loss_rpn_loc: 0.1015  time: 0.7037  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:50:41] d2.utils.events INFO:  eta: 2:05:45  iter: 7399  total_loss: 0.4388  loss_cls: 0.1161  loss_box_reg: 0.1507  loss_rpn_cls: 0.06906  loss_rpn_loc: 0.1078  time: 0.7037  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:50:56] d2.utils.events INFO:  eta: 2:05:34  iter: 7419  total_loss: 0.4435  loss_cls: 0.1148  loss_box_reg: 0.1519  loss_rpn_cls: 0.055  loss_rpn_loc: 0.08485  time: 0.7037  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:51:11] d2.utils.events INFO:  eta: 2:05:25  iter: 7439  total_loss: 0.4402  loss_cls: 0.1487  loss_box_reg: 0.1646  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.08839  time: 0.7038  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:51:25] d2.utils.events INFO:  eta: 2:05:12  iter: 7459  total_loss: 0.4979  loss_cls: 0.1306  loss_box_reg: 0.1243  loss_rpn_cls: 0.09954  loss_rpn_loc: 0.1227  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:51:39] d2.utils.events INFO:  eta: 2:04:58  iter: 7479  total_loss: 0.4497  loss_cls: 0.1167  loss_box_reg: 0.1477  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.08463  time: 0.7038  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:51:54] d2.utils.events INFO:  eta: 2:04:45  iter: 7499  total_loss: 0.5366  loss_cls: 0.1209  loss_box_reg: 0.1798  loss_rpn_cls: 0.05751  loss_rpn_loc: 0.1124  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:52:08] d2.utils.events INFO:  eta: 2:04:31  iter: 7519  total_loss: 0.4687  loss_cls: 0.1143  loss_box_reg: 0.1692  loss_rpn_cls: 0.0893  loss_rpn_loc: 0.0849  time: 0.7039  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:52:22] d2.utils.events INFO:  eta: 2:04:23  iter: 7539  total_loss: 0.487  loss_cls: 0.1259  loss_box_reg: 0.1473  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.1021  time: 0.7039  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:52:36] d2.utils.events INFO:  eta: 2:04:09  iter: 7559  total_loss: 0.3469  loss_cls: 0.07716  loss_box_reg: 0.09697  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.0706  time: 0.7039  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:52:51] d2.utils.events INFO:  eta: 2:03:59  iter: 7579  total_loss: 0.4551  loss_cls: 0.1057  loss_box_reg: 0.1604  loss_rpn_cls: 0.05648  loss_rpn_loc: 0.1041  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:53:05] d2.utils.events INFO:  eta: 2:03:52  iter: 7599  total_loss: 0.4251  loss_cls: 0.1288  loss_box_reg: 0.1517  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.07307  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:53:20] d2.utils.events INFO:  eta: 2:03:40  iter: 7619  total_loss: 0.4102  loss_cls: 0.09895  loss_box_reg: 0.1578  loss_rpn_cls: 0.06136  loss_rpn_loc: 0.07995  time: 0.7041  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:53:34] d2.utils.events INFO:  eta: 2:03:25  iter: 7639  total_loss: 0.4337  loss_cls: 0.119  loss_box_reg: 0.1662  loss_rpn_cls: 0.0634  loss_rpn_loc: 0.1102  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:53:49] d2.utils.events INFO:  eta: 2:03:14  iter: 7659  total_loss: 0.4129  loss_cls: 0.1059  loss_box_reg: 0.1267  loss_rpn_cls: 0.08257  loss_rpn_loc: 0.0712  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:54:02] d2.utils.events INFO:  eta: 2:02:59  iter: 7679  total_loss: 0.4348  loss_cls: 0.11  loss_box_reg: 0.1625  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.1025  time: 0.7041  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:54:16] d2.utils.events INFO:  eta: 2:02:44  iter: 7699  total_loss: 0.4003  loss_cls: 0.09568  loss_box_reg: 0.1447  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.0989  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:54:29] d2.utils.events INFO:  eta: 2:02:11  iter: 7719  total_loss: 0.5114  loss_cls: 0.1446  loss_box_reg: 0.2019  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.07775  time: 0.7039  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:54:44] d2.utils.events INFO:  eta: 2:01:59  iter: 7739  total_loss: 0.5035  loss_cls: 0.1214  loss_box_reg: 0.1799  loss_rpn_cls: 0.09925  loss_rpn_loc: 0.1016  time: 0.7040  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:54:58] d2.utils.events INFO:  eta: 2:01:42  iter: 7759  total_loss: 0.4657  loss_cls: 0.1089  loss_box_reg: 0.1398  loss_rpn_cls: 0.07647  loss_rpn_loc: 0.07321  time: 0.7039  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:55:12] d2.utils.events INFO:  eta: 2:01:28  iter: 7779  total_loss: 0.3601  loss_cls: 0.08596  loss_box_reg: 0.1116  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.09195  time: 0.7039  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:55:26] d2.utils.events INFO:  eta: 2:01:19  iter: 7799  total_loss: 0.5298  loss_cls: 0.1123  loss_box_reg: 0.1414  loss_rpn_cls: 0.07988  loss_rpn_loc: 0.1289  time: 0.7039  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:55:40] d2.utils.events INFO:  eta: 2:01:06  iter: 7819  total_loss: 0.5636  loss_cls: 0.1653  loss_box_reg: 0.2388  loss_rpn_cls: 0.06671  loss_rpn_loc: 0.09679  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:55:55] d2.utils.events INFO:  eta: 2:00:54  iter: 7839  total_loss: 0.3909  loss_cls: 0.1163  loss_box_reg: 0.149  loss_rpn_cls: 0.06817  loss_rpn_loc: 0.09695  time: 0.7040  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:56:09] d2.utils.events INFO:  eta: 2:00:45  iter: 7859  total_loss: 0.5186  loss_cls: 0.1212  loss_box_reg: 0.1766  loss_rpn_cls: 0.08084  loss_rpn_loc: 0.0881  time: 0.7040  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:56:23] d2.utils.events INFO:  eta: 2:00:35  iter: 7879  total_loss: 0.5468  loss_cls: 0.1333  loss_box_reg: 0.1743  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.1208  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:56:37] d2.utils.events INFO:  eta: 2:00:22  iter: 7899  total_loss: 0.3947  loss_cls: 0.1174  loss_box_reg: 0.1549  loss_rpn_cls: 0.05424  loss_rpn_loc: 0.09865  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:56:51] d2.utils.events INFO:  eta: 2:00:09  iter: 7919  total_loss: 0.4224  loss_cls: 0.09473  loss_box_reg: 0.1205  loss_rpn_cls: 0.06362  loss_rpn_loc: 0.08599  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:57:05] d2.utils.events INFO:  eta: 1:59:57  iter: 7939  total_loss: 0.4207  loss_cls: 0.09247  loss_box_reg: 0.1358  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.1023  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:57:19] d2.utils.events INFO:  eta: 1:59:48  iter: 7959  total_loss: 0.4237  loss_cls: 0.09784  loss_box_reg: 0.1282  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.1069  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:57:33] d2.utils.events INFO:  eta: 1:59:31  iter: 7979  total_loss: 0.4138  loss_cls: 0.1001  loss_box_reg: 0.1227  loss_rpn_cls: 0.06483  loss_rpn_loc: 0.09257  time: 0.7039  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:57:47] d2.utils.events INFO:  eta: 1:59:11  iter: 7999  total_loss: 0.4091  loss_cls: 0.1086  loss_box_reg: 0.1315  loss_rpn_cls: 0.05705  loss_rpn_loc: 0.07283  time: 0.7039  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:58:01] d2.utils.events INFO:  eta: 1:58:57  iter: 8019  total_loss: 0.438  loss_cls: 0.1223  loss_box_reg: 0.1435  loss_rpn_cls: 0.07969  loss_rpn_loc: 0.09238  time: 0.7039  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:58:16] d2.utils.events INFO:  eta: 1:58:53  iter: 8039  total_loss: 0.4186  loss_cls: 0.1108  loss_box_reg: 0.1251  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.07915  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:58:30] d2.utils.events INFO:  eta: 1:58:36  iter: 8059  total_loss: 0.3665  loss_cls: 0.1162  loss_box_reg: 0.1335  loss_rpn_cls: 0.06861  loss_rpn_loc: 0.07337  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 02:58:44] d2.utils.events INFO:  eta: 1:58:28  iter: 8079  total_loss: 0.3788  loss_cls: 0.08356  loss_box_reg: 0.1245  loss_rpn_cls: 0.05417  loss_rpn_loc: 0.08865  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:58:58] d2.utils.events INFO:  eta: 1:58:12  iter: 8099  total_loss: 0.4736  loss_cls: 0.1077  loss_box_reg: 0.1826  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.1051  time: 0.7039  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 02:59:11] d2.utils.events INFO:  eta: 1:57:55  iter: 8119  total_loss: 0.3405  loss_cls: 0.0956  loss_box_reg: 0.1224  loss_rpn_cls: 0.05345  loss_rpn_loc: 0.09567  time: 0.7039  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 02:59:24] d2.utils.events INFO:  eta: 1:57:39  iter: 8139  total_loss: 0.4179  loss_cls: 0.1053  loss_box_reg: 0.1361  loss_rpn_cls: 0.05004  loss_rpn_loc: 0.05841  time: 0.7038  data_time: 0.0020  lr: 0.0002  max_mem: 15387M
[01/30 02:59:38] d2.utils.events INFO:  eta: 1:57:27  iter: 8159  total_loss: 0.4935  loss_cls: 0.1193  loss_box_reg: 0.1995  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.107  time: 0.7037  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 02:59:53] d2.utils.events INFO:  eta: 1:57:20  iter: 8179  total_loss: 0.4433  loss_cls: 0.1078  loss_box_reg: 0.1374  loss_rpn_cls: 0.05521  loss_rpn_loc: 0.1078  time: 0.7038  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:00:08] d2.utils.events INFO:  eta: 1:57:18  iter: 8199  total_loss: 0.4029  loss_cls: 0.0935  loss_box_reg: 0.1314  loss_rpn_cls: 0.05945  loss_rpn_loc: 0.07409  time: 0.7039  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:00:23] d2.utils.events INFO:  eta: 1:57:04  iter: 8219  total_loss: 0.5369  loss_cls: 0.1068  loss_box_reg: 0.1624  loss_rpn_cls: 0.0686  loss_rpn_loc: 0.1296  time: 0.7040  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:00:37] d2.utils.events INFO:  eta: 1:56:53  iter: 8239  total_loss: 0.4292  loss_cls: 0.09737  loss_box_reg: 0.1416  loss_rpn_cls: 0.08816  loss_rpn_loc: 0.1006  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:00:51] d2.utils.events INFO:  eta: 1:56:35  iter: 8259  total_loss: 0.4533  loss_cls: 0.1226  loss_box_reg: 0.138  loss_rpn_cls: 0.063  loss_rpn_loc: 0.08427  time: 0.7040  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:01:06] d2.utils.events INFO:  eta: 1:56:24  iter: 8279  total_loss: 0.4766  loss_cls: 0.1177  loss_box_reg: 0.1859  loss_rpn_cls: 0.07384  loss_rpn_loc: 0.07191  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:01:20] d2.utils.events INFO:  eta: 1:56:06  iter: 8299  total_loss: 0.38  loss_cls: 0.0995  loss_box_reg: 0.1174  loss_rpn_cls: 0.05806  loss_rpn_loc: 0.06226  time: 0.7040  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 03:01:34] d2.utils.events INFO:  eta: 1:55:52  iter: 8319  total_loss: 0.4735  loss_cls: 0.1066  loss_box_reg: 0.1643  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.09943  time: 0.7040  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:01:48] d2.utils.events INFO:  eta: 1:55:41  iter: 8339  total_loss: 0.4274  loss_cls: 0.1003  loss_box_reg: 0.116  loss_rpn_cls: 0.06503  loss_rpn_loc: 0.1032  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:02:02] d2.utils.events INFO:  eta: 1:55:18  iter: 8359  total_loss: 0.4386  loss_cls: 0.1157  loss_box_reg: 0.1748  loss_rpn_cls: 0.06518  loss_rpn_loc: 0.09085  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:02:16] d2.utils.events INFO:  eta: 1:55:16  iter: 8379  total_loss: 0.5809  loss_cls: 0.1243  loss_box_reg: 0.1883  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.08653  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:02:30] d2.utils.events INFO:  eta: 1:55:00  iter: 8399  total_loss: 0.6596  loss_cls: 0.1485  loss_box_reg: 0.2509  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.09674  time: 0.7040  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:02:45] d2.utils.events INFO:  eta: 1:54:48  iter: 8419  total_loss: 0.4524  loss_cls: 0.09916  loss_box_reg: 0.1382  loss_rpn_cls: 0.09962  loss_rpn_loc: 0.07679  time: 0.7041  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:02:59] d2.utils.events INFO:  eta: 1:54:32  iter: 8439  total_loss: 0.4074  loss_cls: 0.09452  loss_box_reg: 0.122  loss_rpn_cls: 0.07119  loss_rpn_loc: 0.116  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:03:14] d2.utils.events INFO:  eta: 1:54:19  iter: 8459  total_loss: 0.5418  loss_cls: 0.1319  loss_box_reg: 0.1687  loss_rpn_cls: 0.09061  loss_rpn_loc: 0.08589  time: 0.7041  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:03:29] d2.utils.events INFO:  eta: 1:54:12  iter: 8479  total_loss: 0.4729  loss_cls: 0.1187  loss_box_reg: 0.147  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.1108  time: 0.7042  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:03:44] d2.utils.events INFO:  eta: 1:54:21  iter: 8499  total_loss: 0.552  loss_cls: 0.1418  loss_box_reg: 0.1722  loss_rpn_cls: 0.08247  loss_rpn_loc: 0.1316  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:03:58] d2.utils.events INFO:  eta: 1:54:04  iter: 8519  total_loss: 0.4431  loss_cls: 0.1006  loss_box_reg: 0.1409  loss_rpn_cls: 0.07628  loss_rpn_loc: 0.07152  time: 0.7043  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:04:11] d2.utils.events INFO:  eta: 1:53:26  iter: 8539  total_loss: 0.392  loss_cls: 0.1123  loss_box_reg: 0.1327  loss_rpn_cls: 0.07692  loss_rpn_loc: 0.09027  time: 0.7043  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:04:25] d2.utils.events INFO:  eta: 1:53:07  iter: 8559  total_loss: 0.5385  loss_cls: 0.09224  loss_box_reg: 0.1358  loss_rpn_cls: 0.08598  loss_rpn_loc: 0.09455  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:04:39] d2.utils.events INFO:  eta: 1:52:44  iter: 8579  total_loss: 0.4188  loss_cls: 0.1442  loss_box_reg: 0.1332  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.1148  time: 0.7042  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:04:54] d2.utils.events INFO:  eta: 1:52:30  iter: 8599  total_loss: 0.4748  loss_cls: 0.1195  loss_box_reg: 0.1478  loss_rpn_cls: 0.07637  loss_rpn_loc: 0.1292  time: 0.7043  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:05:07] d2.utils.events INFO:  eta: 1:52:11  iter: 8619  total_loss: 0.4221  loss_cls: 0.1099  loss_box_reg: 0.1283  loss_rpn_cls: 0.07342  loss_rpn_loc: 0.07125  time: 0.7042  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:05:21] d2.utils.events INFO:  eta: 1:51:47  iter: 8639  total_loss: 0.3931  loss_cls: 0.1085  loss_box_reg: 0.1378  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.07045  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:05:35] d2.utils.events INFO:  eta: 1:51:38  iter: 8659  total_loss: 0.5041  loss_cls: 0.1152  loss_box_reg: 0.1693  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.07256  time: 0.7042  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 03:05:50] d2.utils.events INFO:  eta: 1:51:26  iter: 8679  total_loss: 0.4221  loss_cls: 0.1173  loss_box_reg: 0.139  loss_rpn_cls: 0.05386  loss_rpn_loc: 0.08552  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:06:03] d2.utils.events INFO:  eta: 1:51:18  iter: 8699  total_loss: 0.6273  loss_cls: 0.1508  loss_box_reg: 0.234  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.07504  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:06:17] d2.utils.events INFO:  eta: 1:51:12  iter: 8719  total_loss: 0.4416  loss_cls: 0.1154  loss_box_reg: 0.1753  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.07143  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:06:31] d2.utils.events INFO:  eta: 1:51:00  iter: 8739  total_loss: 0.4274  loss_cls: 0.09721  loss_box_reg: 0.1427  loss_rpn_cls: 0.05162  loss_rpn_loc: 0.1202  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:06:45] d2.utils.events INFO:  eta: 1:50:50  iter: 8759  total_loss: 0.4457  loss_cls: 0.09672  loss_box_reg: 0.1302  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.09269  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:07:00] d2.utils.events INFO:  eta: 1:50:54  iter: 8779  total_loss: 0.578  loss_cls: 0.1502  loss_box_reg: 0.1875  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.115  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:07:14] d2.utils.events INFO:  eta: 1:50:16  iter: 8799  total_loss: 0.5531  loss_cls: 0.1539  loss_box_reg: 0.2049  loss_rpn_cls: 0.0923  loss_rpn_loc: 0.07569  time: 0.7042  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:07:28] d2.utils.events INFO:  eta: 1:50:00  iter: 8819  total_loss: 0.5251  loss_cls: 0.1096  loss_box_reg: 0.1446  loss_rpn_cls: 0.08085  loss_rpn_loc: 0.09189  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:07:42] d2.utils.events INFO:  eta: 1:49:42  iter: 8839  total_loss: 0.4606  loss_cls: 0.1282  loss_box_reg: 0.1418  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.08478  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:07:56] d2.utils.events INFO:  eta: 1:49:26  iter: 8859  total_loss: 0.4566  loss_cls: 0.09615  loss_box_reg: 0.1523  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.07364  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:08:10] d2.utils.events INFO:  eta: 1:49:02  iter: 8879  total_loss: 0.5464  loss_cls: 0.1402  loss_box_reg: 0.1773  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.09976  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:08:24] d2.utils.events INFO:  eta: 1:48:48  iter: 8899  total_loss: 0.5021  loss_cls: 0.1265  loss_box_reg: 0.1668  loss_rpn_cls: 0.08803  loss_rpn_loc: 0.08716  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:08:38] d2.utils.events INFO:  eta: 1:48:34  iter: 8919  total_loss: 0.4686  loss_cls: 0.09555  loss_box_reg: 0.1389  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.09525  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:08:53] d2.utils.events INFO:  eta: 1:48:29  iter: 8939  total_loss: 0.3612  loss_cls: 0.09455  loss_box_reg: 0.1044  loss_rpn_cls: 0.06832  loss_rpn_loc: 0.07871  time: 0.7042  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:09:07] d2.utils.events INFO:  eta: 1:48:15  iter: 8959  total_loss: 0.4641  loss_cls: 0.1322  loss_box_reg: 0.1602  loss_rpn_cls: 0.05688  loss_rpn_loc: 0.0878  time: 0.7042  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:09:21] d2.utils.events INFO:  eta: 1:47:53  iter: 8979  total_loss: 0.3879  loss_cls: 0.1157  loss_box_reg: 0.1218  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.09073  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:09:34] d2.utils.events INFO:  eta: 1:47:39  iter: 8999  total_loss: 0.4205  loss_cls: 0.1309  loss_box_reg: 0.1652  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.08961  time: 0.7040  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:09:49] d2.utils.events INFO:  eta: 1:47:24  iter: 9019  total_loss: 0.5275  loss_cls: 0.1238  loss_box_reg: 0.1843  loss_rpn_cls: 0.05651  loss_rpn_loc: 0.1096  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:10:03] d2.utils.events INFO:  eta: 1:47:00  iter: 9039  total_loss: 0.4887  loss_cls: 0.1312  loss_box_reg: 0.1703  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.09052  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:10:17] d2.utils.events INFO:  eta: 1:46:37  iter: 9059  total_loss: 0.3682  loss_cls: 0.09326  loss_box_reg: 0.1175  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.09348  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:10:31] d2.utils.events INFO:  eta: 1:46:20  iter: 9079  total_loss: 0.4978  loss_cls: 0.09701  loss_box_reg: 0.1643  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.09578  time: 0.7041  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:10:46] d2.utils.events INFO:  eta: 1:46:22  iter: 9099  total_loss: 0.5308  loss_cls: 0.1121  loss_box_reg: 0.1627  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1022  time: 0.7041  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:11:00] d2.utils.events INFO:  eta: 1:46:10  iter: 9119  total_loss: 0.3674  loss_cls: 0.07847  loss_box_reg: 0.09729  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.07182  time: 0.7041  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:11:14] d2.utils.events INFO:  eta: 1:46:05  iter: 9139  total_loss: 0.6168  loss_cls: 0.1354  loss_box_reg: 0.2052  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.08899  time: 0.7042  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:11:28] d2.utils.events INFO:  eta: 1:45:54  iter: 9159  total_loss: 0.384  loss_cls: 0.09309  loss_box_reg: 0.1272  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.08075  time: 0.7042  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:11:42] d2.utils.events INFO:  eta: 1:45:28  iter: 9179  total_loss: 0.3771  loss_cls: 0.09676  loss_box_reg: 0.1384  loss_rpn_cls: 0.04234  loss_rpn_loc: 0.07842  time: 0.7041  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:11:57] d2.utils.events INFO:  eta: 1:45:14  iter: 9199  total_loss: 0.5335  loss_cls: 0.1261  loss_box_reg: 0.1643  loss_rpn_cls: 0.06377  loss_rpn_loc: 0.1221  time: 0.7042  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:12:12] d2.utils.events INFO:  eta: 1:45:10  iter: 9219  total_loss: 0.4945  loss_cls: 0.1023  loss_box_reg: 0.1729  loss_rpn_cls: 0.1  loss_rpn_loc: 0.1226  time: 0.7043  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:12:26] d2.utils.events INFO:  eta: 1:44:58  iter: 9239  total_loss: 0.493  loss_cls: 0.1308  loss_box_reg: 0.1618  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.08011  time: 0.7043  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:12:41] d2.utils.events INFO:  eta: 1:44:53  iter: 9259  total_loss: 0.4786  loss_cls: 0.1075  loss_box_reg: 0.1319  loss_rpn_cls: 0.07759  loss_rpn_loc: 0.09334  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:12:56] d2.utils.events INFO:  eta: 1:44:44  iter: 9279  total_loss: 0.4769  loss_cls: 0.08054  loss_box_reg: 0.1178  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.1282  time: 0.7044  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:13:09] d2.utils.events INFO:  eta: 1:44:34  iter: 9299  total_loss: 0.5001  loss_cls: 0.1274  loss_box_reg: 0.2092  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.06618  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:13:24] d2.utils.events INFO:  eta: 1:44:16  iter: 9319  total_loss: 0.4534  loss_cls: 0.1106  loss_box_reg: 0.1661  loss_rpn_cls: 0.06642  loss_rpn_loc: 0.07269  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:13:37] d2.utils.events INFO:  eta: 1:43:56  iter: 9339  total_loss: 0.5058  loss_cls: 0.1404  loss_box_reg: 0.1565  loss_rpn_cls: 0.0716  loss_rpn_loc: 0.07323  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:13:52] d2.utils.events INFO:  eta: 1:43:41  iter: 9359  total_loss: 0.4811  loss_cls: 0.1091  loss_box_reg: 0.187  loss_rpn_cls: 0.05319  loss_rpn_loc: 0.102  time: 0.7044  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:14:06] d2.utils.events INFO:  eta: 1:43:24  iter: 9379  total_loss: 0.4734  loss_cls: 0.08396  loss_box_reg: 0.1037  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.1185  time: 0.7044  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:14:20] d2.utils.events INFO:  eta: 1:43:09  iter: 9399  total_loss: 0.4808  loss_cls: 0.1388  loss_box_reg: 0.1764  loss_rpn_cls: 0.07397  loss_rpn_loc: 0.09295  time: 0.7044  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:14:34] d2.utils.events INFO:  eta: 1:42:47  iter: 9419  total_loss: 0.5696  loss_cls: 0.1447  loss_box_reg: 0.1753  loss_rpn_cls: 0.08446  loss_rpn_loc: 0.06395  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:14:49] d2.utils.events INFO:  eta: 1:42:39  iter: 9439  total_loss: 0.4106  loss_cls: 0.09119  loss_box_reg: 0.1041  loss_rpn_cls: 0.06764  loss_rpn_loc: 0.09147  time: 0.7045  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 03:15:03] d2.utils.events INFO:  eta: 1:42:18  iter: 9459  total_loss: 0.4326  loss_cls: 0.0931  loss_box_reg: 0.1219  loss_rpn_cls: 0.07762  loss_rpn_loc: 0.07938  time: 0.7045  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:15:17] d2.utils.events INFO:  eta: 1:41:48  iter: 9479  total_loss: 0.5619  loss_cls: 0.1529  loss_box_reg: 0.1607  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.0999  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:15:32] d2.utils.events INFO:  eta: 1:41:22  iter: 9499  total_loss: 0.4643  loss_cls: 0.08596  loss_box_reg: 0.1098  loss_rpn_cls: 0.0605  loss_rpn_loc: 0.1402  time: 0.7045  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 03:15:46] d2.utils.events INFO:  eta: 1:41:20  iter: 9519  total_loss: 0.4769  loss_cls: 0.1299  loss_box_reg: 0.1627  loss_rpn_cls: 0.08191  loss_rpn_loc: 0.08764  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:15:59] d2.utils.events INFO:  eta: 1:40:54  iter: 9539  total_loss: 0.4215  loss_cls: 0.1162  loss_box_reg: 0.1222  loss_rpn_cls: 0.08209  loss_rpn_loc: 0.07071  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:16:14] d2.utils.events INFO:  eta: 1:40:41  iter: 9559  total_loss: 0.504  loss_cls: 0.1107  loss_box_reg: 0.1833  loss_rpn_cls: 0.07979  loss_rpn_loc: 0.1202  time: 0.7044  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:16:27] d2.utils.events INFO:  eta: 1:40:26  iter: 9579  total_loss: 0.3926  loss_cls: 0.1073  loss_box_reg: 0.1464  loss_rpn_cls: 0.05575  loss_rpn_loc: 0.09562  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:16:41] d2.utils.events INFO:  eta: 1:40:12  iter: 9599  total_loss: 0.4468  loss_cls: 0.1234  loss_box_reg: 0.1439  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.05347  time: 0.7044  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:16:55] d2.utils.events INFO:  eta: 1:39:58  iter: 9619  total_loss: 0.556  loss_cls: 0.151  loss_box_reg: 0.185  loss_rpn_cls: 0.0502  loss_rpn_loc: 0.07927  time: 0.7043  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:17:09] d2.utils.events INFO:  eta: 1:39:56  iter: 9639  total_loss: 0.4805  loss_cls: 0.1186  loss_box_reg: 0.125  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.104  time: 0.7044  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 03:17:23] d2.utils.events INFO:  eta: 1:39:29  iter: 9659  total_loss: 0.373  loss_cls: 0.09344  loss_box_reg: 0.09467  loss_rpn_cls: 0.05513  loss_rpn_loc: 0.07092  time: 0.7043  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:17:37] d2.utils.events INFO:  eta: 1:39:27  iter: 9679  total_loss: 0.5265  loss_cls: 0.1514  loss_box_reg: 0.1643  loss_rpn_cls: 0.07969  loss_rpn_loc: 0.09111  time: 0.7043  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:17:52] d2.utils.events INFO:  eta: 1:39:13  iter: 9699  total_loss: 0.4475  loss_cls: 0.1079  loss_box_reg: 0.1421  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.08997  time: 0.7043  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:18:06] d2.utils.events INFO:  eta: 1:38:59  iter: 9719  total_loss: 0.4921  loss_cls: 0.1361  loss_box_reg: 0.1825  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.07839  time: 0.7044  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:18:20] d2.utils.events INFO:  eta: 1:38:56  iter: 9739  total_loss: 0.5351  loss_cls: 0.1187  loss_box_reg: 0.1983  loss_rpn_cls: 0.06919  loss_rpn_loc: 0.102  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:18:36] d2.utils.events INFO:  eta: 1:38:55  iter: 9759  total_loss: 0.3572  loss_cls: 0.08948  loss_box_reg: 0.1184  loss_rpn_cls: 0.05036  loss_rpn_loc: 0.1042  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:18:48] d2.utils.events INFO:  eta: 1:38:14  iter: 9779  total_loss: 0.4121  loss_cls: 0.08859  loss_box_reg: 0.1534  loss_rpn_cls: 0.0874  loss_rpn_loc: 0.07985  time: 0.7044  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:19:02] d2.utils.events INFO:  eta: 1:37:49  iter: 9799  total_loss: 0.4267  loss_cls: 0.09041  loss_box_reg: 0.132  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1208  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:19:16] d2.utils.events INFO:  eta: 1:37:40  iter: 9819  total_loss: 0.4523  loss_cls: 0.1024  loss_box_reg: 0.1484  loss_rpn_cls: 0.05563  loss_rpn_loc: 0.09918  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:19:31] d2.utils.events INFO:  eta: 1:37:37  iter: 9839  total_loss: 0.3624  loss_cls: 0.1056  loss_box_reg: 0.1065  loss_rpn_cls: 0.056  loss_rpn_loc: 0.09378  time: 0.7044  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:19:46] d2.utils.events INFO:  eta: 1:37:46  iter: 9859  total_loss: 0.5458  loss_cls: 0.1197  loss_box_reg: 0.1507  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.1085  time: 0.7045  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:20:00] d2.utils.events INFO:  eta: 1:37:33  iter: 9879  total_loss: 0.44  loss_cls: 0.1064  loss_box_reg: 0.128  loss_rpn_cls: 0.05923  loss_rpn_loc: 0.0817  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:20:15] d2.utils.events INFO:  eta: 1:37:19  iter: 9899  total_loss: 0.528  loss_cls: 0.1015  loss_box_reg: 0.1378  loss_rpn_cls: 0.08315  loss_rpn_loc: 0.1146  time: 0.7045  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:20:29] d2.utils.events INFO:  eta: 1:37:01  iter: 9919  total_loss: 0.55  loss_cls: 0.1312  loss_box_reg: 0.1607  loss_rpn_cls: 0.08692  loss_rpn_loc: 0.09048  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:20:43] d2.utils.events INFO:  eta: 1:36:41  iter: 9939  total_loss: 0.403  loss_cls: 0.09917  loss_box_reg: 0.1417  loss_rpn_cls: 0.05961  loss_rpn_loc: 0.09747  time: 0.7045  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:20:56] d2.utils.events INFO:  eta: 1:36:22  iter: 9959  total_loss: 0.486  loss_cls: 0.1163  loss_box_reg: 0.1425  loss_rpn_cls: 0.06748  loss_rpn_loc: 0.0475  time: 0.7044  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:21:10] d2.utils.events INFO:  eta: 1:36:19  iter: 9979  total_loss: 0.3574  loss_cls: 0.09195  loss_box_reg: 0.1035  loss_rpn_cls: 0.05344  loss_rpn_loc: 0.05667  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:21:25] d2.utils.events INFO:  eta: 1:36:10  iter: 9999  total_loss: 0.3779  loss_cls: 0.09866  loss_box_reg: 0.1305  loss_rpn_cls: 0.05039  loss_rpn_loc: 0.1175  time: 0.7045  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:21:40] d2.utils.events INFO:  eta: 1:35:58  iter: 10019  total_loss: 0.503  loss_cls: 0.1003  loss_box_reg: 0.1928  loss_rpn_cls: 0.07521  loss_rpn_loc: 0.09613  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:21:53] d2.utils.events INFO:  eta: 1:35:37  iter: 10039  total_loss: 0.4243  loss_cls: 0.1085  loss_box_reg: 0.1571  loss_rpn_cls: 0.05955  loss_rpn_loc: 0.08248  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:22:07] d2.utils.events INFO:  eta: 1:35:10  iter: 10059  total_loss: 0.5888  loss_cls: 0.1546  loss_box_reg: 0.2085  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.1106  time: 0.7044  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:22:21] d2.utils.events INFO:  eta: 1:35:08  iter: 10079  total_loss: 0.3513  loss_cls: 0.08279  loss_box_reg: 0.1333  loss_rpn_cls: 0.03926  loss_rpn_loc: 0.07521  time: 0.7045  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:22:35] d2.utils.events INFO:  eta: 1:34:51  iter: 10099  total_loss: 0.4405  loss_cls: 0.1041  loss_box_reg: 0.1654  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.09706  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:22:50] d2.utils.events INFO:  eta: 1:34:31  iter: 10119  total_loss: 0.4596  loss_cls: 0.1033  loss_box_reg: 0.1585  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.1069  time: 0.7045  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:23:04] d2.utils.events INFO:  eta: 1:34:17  iter: 10139  total_loss: 0.3812  loss_cls: 0.09141  loss_box_reg: 0.1194  loss_rpn_cls: 0.07686  loss_rpn_loc: 0.0912  time: 0.7045  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:23:19] d2.utils.events INFO:  eta: 1:34:08  iter: 10159  total_loss: 0.4061  loss_cls: 0.09252  loss_box_reg: 0.1432  loss_rpn_cls: 0.06444  loss_rpn_loc: 0.0784  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:23:33] d2.utils.events INFO:  eta: 1:34:01  iter: 10179  total_loss: 0.3365  loss_cls: 0.08317  loss_box_reg: 0.1168  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.08596  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:23:48] d2.utils.events INFO:  eta: 1:33:46  iter: 10199  total_loss: 0.4293  loss_cls: 0.1138  loss_box_reg: 0.1567  loss_rpn_cls: 0.05084  loss_rpn_loc: 0.07007  time: 0.7046  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:24:01] d2.utils.events INFO:  eta: 1:33:26  iter: 10219  total_loss: 0.3191  loss_cls: 0.07861  loss_box_reg: 0.1266  loss_rpn_cls: 0.05873  loss_rpn_loc: 0.08267  time: 0.7046  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:24:16] d2.utils.events INFO:  eta: 1:33:05  iter: 10239  total_loss: 0.4914  loss_cls: 0.1204  loss_box_reg: 0.1687  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.08618  time: 0.7046  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:24:30] d2.utils.events INFO:  eta: 1:32:32  iter: 10259  total_loss: 0.4427  loss_cls: 0.1129  loss_box_reg: 0.1208  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.08184  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:24:44] d2.utils.events INFO:  eta: 1:32:18  iter: 10279  total_loss: 0.351  loss_cls: 0.1065  loss_box_reg: 0.1145  loss_rpn_cls: 0.05354  loss_rpn_loc: 0.05792  time: 0.7046  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:24:59] d2.utils.events INFO:  eta: 1:32:13  iter: 10299  total_loss: 0.5152  loss_cls: 0.1129  loss_box_reg: 0.159  loss_rpn_cls: 0.09105  loss_rpn_loc: 0.1488  time: 0.7047  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:25:13] d2.utils.events INFO:  eta: 1:31:51  iter: 10319  total_loss: 0.4473  loss_cls: 0.1317  loss_box_reg: 0.1619  loss_rpn_cls: 0.05966  loss_rpn_loc: 0.0831  time: 0.7047  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:25:27] d2.utils.events INFO:  eta: 1:31:41  iter: 10339  total_loss: 0.292  loss_cls: 0.07775  loss_box_reg: 0.09566  loss_rpn_cls: 0.04686  loss_rpn_loc: 0.09606  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:25:41] d2.utils.events INFO:  eta: 1:31:25  iter: 10359  total_loss: 0.4647  loss_cls: 0.1102  loss_box_reg: 0.1107  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.09507  time: 0.7046  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:25:55] d2.utils.events INFO:  eta: 1:31:10  iter: 10379  total_loss: 0.4452  loss_cls: 0.1053  loss_box_reg: 0.137  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.1111  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:26:09] d2.utils.events INFO:  eta: 1:30:57  iter: 10399  total_loss: 0.4298  loss_cls: 0.1481  loss_box_reg: 0.1701  loss_rpn_cls: 0.06711  loss_rpn_loc: 0.09204  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:26:24] d2.utils.events INFO:  eta: 1:30:46  iter: 10419  total_loss: 0.3997  loss_cls: 0.08904  loss_box_reg: 0.127  loss_rpn_cls: 0.05175  loss_rpn_loc: 0.09336  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:26:38] d2.utils.events INFO:  eta: 1:30:29  iter: 10439  total_loss: 0.3373  loss_cls: 0.07873  loss_box_reg: 0.1284  loss_rpn_cls: 0.06276  loss_rpn_loc: 0.09282  time: 0.7047  data_time: 0.0026  lr: 0.0002  max_mem: 15387M
[01/30 03:26:52] d2.utils.events INFO:  eta: 1:30:18  iter: 10459  total_loss: 0.4464  loss_cls: 0.1236  loss_box_reg: 0.1484  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.09744  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:27:06] d2.utils.events INFO:  eta: 1:30:03  iter: 10479  total_loss: 0.4332  loss_cls: 0.1247  loss_box_reg: 0.1275  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.0851  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:27:19] d2.utils.events INFO:  eta: 1:29:46  iter: 10499  total_loss: 0.5439  loss_cls: 0.1229  loss_box_reg: 0.1525  loss_rpn_cls: 0.07943  loss_rpn_loc: 0.09968  time: 0.7046  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:27:34] d2.utils.events INFO:  eta: 1:29:32  iter: 10519  total_loss: 0.5352  loss_cls: 0.1045  loss_box_reg: 0.17  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.08202  time: 0.7046  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:27:49] d2.utils.events INFO:  eta: 1:29:44  iter: 10539  total_loss: 0.4613  loss_cls: 0.1027  loss_box_reg: 0.146  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.0838  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:28:03] d2.utils.events INFO:  eta: 1:29:30  iter: 10559  total_loss: 0.3952  loss_cls: 0.0872  loss_box_reg: 0.1331  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.0892  time: 0.7047  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:28:18] d2.utils.events INFO:  eta: 1:29:35  iter: 10579  total_loss: 0.4618  loss_cls: 0.1217  loss_box_reg: 0.1631  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.105  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:28:32] d2.utils.events INFO:  eta: 1:29:14  iter: 10599  total_loss: 0.5227  loss_cls: 0.1556  loss_box_reg: 0.1838  loss_rpn_cls: 0.0718  loss_rpn_loc: 0.09629  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:28:47] d2.utils.events INFO:  eta: 1:29:14  iter: 10619  total_loss: 0.4597  loss_cls: 0.1269  loss_box_reg: 0.1589  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.06967  time: 0.7049  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:29:01] d2.utils.events INFO:  eta: 1:28:52  iter: 10639  total_loss: 0.3886  loss_cls: 0.1075  loss_box_reg: 0.1219  loss_rpn_cls: 0.04227  loss_rpn_loc: 0.09039  time: 0.7049  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:29:16] d2.utils.events INFO:  eta: 1:28:50  iter: 10659  total_loss: 0.3551  loss_cls: 0.08184  loss_box_reg: 0.1029  loss_rpn_cls: 0.06163  loss_rpn_loc: 0.0919  time: 0.7049  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:29:30] d2.utils.events INFO:  eta: 1:28:29  iter: 10679  total_loss: 0.4365  loss_cls: 0.093  loss_box_reg: 0.1468  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.1185  time: 0.7049  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:29:45] d2.utils.events INFO:  eta: 1:28:21  iter: 10699  total_loss: 0.3542  loss_cls: 0.09948  loss_box_reg: 0.1251  loss_rpn_cls: 0.05857  loss_rpn_loc: 0.07299  time: 0.7050  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:29:59] d2.utils.events INFO:  eta: 1:28:02  iter: 10719  total_loss: 0.4835  loss_cls: 0.1242  loss_box_reg: 0.1746  loss_rpn_cls: 0.06689  loss_rpn_loc: 0.1054  time: 0.7050  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:30:14] d2.utils.events INFO:  eta: 1:27:27  iter: 10739  total_loss: 0.4791  loss_cls: 0.1279  loss_box_reg: 0.1493  loss_rpn_cls: 0.06613  loss_rpn_loc: 0.09689  time: 0.7050  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:30:28] d2.utils.events INFO:  eta: 1:27:19  iter: 10759  total_loss: 0.4947  loss_cls: 0.1176  loss_box_reg: 0.1784  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1051  time: 0.7051  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:30:42] d2.utils.events INFO:  eta: 1:27:18  iter: 10779  total_loss: 0.3629  loss_cls: 0.1009  loss_box_reg: 0.1203  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.07098  time: 0.7050  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:30:56] d2.utils.events INFO:  eta: 1:27:12  iter: 10799  total_loss: 0.4361  loss_cls: 0.1122  loss_box_reg: 0.1219  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.109  time: 0.7050  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:31:10] d2.utils.events INFO:  eta: 1:26:53  iter: 10819  total_loss: 0.4659  loss_cls: 0.1133  loss_box_reg: 0.1477  loss_rpn_cls: 0.09507  loss_rpn_loc: 0.07947  time: 0.7050  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:31:24] d2.utils.events INFO:  eta: 1:26:21  iter: 10839  total_loss: 0.5224  loss_cls: 0.1487  loss_box_reg: 0.1758  loss_rpn_cls: 0.09259  loss_rpn_loc: 0.07437  time: 0.7050  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:31:38] d2.utils.events INFO:  eta: 1:25:45  iter: 10859  total_loss: 0.4601  loss_cls: 0.1246  loss_box_reg: 0.1616  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.09566  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:31:52] d2.utils.events INFO:  eta: 1:25:27  iter: 10879  total_loss: 0.4277  loss_cls: 0.09525  loss_box_reg: 0.1833  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.09162  time: 0.7050  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:32:05] d2.utils.events INFO:  eta: 1:25:10  iter: 10899  total_loss: 0.4652  loss_cls: 0.1263  loss_box_reg: 0.1632  loss_rpn_cls: 0.0708  loss_rpn_loc: 0.0651  time: 0.7049  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:32:19] d2.utils.events INFO:  eta: 1:24:50  iter: 10919  total_loss: 0.3728  loss_cls: 0.09794  loss_box_reg: 0.1239  loss_rpn_cls: 0.07962  loss_rpn_loc: 0.06347  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:32:33] d2.utils.events INFO:  eta: 1:24:34  iter: 10939  total_loss: 0.4155  loss_cls: 0.1128  loss_box_reg: 0.1759  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.06457  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:32:46] d2.utils.events INFO:  eta: 1:24:20  iter: 10959  total_loss: 0.3917  loss_cls: 0.1203  loss_box_reg: 0.1404  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.06975  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:33:00] d2.utils.events INFO:  eta: 1:24:10  iter: 10979  total_loss: 0.501  loss_cls: 0.1298  loss_box_reg: 0.1945  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.1188  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:33:14] d2.utils.events INFO:  eta: 1:23:56  iter: 10999  total_loss: 0.5157  loss_cls: 0.1098  loss_box_reg: 0.1967  loss_rpn_cls: 0.08434  loss_rpn_loc: 0.08952  time: 0.7047  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:33:29] d2.utils.events INFO:  eta: 1:23:39  iter: 11019  total_loss: 0.3942  loss_cls: 0.08622  loss_box_reg: 0.1244  loss_rpn_cls: 0.04283  loss_rpn_loc: 0.07503  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:33:43] d2.utils.events INFO:  eta: 1:23:32  iter: 11039  total_loss: 0.4263  loss_cls: 0.1246  loss_box_reg: 0.1198  loss_rpn_cls: 0.05183  loss_rpn_loc: 0.08527  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:33:57] d2.utils.events INFO:  eta: 1:23:29  iter: 11059  total_loss: 0.3628  loss_cls: 0.1056  loss_box_reg: 0.1141  loss_rpn_cls: 0.04633  loss_rpn_loc: 0.08549  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:34:11] d2.utils.events INFO:  eta: 1:23:07  iter: 11079  total_loss: 0.4785  loss_cls: 0.123  loss_box_reg: 0.2201  loss_rpn_cls: 0.05056  loss_rpn_loc: 0.1106  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:34:25] d2.utils.events INFO:  eta: 1:22:58  iter: 11099  total_loss: 0.4147  loss_cls: 0.0989  loss_box_reg: 0.1541  loss_rpn_cls: 0.05578  loss_rpn_loc: 0.07109  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:34:39] d2.utils.events INFO:  eta: 1:22:39  iter: 11119  total_loss: 0.4117  loss_cls: 0.1086  loss_box_reg: 0.1525  loss_rpn_cls: 0.05137  loss_rpn_loc: 0.08899  time: 0.7047  data_time: 0.0025  lr: 0.0002  max_mem: 15387M
[01/30 03:34:54] d2.utils.events INFO:  eta: 1:22:33  iter: 11139  total_loss: 0.472  loss_cls: 0.1123  loss_box_reg: 0.1536  loss_rpn_cls: 0.075  loss_rpn_loc: 0.1125  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:35:08] d2.utils.events INFO:  eta: 1:22:14  iter: 11159  total_loss: 0.4545  loss_cls: 0.1197  loss_box_reg: 0.1909  loss_rpn_cls: 0.064  loss_rpn_loc: 0.08793  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:35:23] d2.utils.events INFO:  eta: 1:21:55  iter: 11179  total_loss: 0.3487  loss_cls: 0.08362  loss_box_reg: 0.1224  loss_rpn_cls: 0.06189  loss_rpn_loc: 0.09104  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:35:37] d2.utils.events INFO:  eta: 1:21:35  iter: 11199  total_loss: 0.2955  loss_cls: 0.07421  loss_box_reg: 0.09485  loss_rpn_cls: 0.04002  loss_rpn_loc: 0.07973  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:35:51] d2.utils.events INFO:  eta: 1:21:19  iter: 11219  total_loss: 0.3748  loss_cls: 0.09012  loss_box_reg: 0.1255  loss_rpn_cls: 0.05925  loss_rpn_loc: 0.08729  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:36:04] d2.utils.events INFO:  eta: 1:21:04  iter: 11239  total_loss: 0.4563  loss_cls: 0.1219  loss_box_reg: 0.1411  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.09824  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:36:18] d2.utils.events INFO:  eta: 1:20:53  iter: 11259  total_loss: 0.4444  loss_cls: 0.1148  loss_box_reg: 0.1563  loss_rpn_cls: 0.06123  loss_rpn_loc: 0.0799  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:36:32] d2.utils.events INFO:  eta: 1:20:35  iter: 11279  total_loss: 0.4589  loss_cls: 0.1057  loss_box_reg: 0.1357  loss_rpn_cls: 0.07155  loss_rpn_loc: 0.08175  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:36:46] d2.utils.events INFO:  eta: 1:20:20  iter: 11299  total_loss: 0.3  loss_cls: 0.05802  loss_box_reg: 0.08539  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1035  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:37:01] d2.utils.events INFO:  eta: 1:20:07  iter: 11319  total_loss: 0.4377  loss_cls: 0.1087  loss_box_reg: 0.143  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.07947  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:37:15] d2.utils.events INFO:  eta: 1:19:55  iter: 11339  total_loss: 0.3984  loss_cls: 0.09964  loss_box_reg: 0.1435  loss_rpn_cls: 0.05786  loss_rpn_loc: 0.09725  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:37:29] d2.utils.events INFO:  eta: 1:19:41  iter: 11359  total_loss: 0.3333  loss_cls: 0.09911  loss_box_reg: 0.1201  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.05478  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:37:42] d2.utils.events INFO:  eta: 1:19:26  iter: 11379  total_loss: 0.5766  loss_cls: 0.1301  loss_box_reg: 0.2002  loss_rpn_cls: 0.06651  loss_rpn_loc: 0.1218  time: 0.7047  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:37:57] d2.utils.events INFO:  eta: 1:19:12  iter: 11399  total_loss: 0.424  loss_cls: 0.1149  loss_box_reg: 0.1632  loss_rpn_cls: 0.07964  loss_rpn_loc: 0.08086  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:38:11] d2.utils.events INFO:  eta: 1:18:54  iter: 11419  total_loss: 0.4352  loss_cls: 0.1271  loss_box_reg: 0.1476  loss_rpn_cls: 0.08036  loss_rpn_loc: 0.1128  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:38:26] d2.utils.events INFO:  eta: 1:18:40  iter: 11439  total_loss: 0.4742  loss_cls: 0.1295  loss_box_reg: 0.1334  loss_rpn_cls: 0.06189  loss_rpn_loc: 0.1328  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:38:40] d2.utils.events INFO:  eta: 1:18:25  iter: 11459  total_loss: 0.3634  loss_cls: 0.06963  loss_box_reg: 0.1066  loss_rpn_cls: 0.0613  loss_rpn_loc: 0.0765  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:38:54] d2.utils.events INFO:  eta: 1:18:12  iter: 11479  total_loss: 0.3921  loss_cls: 0.1024  loss_box_reg: 0.1305  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.07547  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:39:09] d2.utils.events INFO:  eta: 1:17:59  iter: 11499  total_loss: 0.3943  loss_cls: 0.09903  loss_box_reg: 0.1395  loss_rpn_cls: 0.05613  loss_rpn_loc: 0.07267  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:39:23] d2.utils.events INFO:  eta: 1:17:40  iter: 11519  total_loss: 0.4527  loss_cls: 0.104  loss_box_reg: 0.1608  loss_rpn_cls: 0.08708  loss_rpn_loc: 0.08298  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:39:37] d2.utils.events INFO:  eta: 1:17:14  iter: 11539  total_loss: 0.4637  loss_cls: 0.09846  loss_box_reg: 0.1366  loss_rpn_cls: 0.05297  loss_rpn_loc: 0.1169  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:39:50] d2.utils.events INFO:  eta: 1:17:00  iter: 11559  total_loss: 0.3557  loss_cls: 0.08429  loss_box_reg: 0.1181  loss_rpn_cls: 0.05088  loss_rpn_loc: 0.07293  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:40:05] d2.utils.events INFO:  eta: 1:16:45  iter: 11579  total_loss: 0.506  loss_cls: 0.1208  loss_box_reg: 0.201  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.06812  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:40:19] d2.utils.events INFO:  eta: 1:16:30  iter: 11599  total_loss: 0.481  loss_cls: 0.1093  loss_box_reg: 0.151  loss_rpn_cls: 0.08887  loss_rpn_loc: 0.07641  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:40:34] d2.utils.events INFO:  eta: 1:16:15  iter: 11619  total_loss: 0.4603  loss_cls: 0.1143  loss_box_reg: 0.1451  loss_rpn_cls: 0.09826  loss_rpn_loc: 0.1384  time: 0.7048  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:40:48] d2.utils.events INFO:  eta: 1:16:02  iter: 11639  total_loss: 0.3725  loss_cls: 0.07238  loss_box_reg: 0.09876  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.08286  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:41:01] d2.utils.events INFO:  eta: 1:15:39  iter: 11659  total_loss: 0.4787  loss_cls: 0.1396  loss_box_reg: 0.1504  loss_rpn_cls: 0.06716  loss_rpn_loc: 0.07864  time: 0.7048  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:41:14] d2.utils.events INFO:  eta: 1:15:21  iter: 11679  total_loss: 0.4056  loss_cls: 0.1083  loss_box_reg: 0.1557  loss_rpn_cls: 0.06353  loss_rpn_loc: 0.09398  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:41:29] d2.utils.events INFO:  eta: 1:15:05  iter: 11699  total_loss: 0.4283  loss_cls: 0.1278  loss_box_reg: 0.1777  loss_rpn_cls: 0.05581  loss_rpn_loc: 0.08922  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:41:43] d2.utils.events INFO:  eta: 1:14:47  iter: 11719  total_loss: 0.3102  loss_cls: 0.07069  loss_box_reg: 0.1082  loss_rpn_cls: 0.04481  loss_rpn_loc: 0.08877  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:41:57] d2.utils.events INFO:  eta: 1:14:35  iter: 11739  total_loss: 0.4245  loss_cls: 0.1158  loss_box_reg: 0.1174  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.1241  time: 0.7047  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:42:12] d2.utils.events INFO:  eta: 1:14:25  iter: 11759  total_loss: 0.4419  loss_cls: 0.09205  loss_box_reg: 0.1599  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.09732  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:42:26] d2.utils.events INFO:  eta: 1:14:15  iter: 11779  total_loss: 0.4247  loss_cls: 0.09319  loss_box_reg: 0.1561  loss_rpn_cls: 0.05928  loss_rpn_loc: 0.08805  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:42:40] d2.utils.events INFO:  eta: 1:13:58  iter: 11799  total_loss: 0.5195  loss_cls: 0.1084  loss_box_reg: 0.1617  loss_rpn_cls: 0.08015  loss_rpn_loc: 0.0904  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:42:54] d2.utils.events INFO:  eta: 1:13:49  iter: 11819  total_loss: 0.5542  loss_cls: 0.1381  loss_box_reg: 0.1508  loss_rpn_cls: 0.09007  loss_rpn_loc: 0.09086  time: 0.7048  data_time: 0.0023  lr: 0.0002  max_mem: 15387M
[01/30 03:43:08] d2.utils.events INFO:  eta: 1:13:33  iter: 11839  total_loss: 0.5365  loss_cls: 0.1268  loss_box_reg: 0.1717  loss_rpn_cls: 0.06621  loss_rpn_loc: 0.119  time: 0.7048  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:43:22] d2.utils.events INFO:  eta: 1:13:19  iter: 11859  total_loss: 0.4768  loss_cls: 0.1309  loss_box_reg: 0.1464  loss_rpn_cls: 0.07176  loss_rpn_loc: 0.08338  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:43:36] d2.utils.events INFO:  eta: 1:13:03  iter: 11879  total_loss: 0.4267  loss_cls: 0.103  loss_box_reg: 0.1257  loss_rpn_cls: 0.07715  loss_rpn_loc: 0.07499  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:43:50] d2.utils.events INFO:  eta: 1:12:50  iter: 11899  total_loss: 0.4517  loss_cls: 0.1303  loss_box_reg: 0.1504  loss_rpn_cls: 0.08242  loss_rpn_loc: 0.09015  time: 0.7047  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:44:04] d2.utils.events INFO:  eta: 1:12:37  iter: 11919  total_loss: 0.4066  loss_cls: 0.09853  loss_box_reg: 0.1518  loss_rpn_cls: 0.06016  loss_rpn_loc: 0.08552  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:44:18] d2.utils.events INFO:  eta: 1:12:22  iter: 11939  total_loss: 0.5028  loss_cls: 0.1509  loss_box_reg: 0.1738  loss_rpn_cls: 0.08852  loss_rpn_loc: 0.07541  time: 0.7047  data_time: 0.0024  lr: 0.0002  max_mem: 15387M
[01/30 03:44:32] d2.utils.events INFO:  eta: 1:12:08  iter: 11959  total_loss: 0.4519  loss_cls: 0.09815  loss_box_reg: 0.1363  loss_rpn_cls: 0.06705  loss_rpn_loc: 0.08947  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:44:47] d2.utils.events INFO:  eta: 1:11:51  iter: 11979  total_loss: 0.4027  loss_cls: 0.1107  loss_box_reg: 0.1189  loss_rpn_cls: 0.08198  loss_rpn_loc: 0.08762  time: 0.7047  data_time: 0.0022  lr: 0.0002  max_mem: 15387M
[01/30 03:45:01] d2.utils.events INFO:  eta: 1:11:33  iter: 11999  total_loss: 0.4591  loss_cls: 0.1043  loss_box_reg: 0.1252  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.08799  time: 0.7047  data_time: 0.0021  lr: 0.0002  max_mem: 15387M
[01/30 03:45:15] d2.utils.events INFO:  eta: 1:11:20  iter: 12019  total_loss: 0.4024  loss_cls: 0.1038  loss_box_reg: 0.1255  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.07237  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:45:29] d2.utils.events INFO:  eta: 1:11:00  iter: 12039  total_loss: 0.3062  loss_cls: 0.07093  loss_box_reg: 0.1032  loss_rpn_cls: 0.0514  loss_rpn_loc: 0.07419  time: 0.7047  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:45:43] d2.utils.events INFO:  eta: 1:10:44  iter: 12059  total_loss: 0.4236  loss_cls: 0.08232  loss_box_reg: 0.1674  loss_rpn_cls: 0.05078  loss_rpn_loc: 0.06941  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:45:56] d2.utils.events INFO:  eta: 1:10:30  iter: 12079  total_loss: 0.3769  loss_cls: 0.09095  loss_box_reg: 0.1383  loss_rpn_cls: 0.05277  loss_rpn_loc: 0.09063  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:46:10] d2.utils.events INFO:  eta: 1:10:07  iter: 12099  total_loss: 0.3634  loss_cls: 0.08831  loss_box_reg: 0.1505  loss_rpn_cls: 0.05658  loss_rpn_loc: 0.07226  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:46:24] d2.utils.events INFO:  eta: 1:09:50  iter: 12119  total_loss: 0.367  loss_cls: 0.08683  loss_box_reg: 0.1379  loss_rpn_cls: 0.05726  loss_rpn_loc: 0.07823  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:46:38] d2.utils.events INFO:  eta: 1:09:32  iter: 12139  total_loss: 0.3368  loss_cls: 0.09463  loss_box_reg: 0.09931  loss_rpn_cls: 0.06247  loss_rpn_loc: 0.08289  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:46:53] d2.utils.events INFO:  eta: 1:09:19  iter: 12159  total_loss: 0.4041  loss_cls: 0.08456  loss_box_reg: 0.1509  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.08  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:47:07] d2.utils.events INFO:  eta: 1:09:03  iter: 12179  total_loss: 0.4461  loss_cls: 0.1041  loss_box_reg: 0.1854  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.0765  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:47:22] d2.utils.events INFO:  eta: 1:08:56  iter: 12199  total_loss: 0.4827  loss_cls: 0.1146  loss_box_reg: 0.1849  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.07914  time: 0.7047  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:47:35] d2.utils.events INFO:  eta: 1:08:42  iter: 12219  total_loss: 0.4071  loss_cls: 0.0962  loss_box_reg: 0.1287  loss_rpn_cls: 0.06233  loss_rpn_loc: 0.07447  time: 0.7046  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:47:49] d2.utils.events INFO:  eta: 1:08:27  iter: 12239  total_loss: 0.3234  loss_cls: 0.07335  loss_box_reg: 0.1224  loss_rpn_cls: 0.03987  loss_rpn_loc: 0.05909  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:48:03] d2.utils.events INFO:  eta: 1:08:14  iter: 12259  total_loss: 0.4473  loss_cls: 0.1186  loss_box_reg: 0.1711  loss_rpn_cls: 0.05139  loss_rpn_loc: 0.08056  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:48:17] d2.utils.events INFO:  eta: 1:08:04  iter: 12279  total_loss: 0.3297  loss_cls: 0.07688  loss_box_reg: 0.1102  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.05062  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:48:32] d2.utils.events INFO:  eta: 1:07:48  iter: 12299  total_loss: 0.3947  loss_cls: 0.08446  loss_box_reg: 0.113  loss_rpn_cls: 0.07104  loss_rpn_loc: 0.08692  time: 0.7046  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:48:45] d2.utils.events INFO:  eta: 1:07:31  iter: 12319  total_loss: 0.4468  loss_cls: 0.1124  loss_box_reg: 0.1819  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.08305  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:49:00] d2.utils.events INFO:  eta: 1:07:16  iter: 12339  total_loss: 0.4616  loss_cls: 0.0923  loss_box_reg: 0.1511  loss_rpn_cls: 0.05062  loss_rpn_loc: 0.09061  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:49:14] d2.utils.events INFO:  eta: 1:07:03  iter: 12359  total_loss: 0.4928  loss_cls: 0.12  loss_box_reg: 0.1904  loss_rpn_cls: 0.06786  loss_rpn_loc: 0.09485  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:49:28] d2.utils.events INFO:  eta: 1:06:49  iter: 12379  total_loss: 0.4046  loss_cls: 0.1017  loss_box_reg: 0.1591  loss_rpn_cls: 0.04521  loss_rpn_loc: 0.05999  time: 0.7046  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:49:42] d2.utils.events INFO:  eta: 1:06:34  iter: 12399  total_loss: 0.4006  loss_cls: 0.1109  loss_box_reg: 0.1499  loss_rpn_cls: 0.0462  loss_rpn_loc: 0.09018  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:49:56] d2.utils.events INFO:  eta: 1:06:19  iter: 12419  total_loss: 0.4746  loss_cls: 0.08831  loss_box_reg: 0.1559  loss_rpn_cls: 0.06286  loss_rpn_loc: 0.09594  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:50:09] d2.utils.events INFO:  eta: 1:05:55  iter: 12439  total_loss: 0.3878  loss_cls: 0.09216  loss_box_reg: 0.1396  loss_rpn_cls: 0.05331  loss_rpn_loc: 0.07418  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:50:23] d2.utils.events INFO:  eta: 1:05:48  iter: 12459  total_loss: 0.4962  loss_cls: 0.1151  loss_box_reg: 0.2127  loss_rpn_cls: 0.0547  loss_rpn_loc: 0.07834  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:50:37] d2.utils.events INFO:  eta: 1:05:32  iter: 12479  total_loss: 0.4796  loss_cls: 0.1146  loss_box_reg: 0.2233  loss_rpn_cls: 0.05919  loss_rpn_loc: 0.07241  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:50:52] d2.utils.events INFO:  eta: 1:05:21  iter: 12499  total_loss: 0.3686  loss_cls: 0.07842  loss_box_reg: 0.1264  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.08067  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:51:06] d2.utils.events INFO:  eta: 1:05:08  iter: 12519  total_loss: 0.4409  loss_cls: 0.103  loss_box_reg: 0.1607  loss_rpn_cls: 0.04512  loss_rpn_loc: 0.1014  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:51:19] d2.utils.events INFO:  eta: 1:04:54  iter: 12539  total_loss: 0.3977  loss_cls: 0.1129  loss_box_reg: 0.1366  loss_rpn_cls: 0.04863  loss_rpn_loc: 0.08805  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:51:34] d2.utils.events INFO:  eta: 1:04:40  iter: 12559  total_loss: 0.4397  loss_cls: 0.1012  loss_box_reg: 0.1547  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.09538  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:51:49] d2.utils.events INFO:  eta: 1:04:26  iter: 12579  total_loss: 0.371  loss_cls: 0.07628  loss_box_reg: 0.1335  loss_rpn_cls: 0.03937  loss_rpn_loc: 0.08977  time: 0.7046  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 03:52:03] d2.utils.events INFO:  eta: 1:04:11  iter: 12599  total_loss: 0.4301  loss_cls: 0.1182  loss_box_reg: 0.1519  loss_rpn_cls: 0.06023  loss_rpn_loc: 0.07243  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:52:17] d2.utils.events INFO:  eta: 1:03:53  iter: 12619  total_loss: 0.3174  loss_cls: 0.103  loss_box_reg: 0.1197  loss_rpn_cls: 0.04562  loss_rpn_loc: 0.04221  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:52:31] d2.utils.events INFO:  eta: 1:03:34  iter: 12639  total_loss: 0.4416  loss_cls: 0.1108  loss_box_reg: 0.1385  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.07136  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:52:45] d2.utils.events INFO:  eta: 1:03:28  iter: 12659  total_loss: 0.3955  loss_cls: 0.1087  loss_box_reg: 0.1583  loss_rpn_cls: 0.06036  loss_rpn_loc: 0.08401  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:52:59] d2.utils.events INFO:  eta: 1:03:14  iter: 12679  total_loss: 0.3047  loss_cls: 0.07434  loss_box_reg: 0.1115  loss_rpn_cls: 0.05913  loss_rpn_loc: 0.06718  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:53:12] d2.utils.events INFO:  eta: 1:03:00  iter: 12699  total_loss: 0.3384  loss_cls: 0.08027  loss_box_reg: 0.1198  loss_rpn_cls: 0.04513  loss_rpn_loc: 0.06728  time: 0.7044  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:53:26] d2.utils.events INFO:  eta: 1:02:45  iter: 12719  total_loss: 0.3598  loss_cls: 0.08847  loss_box_reg: 0.1396  loss_rpn_cls: 0.0509  loss_rpn_loc: 0.06681  time: 0.7044  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:53:41] d2.utils.events INFO:  eta: 1:02:31  iter: 12739  total_loss: 0.4208  loss_cls: 0.08047  loss_box_reg: 0.1258  loss_rpn_cls: 0.06712  loss_rpn_loc: 0.09121  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:53:56] d2.utils.events INFO:  eta: 1:02:15  iter: 12759  total_loss: 0.4535  loss_cls: 0.1386  loss_box_reg: 0.1836  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.06278  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:54:10] d2.utils.events INFO:  eta: 1:02:02  iter: 12779  total_loss: 0.4279  loss_cls: 0.07866  loss_box_reg: 0.1075  loss_rpn_cls: 0.04944  loss_rpn_loc: 0.1208  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:54:24] d2.utils.events INFO:  eta: 1:01:48  iter: 12799  total_loss: 0.3171  loss_cls: 0.06666  loss_box_reg: 0.1118  loss_rpn_cls: 0.04503  loss_rpn_loc: 0.03991  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:54:38] d2.utils.events INFO:  eta: 1:01:33  iter: 12819  total_loss: 0.3854  loss_cls: 0.0915  loss_box_reg: 0.1703  loss_rpn_cls: 0.0333  loss_rpn_loc: 0.07488  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:54:52] d2.utils.events INFO:  eta: 1:01:20  iter: 12839  total_loss: 0.3906  loss_cls: 0.09333  loss_box_reg: 0.1755  loss_rpn_cls: 0.04153  loss_rpn_loc: 0.08247  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 03:55:07] d2.utils.events INFO:  eta: 1:01:06  iter: 12859  total_loss: 0.3448  loss_cls: 0.09047  loss_box_reg: 0.1112  loss_rpn_cls: 0.0755  loss_rpn_loc: 0.07075  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:55:22] d2.utils.events INFO:  eta: 1:00:54  iter: 12879  total_loss: 0.3097  loss_cls: 0.0781  loss_box_reg: 0.1012  loss_rpn_cls: 0.03568  loss_rpn_loc: 0.07233  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:55:36] d2.utils.events INFO:  eta: 1:00:40  iter: 12899  total_loss: 0.4674  loss_cls: 0.08955  loss_box_reg: 0.1745  loss_rpn_cls: 0.06417  loss_rpn_loc: 0.1169  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:55:49] d2.utils.events INFO:  eta: 1:00:26  iter: 12919  total_loss: 0.3094  loss_cls: 0.08631  loss_box_reg: 0.1168  loss_rpn_cls: 0.04377  loss_rpn_loc: 0.06523  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:56:04] d2.utils.events INFO:  eta: 1:00:13  iter: 12939  total_loss: 0.3944  loss_cls: 0.09236  loss_box_reg: 0.1534  loss_rpn_cls: 0.04848  loss_rpn_loc: 0.08049  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:56:17] d2.utils.events INFO:  eta: 0:59:58  iter: 12959  total_loss: 0.3544  loss_cls: 0.08752  loss_box_reg: 0.1185  loss_rpn_cls: 0.04816  loss_rpn_loc: 0.07216  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:56:32] d2.utils.events INFO:  eta: 0:59:43  iter: 12979  total_loss: 0.4635  loss_cls: 0.1221  loss_box_reg: 0.1778  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.09609  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:56:46] d2.utils.events INFO:  eta: 0:59:30  iter: 12999  total_loss: 0.4089  loss_cls: 0.1018  loss_box_reg: 0.1496  loss_rpn_cls: 0.04676  loss_rpn_loc: 0.0947  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:57:00] d2.utils.events INFO:  eta: 0:59:16  iter: 13019  total_loss: 0.4031  loss_cls: 0.09544  loss_box_reg: 0.1436  loss_rpn_cls: 0.0615  loss_rpn_loc: 0.09291  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:57:14] d2.utils.events INFO:  eta: 0:59:02  iter: 13039  total_loss: 0.4508  loss_cls: 0.08774  loss_box_reg: 0.1761  loss_rpn_cls: 0.05735  loss_rpn_loc: 0.08394  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:57:28] d2.utils.events INFO:  eta: 0:58:48  iter: 13059  total_loss: 0.3097  loss_cls: 0.06758  loss_box_reg: 0.1066  loss_rpn_cls: 0.05198  loss_rpn_loc: 0.06628  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 03:57:42] d2.utils.events INFO:  eta: 0:58:33  iter: 13079  total_loss: 0.3784  loss_cls: 0.09356  loss_box_reg: 0.125  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1172  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:57:56] d2.utils.events INFO:  eta: 0:58:19  iter: 13099  total_loss: 0.4234  loss_cls: 0.09458  loss_box_reg: 0.1539  loss_rpn_cls: 0.0344  loss_rpn_loc: 0.09649  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:58:10] d2.utils.events INFO:  eta: 0:58:12  iter: 13119  total_loss: 0.363  loss_cls: 0.08607  loss_box_reg: 0.1253  loss_rpn_cls: 0.05467  loss_rpn_loc: 0.06546  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:58:24] d2.utils.events INFO:  eta: 0:57:59  iter: 13139  total_loss: 0.3  loss_cls: 0.05891  loss_box_reg: 0.0976  loss_rpn_cls: 0.04958  loss_rpn_loc: 0.07868  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 03:58:39] d2.utils.events INFO:  eta: 0:57:40  iter: 13159  total_loss: 0.3216  loss_cls: 0.08641  loss_box_reg: 0.1224  loss_rpn_cls: 0.04517  loss_rpn_loc: 0.06033  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:58:53] d2.utils.events INFO:  eta: 0:57:28  iter: 13179  total_loss: 0.5716  loss_cls: 0.159  loss_box_reg: 0.1635  loss_rpn_cls: 0.06062  loss_rpn_loc: 0.1039  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:59:08] d2.utils.events INFO:  eta: 0:57:16  iter: 13199  total_loss: 0.3779  loss_cls: 0.1064  loss_box_reg: 0.1674  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.06788  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:59:22] d2.utils.events INFO:  eta: 0:57:04  iter: 13219  total_loss: 0.2974  loss_cls: 0.08304  loss_box_reg: 0.09456  loss_rpn_cls: 0.04943  loss_rpn_loc: 0.06007  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 03:59:36] d2.utils.events INFO:  eta: 0:56:50  iter: 13239  total_loss: 0.3425  loss_cls: 0.08479  loss_box_reg: 0.1279  loss_rpn_cls: 0.04643  loss_rpn_loc: 0.06876  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 03:59:49] d2.utils.events INFO:  eta: 0:56:28  iter: 13259  total_loss: 0.2971  loss_cls: 0.074  loss_box_reg: 0.1111  loss_rpn_cls: 0.04029  loss_rpn_loc: 0.089  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:00:04] d2.utils.events INFO:  eta: 0:56:16  iter: 13279  total_loss: 0.4639  loss_cls: 0.1106  loss_box_reg: 0.1063  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.1085  time: 0.7046  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:00:18] d2.utils.events INFO:  eta: 0:56:03  iter: 13299  total_loss: 0.3592  loss_cls: 0.07727  loss_box_reg: 0.1358  loss_rpn_cls: 0.05068  loss_rpn_loc: 0.05688  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:00:32] d2.utils.events INFO:  eta: 0:55:49  iter: 13319  total_loss: 0.374  loss_cls: 0.0979  loss_box_reg: 0.1447  loss_rpn_cls: 0.04606  loss_rpn_loc: 0.08408  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:00:46] d2.utils.events INFO:  eta: 0:55:33  iter: 13339  total_loss: 0.3348  loss_cls: 0.07612  loss_box_reg: 0.1159  loss_rpn_cls: 0.04901  loss_rpn_loc: 0.05057  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:01:01] d2.utils.events INFO:  eta: 0:55:20  iter: 13359  total_loss: 0.3422  loss_cls: 0.06459  loss_box_reg: 0.0958  loss_rpn_cls: 0.04177  loss_rpn_loc: 0.07204  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:01:14] d2.utils.events INFO:  eta: 0:55:06  iter: 13379  total_loss: 0.406  loss_cls: 0.08267  loss_box_reg: 0.1602  loss_rpn_cls: 0.04469  loss_rpn_loc: 0.1117  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:01:28] d2.utils.events INFO:  eta: 0:54:50  iter: 13399  total_loss: 0.4802  loss_cls: 0.1121  loss_box_reg: 0.1695  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.07909  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:01:42] d2.utils.events INFO:  eta: 0:54:38  iter: 13419  total_loss: 0.429  loss_cls: 0.1008  loss_box_reg: 0.1899  loss_rpn_cls: 0.05163  loss_rpn_loc: 0.06867  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:01:55] d2.utils.events INFO:  eta: 0:54:28  iter: 13439  total_loss: 0.3611  loss_cls: 0.06668  loss_box_reg: 0.1266  loss_rpn_cls: 0.06369  loss_rpn_loc: 0.06473  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:02:09] d2.utils.events INFO:  eta: 0:54:05  iter: 13459  total_loss: 0.3051  loss_cls: 0.06314  loss_box_reg: 0.09864  loss_rpn_cls: 0.03501  loss_rpn_loc: 0.06068  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:02:24] d2.utils.events INFO:  eta: 0:53:59  iter: 13479  total_loss: 0.3466  loss_cls: 0.08109  loss_box_reg: 0.1332  loss_rpn_cls: 0.05604  loss_rpn_loc: 0.1061  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:02:38] d2.utils.events INFO:  eta: 0:53:45  iter: 13499  total_loss: 0.3949  loss_cls: 0.1239  loss_box_reg: 0.1797  loss_rpn_cls: 0.05081  loss_rpn_loc: 0.06873  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:02:52] d2.utils.events INFO:  eta: 0:53:32  iter: 13519  total_loss: 0.356  loss_cls: 0.09648  loss_box_reg: 0.1354  loss_rpn_cls: 0.05785  loss_rpn_loc: 0.07448  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:03:06] d2.utils.events INFO:  eta: 0:53:21  iter: 13539  total_loss: 0.4035  loss_cls: 0.1137  loss_box_reg: 0.162  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.06381  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:03:20] d2.utils.events INFO:  eta: 0:53:04  iter: 13559  total_loss: 0.3824  loss_cls: 0.09588  loss_box_reg: 0.1324  loss_rpn_cls: 0.04975  loss_rpn_loc: 0.0878  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:03:35] d2.utils.events INFO:  eta: 0:52:48  iter: 13579  total_loss: 0.3958  loss_cls: 0.09104  loss_box_reg: 0.1292  loss_rpn_cls: 0.0518  loss_rpn_loc: 0.07968  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:03:49] d2.utils.events INFO:  eta: 0:52:30  iter: 13599  total_loss: 0.4815  loss_cls: 0.1328  loss_box_reg: 0.1777  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.07862  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:04:03] d2.utils.events INFO:  eta: 0:52:17  iter: 13619  total_loss: 0.3625  loss_cls: 0.103  loss_box_reg: 0.1271  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.05891  time: 0.7044  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:04:16] d2.utils.events INFO:  eta: 0:52:02  iter: 13639  total_loss: 0.3686  loss_cls: 0.09379  loss_box_reg: 0.1489  loss_rpn_cls: 0.04944  loss_rpn_loc: 0.05449  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:04:31] d2.utils.events INFO:  eta: 0:51:49  iter: 13659  total_loss: 0.4187  loss_cls: 0.1072  loss_box_reg: 0.1677  loss_rpn_cls: 0.04344  loss_rpn_loc: 0.09689  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:04:46] d2.utils.events INFO:  eta: 0:51:38  iter: 13679  total_loss: 0.3499  loss_cls: 0.0721  loss_box_reg: 0.1281  loss_rpn_cls: 0.03658  loss_rpn_loc: 0.08498  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:05:00] d2.utils.events INFO:  eta: 0:51:28  iter: 13699  total_loss: 0.3481  loss_cls: 0.0858  loss_box_reg: 0.1207  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.06199  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:05:14] d2.utils.events INFO:  eta: 0:51:15  iter: 13719  total_loss: 0.3303  loss_cls: 0.07359  loss_box_reg: 0.1249  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.05261  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:05:28] d2.utils.events INFO:  eta: 0:51:00  iter: 13739  total_loss: 0.3639  loss_cls: 0.1021  loss_box_reg: 0.1324  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.08486  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:05:42] d2.utils.events INFO:  eta: 0:50:38  iter: 13759  total_loss: 0.3218  loss_cls: 0.09479  loss_box_reg: 0.1273  loss_rpn_cls: 0.04349  loss_rpn_loc: 0.0797  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:05:56] d2.utils.events INFO:  eta: 0:50:20  iter: 13779  total_loss: 0.5292  loss_cls: 0.1258  loss_box_reg: 0.2178  loss_rpn_cls: 0.06311  loss_rpn_loc: 0.09851  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:06:10] d2.utils.events INFO:  eta: 0:50:07  iter: 13799  total_loss: 0.4198  loss_cls: 0.103  loss_box_reg: 0.1537  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.08684  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:06:24] d2.utils.events INFO:  eta: 0:49:53  iter: 13819  total_loss: 0.3794  loss_cls: 0.1002  loss_box_reg: 0.1667  loss_rpn_cls: 0.03386  loss_rpn_loc: 0.0844  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:06:38] d2.utils.events INFO:  eta: 0:49:36  iter: 13839  total_loss: 0.3497  loss_cls: 0.09801  loss_box_reg: 0.1256  loss_rpn_cls: 0.05889  loss_rpn_loc: 0.08393  time: 0.7044  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:06:52] d2.utils.events INFO:  eta: 0:49:17  iter: 13859  total_loss: 0.375  loss_cls: 0.08792  loss_box_reg: 0.1384  loss_rpn_cls: 0.0447  loss_rpn_loc: 0.07119  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:07:07] d2.utils.events INFO:  eta: 0:49:04  iter: 13879  total_loss: 0.3852  loss_cls: 0.09345  loss_box_reg: 0.1372  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.08245  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:07:21] d2.utils.events INFO:  eta: 0:48:49  iter: 13899  total_loss: 0.3968  loss_cls: 0.09074  loss_box_reg: 0.13  loss_rpn_cls: 0.05752  loss_rpn_loc: 0.07334  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:07:34] d2.utils.events INFO:  eta: 0:48:33  iter: 13919  total_loss: 0.4134  loss_cls: 0.08504  loss_box_reg: 0.1105  loss_rpn_cls: 0.07203  loss_rpn_loc: 0.1126  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:07:48] d2.utils.events INFO:  eta: 0:48:16  iter: 13939  total_loss: 0.4312  loss_cls: 0.1115  loss_box_reg: 0.1773  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.09369  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:08:03] d2.utils.events INFO:  eta: 0:48:06  iter: 13959  total_loss: 0.4793  loss_cls: 0.1147  loss_box_reg: 0.1992  loss_rpn_cls: 0.05874  loss_rpn_loc: 0.09761  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:08:17] d2.utils.events INFO:  eta: 0:47:52  iter: 13979  total_loss: 0.4426  loss_cls: 0.1321  loss_box_reg: 0.1835  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.06589  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:08:31] d2.utils.events INFO:  eta: 0:47:35  iter: 13999  total_loss: 0.3016  loss_cls: 0.07549  loss_box_reg: 0.09892  loss_rpn_cls: 0.03931  loss_rpn_loc: 0.06859  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:08:46] d2.utils.events INFO:  eta: 0:47:21  iter: 14019  total_loss: 0.3542  loss_cls: 0.08231  loss_box_reg: 0.1482  loss_rpn_cls: 0.04277  loss_rpn_loc: 0.05531  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:08:59] d2.utils.events INFO:  eta: 0:47:06  iter: 14039  total_loss: 0.308  loss_cls: 0.07798  loss_box_reg: 0.09819  loss_rpn_cls: 0.05079  loss_rpn_loc: 0.05224  time: 0.7044  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:09:13] d2.utils.events INFO:  eta: 0:46:52  iter: 14059  total_loss: 0.3703  loss_cls: 0.08512  loss_box_reg: 0.1383  loss_rpn_cls: 0.04823  loss_rpn_loc: 0.07632  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:09:27] d2.utils.events INFO:  eta: 0:46:38  iter: 14079  total_loss: 0.3097  loss_cls: 0.08206  loss_box_reg: 0.1062  loss_rpn_cls: 0.0418  loss_rpn_loc: 0.1025  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:09:41] d2.utils.events INFO:  eta: 0:46:30  iter: 14099  total_loss: 0.322  loss_cls: 0.05799  loss_box_reg: 0.1185  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.08464  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:09:56] d2.utils.events INFO:  eta: 0:46:16  iter: 14119  total_loss: 0.3088  loss_cls: 0.07469  loss_box_reg: 0.1368  loss_rpn_cls: 0.03852  loss_rpn_loc: 0.07818  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:10:09] d2.utils.events INFO:  eta: 0:45:57  iter: 14139  total_loss: 0.3294  loss_cls: 0.09248  loss_box_reg: 0.1356  loss_rpn_cls: 0.04309  loss_rpn_loc: 0.04462  time: 0.7044  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:10:24] d2.utils.events INFO:  eta: 0:45:47  iter: 14159  total_loss: 0.4344  loss_cls: 0.09594  loss_box_reg: 0.1546  loss_rpn_cls: 0.05325  loss_rpn_loc: 0.07077  time: 0.7044  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:10:38] d2.utils.events INFO:  eta: 0:45:28  iter: 14179  total_loss: 0.4039  loss_cls: 0.09158  loss_box_reg: 0.1833  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.0788  time: 0.7044  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:10:53] d2.utils.events INFO:  eta: 0:45:13  iter: 14199  total_loss: 0.4921  loss_cls: 0.1066  loss_box_reg: 0.164  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.101  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:11:07] d2.utils.events INFO:  eta: 0:45:00  iter: 14219  total_loss: 0.4115  loss_cls: 0.08758  loss_box_reg: 0.1611  loss_rpn_cls: 0.06159  loss_rpn_loc: 0.08533  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:11:22] d2.utils.events INFO:  eta: 0:44:49  iter: 14239  total_loss: 0.3968  loss_cls: 0.09222  loss_box_reg: 0.1235  loss_rpn_cls: 0.04209  loss_rpn_loc: 0.0718  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:11:35] d2.utils.events INFO:  eta: 0:44:36  iter: 14259  total_loss: 0.3359  loss_cls: 0.06822  loss_box_reg: 0.1442  loss_rpn_cls: 0.03839  loss_rpn_loc: 0.07507  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:11:51] d2.utils.events INFO:  eta: 0:44:29  iter: 14279  total_loss: 0.3188  loss_cls: 0.07074  loss_box_reg: 0.1093  loss_rpn_cls: 0.03948  loss_rpn_loc: 0.08676  time: 0.7046  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:12:05] d2.utils.events INFO:  eta: 0:44:11  iter: 14299  total_loss: 0.3651  loss_cls: 0.09966  loss_box_reg: 0.1454  loss_rpn_cls: 0.03906  loss_rpn_loc: 0.05567  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:12:20] d2.utils.events INFO:  eta: 0:44:04  iter: 14319  total_loss: 0.3521  loss_cls: 0.09463  loss_box_reg: 0.1225  loss_rpn_cls: 0.03866  loss_rpn_loc: 0.06724  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:12:35] d2.utils.events INFO:  eta: 0:43:55  iter: 14339  total_loss: 0.4346  loss_cls: 0.1224  loss_box_reg: 0.1643  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.0661  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:12:49] d2.utils.events INFO:  eta: 0:43:40  iter: 14359  total_loss: 0.3882  loss_cls: 0.1058  loss_box_reg: 0.1461  loss_rpn_cls: 0.05769  loss_rpn_loc: 0.07076  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:13:03] d2.utils.events INFO:  eta: 0:43:29  iter: 14379  total_loss: 0.599  loss_cls: 0.1434  loss_box_reg: 0.2406  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1116  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:13:17] d2.utils.events INFO:  eta: 0:43:15  iter: 14399  total_loss: 0.3199  loss_cls: 0.08804  loss_box_reg: 0.1187  loss_rpn_cls: 0.03041  loss_rpn_loc: 0.06992  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:13:30] d2.utils.events INFO:  eta: 0:43:00  iter: 14419  total_loss: 0.3959  loss_cls: 0.09379  loss_box_reg: 0.1618  loss_rpn_cls: 0.05033  loss_rpn_loc: 0.07011  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:13:45] d2.utils.events INFO:  eta: 0:42:48  iter: 14439  total_loss: 0.4114  loss_cls: 0.1208  loss_box_reg: 0.1969  loss_rpn_cls: 0.04682  loss_rpn_loc: 0.0751  time: 0.7047  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:13:59] d2.utils.events INFO:  eta: 0:42:35  iter: 14459  total_loss: 0.4042  loss_cls: 0.08814  loss_box_reg: 0.1369  loss_rpn_cls: 0.04639  loss_rpn_loc: 0.04902  time: 0.7046  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:14:12] d2.utils.events INFO:  eta: 0:42:15  iter: 14479  total_loss: 0.2702  loss_cls: 0.06193  loss_box_reg: 0.09647  loss_rpn_cls: 0.03591  loss_rpn_loc: 0.0677  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:14:25] d2.utils.events INFO:  eta: 0:41:56  iter: 14499  total_loss: 0.3118  loss_cls: 0.08441  loss_box_reg: 0.1523  loss_rpn_cls: 0.05051  loss_rpn_loc: 0.05861  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:14:40] d2.utils.events INFO:  eta: 0:41:38  iter: 14519  total_loss: 0.2922  loss_cls: 0.05832  loss_box_reg: 0.1091  loss_rpn_cls: 0.04956  loss_rpn_loc: 0.06777  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:14:54] d2.utils.events INFO:  eta: 0:41:27  iter: 14539  total_loss: 0.4562  loss_cls: 0.1142  loss_box_reg: 0.1969  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.07257  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:15:08] d2.utils.events INFO:  eta: 0:41:15  iter: 14559  total_loss: 0.2636  loss_cls: 0.07489  loss_box_reg: 0.1134  loss_rpn_cls: 0.02445  loss_rpn_loc: 0.05425  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:15:23] d2.utils.events INFO:  eta: 0:41:00  iter: 14579  total_loss: 0.3994  loss_cls: 0.1231  loss_box_reg: 0.1551  loss_rpn_cls: 0.05278  loss_rpn_loc: 0.08893  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:15:36] d2.utils.events INFO:  eta: 0:40:46  iter: 14599  total_loss: 0.3834  loss_cls: 0.103  loss_box_reg: 0.125  loss_rpn_cls: 0.04822  loss_rpn_loc: 0.0781  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:15:50] d2.utils.events INFO:  eta: 0:40:32  iter: 14619  total_loss: 0.4234  loss_cls: 0.1009  loss_box_reg: 0.1533  loss_rpn_cls: 0.04325  loss_rpn_loc: 0.0832  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:16:04] d2.utils.events INFO:  eta: 0:40:17  iter: 14639  total_loss: 0.3605  loss_cls: 0.08452  loss_box_reg: 0.1251  loss_rpn_cls: 0.03102  loss_rpn_loc: 0.07951  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:16:19] d2.utils.events INFO:  eta: 0:40:00  iter: 14659  total_loss: 0.3919  loss_cls: 0.09938  loss_box_reg: 0.1611  loss_rpn_cls: 0.0442  loss_rpn_loc: 0.0757  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:16:33] d2.utils.events INFO:  eta: 0:39:46  iter: 14679  total_loss: 0.3687  loss_cls: 0.08492  loss_box_reg: 0.1321  loss_rpn_cls: 0.04598  loss_rpn_loc: 0.08196  time: 0.7045  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:16:47] d2.utils.events INFO:  eta: 0:39:28  iter: 14699  total_loss: 0.3366  loss_cls: 0.08665  loss_box_reg: 0.1224  loss_rpn_cls: 0.02706  loss_rpn_loc: 0.05617  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:17:02] d2.utils.events INFO:  eta: 0:39:20  iter: 14719  total_loss: 0.4049  loss_cls: 0.09452  loss_box_reg: 0.1367  loss_rpn_cls: 0.04903  loss_rpn_loc: 0.06391  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:17:16] d2.utils.events INFO:  eta: 0:39:07  iter: 14739  total_loss: 0.423  loss_cls: 0.09512  loss_box_reg: 0.1622  loss_rpn_cls: 0.04697  loss_rpn_loc: 0.08737  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:17:30] d2.utils.events INFO:  eta: 0:38:55  iter: 14759  total_loss: 0.2763  loss_cls: 0.07904  loss_box_reg: 0.09142  loss_rpn_cls: 0.02624  loss_rpn_loc: 0.06693  time: 0.7046  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:17:44] d2.utils.events INFO:  eta: 0:38:43  iter: 14779  total_loss: 0.3984  loss_cls: 0.08676  loss_box_reg: 0.09777  loss_rpn_cls: 0.04299  loss_rpn_loc: 0.08904  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:17:59] d2.utils.events INFO:  eta: 0:38:30  iter: 14799  total_loss: 0.4539  loss_cls: 0.1075  loss_box_reg: 0.1535  loss_rpn_cls: 0.05826  loss_rpn_loc: 0.07115  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:18:12] d2.utils.events INFO:  eta: 0:38:13  iter: 14819  total_loss: 0.2833  loss_cls: 0.06761  loss_box_reg: 0.1111  loss_rpn_cls: 0.02471  loss_rpn_loc: 0.05283  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:18:28] d2.utils.events INFO:  eta: 0:38:01  iter: 14839  total_loss: 0.4086  loss_cls: 0.08157  loss_box_reg: 0.1248  loss_rpn_cls: 0.04676  loss_rpn_loc: 0.08049  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:18:42] d2.utils.events INFO:  eta: 0:37:46  iter: 14859  total_loss: 0.4535  loss_cls: 0.1041  loss_box_reg: 0.1562  loss_rpn_cls: 0.0651  loss_rpn_loc: 0.1059  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:18:56] d2.utils.events INFO:  eta: 0:37:32  iter: 14879  total_loss: 0.3697  loss_cls: 0.06311  loss_box_reg: 0.1393  loss_rpn_cls: 0.05248  loss_rpn_loc: 0.07796  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:19:10] d2.utils.events INFO:  eta: 0:37:17  iter: 14899  total_loss: 0.3615  loss_cls: 0.08156  loss_box_reg: 0.1557  loss_rpn_cls: 0.04192  loss_rpn_loc: 0.08851  time: 0.7046  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:19:25] d2.utils.events INFO:  eta: 0:37:07  iter: 14919  total_loss: 0.3896  loss_cls: 0.09096  loss_box_reg: 0.1311  loss_rpn_cls: 0.03977  loss_rpn_loc: 0.08058  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:19:39] d2.utils.events INFO:  eta: 0:36:55  iter: 14939  total_loss: 0.2703  loss_cls: 0.05869  loss_box_reg: 0.08661  loss_rpn_cls: 0.03538  loss_rpn_loc: 0.07314  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:19:53] d2.utils.events INFO:  eta: 0:36:38  iter: 14959  total_loss: 0.3577  loss_cls: 0.08215  loss_box_reg: 0.103  loss_rpn_cls: 0.05763  loss_rpn_loc: 0.08924  time: 0.7047  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:20:07] d2.utils.events INFO:  eta: 0:36:21  iter: 14979  total_loss: 0.4496  loss_cls: 0.1212  loss_box_reg: 0.173  loss_rpn_cls: 0.05115  loss_rpn_loc: 0.1009  time: 0.7047  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:20:21] d2.utils.events INFO:  eta: 0:36:08  iter: 14999  total_loss: 0.3455  loss_cls: 0.07762  loss_box_reg: 0.1091  loss_rpn_cls: 0.04198  loss_rpn_loc: 0.06028  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:20:34] d2.utils.events INFO:  eta: 0:35:52  iter: 15019  total_loss: 0.45  loss_cls: 0.09516  loss_box_reg: 0.1537  loss_rpn_cls: 0.05441  loss_rpn_loc: 0.07403  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:20:48] d2.utils.events INFO:  eta: 0:35:37  iter: 15039  total_loss: 0.3799  loss_cls: 0.08057  loss_box_reg: 0.1652  loss_rpn_cls: 0.0544  loss_rpn_loc: 0.06844  time: 0.7046  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:21:02] d2.utils.events INFO:  eta: 0:35:22  iter: 15059  total_loss: 0.314  loss_cls: 0.07796  loss_box_reg: 0.1256  loss_rpn_cls: 0.04705  loss_rpn_loc: 0.06606  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:21:17] d2.utils.events INFO:  eta: 0:35:08  iter: 15079  total_loss: 0.3675  loss_cls: 0.0814  loss_box_reg: 0.144  loss_rpn_cls: 0.03765  loss_rpn_loc: 0.05177  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:21:31] d2.utils.events INFO:  eta: 0:34:53  iter: 15099  total_loss: 0.386  loss_cls: 0.08799  loss_box_reg: 0.108  loss_rpn_cls: 0.05533  loss_rpn_loc: 0.07566  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:21:44] d2.utils.events INFO:  eta: 0:34:34  iter: 15119  total_loss: 0.3651  loss_cls: 0.06948  loss_box_reg: 0.1103  loss_rpn_cls: 0.04326  loss_rpn_loc: 0.0945  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:21:59] d2.utils.events INFO:  eta: 0:34:24  iter: 15139  total_loss: 0.4245  loss_cls: 0.09966  loss_box_reg: 0.205  loss_rpn_cls: 0.04512  loss_rpn_loc: 0.07266  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:22:13] d2.utils.events INFO:  eta: 0:34:09  iter: 15159  total_loss: 0.2958  loss_cls: 0.08502  loss_box_reg: 0.1328  loss_rpn_cls: 0.04009  loss_rpn_loc: 0.06164  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:22:28] d2.utils.events INFO:  eta: 0:33:58  iter: 15179  total_loss: 0.2822  loss_cls: 0.07633  loss_box_reg: 0.1361  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.05827  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:22:42] d2.utils.events INFO:  eta: 0:33:41  iter: 15199  total_loss: 0.4286  loss_cls: 0.1155  loss_box_reg: 0.1518  loss_rpn_cls: 0.04952  loss_rpn_loc: 0.08447  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:22:56] d2.utils.events INFO:  eta: 0:33:25  iter: 15219  total_loss: 0.434  loss_cls: 0.07732  loss_box_reg: 0.1374  loss_rpn_cls: 0.05379  loss_rpn_loc: 0.1028  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:23:11] d2.utils.events INFO:  eta: 0:33:11  iter: 15239  total_loss: 0.3073  loss_cls: 0.06507  loss_box_reg: 0.1102  loss_rpn_cls: 0.02909  loss_rpn_loc: 0.07294  time: 0.7047  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:23:25] d2.utils.events INFO:  eta: 0:32:58  iter: 15259  total_loss: 0.3448  loss_cls: 0.06604  loss_box_reg: 0.1242  loss_rpn_cls: 0.04457  loss_rpn_loc: 0.05594  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:23:39] d2.utils.events INFO:  eta: 0:32:39  iter: 15279  total_loss: 0.3661  loss_cls: 0.07992  loss_box_reg: 0.1351  loss_rpn_cls: 0.04805  loss_rpn_loc: 0.06621  time: 0.7047  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:23:53] d2.utils.events INFO:  eta: 0:32:23  iter: 15299  total_loss: 0.374  loss_cls: 0.07141  loss_box_reg: 0.1446  loss_rpn_cls: 0.04236  loss_rpn_loc: 0.07691  time: 0.7047  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:24:07] d2.utils.events INFO:  eta: 0:32:06  iter: 15319  total_loss: 0.3666  loss_cls: 0.07539  loss_box_reg: 0.1516  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.04953  time: 0.7047  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:24:21] d2.utils.events INFO:  eta: 0:31:47  iter: 15339  total_loss: 0.3124  loss_cls: 0.08329  loss_box_reg: 0.1372  loss_rpn_cls: 0.03934  loss_rpn_loc: 0.07024  time: 0.7047  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:24:34] d2.utils.events INFO:  eta: 0:31:29  iter: 15359  total_loss: 0.3737  loss_cls: 0.07619  loss_box_reg: 0.1076  loss_rpn_cls: 0.05282  loss_rpn_loc: 0.08075  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:24:48] d2.utils.events INFO:  eta: 0:31:13  iter: 15379  total_loss: 0.2824  loss_cls: 0.0601  loss_box_reg: 0.1003  loss_rpn_cls: 0.05806  loss_rpn_loc: 0.05386  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:25:02] d2.utils.events INFO:  eta: 0:30:58  iter: 15399  total_loss: 0.3292  loss_cls: 0.08011  loss_box_reg: 0.1455  loss_rpn_cls: 0.04892  loss_rpn_loc: 0.07398  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:25:15] d2.utils.events INFO:  eta: 0:30:43  iter: 15419  total_loss: 0.3141  loss_cls: 0.07271  loss_box_reg: 0.1363  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.06942  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:25:30] d2.utils.events INFO:  eta: 0:30:28  iter: 15439  total_loss: 0.5384  loss_cls: 0.1062  loss_box_reg: 0.1885  loss_rpn_cls: 0.0348  loss_rpn_loc: 0.09241  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:25:45] d2.utils.events INFO:  eta: 0:30:16  iter: 15459  total_loss: 0.3993  loss_cls: 0.08551  loss_box_reg: 0.1163  loss_rpn_cls: 0.06352  loss_rpn_loc: 0.06137  time: 0.7046  data_time: 0.0025  lr: 2e-05  max_mem: 15387M
[01/30 04:25:59] d2.utils.events INFO:  eta: 0:30:03  iter: 15479  total_loss: 0.3303  loss_cls: 0.08271  loss_box_reg: 0.1367  loss_rpn_cls: 0.04614  loss_rpn_loc: 0.06189  time: 0.7046  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:26:13] d2.utils.events INFO:  eta: 0:29:51  iter: 15499  total_loss: 0.4907  loss_cls: 0.1242  loss_box_reg: 0.2139  loss_rpn_cls: 0.0473  loss_rpn_loc: 0.07887  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:26:26] d2.utils.events INFO:  eta: 0:29:38  iter: 15519  total_loss: 0.351  loss_cls: 0.07751  loss_box_reg: 0.15  loss_rpn_cls: 0.03719  loss_rpn_loc: 0.09193  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:26:41] d2.utils.events INFO:  eta: 0:29:24  iter: 15539  total_loss: 0.3416  loss_cls: 0.06152  loss_box_reg: 0.1075  loss_rpn_cls: 0.0378  loss_rpn_loc: 0.08032  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:26:56] d2.utils.events INFO:  eta: 0:29:11  iter: 15559  total_loss: 0.3253  loss_cls: 0.07389  loss_box_reg: 0.1166  loss_rpn_cls: 0.04337  loss_rpn_loc: 0.1018  time: 0.7046  data_time: 0.0026  lr: 2e-05  max_mem: 15387M
[01/30 04:27:10] d2.utils.events INFO:  eta: 0:28:56  iter: 15579  total_loss: 0.3918  loss_cls: 0.07864  loss_box_reg: 0.1306  loss_rpn_cls: 0.06064  loss_rpn_loc: 0.1072  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:27:24] d2.utils.events INFO:  eta: 0:28:43  iter: 15599  total_loss: 0.2369  loss_cls: 0.05231  loss_box_reg: 0.1005  loss_rpn_cls: 0.02797  loss_rpn_loc: 0.07003  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:27:38] d2.utils.events INFO:  eta: 0:28:29  iter: 15619  total_loss: 0.2874  loss_cls: 0.05168  loss_box_reg: 0.09661  loss_rpn_cls: 0.04115  loss_rpn_loc: 0.06334  time: 0.7046  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:27:51] d2.utils.events INFO:  eta: 0:28:14  iter: 15639  total_loss: 0.2791  loss_cls: 0.05879  loss_box_reg: 0.1136  loss_rpn_cls: 0.03582  loss_rpn_loc: 0.05797  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:28:05] d2.utils.events INFO:  eta: 0:27:59  iter: 15659  total_loss: 0.3765  loss_cls: 0.09413  loss_box_reg: 0.1409  loss_rpn_cls: 0.0429  loss_rpn_loc: 0.08593  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:28:19] d2.utils.events INFO:  eta: 0:27:44  iter: 15679  total_loss: 0.408  loss_cls: 0.09101  loss_box_reg: 0.139  loss_rpn_cls: 0.04991  loss_rpn_loc: 0.08587  time: 0.7045  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:28:34] d2.utils.events INFO:  eta: 0:27:29  iter: 15699  total_loss: 0.3306  loss_cls: 0.06496  loss_box_reg: 0.1142  loss_rpn_cls: 0.0494  loss_rpn_loc: 0.08091  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:28:47] d2.utils.events INFO:  eta: 0:27:12  iter: 15719  total_loss: 0.3393  loss_cls: 0.07374  loss_box_reg: 0.1117  loss_rpn_cls: 0.03471  loss_rpn_loc: 0.07693  time: 0.7045  data_time: 0.0021  lr: 2e-05  max_mem: 15387M
[01/30 04:29:02] d2.utils.events INFO:  eta: 0:26:56  iter: 15739  total_loss: 0.4077  loss_cls: 0.1104  loss_box_reg: 0.1677  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.06191  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:29:17] d2.utils.events INFO:  eta: 0:26:44  iter: 15759  total_loss: 0.3767  loss_cls: 0.07717  loss_box_reg: 0.1553  loss_rpn_cls: 0.05437  loss_rpn_loc: 0.1044  time: 0.7046  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:29:30] d2.utils.events INFO:  eta: 0:26:27  iter: 15779  total_loss: 0.3521  loss_cls: 0.09287  loss_box_reg: 0.131  loss_rpn_cls: 0.04183  loss_rpn_loc: 0.05197  time: 0.7045  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:29:44] d2.utils.events INFO:  eta: 0:26:11  iter: 15799  total_loss: 0.2996  loss_cls: 0.06724  loss_box_reg: 0.09284  loss_rpn_cls: 0.0384  loss_rpn_loc: 0.06515  time: 0.7045  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:29:57] d2.utils.events INFO:  eta: 0:25:58  iter: 15819  total_loss: 0.3061  loss_cls: 0.06644  loss_box_reg: 0.1233  loss_rpn_cls: 0.02953  loss_rpn_loc: 0.05248  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:30:11] d2.utils.events INFO:  eta: 0:25:42  iter: 15839  total_loss: 0.3539  loss_cls: 0.0742  loss_box_reg: 0.1257  loss_rpn_cls: 0.03618  loss_rpn_loc: 0.08431  time: 0.7044  data_time: 0.0024  lr: 2e-05  max_mem: 15387M
[01/30 04:30:25] d2.utils.events INFO:  eta: 0:25:28  iter: 15859  total_loss: 0.323  loss_cls: 0.06287  loss_box_reg: 0.1221  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.08351  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:30:38] d2.utils.events INFO:  eta: 0:25:11  iter: 15879  total_loss: 0.3948  loss_cls: 0.07446  loss_box_reg: 0.1706  loss_rpn_cls: 0.07083  loss_rpn_loc: 0.07567  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:30:53] d2.utils.events INFO:  eta: 0:24:58  iter: 15899  total_loss: 0.3932  loss_cls: 0.08593  loss_box_reg: 0.1495  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.1104  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:31:06] d2.utils.events INFO:  eta: 0:24:42  iter: 15919  total_loss: 0.3813  loss_cls: 0.07413  loss_box_reg: 0.1187  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.04722  time: 0.7043  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:31:21] d2.utils.events INFO:  eta: 0:24:30  iter: 15939  total_loss: 0.2958  loss_cls: 0.07708  loss_box_reg: 0.1405  loss_rpn_cls: 0.02263  loss_rpn_loc: 0.05009  time: 0.7044  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:31:34] d2.utils.events INFO:  eta: 0:24:14  iter: 15959  total_loss: 0.3406  loss_cls: 0.07112  loss_box_reg: 0.1236  loss_rpn_cls: 0.03474  loss_rpn_loc: 0.08317  time: 0.7043  data_time: 0.0022  lr: 2e-05  max_mem: 15387M
[01/30 04:31:49] d2.utils.events INFO:  eta: 0:24:01  iter: 15979  total_loss: 0.3539  loss_cls: 0.09268  loss_box_reg: 0.1239  loss_rpn_cls: 0.04333  loss_rpn_loc: 0.08495  time: 0.7043  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:32:03] d2.utils.events INFO:  eta: 0:23:50  iter: 15999  total_loss: 0.4284  loss_cls: 0.102  loss_box_reg: 0.1188  loss_rpn_cls: 0.05041  loss_rpn_loc: 0.07974  time: 0.7044  data_time: 0.0023  lr: 2e-05  max_mem: 15387M
[01/30 04:32:18] d2.utils.events INFO:  eta: 0:23:37  iter: 16019  total_loss: 0.3788  loss_cls: 0.08503  loss_box_reg: 0.1537  loss_rpn_cls: 0.0431  loss_rpn_loc: 0.08379  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:32:32] d2.utils.events INFO:  eta: 0:23:23  iter: 16039  total_loss: 0.3142  loss_cls: 0.07356  loss_box_reg: 0.1259  loss_rpn_cls: 0.03251  loss_rpn_loc: 0.04005  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:32:46] d2.utils.events INFO:  eta: 0:23:09  iter: 16059  total_loss: 0.4491  loss_cls: 0.08582  loss_box_reg: 0.1354  loss_rpn_cls: 0.0424  loss_rpn_loc: 0.1036  time: 0.7044  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:33:00] d2.utils.events INFO:  eta: 0:22:55  iter: 16079  total_loss: 0.303  loss_cls: 0.0752  loss_box_reg: 0.104  loss_rpn_cls: 0.0367  loss_rpn_loc: 0.06131  time: 0.7044  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:33:15] d2.utils.events INFO:  eta: 0:22:40  iter: 16099  total_loss: 0.3236  loss_cls: 0.06849  loss_box_reg: 0.1205  loss_rpn_cls: 0.03185  loss_rpn_loc: 0.07941  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:33:28] d2.utils.events INFO:  eta: 0:22:26  iter: 16119  total_loss: 0.2846  loss_cls: 0.0686  loss_box_reg: 0.09108  loss_rpn_cls: 0.03846  loss_rpn_loc: 0.06706  time: 0.7044  data_time: 0.0021  lr: 2e-06  max_mem: 15387M
[01/30 04:33:42] d2.utils.events INFO:  eta: 0:22:09  iter: 16139  total_loss: 0.3404  loss_cls: 0.08597  loss_box_reg: 0.1276  loss_rpn_cls: 0.02801  loss_rpn_loc: 0.06399  time: 0.7043  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:33:56] d2.utils.events INFO:  eta: 0:21:54  iter: 16159  total_loss: 0.3173  loss_cls: 0.06328  loss_box_reg: 0.1154  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.09687  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:34:10] d2.utils.events INFO:  eta: 0:21:38  iter: 16179  total_loss: 0.3937  loss_cls: 0.07909  loss_box_reg: 0.1528  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.07117  time: 0.7043  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:34:24] d2.utils.events INFO:  eta: 0:21:23  iter: 16199  total_loss: 0.2762  loss_cls: 0.08459  loss_box_reg: 0.12  loss_rpn_cls: 0.04099  loss_rpn_loc: 0.05584  time: 0.7043  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:34:37] d2.utils.events INFO:  eta: 0:21:09  iter: 16219  total_loss: 0.3624  loss_cls: 0.08603  loss_box_reg: 0.1438  loss_rpn_cls: 0.03864  loss_rpn_loc: 0.07941  time: 0.7043  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:34:51] d2.utils.events INFO:  eta: 0:20:54  iter: 16239  total_loss: 0.3901  loss_cls: 0.07859  loss_box_reg: 0.1622  loss_rpn_cls: 0.05131  loss_rpn_loc: 0.06346  time: 0.7043  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:35:05] d2.utils.events INFO:  eta: 0:20:38  iter: 16259  total_loss: 0.3639  loss_cls: 0.07997  loss_box_reg: 0.1552  loss_rpn_cls: 0.0231  loss_rpn_loc: 0.09646  time: 0.7042  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:35:19] d2.utils.events INFO:  eta: 0:20:25  iter: 16279  total_loss: 0.4342  loss_cls: 0.1226  loss_box_reg: 0.1321  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.09304  time: 0.7043  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:35:34] d2.utils.events INFO:  eta: 0:20:12  iter: 16299  total_loss: 0.3283  loss_cls: 0.08957  loss_box_reg: 0.1658  loss_rpn_cls: 0.04726  loss_rpn_loc: 0.04925  time: 0.7043  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:35:48] d2.utils.events INFO:  eta: 0:19:58  iter: 16319  total_loss: 0.3445  loss_cls: 0.07463  loss_box_reg: 0.1492  loss_rpn_cls: 0.03957  loss_rpn_loc: 0.07088  time: 0.7043  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:36:02] d2.utils.events INFO:  eta: 0:19:43  iter: 16339  total_loss: 0.2939  loss_cls: 0.07854  loss_box_reg: 0.1435  loss_rpn_cls: 0.0323  loss_rpn_loc: 0.06049  time: 0.7043  data_time: 0.0021  lr: 2e-06  max_mem: 15387M
[01/30 04:36:16] d2.utils.events INFO:  eta: 0:19:29  iter: 16359  total_loss: 0.3132  loss_cls: 0.05661  loss_box_reg: 0.1068  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.04879  time: 0.7043  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:36:31] d2.utils.events INFO:  eta: 0:19:20  iter: 16379  total_loss: 0.3767  loss_cls: 0.06164  loss_box_reg: 0.09885  loss_rpn_cls: 0.03273  loss_rpn_loc: 0.07299  time: 0.7043  data_time: 0.0026  lr: 2e-06  max_mem: 15387M
[01/30 04:36:46] d2.utils.events INFO:  eta: 0:19:06  iter: 16399  total_loss: 0.3218  loss_cls: 0.06257  loss_box_reg: 0.103  loss_rpn_cls: 0.03341  loss_rpn_loc: 0.1061  time: 0.7044  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:37:01] d2.utils.events INFO:  eta: 0:18:54  iter: 16419  total_loss: 0.3141  loss_cls: 0.08188  loss_box_reg: 0.1342  loss_rpn_cls: 0.04048  loss_rpn_loc: 0.07046  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:37:15] d2.utils.events INFO:  eta: 0:18:39  iter: 16439  total_loss: 0.2521  loss_cls: 0.0747  loss_box_reg: 0.1064  loss_rpn_cls: 0.03389  loss_rpn_loc: 0.05581  time: 0.7044  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:37:29] d2.utils.events INFO:  eta: 0:18:24  iter: 16459  total_loss: 0.4458  loss_cls: 0.1099  loss_box_reg: 0.1759  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.1096  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:37:43] d2.utils.events INFO:  eta: 0:18:10  iter: 16479  total_loss: 0.3633  loss_cls: 0.082  loss_box_reg: 0.1518  loss_rpn_cls: 0.03867  loss_rpn_loc: 0.05977  time: 0.7044  data_time: 0.0021  lr: 2e-06  max_mem: 15387M
[01/30 04:37:58] d2.utils.events INFO:  eta: 0:17:56  iter: 16499  total_loss: 0.3202  loss_cls: 0.0512  loss_box_reg: 0.08759  loss_rpn_cls: 0.02906  loss_rpn_loc: 0.06781  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:38:12] d2.utils.events INFO:  eta: 0:17:42  iter: 16519  total_loss: 0.3504  loss_cls: 0.08377  loss_box_reg: 0.1529  loss_rpn_cls: 0.03279  loss_rpn_loc: 0.06686  time: 0.7044  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:38:27] d2.utils.events INFO:  eta: 0:17:29  iter: 16539  total_loss: 0.3768  loss_cls: 0.09126  loss_box_reg: 0.1675  loss_rpn_cls: 0.04522  loss_rpn_loc: 0.08182  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:38:41] d2.utils.events INFO:  eta: 0:17:13  iter: 16559  total_loss: 0.3125  loss_cls: 0.07648  loss_box_reg: 0.1433  loss_rpn_cls: 0.04345  loss_rpn_loc: 0.06101  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:38:55] d2.utils.events INFO:  eta: 0:16:59  iter: 16579  total_loss: 0.3289  loss_cls: 0.06439  loss_box_reg: 0.1128  loss_rpn_cls: 0.0394  loss_rpn_loc: 0.05351  time: 0.7045  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:39:09] d2.utils.events INFO:  eta: 0:16:45  iter: 16599  total_loss: 0.3881  loss_cls: 0.08181  loss_box_reg: 0.1471  loss_rpn_cls: 0.03351  loss_rpn_loc: 0.1067  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:39:23] d2.utils.events INFO:  eta: 0:16:30  iter: 16619  total_loss: 0.3019  loss_cls: 0.05887  loss_box_reg: 0.09818  loss_rpn_cls: 0.02839  loss_rpn_loc: 0.05858  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:39:37] d2.utils.events INFO:  eta: 0:16:16  iter: 16639  total_loss: 0.3218  loss_cls: 0.07787  loss_box_reg: 0.1352  loss_rpn_cls: 0.03441  loss_rpn_loc: 0.06845  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:39:52] d2.utils.events INFO:  eta: 0:16:02  iter: 16659  total_loss: 0.3394  loss_cls: 0.07596  loss_box_reg: 0.1358  loss_rpn_cls: 0.03307  loss_rpn_loc: 0.06971  time: 0.7045  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:40:06] d2.utils.events INFO:  eta: 0:15:48  iter: 16679  total_loss: 0.3014  loss_cls: 0.06819  loss_box_reg: 0.1064  loss_rpn_cls: 0.03912  loss_rpn_loc: 0.07173  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:40:20] d2.utils.events INFO:  eta: 0:15:35  iter: 16699  total_loss: 0.4266  loss_cls: 0.1185  loss_box_reg: 0.1407  loss_rpn_cls: 0.04725  loss_rpn_loc: 0.1077  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:40:35] d2.utils.events INFO:  eta: 0:15:24  iter: 16719  total_loss: 0.3031  loss_cls: 0.06912  loss_box_reg: 0.1147  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.07333  time: 0.7046  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:40:49] d2.utils.events INFO:  eta: 0:15:08  iter: 16739  total_loss: 0.3658  loss_cls: 0.07459  loss_box_reg: 0.1363  loss_rpn_cls: 0.04657  loss_rpn_loc: 0.07178  time: 0.7046  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:41:03] d2.utils.events INFO:  eta: 0:14:54  iter: 16759  total_loss: 0.2468  loss_cls: 0.05364  loss_box_reg: 0.102  loss_rpn_cls: 0.03452  loss_rpn_loc: 0.05788  time: 0.7046  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:41:17] d2.utils.events INFO:  eta: 0:14:39  iter: 16779  total_loss: 0.3515  loss_cls: 0.06637  loss_box_reg: 0.1571  loss_rpn_cls: 0.03545  loss_rpn_loc: 0.08126  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:41:30] d2.utils.events INFO:  eta: 0:14:25  iter: 16799  total_loss: 0.3376  loss_cls: 0.07275  loss_box_reg: 0.1286  loss_rpn_cls: 0.04067  loss_rpn_loc: 0.04433  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:41:45] d2.utils.events INFO:  eta: 0:14:13  iter: 16819  total_loss: 0.3722  loss_cls: 0.09404  loss_box_reg: 0.1367  loss_rpn_cls: 0.03959  loss_rpn_loc: 0.05818  time: 0.7045  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:41:59] d2.utils.events INFO:  eta: 0:13:57  iter: 16839  total_loss: 0.2734  loss_cls: 0.0727  loss_box_reg: 0.09878  loss_rpn_cls: 0.04141  loss_rpn_loc: 0.08093  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:42:12] d2.utils.events INFO:  eta: 0:13:43  iter: 16859  total_loss: 0.3881  loss_cls: 0.09733  loss_box_reg: 0.1366  loss_rpn_cls: 0.03812  loss_rpn_loc: 0.05443  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:42:26] d2.utils.events INFO:  eta: 0:13:28  iter: 16879  total_loss: 0.3177  loss_cls: 0.07292  loss_box_reg: 0.1167  loss_rpn_cls: 0.04601  loss_rpn_loc: 0.05279  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:42:40] d2.utils.events INFO:  eta: 0:13:13  iter: 16899  total_loss: 0.3327  loss_cls: 0.07625  loss_box_reg: 0.1162  loss_rpn_cls: 0.03502  loss_rpn_loc: 0.08368  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:42:54] d2.utils.events INFO:  eta: 0:12:59  iter: 16919  total_loss: 0.3663  loss_cls: 0.07596  loss_box_reg: 0.1128  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.07766  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:43:09] d2.utils.events INFO:  eta: 0:12:44  iter: 16939  total_loss: 0.3403  loss_cls: 0.06531  loss_box_reg: 0.1013  loss_rpn_cls: 0.04417  loss_rpn_loc: 0.1134  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:43:23] d2.utils.events INFO:  eta: 0:12:31  iter: 16959  total_loss: 0.4172  loss_cls: 0.09242  loss_box_reg: 0.1669  loss_rpn_cls: 0.04879  loss_rpn_loc: 0.08075  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:43:37] d2.utils.events INFO:  eta: 0:12:16  iter: 16979  total_loss: 0.3538  loss_cls: 0.0835  loss_box_reg: 0.143  loss_rpn_cls: 0.05023  loss_rpn_loc: 0.07924  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:43:52] d2.utils.events INFO:  eta: 0:12:01  iter: 16999  total_loss: 0.344  loss_cls: 0.06891  loss_box_reg: 0.1203  loss_rpn_cls: 0.03941  loss_rpn_loc: 0.06073  time: 0.7045  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:44:06] d2.utils.events INFO:  eta: 0:11:45  iter: 17019  total_loss: 0.5166  loss_cls: 0.1155  loss_box_reg: 0.2176  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.1047  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:44:21] d2.utils.events INFO:  eta: 0:11:32  iter: 17039  total_loss: 0.3072  loss_cls: 0.05953  loss_box_reg: 0.09676  loss_rpn_cls: 0.04034  loss_rpn_loc: 0.1096  time: 0.7045  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:44:35] d2.utils.events INFO:  eta: 0:11:16  iter: 17059  total_loss: 0.3924  loss_cls: 0.08272  loss_box_reg: 0.1418  loss_rpn_cls: 0.03548  loss_rpn_loc: 0.0792  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:44:48] d2.utils.events INFO:  eta: 0:11:01  iter: 17079  total_loss: 0.3401  loss_cls: 0.08016  loss_box_reg: 0.1467  loss_rpn_cls: 0.03142  loss_rpn_loc: 0.09827  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:45:03] d2.utils.events INFO:  eta: 0:10:48  iter: 17099  total_loss: 0.3469  loss_cls: 0.09841  loss_box_reg: 0.1184  loss_rpn_cls: 0.047  loss_rpn_loc: 0.04847  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:45:16] d2.utils.events INFO:  eta: 0:10:34  iter: 17119  total_loss: 0.2761  loss_cls: 0.0635  loss_box_reg: 0.08427  loss_rpn_cls: 0.03213  loss_rpn_loc: 0.05352  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:45:31] d2.utils.events INFO:  eta: 0:10:19  iter: 17139  total_loss: 0.4108  loss_cls: 0.1049  loss_box_reg: 0.1445  loss_rpn_cls: 0.03272  loss_rpn_loc: 0.0887  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:45:44] d2.utils.events INFO:  eta: 0:10:05  iter: 17159  total_loss: 0.3806  loss_cls: 0.08968  loss_box_reg: 0.1038  loss_rpn_cls: 0.04441  loss_rpn_loc: 0.07096  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:45:58] d2.utils.events INFO:  eta: 0:09:49  iter: 17179  total_loss: 0.3214  loss_cls: 0.07816  loss_box_reg: 0.1195  loss_rpn_cls: 0.05199  loss_rpn_loc: 0.03999  time: 0.7044  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:46:13] d2.utils.events INFO:  eta: 0:09:35  iter: 17199  total_loss: 0.4026  loss_cls: 0.07399  loss_box_reg: 0.1376  loss_rpn_cls: 0.05332  loss_rpn_loc: 0.0947  time: 0.7045  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:46:26] d2.utils.events INFO:  eta: 0:09:21  iter: 17219  total_loss: 0.2421  loss_cls: 0.04654  loss_box_reg: 0.07862  loss_rpn_cls: 0.03049  loss_rpn_loc: 0.04193  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:46:40] d2.utils.events INFO:  eta: 0:09:06  iter: 17239  total_loss: 0.3004  loss_cls: 0.07241  loss_box_reg: 0.1217  loss_rpn_cls: 0.0485  loss_rpn_loc: 0.08332  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:46:54] d2.utils.events INFO:  eta: 0:08:53  iter: 17259  total_loss: 0.3943  loss_cls: 0.08242  loss_box_reg: 0.1462  loss_rpn_cls: 0.04368  loss_rpn_loc: 0.08967  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:47:09] d2.utils.events INFO:  eta: 0:08:38  iter: 17279  total_loss: 0.4018  loss_cls: 0.08619  loss_box_reg: 0.1562  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.09582  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:47:22] d2.utils.events INFO:  eta: 0:08:22  iter: 17299  total_loss: 0.4364  loss_cls: 0.1072  loss_box_reg: 0.2179  loss_rpn_cls: 0.04812  loss_rpn_loc: 0.06793  time: 0.7044  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:47:36] d2.utils.events INFO:  eta: 0:08:08  iter: 17319  total_loss: 0.3808  loss_cls: 0.1037  loss_box_reg: 0.1247  loss_rpn_cls: 0.03837  loss_rpn_loc: 0.06885  time: 0.7044  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:47:50] d2.utils.events INFO:  eta: 0:07:54  iter: 17339  total_loss: 0.404  loss_cls: 0.09142  loss_box_reg: 0.1314  loss_rpn_cls: 0.03736  loss_rpn_loc: 0.07472  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:48:05] d2.utils.events INFO:  eta: 0:07:40  iter: 17359  total_loss: 0.3104  loss_cls: 0.08081  loss_box_reg: 0.1117  loss_rpn_cls: 0.03633  loss_rpn_loc: 0.09444  time: 0.7044  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:48:19] d2.utils.events INFO:  eta: 0:07:24  iter: 17379  total_loss: 0.3116  loss_cls: 0.06537  loss_box_reg: 0.1141  loss_rpn_cls: 0.0322  loss_rpn_loc: 0.05866  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:48:33] d2.utils.events INFO:  eta: 0:07:10  iter: 17399  total_loss: 0.2398  loss_cls: 0.05514  loss_box_reg: 0.09661  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.04253  time: 0.7044  data_time: 0.0021  lr: 2e-06  max_mem: 15387M
[01/30 04:48:48] d2.utils.events INFO:  eta: 0:06:55  iter: 17419  total_loss: 0.2955  loss_cls: 0.06849  loss_box_reg: 0.1088  loss_rpn_cls: 0.03507  loss_rpn_loc: 0.07167  time: 0.7044  data_time: 0.0021  lr: 2e-06  max_mem: 15387M
[01/30 04:49:03] d2.utils.events INFO:  eta: 0:06:41  iter: 17439  total_loss: 0.4437  loss_cls: 0.1005  loss_box_reg: 0.1633  loss_rpn_cls: 0.04149  loss_rpn_loc: 0.07484  time: 0.7045  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:49:18] d2.utils.events INFO:  eta: 0:06:27  iter: 17459  total_loss: 0.2875  loss_cls: 0.06422  loss_box_reg: 0.09367  loss_rpn_cls: 0.03834  loss_rpn_loc: 0.08289  time: 0.7045  data_time: 0.0026  lr: 2e-06  max_mem: 15387M
[01/30 04:49:33] d2.utils.events INFO:  eta: 0:06:13  iter: 17479  total_loss: 0.3729  loss_cls: 0.08335  loss_box_reg: 0.1506  loss_rpn_cls: 0.04669  loss_rpn_loc: 0.07306  time: 0.7046  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:49:47] d2.utils.events INFO:  eta: 0:05:58  iter: 17499  total_loss: 0.2725  loss_cls: 0.05777  loss_box_reg: 0.101  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.05625  time: 0.7046  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:50:01] d2.utils.events INFO:  eta: 0:05:44  iter: 17519  total_loss: 0.2817  loss_cls: 0.05124  loss_box_reg: 0.1014  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.06268  time: 0.7046  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:50:15] d2.utils.events INFO:  eta: 0:05:29  iter: 17539  total_loss: 0.4206  loss_cls: 0.06945  loss_box_reg: 0.1374  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.1027  time: 0.7046  data_time: 0.0025  lr: 2e-06  max_mem: 15387M
[01/30 04:50:29] d2.utils.events INFO:  eta: 0:05:15  iter: 17559  total_loss: 0.4021  loss_cls: 0.08266  loss_box_reg: 0.1241  loss_rpn_cls: 0.03905  loss_rpn_loc: 0.07892  time: 0.7046  data_time: 0.0021  lr: 2e-06  max_mem: 15387M
[01/30 04:50:42] d2.utils.events INFO:  eta: 0:05:00  iter: 17579  total_loss: 0.3352  loss_cls: 0.07302  loss_box_reg: 0.1365  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.07329  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:50:56] d2.utils.events INFO:  eta: 0:04:45  iter: 17599  total_loss: 0.3914  loss_cls: 0.07452  loss_box_reg: 0.1438  loss_rpn_cls: 0.04063  loss_rpn_loc: 0.09608  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:51:09] d2.utils.events INFO:  eta: 0:04:31  iter: 17619  total_loss: 0.3133  loss_cls: 0.05572  loss_box_reg: 0.1488  loss_rpn_cls: 0.04577  loss_rpn_loc: 0.05478  time: 0.7045  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:51:24] d2.utils.events INFO:  eta: 0:04:17  iter: 17639  total_loss: 0.271  loss_cls: 0.05527  loss_box_reg: 0.1016  loss_rpn_cls: 0.03248  loss_rpn_loc: 0.1039  time: 0.7045  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:51:37] d2.utils.events INFO:  eta: 0:04:02  iter: 17659  total_loss: 0.3273  loss_cls: 0.06749  loss_box_reg: 0.1443  loss_rpn_cls: 0.04724  loss_rpn_loc: 0.08592  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:51:51] d2.utils.events INFO:  eta: 0:03:48  iter: 17679  total_loss: 0.4442  loss_cls: 0.101  loss_box_reg: 0.1816  loss_rpn_cls: 0.04747  loss_rpn_loc: 0.07602  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:52:05] d2.utils.events INFO:  eta: 0:03:33  iter: 17699  total_loss: 0.3078  loss_cls: 0.05561  loss_box_reg: 0.1011  loss_rpn_cls: 0.0484  loss_rpn_loc: 0.06041  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:52:18] d2.utils.events INFO:  eta: 0:03:19  iter: 17719  total_loss: 0.2467  loss_cls: 0.05214  loss_box_reg: 0.1035  loss_rpn_cls: 0.02734  loss_rpn_loc: 0.05566  time: 0.7043  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:52:32] d2.utils.events INFO:  eta: 0:03:04  iter: 17739  total_loss: 0.3515  loss_cls: 0.06847  loss_box_reg: 0.1165  loss_rpn_cls: 0.03892  loss_rpn_loc: 0.09306  time: 0.7043  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:52:47] d2.utils.events INFO:  eta: 0:02:50  iter: 17759  total_loss: 0.3847  loss_cls: 0.1014  loss_box_reg: 0.1191  loss_rpn_cls: 0.03142  loss_rpn_loc: 0.1022  time: 0.7044  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:53:01] d2.utils.events INFO:  eta: 0:02:36  iter: 17779  total_loss: 0.2817  loss_cls: 0.06579  loss_box_reg: 0.101  loss_rpn_cls: 0.03917  loss_rpn_loc: 0.039  time: 0.7044  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:53:15] d2.utils.events INFO:  eta: 0:02:22  iter: 17799  total_loss: 0.3262  loss_cls: 0.07377  loss_box_reg: 0.1306  loss_rpn_cls: 0.05048  loss_rpn_loc: 0.06129  time: 0.7043  data_time: 0.0024  lr: 2e-06  max_mem: 15387M
[01/30 04:53:29] d2.utils.events INFO:  eta: 0:02:07  iter: 17819  total_loss: 0.3441  loss_cls: 0.07104  loss_box_reg: 0.1189  loss_rpn_cls: 0.04795  loss_rpn_loc: 0.05858  time: 0.7043  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:53:42] d2.utils.events INFO:  eta: 0:01:53  iter: 17839  total_loss: 0.4221  loss_cls: 0.108  loss_box_reg: 0.1888  loss_rpn_cls: 0.04286  loss_rpn_loc: 0.06056  time: 0.7043  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:53:55] d2.utils.events INFO:  eta: 0:01:39  iter: 17859  total_loss: 0.3641  loss_cls: 0.09874  loss_box_reg: 0.1652  loss_rpn_cls: 0.04483  loss_rpn_loc: 0.06814  time: 0.7042  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:54:09] d2.utils.events INFO:  eta: 0:01:25  iter: 17879  total_loss: 0.3818  loss_cls: 0.08243  loss_box_reg: 0.1691  loss_rpn_cls: 0.05126  loss_rpn_loc: 0.08892  time: 0.7042  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:54:22] d2.utils.events INFO:  eta: 0:01:10  iter: 17899  total_loss: 0.3355  loss_cls: 0.0721  loss_box_reg: 0.1104  loss_rpn_cls: 0.04326  loss_rpn_loc: 0.07309  time: 0.7042  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:54:36] d2.utils.events INFO:  eta: 0:00:56  iter: 17919  total_loss: 0.2443  loss_cls: 0.05646  loss_box_reg: 0.1054  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.0381  time: 0.7041  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:54:49] d2.utils.events INFO:  eta: 0:00:42  iter: 17939  total_loss: 0.2616  loss_cls: 0.05999  loss_box_reg: 0.1106  loss_rpn_cls: 0.03425  loss_rpn_loc: 0.05934  time: 0.7041  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:55:04] d2.utils.events INFO:  eta: 0:00:28  iter: 17959  total_loss: 0.4053  loss_cls: 0.09148  loss_box_reg: 0.1872  loss_rpn_cls: 0.04341  loss_rpn_loc: 0.09376  time: 0.7041  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:55:18] d2.utils.events INFO:  eta: 0:00:14  iter: 17979  total_loss: 0.3997  loss_cls: 0.1054  loss_box_reg: 0.1384  loss_rpn_cls: 0.04356  loss_rpn_loc: 0.06565  time: 0.7041  data_time: 0.0023  lr: 2e-06  max_mem: 15387M
[01/30 04:55:32] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_0017999.pth
[01/30 04:55:33] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[01/30 04:55:34] d2.utils.events INFO:  eta: 0:00:00  iter: 17999  total_loss: 0.3549  loss_cls: 0.09469  loss_box_reg: 0.1598  loss_rpn_cls: 0.03272  loss_rpn_loc: 0.05785  time: 0.7041  data_time: 0.0022  lr: 2e-06  max_mem: 15387M
[01/30 04:55:34] d2.engine.hooks INFO: Overall training speed: 17998 iterations in 3:31:12 (0.7041 s / it)
[01/30 04:55:34] d2.engine.hooks INFO: Total training time: 3:31:54 (0:00:41 on hooks)
[01/30 04:55:34] d2.data.build INFO: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 285          |   bicycle   | 337          |    boat     | 263          |
|   bottle   | 469          |     car     | 1201         |     cat     | 358          |
|   chair    | 756          | diningtable | 206          |     dog     | 489          |
|   horse    | 348          |   person    | 4528         | pottedplant | 480          |
|   sheep    | 242          |    train    | 282          |  tvmonitor  | 308          |
|    bird    | 459          |     bus     | 213          |     cow     | 244          |
| motorbike  | 325          |    sofa     | 239          |             |              |
|   total    | 12032        |             |              |             |              |
[01/30 04:55:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[01/30 04:55:34] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[01/30 04:55:34] d2.data.common INFO: Serialized dataset takes 2.12 MiB
[01/30 04:55:34] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[01/30 04:55:35] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0006 s/iter. Inference: 0.0758 s/iter. Eval: 0.0002 s/iter. Total: 0.0766 s/iter. ETA=0:06:18
[01/30 04:55:40] d2.evaluation.evaluator INFO: Inference done 82/4952. Dataloading: 0.0008 s/iter. Inference: 0.0702 s/iter. Eval: 0.0002 s/iter. Total: 0.0713 s/iter. ETA=0:05:47
[01/30 04:55:45] d2.evaluation.evaluator INFO: Inference done 150/4952. Dataloading: 0.0008 s/iter. Inference: 0.0714 s/iter. Eval: 0.0002 s/iter. Total: 0.0725 s/iter. ETA=0:05:47
[01/30 04:55:50] d2.evaluation.evaluator INFO: Inference done 219/4952. Dataloading: 0.0008 s/iter. Inference: 0.0717 s/iter. Eval: 0.0002 s/iter. Total: 0.0727 s/iter. ETA=0:05:44
[01/30 04:55:56] d2.evaluation.evaluator INFO: Inference done 292/4952. Dataloading: 0.0008 s/iter. Inference: 0.0707 s/iter. Eval: 0.0002 s/iter. Total: 0.0718 s/iter. ETA=0:05:34
[01/30 04:56:01] d2.evaluation.evaluator INFO: Inference done 364/4952. Dataloading: 0.0008 s/iter. Inference: 0.0704 s/iter. Eval: 0.0002 s/iter. Total: 0.0714 s/iter. ETA=0:05:27
[01/30 04:56:06] d2.evaluation.evaluator INFO: Inference done 434/4952. Dataloading: 0.0008 s/iter. Inference: 0.0704 s/iter. Eval: 0.0002 s/iter. Total: 0.0715 s/iter. ETA=0:05:22
[01/30 04:56:11] d2.evaluation.evaluator INFO: Inference done 509/4952. Dataloading: 0.0008 s/iter. Inference: 0.0698 s/iter. Eval: 0.0002 s/iter. Total: 0.0709 s/iter. ETA=0:05:15
[01/30 04:56:16] d2.evaluation.evaluator INFO: Inference done 584/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:05:07
[01/30 04:56:21] d2.evaluation.evaluator INFO: Inference done 657/4952. Dataloading: 0.0008 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:05:01
[01/30 04:56:26] d2.evaluation.evaluator INFO: Inference done 725/4952. Dataloading: 0.0008 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:58
[01/30 04:56:31] d2.evaluation.evaluator INFO: Inference done 796/4952. Dataloading: 0.0008 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:53
[01/30 04:56:36] d2.evaluation.evaluator INFO: Inference done 867/4952. Dataloading: 0.0008 s/iter. Inference: 0.0696 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:48
[01/30 04:56:41] d2.evaluation.evaluator INFO: Inference done 936/4952. Dataloading: 0.0008 s/iter. Inference: 0.0697 s/iter. Eval: 0.0002 s/iter. Total: 0.0708 s/iter. ETA=0:04:44
[01/30 04:56:46] d2.evaluation.evaluator INFO: Inference done 1009/4952. Dataloading: 0.0009 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:38
[01/30 04:56:51] d2.evaluation.evaluator INFO: Inference done 1078/4952. Dataloading: 0.0009 s/iter. Inference: 0.0697 s/iter. Eval: 0.0002 s/iter. Total: 0.0708 s/iter. ETA=0:04:34
[01/30 04:56:56] d2.evaluation.evaluator INFO: Inference done 1151/4952. Dataloading: 0.0009 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:28
[01/30 04:57:01] d2.evaluation.evaluator INFO: Inference done 1223/4952. Dataloading: 0.0009 s/iter. Inference: 0.0696 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:23
[01/30 04:57:06] d2.evaluation.evaluator INFO: Inference done 1295/4952. Dataloading: 0.0009 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:04:18
[01/30 04:57:11] d2.evaluation.evaluator INFO: Inference done 1365/4952. Dataloading: 0.0009 s/iter. Inference: 0.0696 s/iter. Eval: 0.0002 s/iter. Total: 0.0707 s/iter. ETA=0:04:13
[01/30 04:57:16] d2.evaluation.evaluator INFO: Inference done 1434/4952. Dataloading: 0.0009 s/iter. Inference: 0.0697 s/iter. Eval: 0.0002 s/iter. Total: 0.0708 s/iter. ETA=0:04:08
[01/30 04:57:21] d2.evaluation.evaluator INFO: Inference done 1507/4952. Dataloading: 0.0009 s/iter. Inference: 0.0696 s/iter. Eval: 0.0002 s/iter. Total: 0.0707 s/iter. ETA=0:04:03
[01/30 04:57:26] d2.evaluation.evaluator INFO: Inference done 1583/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:03:57
[01/30 04:57:31] d2.evaluation.evaluator INFO: Inference done 1657/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:03:51
[01/30 04:57:36] d2.evaluation.evaluator INFO: Inference done 1727/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:03:47
[01/30 04:57:41] d2.evaluation.evaluator INFO: Inference done 1797/4952. Dataloading: 0.0008 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:03:42
[01/30 04:57:46] d2.evaluation.evaluator INFO: Inference done 1865/4952. Dataloading: 0.0008 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:03:37
[01/30 04:57:51] d2.evaluation.evaluator INFO: Inference done 1942/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:03:31
[01/30 04:57:56] d2.evaluation.evaluator INFO: Inference done 2018/4952. Dataloading: 0.0008 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:03:26
[01/30 04:58:01] d2.evaluation.evaluator INFO: Inference done 2090/4952. Dataloading: 0.0008 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0702 s/iter. ETA=0:03:21
[01/30 04:58:06] d2.evaluation.evaluator INFO: Inference done 2158/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:03:16
[01/30 04:58:11] d2.evaluation.evaluator INFO: Inference done 2229/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:03:11
[01/30 04:58:16] d2.evaluation.evaluator INFO: Inference done 2301/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:03:06
[01/30 04:58:21] d2.evaluation.evaluator INFO: Inference done 2370/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:03:01
[01/30 04:58:26] d2.evaluation.evaluator INFO: Inference done 2440/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:57
[01/30 04:58:32] d2.evaluation.evaluator INFO: Inference done 2510/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:52
[01/30 04:58:37] d2.evaluation.evaluator INFO: Inference done 2580/4952. Dataloading: 0.0009 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:47
[01/30 04:58:42] d2.evaluation.evaluator INFO: Inference done 2654/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:41
[01/30 04:58:47] d2.evaluation.evaluator INFO: Inference done 2727/4952. Dataloading: 0.0008 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:02:36
[01/30 04:58:52] d2.evaluation.evaluator INFO: Inference done 2800/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:02:31
[01/30 04:58:57] d2.evaluation.evaluator INFO: Inference done 2871/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:02:26
[01/30 04:59:02] d2.evaluation.evaluator INFO: Inference done 2940/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:21
[01/30 04:59:07] d2.evaluation.evaluator INFO: Inference done 3012/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:02:16
[01/30 04:59:12] d2.evaluation.evaluator INFO: Inference done 3081/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:11
[01/30 04:59:17] d2.evaluation.evaluator INFO: Inference done 3153/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:02:06
[01/30 04:59:22] d2.evaluation.evaluator INFO: Inference done 3221/4952. Dataloading: 0.0009 s/iter. Inference: 0.0695 s/iter. Eval: 0.0002 s/iter. Total: 0.0706 s/iter. ETA=0:02:02
[01/30 04:59:27] d2.evaluation.evaluator INFO: Inference done 3294/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:01:56
[01/30 04:59:32] d2.evaluation.evaluator INFO: Inference done 3371/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:01:51
[01/30 04:59:37] d2.evaluation.evaluator INFO: Inference done 3446/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:01:45
[01/30 04:59:42] d2.evaluation.evaluator INFO: Inference done 3518/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:01:40
[01/30 04:59:47] d2.evaluation.evaluator INFO: Inference done 3593/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:01:35
[01/30 04:59:52] d2.evaluation.evaluator INFO: Inference done 3665/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:01:30
[01/30 04:59:57] d2.evaluation.evaluator INFO: Inference done 3742/4952. Dataloading: 0.0009 s/iter. Inference: 0.0691 s/iter. Eval: 0.0002 s/iter. Total: 0.0701 s/iter. ETA=0:01:24
[01/30 05:00:02] d2.evaluation.evaluator INFO: Inference done 3812/4952. Dataloading: 0.0009 s/iter. Inference: 0.0691 s/iter. Eval: 0.0002 s/iter. Total: 0.0702 s/iter. ETA=0:01:20
[01/30 05:00:07] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0702 s/iter. ETA=0:01:15
[01/30 05:00:12] d2.evaluation.evaluator INFO: Inference done 3953/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0702 s/iter. ETA=0:01:10
[01/30 05:00:17] d2.evaluation.evaluator INFO: Inference done 4021/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:01:05
[01/30 05:00:22] d2.evaluation.evaluator INFO: Inference done 4092/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:01:00
[01/30 05:00:27] d2.evaluation.evaluator INFO: Inference done 4165/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:55
[01/30 05:00:32] d2.evaluation.evaluator INFO: Inference done 4234/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:50
[01/30 05:00:37] d2.evaluation.evaluator INFO: Inference done 4306/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:45
[01/30 05:00:42] d2.evaluation.evaluator INFO: Inference done 4379/4952. Dataloading: 0.0009 s/iter. Inference: 0.0692 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:40
[01/30 05:00:47] d2.evaluation.evaluator INFO: Inference done 4449/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:35
[01/30 05:00:53] d2.evaluation.evaluator INFO: Inference done 4520/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:30
[01/30 05:00:58] d2.evaluation.evaluator INFO: Inference done 4591/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:25
[01/30 05:01:03] d2.evaluation.evaluator INFO: Inference done 4664/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0703 s/iter. ETA=0:00:20
[01/30 05:01:08] d2.evaluation.evaluator INFO: Inference done 4735/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:15
[01/30 05:01:13] d2.evaluation.evaluator INFO: Inference done 4806/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:10
[01/30 05:01:18] d2.evaluation.evaluator INFO: Inference done 4875/4952. Dataloading: 0.0009 s/iter. Inference: 0.0693 s/iter. Eval: 0.0002 s/iter. Total: 0.0704 s/iter. ETA=0:00:05
[01/30 05:01:23] d2.evaluation.evaluator INFO: Inference done 4943/4952. Dataloading: 0.0009 s/iter. Inference: 0.0694 s/iter. Eval: 0.0002 s/iter. Total: 0.0705 s/iter. ETA=0:00:00
[01/30 05:01:23] d2.evaluation.evaluator INFO: Total inference time: 0:05:48.487165 (0.070444 s / iter per device, on 1 devices)
[01/30 05:01:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:05:43 (0.069343 s / iter per device, on 1 devices)
[01/30 05:01:23] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[01/30 05:01:45] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car   |  cat   |  chair  |  diningtable  |  dog   |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow  |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:------:|:------:|:-------:|:-------------:|:------:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:-----:|:-----------:|:------:|
|   83.777    |  84.351   | 70.343 |  71.282  | 87.361 | 87.830 | 63.317  |    71.949     | 79.856 | 83.365  |  85.087  |    54.795     | 75.718  | 82.907  |   77.711    | 0.000  | 0.000 | 0.000 |    0.000    | 0.000  |
[01/30 05:01:45] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|   AP   |  AP50  |  AP75  |  bAP   |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:------:|:------:|:------:|:------:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 36.743 | 57.982 | 39.306 | 48.991 | 77.310  | 52.408  | 0.000 |  0.000  |  0.000  |
[01/30 05:01:45] d2.engine.defaults INFO: Evaluation results for voc_2007_test_all1 in csv format:
[01/30 05:01:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[01/30 05:01:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[01/30 05:01:45] d2.evaluation.testing INFO: copypaste: 36.7431,57.9824,39.3062,48.9908,77.3099,52.4083,0.0000,0.0000,0.0000
[01/30 19:38:37] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 19:38:38] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 19:38:38] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/30 19:38:38] detectron2 INFO: Contents of args.config_file=configs/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li.yaml:
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./pvt_v2_b2_li_C4.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_PVT_backbone"
    TYPE: "pvt_v2_b2_li"
  META_ARCHITECTURE: "GeneralizedRCNN"
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "PVTROIHeads"
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0002
  CHECKPOINT_PERIOD: 18000
  STEPS: (12000, 16000)
  MAX_ITER: 18000
  WARMUP_ITERS: 100
INPUT:
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MAX_SIZE_TEST: 1333
OUTPUT_DIR: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/"
TEST:
  EVAL_PERIOD: 18000
VERSION: 2

[01/30 19:38:38] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_PVT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: PVTROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./pvt_v2_b2_li_C4.pth
OUTPUT_DIR: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0002
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 18000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 1.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 18000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 12000
  - 16000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 100
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 18000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 19:38:38] detectron2 INFO: Full config saved to ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 19:38:38] d2.utils.env INFO: Using a generated random seed 38263171
[01/30 19:38:40] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): pvt_v2_b2_li(
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.007)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.013)
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.020)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.027)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.033)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.040)
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.047)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.053)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.060)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.067)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.073)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.080)
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): PVTROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.087)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.093)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath(drop_prob=0.100)
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=512, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=512, out_features=320, bias=True)
    )
  )
)
[01/30 19:38:41] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 19:38:42] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 19:38:42] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[01/30 19:38:42] d2.data.build INFO: Using training sampler TrainingSampler
[01/30 19:38:42] d2.data.common INFO: Serializing 14554 elements to byte tensors and concatenating them all ...
[01/30 19:38:42] d2.data.common INFO: Serialized dataset takes 6.47 MiB
[01/30 19:38:42] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./pvt_v2_b2_li_C4.pth ...
[01/30 19:38:42] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[01/30 19:38:42] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  head.{bias, weight}
[01/30 19:38:42] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 19:38:50] d2.engine.hooks INFO: Overall training speed: 7 iterations in 0:00:05 (0.7995 s / it)
[01/30 19:38:50] d2.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[01/30 19:38:50] d2.utils.events INFO:  eta: 3:38:29  iter: 9  total_loss: 5.188  loss_cls: 4.322  loss_box_reg: 0.08774  loss_rpn_cls: 0.6945  loss_rpn_loc: 0.05118  time: 0.7052  data_time: 0.0148  lr: 1.6184e-05  max_mem: 14305M
