[01/30 14:51:24] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 14:51:24] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 14:51:24] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 14:51:24] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 14:51:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 14:51:24] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 14:51:24] d2.utils.env INFO: Using a generated random seed 24846022
[01/30 14:51:27] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 15:14:58] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 15:14:58] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 15:14:58] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 15:14:58] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 15:14:58] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 15:14:58] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 15:14:58] d2.utils.env INFO: Using a generated random seed 58857535
[01/30 15:15:01] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 19:23:12] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 19:23:12] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 19:23:12] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 19:23:12] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 19:23:12] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 19:23:12] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 19:23:12] d2.utils.env INFO: Using a generated random seed 12767993
[01/30 19:23:15] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 19:34:37] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 19:34:37] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 19:34:37] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 19:34:37] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 19:34:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 19:34:37] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 19:34:37] d2.utils.env INFO: Using a generated random seed 37797678
[01/30 19:34:40] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 19:41:36] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 19:41:36] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 19:41:36] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 19:41:36] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 19:41:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 19:41:36] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 19:41:36] d2.utils.env INFO: Using a generated random seed 36744581
[01/30 19:41:39] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 19:45:46] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 19:45:47] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 19:45:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 19:45:47] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 19:45:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 19:45:47] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 19:45:47] d2.utils.env INFO: Using a generated random seed 47280054
[01/30 19:45:49] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 19:50:16] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 19:50:16] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 19:50:16] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 19:50:16] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 19:50:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 19:50:16] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 19:50:16] d2.utils.env INFO: Using a generated random seed 16987086
[01/30 19:50:19] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:15:33] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:15:33] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:15:33] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:15:33] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:15:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:15:33] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:15:33] d2.utils.env INFO: Using a generated random seed 34026542
[01/30 20:15:36] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:15:37] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:15:38] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:15:38] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:15:38] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:15:39] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:15:39] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:20:20] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:20:20] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:20:20] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:20:20] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 9999
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 9999
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 9999

[01/30 20:20:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 9999
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 9999
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 9999
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:20:20] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:20:20] d2.utils.env INFO: Using a generated random seed 20709550
[01/30 20:20:23] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:20:24] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:20:24] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:20:25] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:20:25] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:20:25] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:20:25] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:21:49] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:21:50] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:21:50] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:21:50] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:21:50] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:21:50] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:21:50] d2.utils.env INFO: Using a generated random seed 50447527
[01/30 20:21:52] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:21:54] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:21:54] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:21:55] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:21:55] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:21:55] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:21:55] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:21:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:21:55] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:21:55] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:21:55] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:21:55] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 251, in generate_support
    support_data = utils.read_image("./datasets/pascal_voc/" + support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/pascal_voc/home/rmedu/fct/FCT/datasets/pascal_voc/voc_2012_trainval_base1/2010_000872/0000.jpg'

[01/30 20:21:55] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/30 20:21:55] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[01/30 20:30:15] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:30:15] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:30:15] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:30:15] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:30:15] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:30:15] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:30:15] d2.utils.env INFO: Using a generated random seed 15864036
[01/30 20:30:18] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:30:19] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:30:20] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:30:20] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:30:20] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:30:20] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:30:20] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:30:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:30:21] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:30:21] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:30:21] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:30:21] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 251, in generate_support
    support_data = utils.read_image("./datasets/pascal_voc/" + support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/pascal_voc/home/rmedu/fct/FCT/datasets/pascal_voc/voc_2012_trainval_base1/2008_002687/0000.jpg'

[01/30 20:30:21] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/30 20:30:21] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[01/30 20:32:25] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:32:26] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:32:26] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:32:26] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:32:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:32:26] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:32:26] d2.utils.env INFO: Using a generated random seed 26456510
[01/30 20:32:28] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:32:30] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:32:30] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:32:31] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:32:31] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:32:31] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:32:31] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:32:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:32:31] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:32:31] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:32:31] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:32:31] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 251, in generate_support
    support_data = utils.read_image("./datasets/pascal_voc/" + support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/pascal_voc/home/rmedu/fct/FCT/datasets/pascal_voc/voc_2012_trainval_base1/2009_004524/0000.jpg'

[01/30 20:32:31] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/30 20:32:31] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[01/30 20:37:57] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:37:58] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:37:58] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:37:58] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:37:58] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:37:58] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:37:58] d2.utils.env INFO: Using a generated random seed 58260182
[01/30 20:38:00] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:38:02] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:38:02] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:38:03] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:38:03] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:38:03] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:38:03] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:38:03] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:38:03] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:38:03] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:38:03] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:38:03] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 286, in generate_support
    support_data = utils.read_image("./datasets/pascal_voc/" + support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/pascal_voc/home/rmedu/fct/FCT/datasets/pascal_voc/voc_2007_trainval_base1/005702/0000.jpg'

[01/30 20:38:03] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/30 20:38:03] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[01/30 20:39:29] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:39:30] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:39:30] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:39:30] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:39:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:39:30] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:39:30] d2.utils.env INFO: Using a generated random seed 30249921
[01/30 20:39:32] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:39:34] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:39:34] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:39:35] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:39:35] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:39:35] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:39:35] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:39:35] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:39:35] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:39:35] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:39:35] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:39:37] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 23.70 GiB total capacity; 21.09 GiB already allocated; 43.19 MiB free; 21.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 20:39:37] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 20:39:37] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21600M
[01/30 20:43:04] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:43:05] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:43:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:43:05] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 576, 640, 640, 640)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:43:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 576
  - 640
  - 640
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:43:05] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:43:05] d2.utils.env INFO: Using a generated random seed 5456577
[01/30 20:43:08] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:43:09] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:43:09] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:43:10] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:43:10] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:43:10] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:43:10] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:43:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:43:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:43:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:43:10] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:43:12] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 260, in forward
    outs = self.drop_path(self.attn(self.norm1(x), H_x, W_x, self.norm1(y), H_y, W_y))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 219, in forward
    y = (attn_y @ v_cat_y).transpose(1, 2).reshape(B_y, N_y, C_y)
RuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.70 GiB total capacity; 21.07 GiB already allocated; 47.69 MiB free; 21.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 20:43:12] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 20:43:12] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21571M
[01/30 20:44:33] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:44:33] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:44:33] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:44:33] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 576, 640, 640, 640)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:44:34] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 576
  - 640
  - 640
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:44:34] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:44:34] d2.utils.env INFO: Using a generated random seed 34192695
[01/30 20:44:36] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:44:37] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:44:38] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:44:38] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:44:38] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:44:39] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:44:39] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:44:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:44:39] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:44:39] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:44:39] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:44:40] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 87, in forward
    x = self.fc1(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 23.70 GiB total capacity; 20.91 GiB already allocated; 125.50 MiB free; 21.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 20:44:40] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 20:44:40] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21415M
[01/30 20:55:59] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:55:59] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:55:59] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:55:59] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (480, 512, 512, 576, 480, 512, 512, 480, 512, 512, 576)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:55:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 512
  - 576
  - 480
  - 512
  - 512
  - 480
  - 512
  - 512
  - 576
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:55:59] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:55:59] d2.utils.env INFO: Using a generated random seed 59878235
[01/30 20:56:02] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:56:03] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:56:04] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:56:04] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:56:04] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:56:04] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:56:04] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:56:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:56:05] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:56:05] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:56:05] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:56:06] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 23.70 GiB total capacity; 20.68 GiB already allocated; 80.25 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 20:56:06] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 20:56:06] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21174M
[01/30 20:56:52] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:56:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:56:52] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:56:52] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 1
  MIN_SIZE_TRAIN: (480, 512, 512, 576, 480, 512, 512, 480, 512, 512, 576)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:56:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 1
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 512
  - 576
  - 480
  - 512
  - 512
  - 480
  - 512
  - 512
  - 576
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:56:52] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:56:52] d2.utils.env INFO: Using a generated random seed 52620120
[01/30 20:56:55] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:56:56] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:56:56] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:56:57] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:56:57] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:56:57] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:56:57] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:56:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:56:57] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:56:57] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:56:57] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:56:58] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 184, in forward
    if batched_inputs[b_1]['support_cls'][idx] != batched_inputs[b_1]['support_cls'][begin_rel]:
UnboundLocalError: local variable 'idx' referenced before assignment
[01/30 20:56:58] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/30 20:56:58] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 167M
[01/30 20:58:22] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:58:22] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:58:22] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:58:22] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 2
  MIN_SIZE_TRAIN: (480, 512, 512, 576, 480, 512, 512, 480, 512, 512, 576)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:58:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 2
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 512
  - 576
  - 480
  - 512
  - 512
  - 480
  - 512
  - 512
  - 576
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:58:23] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:58:23] d2.utils.env INFO: Using a generated random seed 23195718
[01/30 20:58:25] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:58:26] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:58:27] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:58:27] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:58:28] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:58:28] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:58:28] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:58:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:58:28] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:58:28] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:58:28] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:58:29] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 213, in forward
    pos_support_features = self.roi_heads.roi_pooling(support_features, support_bboxes_ls[pos_begin:pos_end])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 249, in roi_pooling
    [features[f] for f in self.in_features], boxes
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/modeling/poolers.py", line 214, in forward
    x[0].size(0), len(box_lists)
AssertionError: unequal value, x[0] batch dim 0 is 2, but box_list has length 1
[01/30 20:58:29] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 20:58:29] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 19088M
[01/30 20:59:04] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 20:59:04] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 20:59:04] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 20:59:04] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 3
  MIN_SIZE_TRAIN: (480, 512, 512, 576, 480, 512, 512, 480, 512, 512, 576)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 20:59:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 3
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 512
  - 576
  - 480
  - 512
  - 512
  - 480
  - 512
  - 512
  - 576
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 20:59:04] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 20:59:04] d2.utils.env INFO: Using a generated random seed 4703014
[01/30 20:59:07] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 20:59:08] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 20:59:09] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 20:59:09] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 20:59:09] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 20:59:09] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 20:59:09] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 20:59:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 20:59:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 20:59:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 20:59:10] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 20:59:11] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 53, in forward
    return drop_path(x[0], x[1], self.drop_prob, self.training)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 36, in drop_path
    output_x = x.div(keep_prob) * random_tensor_x
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.70 GiB total capacity; 21.05 GiB already allocated; 39.44 MiB free; 21.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 20:59:11] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 20:59:11] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21552M
[01/30 21:01:26] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 21:01:27] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 21:01:27] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 21:01:27] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 15
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 21:01:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 250
  - 250
  - 250
  - 250
  - 250
  - 250
  - 250
  - 250
  - 250
  - 250
  - 250
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 15
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 21:01:27] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 21:01:27] d2.utils.env INFO: Using a generated random seed 27218520
[01/30 21:01:29] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 21:01:30] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 21:01:31] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 21:01:31] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 21:01:31] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 21:01:32] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 21:01:32] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 21:01:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 21:01:32] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 21:01:32] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 21:01:32] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 21:01:33] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 53, in forward
    return drop_path(x[0], x[1], self.drop_prob, self.training)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 36, in drop_path
    output_x = x.div(keep_prob) * random_tensor_x
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 23.70 GiB total capacity; 21.19 GiB already allocated; 31.50 MiB free; 21.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 21:01:33] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 21:01:33] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21697M
[01/30 21:02:22] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 21:02:23] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 21:02:23] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 21:02:23] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 15
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 21:02:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 15
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 21:02:23] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 21:02:23] d2.utils.env INFO: Using a generated random seed 23196217
[01/30 21:02:25] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 21:02:26] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 21:02:27] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 21:02:27] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 21:02:27] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 21:02:28] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 21:02:28] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 21:02:28] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 21:02:28] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 21:02:28] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 21:02:28] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 21:02:29] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.70 GiB total capacity; 20.82 GiB already allocated; 100.88 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 21:02:29] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 21:02:29] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21319M
[01/30 21:03:36] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 21:03:36] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 21:03:36] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 21:03:36] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 15
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 500
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 21:03:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 500
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 15
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 21:03:36] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 21:03:36] d2.utils.env INFO: Using a generated random seed 36636117
[01/30 21:03:39] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 21:03:40] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 21:03:40] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 21:03:41] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 21:03:41] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 21:03:41] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 21:03:41] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 21:03:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 21:03:41] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 21:03:41] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 21:03:41] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 21:03:43] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.70 GiB total capacity; 20.82 GiB already allocated; 103.50 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 21:03:43] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 21:03:43] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21319M
[01/30 21:04:04] detectron2 INFO: Rank of current process: 0. World size: 1
[01/30 21:04:04] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/30 21:04:04] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/30 21:04:04] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 15
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/30 21:04:04] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 15
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/30 21:04:04] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/30 21:04:04] d2.utils.env INFO: Using a generated random seed 4977906
[01/30 21:04:07] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/30 21:04:08] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/30 21:04:09] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/30 21:04:09] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/30 21:04:09] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/30 21:04:10] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/30 21:04:10] FCT.data.build INFO: Using training sampler TrainingSampler
[01/30 21:04:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/30 21:04:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/30 21:04:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/30 21:04:10] d2.engine.train_loop INFO: Starting training from iteration 0
[01/30 21:04:11] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.70 GiB total capacity; 20.82 GiB already allocated; 101.50 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/30 21:04:11] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/30 21:04:11] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21319M
[01/31 01:35:53] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:35:53] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:35:53] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=False)
[01/31 01:35:53] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:35:53] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:35:53] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:35:53] d2.utils.env INFO: Using a generated random seed 54092247
[01/31 01:35:56] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:35:57] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:35:58] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:35:58] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:35:58] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:35:59] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:35:59] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:35:59] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:35:59] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:35:59] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:35:59] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:36:00] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 213, in forward
    pos_support_features = self.roi_heads.roi_pooling(support_features, support_bboxes_ls[pos_begin:pos_end])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 249, in roi_pooling
    [features[f] for f in self.in_features], boxes
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/modeling/poolers.py", line 214, in forward
    x[0].size(0), len(box_lists)
AssertionError: unequal value, x[0] batch dim 0 is 10, but box_list has length 9
[01/31 01:36:00] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:36:00] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 13683M
[01/31 01:36:35] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:36:35] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:36:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '8'], resume=False)
[01/31 01:36:35] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:36:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:36:35] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:36:35] d2.utils.env INFO: Using a generated random seed 36063918
[01/31 01:36:38] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:36:39] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:36:40] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:36:40] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:36:40] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:36:41] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:36:41] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:36:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:36:41] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:36:41] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:36:41] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:36:42] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 23.70 GiB total capacity; 20.82 GiB already allocated; 144.75 MiB free; 21.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 01:36:42] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:36:42] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21319M
[01/31 01:38:30] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:38:31] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:38:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 01:38:31] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:38:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:38:31] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:38:31] d2.utils.env INFO: Using a generated random seed 31458148
[01/31 01:38:33] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:38:35] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:38:35] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:38:36] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:38:36] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:38:36] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:38:36] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:38:36] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:38:36] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:38:36] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:38:36] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:38:37] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 213, in forward
    pos_support_features = self.roi_heads.roi_pooling(support_features, support_bboxes_ls[pos_begin:pos_end])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 249, in roi_pooling
    [features[f] for f in self.in_features], boxes
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/modeling/poolers.py", line 214, in forward
    x[0].size(0), len(box_lists)
AssertionError: unequal value, x[0] batch dim 0 is 10, but box_list has length 9
[01/31 01:38:37] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:38:37] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 6892M
[01/31 01:47:38] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:47:38] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:47:38] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=False)
[01/31 01:47:38] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:47:38] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:47:38] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:47:38] d2.utils.env INFO: Using a generated random seed 38565287
[01/31 01:47:41] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:47:42] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:47:42] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:47:43] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:47:43] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:47:43] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:47:43] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:48:46] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:48:46] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:48:46] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=False)
[01/31 01:48:46] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 10000)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:48:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 10000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:48:46] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:48:46] d2.utils.env INFO: Using a generated random seed 46667583
[01/31 01:48:49] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:48:50] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:48:50] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:48:51] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:48:51] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:48:51] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:48:51] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:50:25] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:50:25] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:50:25] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4'], resume=False)
[01/31 01:50:25] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:50:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:50:25] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:50:25] d2.utils.env INFO: Using a generated random seed 25803017
[01/31 01:50:28] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:50:29] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:50:30] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:50:30] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:50:30] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:50:30] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:50:30] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:50:31] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:50:31] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:50:31] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:50:31] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:50:32] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 87, in forward
    x = self.fc1(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 23.70 GiB total capacity; 21.01 GiB already allocated; 60.38 MiB free; 21.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 01:50:32] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:50:32] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21510M
[01/31 01:50:51] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:50:52] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:50:52] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 01:50:52] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:50:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:50:52] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:50:52] d2.utils.env INFO: Using a generated random seed 52460247
[01/31 01:50:54] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:50:56] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:50:56] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:50:57] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:50:57] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:50:57] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:50:57] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:50:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:50:57] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:50:57] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:50:57] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:50:59] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 93, in forward
    x = self.fc2(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 23.70 GiB total capacity; 21.04 GiB already allocated; 59.69 MiB free; 21.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 01:50:59] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:50:59] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21543M
[01/31 01:53:41] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:53:41] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:53:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '1'], resume=False)
[01/31 01:53:41] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 30
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:53:41] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 30
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:53:41] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:53:41] d2.utils.env INFO: Using a generated random seed 41807549
[01/31 01:53:44] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:53:45] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:53:46] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:53:46] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:53:46] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:53:46] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:53:46] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:53:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:53:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:53:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:53:47] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:53:48] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 90, in forward
    x = self.dwconv(x, H, W)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 600, in forward
    x = self.dwconv(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 446, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 23.70 GiB total capacity; 21.06 GiB already allocated; 65.38 MiB free; 21.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 01:53:48] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:53:48] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21568M
[01/31 01:54:39] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:54:39] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:54:39] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 01:54:39] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:54:39] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:54:39] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:54:39] d2.utils.env INFO: Using a generated random seed 39938356
[01/31 01:54:42] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:54:43] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:54:44] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:54:44] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:54:44] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:54:44] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:54:44] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:54:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:54:45] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:54:45] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:54:45] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:54:46] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 189, in forward
    features_dict[b_1][b_2] = self.backbone.forward_with_two_branch(images.tensor[b_1,:].unsqueeze(0), support_images[pos_begin:pos_end,:])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 492, in forward_with_two_branch
    outs = self.forward_features_with_two_branch(x, y)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 480, in forward_features_with_two_branch
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 263, in forward
    outs = self.drop_path((self.mlp(self.norm2(x), H_x, W_x), self.mlp(self.norm2(y), H_y, W_y)))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 93, in forward
    x = self.fc2(x)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.70 GiB total capacity; 20.77 GiB already allocated; 46.19 MiB free; 21.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 01:54:46] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:54:46] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21265M
[01/31 01:55:11] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:55:11] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:55:11] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 01:55:11] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 1
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:55:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 1
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:55:11] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:55:11] d2.utils.env INFO: Using a generated random seed 12094972
[01/31 01:55:14] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:55:15] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:55:16] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:55:16] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:55:16] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:55:16] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:55:16] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:55:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:55:17] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:55:17] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:55:17] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:55:18] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 213, in forward
    pos_support_features = self.roi_heads.roi_pooling(support_features, support_bboxes_ls[pos_begin:pos_end])
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 249, in roi_pooling
    [features[f] for f in self.in_features], boxes
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/modeling/poolers.py", line 214, in forward
    x[0].size(0), len(box_lists)
AssertionError: unequal value, x[0] batch dim 0 is 10, but box_list has length 9
[01/31 01:55:18] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:55:18] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 13309M
[01/31 01:55:41] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:55:41] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:55:41] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 01:55:41] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50)
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:55:41] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 100
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  - 50
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:55:41] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:55:41] d2.utils.env INFO: Using a generated random seed 42090072
[01/31 01:55:44] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:55:45] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:55:46] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:55:46] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:55:46] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:55:47] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:55:47] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:55:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:55:47] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:55:47] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:55:47] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:56:12] d2.utils.events INFO:  eta: 3:17:40  iter: 19  total_loss: 1.078  loss_cls: 0.8572  loss_box_reg: 0.08861  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.0115  time: 1.1904  data_time: 0.0244  lr: 2.684e-06  max_mem: 17191M
[01/31 01:56:36] d2.utils.events INFO:  eta: 3:18:23  iter: 39  total_loss: 0.9079  loss_cls: 0.7398  loss_box_reg: 0.04838  loss_rpn_cls: 0.08571  loss_rpn_loc: 0.009266  time: 1.2033  data_time: 0.0069  lr: 3.404e-06  max_mem: 18079M
[01/31 01:57:00] d2.utils.events INFO:  eta: 3:18:33  iter: 59  total_loss: 0.8907  loss_cls: 0.7069  loss_box_reg: 0.08528  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.009583  time: 1.2024  data_time: 0.0066  lr: 4.124e-06  max_mem: 18079M
[01/31 01:57:25] d2.utils.events INFO:  eta: 3:18:12  iter: 79  total_loss: 0.8258  loss_cls: 0.6457  loss_box_reg: 0.1009  loss_rpn_cls: 0.06232  loss_rpn_loc: 0.006785  time: 1.2065  data_time: 0.0068  lr: 4.844e-06  max_mem: 18079M
[01/31 01:57:49] d2.utils.events INFO:  eta: 3:18:09  iter: 99  total_loss: 0.7789  loss_cls: 0.638  loss_box_reg: 0.0511  loss_rpn_cls: 0.06009  loss_rpn_loc: 0.01268  time: 1.2102  data_time: 0.0069  lr: 5.564e-06  max_mem: 18079M
[01/31 01:58:13] d2.utils.events INFO:  eta: 3:18:06  iter: 119  total_loss: 0.8005  loss_cls: 0.6154  loss_box_reg: 0.09231  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.006587  time: 1.2113  data_time: 0.0070  lr: 6.284e-06  max_mem: 18079M
[01/31 01:58:38] d2.utils.events INFO:  eta: 3:18:11  iter: 139  total_loss: 0.7498  loss_cls: 0.6244  loss_box_reg: 0.07611  loss_rpn_cls: 0.04687  loss_rpn_loc: 0.009622  time: 1.2150  data_time: 0.0076  lr: 7.004e-06  max_mem: 18079M
[01/31 01:59:02] d2.engine.hooks INFO: Overall training speed: 156 iterations in 0:03:11 (1.2273 s / it)
[01/31 01:59:02] d2.engine.hooks INFO: Total training time: 0:03:11 (0:00:00 on hooks)
[01/31 01:59:02] d2.utils.events INFO:  eta: 3:18:21  iter: 158  total_loss: 0.7614  loss_cls: 0.6086  loss_box_reg: 0.0663  loss_rpn_cls: 0.04724  loss_rpn_loc: 0.008904  time: 1.2184  data_time: 0.0072  lr: 7.652e-06  max_mem: 18079M
[01/31 01:59:06] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 01:59:07] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 01:59:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 01:59:07] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 01:59:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 01:59:07] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 01:59:07] d2.utils.env INFO: Using a generated random seed 7220931
[01/31 01:59:09] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 01:59:10] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 01:59:11] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 01:59:12] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 01:59:12] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 01:59:12] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 01:59:12] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 01:59:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 01:59:12] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 01:59:12] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 01:59:12] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 01:59:13] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 220, in forward
    pos_pred_class_logits, pos_pred_proposal_deltas, pos_detector_proposals = self.roi_heads(query_images, query_features, pos_support_features, pos_proposals, query_gt_instances) # pos rcnn
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 270, in forward
    box_features, support_box_features = self._shared_roi_transform_mutual(box_features, support_box_features)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 235, in _shared_roi_transform_mutual
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 260, in forward
    outs = self.drop_path(self.attn(self.norm1(x), H_x, W_x, self.norm1(y), H_y, W_y))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 200, in forward
    x = (attn_x @ v_cat_x).transpose(1, 2).reshape(B_x, N_x, C_x)
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 23.70 GiB total capacity; 21.11 GiB already allocated; 43.56 MiB free; 21.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 01:59:13] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 01:59:13] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21617M
[01/31 02:00:01] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 02:00:02] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 02:00:02] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 02:00:02] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
  MAX_SIZE_TRAIN: 800
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 02:00:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 800
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 02:00:02] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 02:00:02] d2.utils.env INFO: Using a generated random seed 2218194
[01/31 02:00:04] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 02:00:05] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 02:00:06] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 02:00:06] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 02:00:06] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 02:00:07] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 02:00:07] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 02:00:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 02:00:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 02:00:07] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 02:00:07] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 02:00:08] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 220, in forward
    pos_pred_class_logits, pos_pred_proposal_deltas, pos_detector_proposals = self.roi_heads(query_images, query_features, pos_support_features, pos_proposals, query_gt_instances) # pos rcnn
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 270, in forward
    box_features, support_box_features = self._shared_roi_transform_mutual(box_features, support_box_features)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 235, in _shared_roi_transform_mutual
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 260, in forward
    outs = self.drop_path(self.attn(self.norm1(x), H_x, W_x, self.norm1(y), H_y, W_y))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 170, in forward
    kv_x = self.kv(x_).reshape(B_x, -1, 2, self.num_heads, C_x // self.num_heads).permute(2, 0, 3, 1, 4)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 23.70 GiB total capacity; 21.06 GiB already allocated; 40.19 MiB free; 21.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 02:00:08] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 02:00:08] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21566M
[01/31 02:01:13] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 02:01:14] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 02:01:14] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 02:01:14] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (480, 480, 480, 480, 480, 480, 480, 480, 480, 480, 480)
  MAX_SIZE_TRAIN: 800
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 02:01:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 800
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 480
  - 480
  - 480
  - 480
  - 480
  - 480
  - 480
  - 480
  - 480
  - 480
  - 480
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 02:01:14] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 02:01:14] d2.utils.env INFO: Using a generated random seed 14340865
[01/31 02:01:16] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 02:01:18] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 02:01:18] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 02:01:19] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 02:01:19] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 02:01:19] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 02:01:19] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 02:01:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 02:01:19] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 02:01:19] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 02:01:19] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 02:01:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_rcnn.py", line 220, in forward
    pos_pred_class_logits, pos_pred_proposal_deltas, pos_detector_proposals = self.roi_heads(query_images, query_features, pos_support_features, pos_proposals, query_gt_instances) # pos rcnn
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 270, in forward
    box_features, support_box_features = self._shared_roi_transform_mutual(box_features, support_box_features)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/fsod_roi_heads.py", line 235, in _shared_roi_transform_mutual
    x, y = blk(x, H_x, W_x, y, H_y, W_y)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 260, in forward
    outs = self.drop_path(self.attn(self.norm1(x), H_x, W_x, self.norm1(y), H_y, W_y))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/modeling/fsod/FCT.py", line 200, in forward
    x = (attn_x @ v_cat_x).transpose(1, 2).reshape(B_x, N_x, C_x)
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 23.70 GiB total capacity; 21.00 GiB already allocated; 37.94 MiB free; 21.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/31 02:01:20] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[01/31 02:01:20] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 21506M
[01/31 02:02:01] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 02:02:01] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 02:02:01] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[01/31 02:02:01] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[01/31 02:02:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[01/31 02:02:01] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[01/31 02:02:01] d2.utils.env INFO: Using a generated random seed 1921790
[01/31 02:02:04] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[01/31 02:02:05] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[01/31 02:02:06] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[01/31 02:02:06] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[01/31 02:02:06] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[01/31 02:02:07] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[01/31 02:02:07] FCT.data.build INFO: Using training sampler TrainingSampler
[01/31 02:02:07] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[01/31 02:02:07] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[01/31 02:02:07] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[01/31 02:02:07] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 02:02:33] d2.utils.events INFO:  eta: 3:28:45  iter: 19  total_loss: 1.132  loss_cls: 0.8921  loss_box_reg: 0.1096  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.004152  time: 1.2618  data_time: 0.0253  lr: 2.684e-06  max_mem: 18976M
[01/31 02:02:58] d2.utils.events INFO:  eta: 3:28:45  iter: 39  total_loss: 0.9707  loss_cls: 0.7347  loss_box_reg: 0.1457  loss_rpn_cls: 0.07986  loss_rpn_loc: 0.00539  time: 1.2624  data_time: 0.0066  lr: 3.404e-06  max_mem: 18976M
[01/31 02:03:24] d2.utils.events INFO:  eta: 3:28:45  iter: 59  total_loss: 0.8867  loss_cls: 0.6742  loss_box_reg: 0.1386  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.003775  time: 1.2671  data_time: 0.0067  lr: 4.124e-06  max_mem: 18976M
[01/31 02:03:49] d2.utils.events INFO:  eta: 3:28:44  iter: 79  total_loss: 0.8425  loss_cls: 0.6366  loss_box_reg: 0.1284  loss_rpn_cls: 0.06446  loss_rpn_loc: 0.007191  time: 1.2693  data_time: 0.0067  lr: 4.844e-06  max_mem: 18976M
[01/31 02:04:15] d2.utils.events INFO:  eta: 3:28:30  iter: 99  total_loss: 0.8229  loss_cls: 0.6172  loss_box_reg: 0.1363  loss_rpn_cls: 0.04982  loss_rpn_loc: 0.003633  time: 1.2710  data_time: 0.0070  lr: 5.564e-06  max_mem: 18976M
[01/31 02:04:41] d2.utils.events INFO:  eta: 3:28:20  iter: 119  total_loss: 0.7911  loss_cls: 0.6201  loss_box_reg: 0.1064  loss_rpn_cls: 0.03994  loss_rpn_loc: 0.005823  time: 1.2718  data_time: 0.0076  lr: 6.284e-06  max_mem: 19009M
[01/31 02:05:06] d2.utils.events INFO:  eta: 3:28:11  iter: 139  total_loss: 0.7918  loss_cls: 0.6174  loss_box_reg: 0.127  loss_rpn_cls: 0.04768  loss_rpn_loc: 0.004854  time: 1.2719  data_time: 0.0072  lr: 7.004e-06  max_mem: 19009M
[01/31 02:05:32] d2.utils.events INFO:  eta: 3:27:48  iter: 159  total_loss: 0.7781  loss_cls: 0.6203  loss_box_reg: 0.09379  loss_rpn_cls: 0.04132  loss_rpn_loc: 0.005536  time: 1.2726  data_time: 0.0068  lr: 7.724e-06  max_mem: 19009M
[01/31 02:05:57] d2.utils.events INFO:  eta: 3:27:22  iter: 179  total_loss: 0.7832  loss_cls: 0.5733  loss_box_reg: 0.1338  loss_rpn_cls: 0.0407  loss_rpn_loc: 0.003571  time: 1.2721  data_time: 0.0068  lr: 8.444e-06  max_mem: 19009M
[01/31 02:06:23] d2.utils.events INFO:  eta: 3:26:51  iter: 199  total_loss: 0.7748  loss_cls: 0.6043  loss_box_reg: 0.09552  loss_rpn_cls: 0.04017  loss_rpn_loc: 0.005892  time: 1.2717  data_time: 0.0068  lr: 9.164e-06  max_mem: 19009M
[01/31 02:06:48] d2.utils.events INFO:  eta: 3:26:32  iter: 219  total_loss: 0.7631  loss_cls: 0.5904  loss_box_reg: 0.111  loss_rpn_cls: 0.04466  loss_rpn_loc: 0.005488  time: 1.2717  data_time: 0.0074  lr: 9.884e-06  max_mem: 19009M
[01/31 02:07:14] d2.utils.events INFO:  eta: 3:26:10  iter: 239  total_loss: 0.7401  loss_cls: 0.5695  loss_box_reg: 0.1341  loss_rpn_cls: 0.0372  loss_rpn_loc: 0.002755  time: 1.2719  data_time: 0.0073  lr: 1.0604e-05  max_mem: 19009M
[01/31 02:07:39] d2.utils.events INFO:  eta: 3:25:49  iter: 259  total_loss: 0.7484  loss_cls: 0.5538  loss_box_reg: 0.122  loss_rpn_cls: 0.04223  loss_rpn_loc: 0.004506  time: 1.2724  data_time: 0.0071  lr: 1.1324e-05  max_mem: 19009M
[01/31 02:08:05] d2.utils.events INFO:  eta: 3:25:27  iter: 279  total_loss: 0.7512  loss_cls: 0.5935  loss_box_reg: 0.1067  loss_rpn_cls: 0.03046  loss_rpn_loc: 0.002607  time: 1.2732  data_time: 0.0072  lr: 1.2044e-05  max_mem: 19009M
[01/31 02:08:30] d2.utils.events INFO:  eta: 3:24:58  iter: 299  total_loss: 0.6833  loss_cls: 0.5187  loss_box_reg: 0.1113  loss_rpn_cls: 0.0362  loss_rpn_loc: 0.003793  time: 1.2729  data_time: 0.0071  lr: 1.2764e-05  max_mem: 19009M
[01/31 02:08:56] d2.utils.events INFO:  eta: 3:24:35  iter: 319  total_loss: 0.7449  loss_cls: 0.5293  loss_box_reg: 0.1575  loss_rpn_cls: 0.03953  loss_rpn_loc: 0.003436  time: 1.2727  data_time: 0.0076  lr: 1.3484e-05  max_mem: 19009M
[01/31 02:09:21] d2.utils.events INFO:  eta: 3:24:07  iter: 339  total_loss: 0.7167  loss_cls: 0.5821  loss_box_reg: 0.104  loss_rpn_cls: 0.04073  loss_rpn_loc: 0.005099  time: 1.2727  data_time: 0.0074  lr: 1.4204e-05  max_mem: 19009M
[01/31 02:09:47] d2.utils.events INFO:  eta: 3:23:43  iter: 359  total_loss: 0.7395  loss_cls: 0.5436  loss_box_reg: 0.1447  loss_rpn_cls: 0.03751  loss_rpn_loc: 0.004242  time: 1.2733  data_time: 0.0077  lr: 1.4924e-05  max_mem: 19009M
[01/31 02:10:13] d2.utils.events INFO:  eta: 3:23:18  iter: 379  total_loss: 0.7399  loss_cls: 0.5752  loss_box_reg: 0.1206  loss_rpn_cls: 0.03504  loss_rpn_loc: 0.00291  time: 1.2733  data_time: 0.0075  lr: 1.5644e-05  max_mem: 19009M
[01/31 02:10:38] d2.utils.events INFO:  eta: 3:22:51  iter: 399  total_loss: 0.6521  loss_cls: 0.4877  loss_box_reg: 0.1076  loss_rpn_cls: 0.02766  loss_rpn_loc: 0.002557  time: 1.2731  data_time: 0.0075  lr: 1.6364e-05  max_mem: 19009M
[01/31 02:11:03] d2.utils.events INFO:  eta: 3:22:24  iter: 419  total_loss: 0.7223  loss_cls: 0.5444  loss_box_reg: 0.1313  loss_rpn_cls: 0.02995  loss_rpn_loc: 0.002121  time: 1.2729  data_time: 0.0073  lr: 1.7084e-05  max_mem: 19009M
[01/31 02:11:29] d2.utils.events INFO:  eta: 3:21:59  iter: 439  total_loss: 0.6719  loss_cls: 0.5492  loss_box_reg: 0.1131  loss_rpn_cls: 0.02985  loss_rpn_loc: 0.003195  time: 1.2729  data_time: 0.0074  lr: 1.7804e-05  max_mem: 19009M
[01/31 02:11:54] d2.utils.events INFO:  eta: 3:21:31  iter: 459  total_loss: 0.7136  loss_cls: 0.4888  loss_box_reg: 0.1875  loss_rpn_cls: 0.03221  loss_rpn_loc: 0.003817  time: 1.2726  data_time: 0.0075  lr: 1.8524e-05  max_mem: 19009M
[01/31 02:12:20] d2.utils.events INFO:  eta: 3:21:10  iter: 479  total_loss: 0.6765  loss_cls: 0.5511  loss_box_reg: 0.09316  loss_rpn_cls: 0.03432  loss_rpn_loc: 0.003718  time: 1.2729  data_time: 0.0080  lr: 1.9244e-05  max_mem: 19009M
[01/31 02:12:46] d2.utils.events INFO:  eta: 3:20:44  iter: 499  total_loss: 0.6488  loss_cls: 0.5212  loss_box_reg: 0.09972  loss_rpn_cls: 0.03639  loss_rpn_loc: 0.003761  time: 1.2729  data_time: 0.0075  lr: 1.9964e-05  max_mem: 19009M
[01/31 02:13:11] d2.utils.events INFO:  eta: 3:20:15  iter: 519  total_loss: 0.6938  loss_cls: 0.5223  loss_box_reg: 0.1492  loss_rpn_cls: 0.03214  loss_rpn_loc: 0.003194  time: 1.2726  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:13:36] d2.utils.events INFO:  eta: 3:19:52  iter: 539  total_loss: 0.6733  loss_cls: 0.487  loss_box_reg: 0.09462  loss_rpn_cls: 0.02811  loss_rpn_loc: 0.002668  time: 1.2726  data_time: 0.0072  lr: 2e-05  max_mem: 19009M
[01/31 02:14:02] d2.utils.events INFO:  eta: 3:19:25  iter: 559  total_loss: 0.6658  loss_cls: 0.4956  loss_box_reg: 0.1174  loss_rpn_cls: 0.02917  loss_rpn_loc: 0.003457  time: 1.2724  data_time: 0.0071  lr: 2e-05  max_mem: 19009M
[01/31 02:14:27] d2.utils.events INFO:  eta: 3:19:03  iter: 579  total_loss: 0.6865  loss_cls: 0.5171  loss_box_reg: 0.1302  loss_rpn_cls: 0.03204  loss_rpn_loc: 0.003312  time: 1.2724  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:14:53] d2.utils.events INFO:  eta: 3:18:38  iter: 599  total_loss: 0.6469  loss_cls: 0.5104  loss_box_reg: 0.1327  loss_rpn_cls: 0.02699  loss_rpn_loc: 0.002644  time: 1.2725  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:15:18] d2.utils.events INFO:  eta: 3:18:12  iter: 619  total_loss: 0.66  loss_cls: 0.5344  loss_box_reg: 0.09593  loss_rpn_cls: 0.02731  loss_rpn_loc: 0.004423  time: 1.2724  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:15:44] d2.utils.events INFO:  eta: 3:17:50  iter: 639  total_loss: 0.6761  loss_cls: 0.5101  loss_box_reg: 0.1096  loss_rpn_cls: 0.02725  loss_rpn_loc: 0.003037  time: 1.2728  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:16:10] d2.utils.events INFO:  eta: 3:17:25  iter: 659  total_loss: 0.6796  loss_cls: 0.5479  loss_box_reg: 0.07881  loss_rpn_cls: 0.02995  loss_rpn_loc: 0.00453  time: 1.2730  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:16:35] d2.utils.events INFO:  eta: 3:17:00  iter: 679  total_loss: 0.6437  loss_cls: 0.4607  loss_box_reg: 0.124  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.003545  time: 1.2732  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:17:01] d2.utils.events INFO:  eta: 3:16:35  iter: 699  total_loss: 0.6939  loss_cls: 0.5355  loss_box_reg: 0.1034  loss_rpn_cls: 0.02564  loss_rpn_loc: 0.004661  time: 1.2732  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:17:26] d2.utils.events INFO:  eta: 3:16:09  iter: 719  total_loss: 0.6493  loss_cls: 0.4823  loss_box_reg: 0.125  loss_rpn_cls: 0.02358  loss_rpn_loc: 0.002067  time: 1.2731  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:17:52] d2.utils.events INFO:  eta: 3:15:41  iter: 739  total_loss: 0.6604  loss_cls: 0.504  loss_box_reg: 0.08097  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.004396  time: 1.2728  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:18:17] d2.utils.events INFO:  eta: 3:15:15  iter: 759  total_loss: 0.6701  loss_cls: 0.5672  loss_box_reg: 0.0895  loss_rpn_cls: 0.02028  loss_rpn_loc: 0.002613  time: 1.2728  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:18:43] d2.utils.events INFO:  eta: 3:14:49  iter: 779  total_loss: 0.6298  loss_cls: 0.4632  loss_box_reg: 0.1264  loss_rpn_cls: 0.01991  loss_rpn_loc: 0.002944  time: 1.2730  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:19:08] d2.utils.events INFO:  eta: 3:14:24  iter: 799  total_loss: 0.6695  loss_cls: 0.5465  loss_box_reg: 0.08074  loss_rpn_cls: 0.02562  loss_rpn_loc: 0.003651  time: 1.2729  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:19:34] d2.utils.events INFO:  eta: 3:13:58  iter: 819  total_loss: 0.6229  loss_cls: 0.5033  loss_box_reg: 0.1119  loss_rpn_cls: 0.02685  loss_rpn_loc: 0.003965  time: 1.2730  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:19:59] d2.utils.events INFO:  eta: 3:13:33  iter: 839  total_loss: 0.6212  loss_cls: 0.4932  loss_box_reg: 0.08826  loss_rpn_cls: 0.02736  loss_rpn_loc: 0.004248  time: 1.2729  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:20:25] d2.utils.events INFO:  eta: 3:13:07  iter: 859  total_loss: 0.6475  loss_cls: 0.4959  loss_box_reg: 0.08377  loss_rpn_cls: 0.02832  loss_rpn_loc: 0.004145  time: 1.2729  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:20:50] d2.utils.events INFO:  eta: 3:12:40  iter: 879  total_loss: 0.6482  loss_cls: 0.4971  loss_box_reg: 0.142  loss_rpn_cls: 0.02406  loss_rpn_loc: 0.004164  time: 1.2729  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:21:16] d2.utils.events INFO:  eta: 3:12:14  iter: 899  total_loss: 0.592  loss_cls: 0.4904  loss_box_reg: 0.1018  loss_rpn_cls: 0.02072  loss_rpn_loc: 0.003878  time: 1.2728  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:21:41] d2.utils.events INFO:  eta: 3:11:47  iter: 919  total_loss: 0.6205  loss_cls: 0.4797  loss_box_reg: 0.1149  loss_rpn_cls: 0.02443  loss_rpn_loc: 0.003657  time: 1.2727  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:22:07] d2.utils.events INFO:  eta: 3:11:21  iter: 939  total_loss: 0.6501  loss_cls: 0.4483  loss_box_reg: 0.09853  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.002553  time: 1.2727  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:22:32] d2.utils.events INFO:  eta: 3:10:56  iter: 959  total_loss: 0.6193  loss_cls: 0.4761  loss_box_reg: 0.1098  loss_rpn_cls: 0.02015  loss_rpn_loc: 0.003357  time: 1.2727  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:22:58] d2.utils.events INFO:  eta: 3:10:32  iter: 979  total_loss: 0.6253  loss_cls: 0.5029  loss_box_reg: 0.1008  loss_rpn_cls: 0.02293  loss_rpn_loc: 0.003674  time: 1.2729  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:23:24] d2.utils.events INFO:  eta: 3:10:07  iter: 999  total_loss: 0.6046  loss_cls: 0.4049  loss_box_reg: 0.1555  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.003756  time: 1.2728  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:23:49] d2.utils.events INFO:  eta: 3:09:44  iter: 1019  total_loss: 0.639  loss_cls: 0.42  loss_box_reg: 0.1255  loss_rpn_cls: 0.02081  loss_rpn_loc: 0.003111  time: 1.2728  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:24:15] d2.utils.events INFO:  eta: 3:09:21  iter: 1039  total_loss: 0.5936  loss_cls: 0.445  loss_box_reg: 0.1414  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.003244  time: 1.2730  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:24:40] d2.utils.events INFO:  eta: 3:08:56  iter: 1059  total_loss: 0.6037  loss_cls: 0.4642  loss_box_reg: 0.1212  loss_rpn_cls: 0.02363  loss_rpn_loc: 0.003869  time: 1.2729  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:25:06] d2.utils.events INFO:  eta: 3:08:29  iter: 1079  total_loss: 0.6388  loss_cls: 0.5014  loss_box_reg: 0.1233  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.00468  time: 1.2728  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:25:31] d2.utils.events INFO:  eta: 3:08:02  iter: 1099  total_loss: 0.6413  loss_cls: 0.4754  loss_box_reg: 0.1028  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.003665  time: 1.2727  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:25:57] d2.utils.events INFO:  eta: 3:07:35  iter: 1119  total_loss: 0.6749  loss_cls: 0.4447  loss_box_reg: 0.1079  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.003049  time: 1.2728  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:26:22] d2.utils.events INFO:  eta: 3:07:09  iter: 1139  total_loss: 0.6082  loss_cls: 0.425  loss_box_reg: 0.153  loss_rpn_cls: 0.0189  loss_rpn_loc: 0.002536  time: 1.2727  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:26:47] d2.utils.events INFO:  eta: 3:06:44  iter: 1159  total_loss: 0.6422  loss_cls: 0.5087  loss_box_reg: 0.1017  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.002959  time: 1.2726  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:27:13] d2.utils.events INFO:  eta: 3:06:19  iter: 1179  total_loss: 0.6403  loss_cls: 0.484  loss_box_reg: 0.1339  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.004729  time: 1.2726  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:27:38] d2.utils.events INFO:  eta: 3:05:56  iter: 1199  total_loss: 0.6128  loss_cls: 0.4352  loss_box_reg: 0.1162  loss_rpn_cls: 0.01758  loss_rpn_loc: 0.003366  time: 1.2726  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:28:04] d2.utils.events INFO:  eta: 3:05:29  iter: 1219  total_loss: 0.6427  loss_cls: 0.4644  loss_box_reg: 0.1051  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.003389  time: 1.2726  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:28:29] d2.utils.events INFO:  eta: 3:05:02  iter: 1239  total_loss: 0.6214  loss_cls: 0.4888  loss_box_reg: 0.1129  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.002882  time: 1.2726  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:28:55] d2.utils.events INFO:  eta: 3:04:37  iter: 1259  total_loss: 0.6596  loss_cls: 0.4734  loss_box_reg: 0.1273  loss_rpn_cls: 0.01756  loss_rpn_loc: 0.002963  time: 1.2726  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:29:20] d2.utils.events INFO:  eta: 3:04:10  iter: 1279  total_loss: 0.629  loss_cls: 0.4541  loss_box_reg: 0.1258  loss_rpn_cls: 0.02225  loss_rpn_loc: 0.002673  time: 1.2726  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:29:46] d2.utils.events INFO:  eta: 3:03:46  iter: 1299  total_loss: 0.6058  loss_cls: 0.435  loss_box_reg: 0.1123  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.00373  time: 1.2726  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:30:12] d2.utils.events INFO:  eta: 3:03:21  iter: 1319  total_loss: 0.6273  loss_cls: 0.4809  loss_box_reg: 0.1347  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.003252  time: 1.2727  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:30:37] d2.utils.events INFO:  eta: 3:02:55  iter: 1339  total_loss: 0.5942  loss_cls: 0.4384  loss_box_reg: 0.1564  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.002805  time: 1.2726  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:31:02] d2.utils.events INFO:  eta: 3:02:29  iter: 1359  total_loss: 0.627  loss_cls: 0.4718  loss_box_reg: 0.1446  loss_rpn_cls: 0.02162  loss_rpn_loc: 0.004149  time: 1.2726  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:31:28] d2.utils.events INFO:  eta: 3:02:02  iter: 1379  total_loss: 0.6038  loss_cls: 0.4674  loss_box_reg: 0.1145  loss_rpn_cls: 0.01945  loss_rpn_loc: 0.003595  time: 1.2725  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:31:53] d2.utils.events INFO:  eta: 3:01:38  iter: 1399  total_loss: 0.5861  loss_cls: 0.5233  loss_box_reg: 0.102  loss_rpn_cls: 0.0187  loss_rpn_loc: 0.003175  time: 1.2725  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:32:19] d2.utils.events INFO:  eta: 3:01:13  iter: 1419  total_loss: 0.6727  loss_cls: 0.4621  loss_box_reg: 0.1729  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.002816  time: 1.2724  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:32:44] d2.utils.events INFO:  eta: 3:00:47  iter: 1439  total_loss: 0.6492  loss_cls: 0.4611  loss_box_reg: 0.1543  loss_rpn_cls: 0.01804  loss_rpn_loc: 0.00233  time: 1.2723  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:33:09] d2.utils.events INFO:  eta: 3:00:21  iter: 1459  total_loss: 0.5782  loss_cls: 0.3833  loss_box_reg: 0.1365  loss_rpn_cls: 0.01733  loss_rpn_loc: 0.002844  time: 1.2722  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:33:35] d2.utils.events INFO:  eta: 2:59:53  iter: 1479  total_loss: 0.5883  loss_cls: 0.4184  loss_box_reg: 0.1737  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.002686  time: 1.2721  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:34:00] d2.utils.events INFO:  eta: 2:59:28  iter: 1499  total_loss: 0.6015  loss_cls: 0.452  loss_box_reg: 0.1634  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.002491  time: 1.2720  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:34:26] d2.utils.events INFO:  eta: 2:59:04  iter: 1519  total_loss: 0.6232  loss_cls: 0.4448  loss_box_reg: 0.1395  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.002881  time: 1.2720  data_time: 0.0084  lr: 2e-05  max_mem: 19009M
[01/31 02:34:51] d2.utils.events INFO:  eta: 2:58:38  iter: 1539  total_loss: 0.6585  loss_cls: 0.4591  loss_box_reg: 0.1448  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.00376  time: 1.2719  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 02:35:16] d2.utils.events INFO:  eta: 2:58:12  iter: 1559  total_loss: 0.5937  loss_cls: 0.4604  loss_box_reg: 0.1082  loss_rpn_cls: 0.01922  loss_rpn_loc: 0.003846  time: 1.2718  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:35:42] d2.utils.events INFO:  eta: 2:57:44  iter: 1579  total_loss: 0.5823  loss_cls: 0.4174  loss_box_reg: 0.1151  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.003356  time: 1.2716  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:36:07] d2.utils.events INFO:  eta: 2:57:17  iter: 1599  total_loss: 0.608  loss_cls: 0.4116  loss_box_reg: 0.16  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.002919  time: 1.2715  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:36:32] d2.utils.events INFO:  eta: 2:56:52  iter: 1619  total_loss: 0.6167  loss_cls: 0.4592  loss_box_reg: 0.1382  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.002839  time: 1.2715  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 02:36:58] d2.utils.events INFO:  eta: 2:56:26  iter: 1639  total_loss: 0.6108  loss_cls: 0.5202  loss_box_reg: 0.08767  loss_rpn_cls: 0.01939  loss_rpn_loc: 0.002924  time: 1.2715  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 02:37:23] d2.utils.events INFO:  eta: 2:56:01  iter: 1659  total_loss: 0.5969  loss_cls: 0.4479  loss_box_reg: 0.11  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.004201  time: 1.2715  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:37:49] d2.utils.events INFO:  eta: 2:55:35  iter: 1679  total_loss: 0.7005  loss_cls: 0.4818  loss_box_reg: 0.1364  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.007014  time: 1.2714  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:38:14] d2.utils.events INFO:  eta: 2:55:09  iter: 1699  total_loss: 0.5815  loss_cls: 0.467  loss_box_reg: 0.09533  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.003536  time: 1.2714  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:38:39] d2.utils.events INFO:  eta: 2:54:42  iter: 1719  total_loss: 0.6418  loss_cls: 0.4727  loss_box_reg: 0.1134  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.00369  time: 1.2713  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:39:05] d2.utils.events INFO:  eta: 2:54:18  iter: 1739  total_loss: 0.6001  loss_cls: 0.4427  loss_box_reg: 0.1196  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.002949  time: 1.2712  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 02:39:30] d2.utils.events INFO:  eta: 2:53:53  iter: 1759  total_loss: 0.5739  loss_cls: 0.4324  loss_box_reg: 0.1291  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.002892  time: 1.2712  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:39:56] d2.utils.events INFO:  eta: 2:53:27  iter: 1779  total_loss: 0.6475  loss_cls: 0.4055  loss_box_reg: 0.1694  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.002675  time: 1.2711  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:40:21] d2.utils.events INFO:  eta: 2:53:02  iter: 1799  total_loss: 0.5525  loss_cls: 0.4609  loss_box_reg: 0.08541  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.003147  time: 1.2711  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:40:47] d2.utils.events INFO:  eta: 2:52:36  iter: 1819  total_loss: 0.5462  loss_cls: 0.415  loss_box_reg: 0.1158  loss_rpn_cls: 0.01806  loss_rpn_loc: 0.0025  time: 1.2711  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 02:41:12] d2.utils.events INFO:  eta: 2:52:10  iter: 1839  total_loss: 0.5685  loss_cls: 0.4302  loss_box_reg: 0.1245  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.002779  time: 1.2710  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:41:37] d2.utils.events INFO:  eta: 2:51:44  iter: 1859  total_loss: 0.5537  loss_cls: 0.4046  loss_box_reg: 0.1002  loss_rpn_cls: 0.01658  loss_rpn_loc: 0.002702  time: 1.2710  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:42:03] d2.utils.events INFO:  eta: 2:51:20  iter: 1879  total_loss: 0.6078  loss_cls: 0.4439  loss_box_reg: 0.1147  loss_rpn_cls: 0.0243  loss_rpn_loc: 0.00375  time: 1.2709  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:42:28] d2.utils.events INFO:  eta: 2:50:54  iter: 1899  total_loss: 0.584  loss_cls: 0.4258  loss_box_reg: 0.1048  loss_rpn_cls: 0.01915  loss_rpn_loc: 0.006463  time: 1.2708  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:42:53] d2.utils.events INFO:  eta: 2:50:29  iter: 1919  total_loss: 0.5799  loss_cls: 0.4076  loss_box_reg: 0.1301  loss_rpn_cls: 0.01782  loss_rpn_loc: 0.002482  time: 1.2708  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:43:19] d2.utils.events INFO:  eta: 2:50:03  iter: 1939  total_loss: 0.5922  loss_cls: 0.4219  loss_box_reg: 0.1248  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.002667  time: 1.2707  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:43:44] d2.utils.events INFO:  eta: 2:49:37  iter: 1959  total_loss: 0.5785  loss_cls: 0.4126  loss_box_reg: 0.1352  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.00407  time: 1.2706  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:44:10] d2.utils.events INFO:  eta: 2:49:11  iter: 1979  total_loss: 0.5717  loss_cls: 0.4184  loss_box_reg: 0.1038  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.003577  time: 1.2706  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:44:35] d2.utils.events INFO:  eta: 2:48:46  iter: 1999  total_loss: 0.6091  loss_cls: 0.434  loss_box_reg: 0.1062  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.002933  time: 1.2706  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 02:45:00] d2.utils.events INFO:  eta: 2:48:19  iter: 2019  total_loss: 0.6688  loss_cls: 0.4944  loss_box_reg: 0.1311  loss_rpn_cls: 0.01792  loss_rpn_loc: 0.003533  time: 1.2706  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:45:26] d2.utils.events INFO:  eta: 2:47:53  iter: 2039  total_loss: 0.6024  loss_cls: 0.4584  loss_box_reg: 0.1394  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.002508  time: 1.2706  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:45:51] d2.utils.events INFO:  eta: 2:47:29  iter: 2059  total_loss: 0.6236  loss_cls: 0.4789  loss_box_reg: 0.1008  loss_rpn_cls: 0.0168  loss_rpn_loc: 0.002708  time: 1.2705  data_time: 0.0084  lr: 2e-05  max_mem: 19009M
[01/31 02:46:17] d2.utils.events INFO:  eta: 2:47:04  iter: 2079  total_loss: 0.6491  loss_cls: 0.5369  loss_box_reg: 0.1012  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.002637  time: 1.2705  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:46:42] d2.utils.events INFO:  eta: 2:46:38  iter: 2099  total_loss: 0.5554  loss_cls: 0.4323  loss_box_reg: 0.1094  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.003192  time: 1.2704  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:47:07] d2.utils.events INFO:  eta: 2:46:11  iter: 2119  total_loss: 0.5704  loss_cls: 0.4198  loss_box_reg: 0.1444  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.003025  time: 1.2703  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:47:32] d2.utils.events INFO:  eta: 2:45:44  iter: 2139  total_loss: 0.5445  loss_cls: 0.3768  loss_box_reg: 0.109  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.003055  time: 1.2703  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:47:58] d2.utils.events INFO:  eta: 2:45:17  iter: 2159  total_loss: 0.5579  loss_cls: 0.3998  loss_box_reg: 0.1151  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.00298  time: 1.2702  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:48:23] d2.utils.events INFO:  eta: 2:44:51  iter: 2179  total_loss: 0.6093  loss_cls: 0.4246  loss_box_reg: 0.1195  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.002705  time: 1.2701  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:48:48] d2.utils.events INFO:  eta: 2:44:25  iter: 2199  total_loss: 0.6112  loss_cls: 0.5138  loss_box_reg: 0.08514  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.003815  time: 1.2700  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:49:14] d2.utils.events INFO:  eta: 2:43:59  iter: 2219  total_loss: 0.5723  loss_cls: 0.4725  loss_box_reg: 0.1032  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.001978  time: 1.2700  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:49:39] d2.utils.events INFO:  eta: 2:43:33  iter: 2239  total_loss: 0.5531  loss_cls: 0.4498  loss_box_reg: 0.1232  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.001904  time: 1.2700  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:50:04] d2.utils.events INFO:  eta: 2:43:07  iter: 2259  total_loss: 0.5581  loss_cls: 0.406  loss_box_reg: 0.1087  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.002229  time: 1.2699  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:50:30] d2.utils.events INFO:  eta: 2:42:42  iter: 2279  total_loss: 0.5668  loss_cls: 0.4131  loss_box_reg: 0.1004  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.002966  time: 1.2699  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:50:55] d2.utils.events INFO:  eta: 2:42:17  iter: 2299  total_loss: 0.6081  loss_cls: 0.4774  loss_box_reg: 0.1063  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.002627  time: 1.2699  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:51:21] d2.utils.events INFO:  eta: 2:41:51  iter: 2319  total_loss: 0.5423  loss_cls: 0.4351  loss_box_reg: 0.09435  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.002954  time: 1.2699  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:51:46] d2.utils.events INFO:  eta: 2:41:25  iter: 2339  total_loss: 0.5661  loss_cls: 0.4547  loss_box_reg: 0.0957  loss_rpn_cls: 0.01522  loss_rpn_loc: 0.002894  time: 1.2698  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:52:11] d2.utils.events INFO:  eta: 2:40:59  iter: 2359  total_loss: 0.5919  loss_cls: 0.4402  loss_box_reg: 0.1034  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.003586  time: 1.2697  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:52:37] d2.utils.events INFO:  eta: 2:40:33  iter: 2379  total_loss: 0.5995  loss_cls: 0.4613  loss_box_reg: 0.0993  loss_rpn_cls: 0.01832  loss_rpn_loc: 0.003062  time: 1.2697  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:53:02] d2.utils.events INFO:  eta: 2:40:08  iter: 2399  total_loss: 0.5861  loss_cls: 0.4682  loss_box_reg: 0.09334  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.003657  time: 1.2697  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 02:53:27] d2.utils.events INFO:  eta: 2:39:41  iter: 2419  total_loss: 0.4697  loss_cls: 0.3406  loss_box_reg: 0.1058  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.002656  time: 1.2696  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:53:53] d2.utils.events INFO:  eta: 2:39:16  iter: 2439  total_loss: 0.6  loss_cls: 0.4474  loss_box_reg: 0.09462  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.004138  time: 1.2696  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:54:18] d2.utils.events INFO:  eta: 2:38:52  iter: 2459  total_loss: 0.5228  loss_cls: 0.4053  loss_box_reg: 0.1055  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.002519  time: 1.2696  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:54:44] d2.utils.events INFO:  eta: 2:38:27  iter: 2479  total_loss: 0.6047  loss_cls: 0.4255  loss_box_reg: 0.08874  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.002066  time: 1.2695  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:55:09] d2.utils.events INFO:  eta: 2:38:01  iter: 2499  total_loss: 0.5776  loss_cls: 0.4783  loss_box_reg: 0.07623  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.002935  time: 1.2695  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 02:55:34] d2.utils.events INFO:  eta: 2:37:34  iter: 2519  total_loss: 0.5257  loss_cls: 0.4085  loss_box_reg: 0.1095  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.002091  time: 1.2694  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 02:55:59] d2.utils.events INFO:  eta: 2:37:08  iter: 2539  total_loss: 0.5048  loss_cls: 0.3343  loss_box_reg: 0.1169  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.002476  time: 1.2693  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 02:56:25] d2.utils.events INFO:  eta: 2:36:43  iter: 2559  total_loss: 0.5499  loss_cls: 0.3677  loss_box_reg: 0.132  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.00288  time: 1.2693  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:56:50] d2.utils.events INFO:  eta: 2:36:19  iter: 2579  total_loss: 0.5464  loss_cls: 0.4115  loss_box_reg: 0.1138  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.003521  time: 1.2693  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:57:16] d2.utils.events INFO:  eta: 2:35:54  iter: 2599  total_loss: 0.5956  loss_cls: 0.4571  loss_box_reg: 0.1032  loss_rpn_cls: 0.01628  loss_rpn_loc: 0.003149  time: 1.2693  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:57:41] d2.utils.events INFO:  eta: 2:35:28  iter: 2619  total_loss: 0.5734  loss_cls: 0.4491  loss_box_reg: 0.09105  loss_rpn_cls: 0.02016  loss_rpn_loc: 0.004736  time: 1.2693  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 02:58:06] d2.utils.events INFO:  eta: 2:35:02  iter: 2639  total_loss: 0.4789  loss_cls: 0.3688  loss_box_reg: 0.08969  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.003643  time: 1.2692  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:58:32] d2.utils.events INFO:  eta: 2:34:36  iter: 2659  total_loss: 0.5762  loss_cls: 0.4364  loss_box_reg: 0.0899  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.004276  time: 1.2692  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 02:58:57] d2.utils.events INFO:  eta: 2:34:11  iter: 2679  total_loss: 0.5668  loss_cls: 0.3814  loss_box_reg: 0.1352  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.003301  time: 1.2692  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 02:59:22] d2.utils.events INFO:  eta: 2:33:45  iter: 2699  total_loss: 0.541  loss_cls: 0.4247  loss_box_reg: 0.08244  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.002444  time: 1.2691  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 02:59:48] d2.utils.events INFO:  eta: 2:33:21  iter: 2719  total_loss: 0.517  loss_cls: 0.3918  loss_box_reg: 0.1079  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.003112  time: 1.2691  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:00:13] d2.utils.events INFO:  eta: 2:32:55  iter: 2739  total_loss: 0.5749  loss_cls: 0.4099  loss_box_reg: 0.09938  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.002746  time: 1.2691  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 03:00:39] d2.utils.events INFO:  eta: 2:32:30  iter: 2759  total_loss: 0.5303  loss_cls: 0.4072  loss_box_reg: 0.08223  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.002981  time: 1.2691  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:01:04] d2.utils.events INFO:  eta: 2:32:05  iter: 2779  total_loss: 0.5462  loss_cls: 0.4047  loss_box_reg: 0.1168  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.002618  time: 1.2691  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:01:29] d2.utils.events INFO:  eta: 2:31:39  iter: 2799  total_loss: 0.584  loss_cls: 0.4124  loss_box_reg: 0.09255  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.004045  time: 1.2691  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:01:55] d2.utils.events INFO:  eta: 2:31:13  iter: 2819  total_loss: 0.5526  loss_cls: 0.434  loss_box_reg: 0.1127  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.002441  time: 1.2690  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:02:20] d2.utils.events INFO:  eta: 2:30:48  iter: 2839  total_loss: 0.5839  loss_cls: 0.3876  loss_box_reg: 0.07419  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.002438  time: 1.2690  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:02:45] d2.utils.events INFO:  eta: 2:30:23  iter: 2859  total_loss: 0.5872  loss_cls: 0.4475  loss_box_reg: 0.07999  loss_rpn_cls: 0.01985  loss_rpn_loc: 0.003859  time: 1.2690  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:03:11] d2.utils.events INFO:  eta: 2:29:57  iter: 2879  total_loss: 0.5506  loss_cls: 0.4478  loss_box_reg: 0.09538  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.002719  time: 1.2690  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:03:36] d2.utils.events INFO:  eta: 2:29:32  iter: 2899  total_loss: 0.5367  loss_cls: 0.4027  loss_box_reg: 0.1096  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.002221  time: 1.2689  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:04:02] d2.utils.events INFO:  eta: 2:29:07  iter: 2919  total_loss: 0.5551  loss_cls: 0.4043  loss_box_reg: 0.08922  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.002859  time: 1.2689  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:04:27] d2.utils.events INFO:  eta: 2:28:42  iter: 2939  total_loss: 0.5723  loss_cls: 0.4393  loss_box_reg: 0.08248  loss_rpn_cls: 0.01555  loss_rpn_loc: 0.002996  time: 1.2689  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 03:04:52] d2.utils.events INFO:  eta: 2:28:17  iter: 2959  total_loss: 0.5655  loss_cls: 0.4344  loss_box_reg: 0.08122  loss_rpn_cls: 0.01592  loss_rpn_loc: 0.003323  time: 1.2689  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:05:18] d2.utils.events INFO:  eta: 2:27:51  iter: 2979  total_loss: 0.5067  loss_cls: 0.3847  loss_box_reg: 0.1033  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.002468  time: 1.2688  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:05:43] d2.utils.events INFO:  eta: 2:27:25  iter: 2999  total_loss: 0.5717  loss_cls: 0.412  loss_box_reg: 0.1154  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.002939  time: 1.2688  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 03:06:08] d2.utils.events INFO:  eta: 2:27:01  iter: 3019  total_loss: 0.5568  loss_cls: 0.3624  loss_box_reg: 0.09523  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.002286  time: 1.2688  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:06:34] d2.utils.events INFO:  eta: 2:26:35  iter: 3039  total_loss: 0.5557  loss_cls: 0.4363  loss_box_reg: 0.1054  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.00241  time: 1.2688  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:06:59] d2.utils.events INFO:  eta: 2:26:10  iter: 3059  total_loss: 0.5733  loss_cls: 0.4181  loss_box_reg: 0.1125  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.003326  time: 1.2688  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:07:25] d2.utils.events INFO:  eta: 2:25:45  iter: 3079  total_loss: 0.5211  loss_cls: 0.3936  loss_box_reg: 0.1079  loss_rpn_cls: 0.01542  loss_rpn_loc: 0.002524  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:07:50] d2.utils.events INFO:  eta: 2:25:20  iter: 3099  total_loss: 0.546  loss_cls: 0.4046  loss_box_reg: 0.08202  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.002314  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:08:15] d2.utils.events INFO:  eta: 2:24:55  iter: 3119  total_loss: 0.5583  loss_cls: 0.4801  loss_box_reg: 0.07728  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.003058  time: 1.2687  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:08:41] d2.utils.events INFO:  eta: 2:24:31  iter: 3139  total_loss: 0.5606  loss_cls: 0.4311  loss_box_reg: 0.1038  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.002794  time: 1.2687  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:09:06] d2.utils.events INFO:  eta: 2:24:06  iter: 3159  total_loss: 0.5698  loss_cls: 0.4227  loss_box_reg: 0.08021  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.003899  time: 1.2687  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:09:32] d2.utils.events INFO:  eta: 2:23:42  iter: 3179  total_loss: 0.5973  loss_cls: 0.4502  loss_box_reg: 0.1117  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.004388  time: 1.2687  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:09:57] d2.utils.events INFO:  eta: 2:23:18  iter: 3199  total_loss: 0.525  loss_cls: 0.3885  loss_box_reg: 0.0976  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.002188  time: 1.2687  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:10:23] d2.utils.events INFO:  eta: 2:22:54  iter: 3219  total_loss: 0.529  loss_cls: 0.3809  loss_box_reg: 0.09852  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.002684  time: 1.2688  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:10:48] d2.utils.events INFO:  eta: 2:22:29  iter: 3239  total_loss: 0.6204  loss_cls: 0.4213  loss_box_reg: 0.1348  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.002669  time: 1.2687  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:11:13] d2.utils.events INFO:  eta: 2:22:04  iter: 3259  total_loss: 0.5602  loss_cls: 0.4503  loss_box_reg: 0.1077  loss_rpn_cls: 0.01917  loss_rpn_loc: 0.002681  time: 1.2687  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:11:39] d2.utils.events INFO:  eta: 2:21:40  iter: 3279  total_loss: 0.5741  loss_cls: 0.4457  loss_box_reg: 0.117  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.003738  time: 1.2688  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:12:04] d2.utils.events INFO:  eta: 2:21:14  iter: 3299  total_loss: 0.5358  loss_cls: 0.4252  loss_box_reg: 0.09234  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.002051  time: 1.2688  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:12:30] d2.utils.events INFO:  eta: 2:20:51  iter: 3319  total_loss: 0.5815  loss_cls: 0.4543  loss_box_reg: 0.09391  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.003146  time: 1.2688  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:12:55] d2.utils.events INFO:  eta: 2:20:26  iter: 3339  total_loss: 0.5101  loss_cls: 0.4188  loss_box_reg: 0.08151  loss_rpn_cls: 0.01038  loss_rpn_loc: 0.001885  time: 1.2688  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:13:21] d2.utils.events INFO:  eta: 2:20:02  iter: 3359  total_loss: 0.4981  loss_cls: 0.3675  loss_box_reg: 0.1162  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.002108  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:13:46] d2.utils.events INFO:  eta: 2:19:38  iter: 3379  total_loss: 0.5371  loss_cls: 0.4311  loss_box_reg: 0.09465  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.003419  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:14:11] d2.utils.events INFO:  eta: 2:19:13  iter: 3399  total_loss: 0.5782  loss_cls: 0.4282  loss_box_reg: 0.08835  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.003426  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:14:37] d2.utils.events INFO:  eta: 2:18:48  iter: 3419  total_loss: 0.5782  loss_cls: 0.3799  loss_box_reg: 0.1052  loss_rpn_cls: 0.02005  loss_rpn_loc: 0.003759  time: 1.2688  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:15:02] d2.utils.events INFO:  eta: 2:18:23  iter: 3439  total_loss: 0.5056  loss_cls: 0.3706  loss_box_reg: 0.09466  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.002225  time: 1.2687  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:15:28] d2.utils.events INFO:  eta: 2:17:58  iter: 3459  total_loss: 0.5252  loss_cls: 0.4155  loss_box_reg: 0.06083  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.00322  time: 1.2687  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:15:53] d2.utils.events INFO:  eta: 2:17:32  iter: 3479  total_loss: 0.5516  loss_cls: 0.3728  loss_box_reg: 0.1121  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.002489  time: 1.2687  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:16:18] d2.utils.events INFO:  eta: 2:17:07  iter: 3499  total_loss: 0.5061  loss_cls: 0.3633  loss_box_reg: 0.1217  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.002191  time: 1.2687  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:16:44] d2.utils.events INFO:  eta: 2:16:42  iter: 3519  total_loss: 0.6068  loss_cls: 0.4638  loss_box_reg: 0.1144  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.002969  time: 1.2686  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:17:09] d2.utils.events INFO:  eta: 2:16:18  iter: 3539  total_loss: 0.5471  loss_cls: 0.41  loss_box_reg: 0.07959  loss_rpn_cls: 0.01254  loss_rpn_loc: 0.001872  time: 1.2686  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:17:34] d2.utils.events INFO:  eta: 2:15:53  iter: 3559  total_loss: 0.5224  loss_cls: 0.3821  loss_box_reg: 0.1055  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.002624  time: 1.2686  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:18:00] d2.utils.events INFO:  eta: 2:15:28  iter: 3579  total_loss: 0.5227  loss_cls: 0.3661  loss_box_reg: 0.105  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.002828  time: 1.2686  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:18:25] d2.utils.events INFO:  eta: 2:15:02  iter: 3599  total_loss: 0.5183  loss_cls: 0.3776  loss_box_reg: 0.08096  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.002335  time: 1.2686  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:18:50] d2.utils.events INFO:  eta: 2:14:36  iter: 3619  total_loss: 0.5438  loss_cls: 0.4234  loss_box_reg: 0.1033  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.002447  time: 1.2686  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:19:16] d2.utils.events INFO:  eta: 2:14:10  iter: 3639  total_loss: 0.5557  loss_cls: 0.4171  loss_box_reg: 0.1068  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.00268  time: 1.2685  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:19:41] d2.utils.events INFO:  eta: 2:13:44  iter: 3659  total_loss: 0.5473  loss_cls: 0.3931  loss_box_reg: 0.1403  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.002482  time: 1.2685  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:20:06] d2.utils.events INFO:  eta: 2:13:18  iter: 3679  total_loss: 0.5435  loss_cls: 0.3972  loss_box_reg: 0.09375  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.001973  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:20:32] d2.utils.events INFO:  eta: 2:12:54  iter: 3699  total_loss: 0.5415  loss_cls: 0.4138  loss_box_reg: 0.1096  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.002223  time: 1.2685  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 03:20:57] d2.utils.events INFO:  eta: 2:12:28  iter: 3719  total_loss: 0.5061  loss_cls: 0.4085  loss_box_reg: 0.112  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.002364  time: 1.2685  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:21:23] d2.utils.events INFO:  eta: 2:12:03  iter: 3739  total_loss: 0.6318  loss_cls: 0.4741  loss_box_reg: 0.09015  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.004312  time: 1.2685  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:21:48] d2.utils.events INFO:  eta: 2:11:39  iter: 3759  total_loss: 0.5574  loss_cls: 0.4331  loss_box_reg: 0.1239  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.00321  time: 1.2685  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:22:13] d2.utils.events INFO:  eta: 2:11:14  iter: 3779  total_loss: 0.4759  loss_cls: 0.3661  loss_box_reg: 0.1081  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.002001  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:22:39] d2.utils.events INFO:  eta: 2:10:48  iter: 3799  total_loss: 0.5425  loss_cls: 0.3878  loss_box_reg: 0.1034  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.002292  time: 1.2685  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:23:04] d2.utils.events INFO:  eta: 2:10:24  iter: 3819  total_loss: 0.5401  loss_cls: 0.4139  loss_box_reg: 0.1289  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.002344  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:23:30] d2.utils.events INFO:  eta: 2:09:59  iter: 3839  total_loss: 0.4911  loss_cls: 0.4081  loss_box_reg: 0.07305  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.002159  time: 1.2685  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:23:55] d2.utils.events INFO:  eta: 2:09:34  iter: 3859  total_loss: 0.4965  loss_cls: 0.3921  loss_box_reg: 0.07311  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.002427  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:24:21] d2.utils.events INFO:  eta: 2:09:09  iter: 3879  total_loss: 0.568  loss_cls: 0.4534  loss_box_reg: 0.09742  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.002745  time: 1.2685  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:24:46] d2.utils.events INFO:  eta: 2:08:44  iter: 3899  total_loss: 0.5575  loss_cls: 0.385  loss_box_reg: 0.1018  loss_rpn_cls: 0.01445  loss_rpn_loc: 0.002719  time: 1.2685  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:25:11] d2.utils.events INFO:  eta: 2:08:19  iter: 3919  total_loss: 0.5559  loss_cls: 0.4122  loss_box_reg: 0.09046  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.002897  time: 1.2685  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:25:37] d2.utils.events INFO:  eta: 2:07:54  iter: 3939  total_loss: 0.554  loss_cls: 0.4083  loss_box_reg: 0.1084  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.003933  time: 1.2685  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:26:02] d2.utils.events INFO:  eta: 2:07:29  iter: 3959  total_loss: 0.5697  loss_cls: 0.4199  loss_box_reg: 0.1028  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.003108  time: 1.2685  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:26:28] d2.utils.events INFO:  eta: 2:07:04  iter: 3979  total_loss: 0.4954  loss_cls: 0.4173  loss_box_reg: 0.06393  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.002111  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:26:53] d2.utils.events INFO:  eta: 2:06:39  iter: 3999  total_loss: 0.5336  loss_cls: 0.3686  loss_box_reg: 0.08381  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.002422  time: 1.2685  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:27:18] d2.utils.events INFO:  eta: 2:06:13  iter: 4019  total_loss: 0.5668  loss_cls: 0.3916  loss_box_reg: 0.1005  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.002898  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:27:44] d2.utils.events INFO:  eta: 2:05:47  iter: 4039  total_loss: 0.4959  loss_cls: 0.373  loss_box_reg: 0.112  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.002724  time: 1.2684  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:28:09] d2.utils.events INFO:  eta: 2:05:22  iter: 4059  total_loss: 0.5106  loss_cls: 0.4283  loss_box_reg: 0.1162  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.002229  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:28:35] d2.utils.events INFO:  eta: 2:04:57  iter: 4079  total_loss: 0.5383  loss_cls: 0.3857  loss_box_reg: 0.08736  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.002421  time: 1.2684  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:29:00] d2.utils.events INFO:  eta: 2:04:31  iter: 4099  total_loss: 0.5559  loss_cls: 0.4053  loss_box_reg: 0.08169  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.002275  time: 1.2684  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:29:25] d2.utils.events INFO:  eta: 2:04:06  iter: 4119  total_loss: 0.5701  loss_cls: 0.4561  loss_box_reg: 0.08289  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.002488  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:29:51] d2.utils.events INFO:  eta: 2:03:40  iter: 4139  total_loss: 0.5536  loss_cls: 0.4031  loss_box_reg: 0.1018  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.002399  time: 1.2684  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:30:16] d2.utils.events INFO:  eta: 2:03:14  iter: 4159  total_loss: 0.5508  loss_cls: 0.4251  loss_box_reg: 0.0921  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.004626  time: 1.2684  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:30:41] d2.utils.events INFO:  eta: 2:02:49  iter: 4179  total_loss: 0.5293  loss_cls: 0.4056  loss_box_reg: 0.07961  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.002533  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:31:07] d2.utils.events INFO:  eta: 2:02:23  iter: 4199  total_loss: 0.5616  loss_cls: 0.385  loss_box_reg: 0.1023  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.003403  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:31:32] d2.utils.events INFO:  eta: 2:01:58  iter: 4219  total_loss: 0.4937  loss_cls: 0.3747  loss_box_reg: 0.09104  loss_rpn_cls: 0.01487  loss_rpn_loc: 0.002453  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:31:58] d2.utils.events INFO:  eta: 2:01:33  iter: 4239  total_loss: 0.53  loss_cls: 0.402  loss_box_reg: 0.1227  loss_rpn_cls: 0.01235  loss_rpn_loc: 0.002293  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:32:23] d2.utils.events INFO:  eta: 2:01:07  iter: 4259  total_loss: 0.5066  loss_cls: 0.4299  loss_box_reg: 0.07834  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.001933  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:32:49] d2.utils.events INFO:  eta: 2:00:41  iter: 4279  total_loss: 0.5762  loss_cls: 0.4408  loss_box_reg: 0.06624  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.002366  time: 1.2684  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:33:14] d2.utils.events INFO:  eta: 2:00:15  iter: 4299  total_loss: 0.4971  loss_cls: 0.4005  loss_box_reg: 0.09828  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.002765  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:33:39] d2.utils.events INFO:  eta: 1:59:50  iter: 4319  total_loss: 0.4992  loss_cls: 0.3879  loss_box_reg: 0.09284  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.002912  time: 1.2683  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:34:05] d2.utils.events INFO:  eta: 1:59:24  iter: 4339  total_loss: 0.5166  loss_cls: 0.4253  loss_box_reg: 0.08035  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.002618  time: 1.2683  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:34:30] d2.utils.events INFO:  eta: 1:58:59  iter: 4359  total_loss: 0.516  loss_cls: 0.4133  loss_box_reg: 0.09642  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.005034  time: 1.2683  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:34:55] d2.utils.events INFO:  eta: 1:58:32  iter: 4379  total_loss: 0.5073  loss_cls: 0.3998  loss_box_reg: 0.08207  loss_rpn_cls: 0.01503  loss_rpn_loc: 0.003231  time: 1.2683  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:35:21] d2.utils.events INFO:  eta: 1:58:07  iter: 4399  total_loss: 0.5862  loss_cls: 0.4171  loss_box_reg: 0.1148  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.002654  time: 1.2683  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:35:46] d2.utils.events INFO:  eta: 1:57:42  iter: 4419  total_loss: 0.5537  loss_cls: 0.4648  loss_box_reg: 0.08723  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.002688  time: 1.2683  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:36:12] d2.utils.events INFO:  eta: 1:57:18  iter: 4439  total_loss: 0.5629  loss_cls: 0.4153  loss_box_reg: 0.1058  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.002637  time: 1.2683  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:36:37] d2.utils.events INFO:  eta: 1:56:52  iter: 4459  total_loss: 0.5408  loss_cls: 0.4058  loss_box_reg: 0.09994  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.002731  time: 1.2683  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:37:02] d2.utils.events INFO:  eta: 1:56:27  iter: 4479  total_loss: 0.52  loss_cls: 0.3475  loss_box_reg: 0.1032  loss_rpn_cls: 0.009971  loss_rpn_loc: 0.002245  time: 1.2683  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:37:28] d2.utils.events INFO:  eta: 1:56:02  iter: 4499  total_loss: 0.559  loss_cls: 0.4128  loss_box_reg: 0.08202  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.004141  time: 1.2683  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:37:53] d2.utils.events INFO:  eta: 1:55:36  iter: 4519  total_loss: 0.5551  loss_cls: 0.3843  loss_box_reg: 0.07895  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.002636  time: 1.2682  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 03:38:18] d2.utils.events INFO:  eta: 1:55:11  iter: 4539  total_loss: 0.5512  loss_cls: 0.4131  loss_box_reg: 0.1017  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.004298  time: 1.2682  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 03:38:44] d2.utils.events INFO:  eta: 1:54:45  iter: 4559  total_loss: 0.518  loss_cls: 0.3707  loss_box_reg: 0.1151  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.002731  time: 1.2682  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:39:09] d2.utils.events INFO:  eta: 1:54:19  iter: 4579  total_loss: 0.4911  loss_cls: 0.3589  loss_box_reg: 0.1184  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.002251  time: 1.2682  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:39:34] d2.utils.events INFO:  eta: 1:53:53  iter: 4599  total_loss: 0.518  loss_cls: 0.4071  loss_box_reg: 0.07631  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.00292  time: 1.2682  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 03:40:00] d2.utils.events INFO:  eta: 1:53:29  iter: 4619  total_loss: 0.4806  loss_cls: 0.3691  loss_box_reg: 0.09019  loss_rpn_cls: 0.009557  loss_rpn_loc: 0.002243  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:40:25] d2.utils.events INFO:  eta: 1:53:05  iter: 4639  total_loss: 0.5317  loss_cls: 0.4065  loss_box_reg: 0.117  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.002087  time: 1.2682  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:40:51] d2.utils.events INFO:  eta: 1:52:40  iter: 4659  total_loss: 0.5445  loss_cls: 0.3703  loss_box_reg: 0.1125  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.004372  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:41:16] d2.utils.events INFO:  eta: 1:52:14  iter: 4679  total_loss: 0.5283  loss_cls: 0.389  loss_box_reg: 0.09027  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.002424  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:41:41] d2.utils.events INFO:  eta: 1:51:48  iter: 4699  total_loss: 0.6331  loss_cls: 0.4465  loss_box_reg: 0.09312  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.002758  time: 1.2681  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:42:07] d2.utils.events INFO:  eta: 1:51:23  iter: 4719  total_loss: 0.5256  loss_cls: 0.417  loss_box_reg: 0.1316  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.002899  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:42:32] d2.utils.events INFO:  eta: 1:50:58  iter: 4739  total_loss: 0.5022  loss_cls: 0.3893  loss_box_reg: 0.0837  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.002498  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:42:57] d2.utils.events INFO:  eta: 1:50:32  iter: 4759  total_loss: 0.5712  loss_cls: 0.4384  loss_box_reg: 0.1116  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.002593  time: 1.2681  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:43:23] d2.utils.events INFO:  eta: 1:50:07  iter: 4779  total_loss: 0.4805  loss_cls: 0.3635  loss_box_reg: 0.09849  loss_rpn_cls: 0.009866  loss_rpn_loc: 0.001938  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:43:48] d2.utils.events INFO:  eta: 1:49:42  iter: 4799  total_loss: 0.4634  loss_cls: 0.3377  loss_box_reg: 0.1086  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.001378  time: 1.2681  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 03:44:14] d2.utils.events INFO:  eta: 1:49:16  iter: 4819  total_loss: 0.5667  loss_cls: 0.4478  loss_box_reg: 0.1155  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.001826  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:44:39] d2.utils.events INFO:  eta: 1:48:51  iter: 4839  total_loss: 0.4856  loss_cls: 0.3916  loss_box_reg: 0.08638  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.002625  time: 1.2681  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:45:04] d2.utils.events INFO:  eta: 1:48:25  iter: 4859  total_loss: 0.5256  loss_cls: 0.3845  loss_box_reg: 0.09646  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.003186  time: 1.2681  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:45:30] d2.utils.events INFO:  eta: 1:47:59  iter: 4879  total_loss: 0.4676  loss_cls: 0.2968  loss_box_reg: 0.1207  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.001825  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:45:55] d2.utils.events INFO:  eta: 1:47:34  iter: 4899  total_loss: 0.5161  loss_cls: 0.3594  loss_box_reg: 0.07137  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.002547  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:46:21] d2.utils.events INFO:  eta: 1:47:08  iter: 4919  total_loss: 0.5558  loss_cls: 0.4534  loss_box_reg: 0.086  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.003399  time: 1.2681  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:46:46] d2.utils.events INFO:  eta: 1:46:43  iter: 4939  total_loss: 0.5599  loss_cls: 0.4408  loss_box_reg: 0.08121  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.003361  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:47:11] d2.utils.events INFO:  eta: 1:46:16  iter: 4959  total_loss: 0.514  loss_cls: 0.3438  loss_box_reg: 0.09216  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.002719  time: 1.2680  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:47:37] d2.utils.events INFO:  eta: 1:45:51  iter: 4979  total_loss: 0.5563  loss_cls: 0.4271  loss_box_reg: 0.09564  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.003103  time: 1.2680  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:48:02] d2.utils.events INFO:  eta: 1:45:27  iter: 4999  total_loss: 0.4834  loss_cls: 0.3945  loss_box_reg: 0.08877  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.003518  time: 1.2680  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:48:27] d2.utils.events INFO:  eta: 1:45:01  iter: 5019  total_loss: 0.5653  loss_cls: 0.4353  loss_box_reg: 0.08766  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.004483  time: 1.2680  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:48:53] d2.utils.events INFO:  eta: 1:44:36  iter: 5039  total_loss: 0.5172  loss_cls: 0.3859  loss_box_reg: 0.07423  loss_rpn_cls: 0.02186  loss_rpn_loc: 0.004771  time: 1.2680  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:49:18] d2.utils.events INFO:  eta: 1:44:12  iter: 5059  total_loss: 0.5214  loss_cls: 0.4007  loss_box_reg: 0.1044  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.002568  time: 1.2681  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 03:49:44] d2.utils.events INFO:  eta: 1:43:47  iter: 5079  total_loss: 0.5285  loss_cls: 0.3708  loss_box_reg: 0.1077  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.002119  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:50:09] d2.utils.events INFO:  eta: 1:43:23  iter: 5099  total_loss: 0.516  loss_cls: 0.3884  loss_box_reg: 0.07479  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.002518  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:50:35] d2.utils.events INFO:  eta: 1:42:57  iter: 5119  total_loss: 0.5326  loss_cls: 0.3867  loss_box_reg: 0.09989  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.002785  time: 1.2681  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:51:00] d2.utils.events INFO:  eta: 1:42:32  iter: 5139  total_loss: 0.4955  loss_cls: 0.3525  loss_box_reg: 0.1134  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.002201  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:51:26] d2.utils.events INFO:  eta: 1:42:07  iter: 5159  total_loss: 0.527  loss_cls: 0.4302  loss_box_reg: 0.09427  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.002742  time: 1.2681  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:51:51] d2.utils.events INFO:  eta: 1:41:42  iter: 5179  total_loss: 0.5095  loss_cls: 0.3129  loss_box_reg: 0.1082  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.002871  time: 1.2681  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:52:17] d2.utils.events INFO:  eta: 1:41:16  iter: 5199  total_loss: 0.5251  loss_cls: 0.4349  loss_box_reg: 0.08309  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.00231  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:52:42] d2.utils.events INFO:  eta: 1:40:50  iter: 5219  total_loss: 0.5809  loss_cls: 0.418  loss_box_reg: 0.09653  loss_rpn_cls: 0.01764  loss_rpn_loc: 0.00261  time: 1.2681  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:53:07] d2.utils.events INFO:  eta: 1:40:25  iter: 5239  total_loss: 0.5128  loss_cls: 0.3843  loss_box_reg: 0.1053  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.002757  time: 1.2681  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:53:33] d2.utils.events INFO:  eta: 1:39:59  iter: 5259  total_loss: 0.5693  loss_cls: 0.3899  loss_box_reg: 0.1184  loss_rpn_cls: 0.01517  loss_rpn_loc: 0.002221  time: 1.2681  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:53:58] d2.utils.events INFO:  eta: 1:39:34  iter: 5279  total_loss: 0.4322  loss_cls: 0.2936  loss_box_reg: 0.0928  loss_rpn_cls: 0.00992  loss_rpn_loc: 0.002054  time: 1.2680  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:54:23] d2.utils.events INFO:  eta: 1:39:08  iter: 5299  total_loss: 0.432  loss_cls: 0.3101  loss_box_reg: 0.07598  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.002526  time: 1.2680  data_time: 0.0075  lr: 2e-05  max_mem: 19009M
[01/31 03:54:48] d2.utils.events INFO:  eta: 1:38:42  iter: 5319  total_loss: 0.548  loss_cls: 0.3644  loss_box_reg: 0.09402  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.002602  time: 1.2680  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:55:14] d2.utils.events INFO:  eta: 1:38:15  iter: 5339  total_loss: 0.5651  loss_cls: 0.4327  loss_box_reg: 0.09879  loss_rpn_cls: 0.014  loss_rpn_loc: 0.002814  time: 1.2679  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:55:39] d2.utils.events INFO:  eta: 1:37:50  iter: 5359  total_loss: 0.5535  loss_cls: 0.4426  loss_box_reg: 0.07111  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.003958  time: 1.2679  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 03:56:04] d2.utils.events INFO:  eta: 1:37:24  iter: 5379  total_loss: 0.4936  loss_cls: 0.4009  loss_box_reg: 0.07099  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.002944  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:56:30] d2.utils.events INFO:  eta: 1:36:59  iter: 5399  total_loss: 0.5652  loss_cls: 0.4314  loss_box_reg: 0.109  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.002646  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:56:55] d2.utils.events INFO:  eta: 1:36:33  iter: 5419  total_loss: 0.5113  loss_cls: 0.413  loss_box_reg: 0.09391  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.002414  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:57:20] d2.utils.events INFO:  eta: 1:36:07  iter: 5439  total_loss: 0.6017  loss_cls: 0.4832  loss_box_reg: 0.09128  loss_rpn_cls: 0.01726  loss_rpn_loc: 0.002831  time: 1.2679  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:57:46] d2.utils.events INFO:  eta: 1:35:42  iter: 5459  total_loss: 0.5294  loss_cls: 0.3682  loss_box_reg: 0.1011  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.002868  time: 1.2679  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:58:11] d2.utils.events INFO:  eta: 1:35:16  iter: 5479  total_loss: 0.5258  loss_cls: 0.4494  loss_box_reg: 0.0876  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.003292  time: 1.2678  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 03:58:36] d2.utils.events INFO:  eta: 1:34:50  iter: 5499  total_loss: 0.4678  loss_cls: 0.3637  loss_box_reg: 0.08553  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.001955  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 03:59:02] d2.utils.events INFO:  eta: 1:34:26  iter: 5519  total_loss: 0.457  loss_cls: 0.3559  loss_box_reg: 0.09197  loss_rpn_cls: 0.00993  loss_rpn_loc: 0.002144  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 03:59:27] d2.utils.events INFO:  eta: 1:34:01  iter: 5539  total_loss: 0.5282  loss_cls: 0.4054  loss_box_reg: 0.09338  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.002667  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 03:59:53] d2.utils.events INFO:  eta: 1:33:36  iter: 5559  total_loss: 0.5611  loss_cls: 0.4097  loss_box_reg: 0.104  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.002007  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:00:18] d2.utils.events INFO:  eta: 1:33:11  iter: 5579  total_loss: 0.4672  loss_cls: 0.3455  loss_box_reg: 0.08099  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.002527  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:00:43] d2.utils.events INFO:  eta: 1:32:46  iter: 5599  total_loss: 0.5447  loss_cls: 0.4139  loss_box_reg: 0.1025  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.002446  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:01:09] d2.utils.events INFO:  eta: 1:32:22  iter: 5619  total_loss: 0.5146  loss_cls: 0.4093  loss_box_reg: 0.08008  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.003353  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:01:34] d2.utils.events INFO:  eta: 1:31:57  iter: 5639  total_loss: 0.4764  loss_cls: 0.3804  loss_box_reg: 0.09698  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.002325  time: 1.2679  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:02:00] d2.utils.events INFO:  eta: 1:31:31  iter: 5659  total_loss: 0.6332  loss_cls: 0.4048  loss_box_reg: 0.1287  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.001691  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 04:02:25] d2.utils.events INFO:  eta: 1:31:06  iter: 5679  total_loss: 0.5333  loss_cls: 0.414  loss_box_reg: 0.1041  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.002146  time: 1.2678  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:02:50] d2.utils.events INFO:  eta: 1:30:40  iter: 5699  total_loss: 0.517  loss_cls: 0.3663  loss_box_reg: 0.07447  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.002595  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 04:03:15] d2.utils.events INFO:  eta: 1:30:14  iter: 5719  total_loss: 0.5081  loss_cls: 0.3813  loss_box_reg: 0.07444  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.002747  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 04:03:41] d2.utils.events INFO:  eta: 1:29:49  iter: 5739  total_loss: 0.419  loss_cls: 0.3028  loss_box_reg: 0.06891  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.002152  time: 1.2678  data_time: 0.0084  lr: 2e-05  max_mem: 19009M
[01/31 04:04:07] d2.utils.events INFO:  eta: 1:29:24  iter: 5759  total_loss: 0.4924  loss_cls: 0.4114  loss_box_reg: 0.07121  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.003101  time: 1.2678  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:04:32] d2.utils.events INFO:  eta: 1:28:59  iter: 5779  total_loss: 0.5813  loss_cls: 0.4706  loss_box_reg: 0.08396  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.001943  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:04:58] d2.utils.events INFO:  eta: 1:28:34  iter: 5799  total_loss: 0.5249  loss_cls: 0.4006  loss_box_reg: 0.08273  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.002783  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:05:23] d2.utils.events INFO:  eta: 1:28:09  iter: 5819  total_loss: 0.492  loss_cls: 0.4297  loss_box_reg: 0.08426  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.002547  time: 1.2678  data_time: 0.0086  lr: 2e-05  max_mem: 19009M
[01/31 04:05:48] d2.utils.events INFO:  eta: 1:27:44  iter: 5839  total_loss: 0.4518  loss_cls: 0.3507  loss_box_reg: 0.0783  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.002417  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:06:14] d2.utils.events INFO:  eta: 1:27:18  iter: 5859  total_loss: 0.4824  loss_cls: 0.3518  loss_box_reg: 0.09274  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.00228  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:06:39] d2.utils.events INFO:  eta: 1:26:55  iter: 5879  total_loss: 0.5754  loss_cls: 0.4515  loss_box_reg: 0.09419  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.003346  time: 1.2679  data_time: 0.0085  lr: 2e-05  max_mem: 19009M
[01/31 04:07:05] d2.utils.events INFO:  eta: 1:26:29  iter: 5899  total_loss: 0.5624  loss_cls: 0.4018  loss_box_reg: 0.1249  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.002952  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:07:30] d2.utils.events INFO:  eta: 1:26:04  iter: 5919  total_loss: 0.426  loss_cls: 0.3058  loss_box_reg: 0.07655  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.002263  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:07:56] d2.utils.events INFO:  eta: 1:25:39  iter: 5939  total_loss: 0.4804  loss_cls: 0.3791  loss_box_reg: 0.08541  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.00306  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:08:21] d2.utils.events INFO:  eta: 1:25:15  iter: 5959  total_loss: 0.4691  loss_cls: 0.3222  loss_box_reg: 0.09167  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.002821  time: 1.2679  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:08:46] d2.utils.events INFO:  eta: 1:24:48  iter: 5979  total_loss: 0.5216  loss_cls: 0.3838  loss_box_reg: 0.09188  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.002346  time: 1.2679  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:09:12] d2.utils.events INFO:  eta: 1:24:23  iter: 5999  total_loss: 0.5287  loss_cls: 0.418  loss_box_reg: 0.06848  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.0024  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:09:37] d2.utils.events INFO:  eta: 1:23:58  iter: 6019  total_loss: 0.5718  loss_cls: 0.4122  loss_box_reg: 0.0955  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.002841  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:10:03] d2.utils.events INFO:  eta: 1:23:32  iter: 6039  total_loss: 0.4965  loss_cls: 0.37  loss_box_reg: 0.1168  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.002686  time: 1.2679  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:10:28] d2.utils.events INFO:  eta: 1:23:06  iter: 6059  total_loss: 0.5973  loss_cls: 0.4036  loss_box_reg: 0.09267  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.004872  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:10:53] d2.utils.events INFO:  eta: 1:22:40  iter: 6079  total_loss: 0.5342  loss_cls: 0.3883  loss_box_reg: 0.1051  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.002829  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:11:19] d2.utils.events INFO:  eta: 1:22:14  iter: 6099  total_loss: 0.5219  loss_cls: 0.4363  loss_box_reg: 0.09166  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.002589  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:11:44] d2.utils.events INFO:  eta: 1:21:49  iter: 6119  total_loss: 0.574  loss_cls: 0.4633  loss_box_reg: 0.06982  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.002681  time: 1.2679  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 04:12:10] d2.utils.events INFO:  eta: 1:21:24  iter: 6139  total_loss: 0.5148  loss_cls: 0.4094  loss_box_reg: 0.1026  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.002567  time: 1.2679  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:12:35] d2.utils.events INFO:  eta: 1:20:59  iter: 6159  total_loss: 0.503  loss_cls: 0.3969  loss_box_reg: 0.07422  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.002163  time: 1.2679  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:13:00] d2.utils.events INFO:  eta: 1:20:33  iter: 6179  total_loss: 0.5135  loss_cls: 0.4235  loss_box_reg: 0.09115  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.004268  time: 1.2679  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:13:26] d2.utils.events INFO:  eta: 1:20:07  iter: 6199  total_loss: 0.4878  loss_cls: 0.3699  loss_box_reg: 0.07533  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.002586  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:13:51] d2.utils.events INFO:  eta: 1:19:42  iter: 6219  total_loss: 0.529  loss_cls: 0.3696  loss_box_reg: 0.1026  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.002696  time: 1.2678  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 04:14:17] d2.utils.events INFO:  eta: 1:19:17  iter: 6239  total_loss: 0.4933  loss_cls: 0.3643  loss_box_reg: 0.0804  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.002592  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:14:42] d2.utils.events INFO:  eta: 1:18:51  iter: 6259  total_loss: 0.5173  loss_cls: 0.3717  loss_box_reg: 0.09391  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.002549  time: 1.2678  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:15:07] d2.utils.events INFO:  eta: 1:18:26  iter: 6279  total_loss: 0.5296  loss_cls: 0.3887  loss_box_reg: 0.1243  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.001674  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:15:33] d2.utils.events INFO:  eta: 1:18:02  iter: 6299  total_loss: 0.5251  loss_cls: 0.3978  loss_box_reg: 0.09737  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.003545  time: 1.2678  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:15:58] d2.utils.events INFO:  eta: 1:17:38  iter: 6319  total_loss: 0.5143  loss_cls: 0.3817  loss_box_reg: 0.1057  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.002363  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:16:24] d2.utils.events INFO:  eta: 1:17:14  iter: 6339  total_loss: 0.6056  loss_cls: 0.426  loss_box_reg: 0.08257  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.002802  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:16:49] d2.utils.events INFO:  eta: 1:16:48  iter: 6359  total_loss: 0.4526  loss_cls: 0.3209  loss_box_reg: 0.08553  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.002253  time: 1.2678  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 04:17:14] d2.utils.events INFO:  eta: 1:16:22  iter: 6379  total_loss: 0.5339  loss_cls: 0.3615  loss_box_reg: 0.09959  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.002173  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:17:40] d2.utils.events INFO:  eta: 1:15:56  iter: 6399  total_loss: 0.4794  loss_cls: 0.3719  loss_box_reg: 0.09045  loss_rpn_cls: 0.009993  loss_rpn_loc: 0.002273  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19009M
[01/31 04:18:05] d2.utils.events INFO:  eta: 1:15:31  iter: 6419  total_loss: 0.6196  loss_cls: 0.4776  loss_box_reg: 0.06817  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.002591  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:18:30] d2.utils.events INFO:  eta: 1:15:06  iter: 6439  total_loss: 0.5383  loss_cls: 0.3982  loss_box_reg: 0.08816  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.002069  time: 1.2678  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:18:56] d2.utils.events INFO:  eta: 1:14:40  iter: 6459  total_loss: 0.4352  loss_cls: 0.3191  loss_box_reg: 0.09911  loss_rpn_cls: 0.009774  loss_rpn_loc: 0.002084  time: 1.2678  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 04:19:21] d2.utils.events INFO:  eta: 1:14:15  iter: 6479  total_loss: 0.4806  loss_cls: 0.3791  loss_box_reg: 0.07234  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.002289  time: 1.2678  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:19:46] d2.utils.events INFO:  eta: 1:13:50  iter: 6499  total_loss: 0.4894  loss_cls: 0.3782  loss_box_reg: 0.1001  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.002077  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:20:12] d2.utils.events INFO:  eta: 1:13:23  iter: 6519  total_loss: 0.5426  loss_cls: 0.3764  loss_box_reg: 0.1129  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.00414  time: 1.2677  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:20:37] d2.utils.events INFO:  eta: 1:12:57  iter: 6539  total_loss: 0.507  loss_cls: 0.3995  loss_box_reg: 0.0726  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.002939  time: 1.2677  data_time: 0.0082  lr: 2e-05  max_mem: 19009M
[01/31 04:21:02] d2.utils.events INFO:  eta: 1:12:31  iter: 6559  total_loss: 0.4934  loss_cls: 0.3695  loss_box_reg: 0.08867  loss_rpn_cls: 0.009544  loss_rpn_loc: 0.001954  time: 1.2677  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:21:28] d2.utils.events INFO:  eta: 1:12:06  iter: 6579  total_loss: 0.5233  loss_cls: 0.3803  loss_box_reg: 0.1121  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.002699  time: 1.2677  data_time: 0.0084  lr: 2e-05  max_mem: 19009M
[01/31 04:21:53] d2.utils.events INFO:  eta: 1:11:41  iter: 6599  total_loss: 0.5193  loss_cls: 0.3632  loss_box_reg: 0.08783  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.002268  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:22:19] d2.utils.events INFO:  eta: 1:11:15  iter: 6619  total_loss: 0.4776  loss_cls: 0.3704  loss_box_reg: 0.07724  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.003262  time: 1.2677  data_time: 0.0085  lr: 2e-05  max_mem: 19009M
[01/31 04:22:44] d2.utils.events INFO:  eta: 1:10:50  iter: 6639  total_loss: 0.5299  loss_cls: 0.3585  loss_box_reg: 0.08429  loss_rpn_cls: 0.01101  loss_rpn_loc: 0.002564  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:23:10] d2.utils.events INFO:  eta: 1:10:25  iter: 6659  total_loss: 0.4941  loss_cls: 0.3436  loss_box_reg: 0.07692  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.002701  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:23:35] d2.utils.events INFO:  eta: 1:10:01  iter: 6679  total_loss: 0.5268  loss_cls: 0.4333  loss_box_reg: 0.07577  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.002797  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:24:00] d2.utils.events INFO:  eta: 1:09:37  iter: 6699  total_loss: 0.5474  loss_cls: 0.4328  loss_box_reg: 0.08337  loss_rpn_cls: 0.012  loss_rpn_loc: 0.002133  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:24:26] d2.utils.events INFO:  eta: 1:09:12  iter: 6719  total_loss: 0.4879  loss_cls: 0.4053  loss_box_reg: 0.07991  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.002435  time: 1.2678  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:24:51] d2.utils.events INFO:  eta: 1:08:47  iter: 6739  total_loss: 0.5047  loss_cls: 0.372  loss_box_reg: 0.08829  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.002407  time: 1.2678  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:25:17] d2.utils.events INFO:  eta: 1:08:21  iter: 6759  total_loss: 0.4832  loss_cls: 0.3072  loss_box_reg: 0.09874  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.002075  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:25:42] d2.utils.events INFO:  eta: 1:07:54  iter: 6779  total_loss: 0.5088  loss_cls: 0.376  loss_box_reg: 0.08634  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.002428  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:26:08] d2.utils.events INFO:  eta: 1:07:29  iter: 6799  total_loss: 0.5446  loss_cls: 0.4193  loss_box_reg: 0.1118  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.002711  time: 1.2678  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:26:33] d2.utils.events INFO:  eta: 1:07:03  iter: 6819  total_loss: 0.5728  loss_cls: 0.4486  loss_box_reg: 0.07209  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.003435  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:26:58] d2.utils.events INFO:  eta: 1:06:37  iter: 6839  total_loss: 0.5154  loss_cls: 0.3989  loss_box_reg: 0.09422  loss_rpn_cls: 0.01078  loss_rpn_loc: 0.002145  time: 1.2678  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:27:24] d2.utils.events INFO:  eta: 1:06:12  iter: 6859  total_loss: 0.5583  loss_cls: 0.3965  loss_box_reg: 0.08596  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.002118  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:27:49] d2.utils.events INFO:  eta: 1:05:46  iter: 6879  total_loss: 0.5043  loss_cls: 0.3552  loss_box_reg: 0.1346  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.003381  time: 1.2677  data_time: 0.0074  lr: 2e-05  max_mem: 19009M
[01/31 04:28:14] d2.utils.events INFO:  eta: 1:05:21  iter: 6899  total_loss: 0.5243  loss_cls: 0.4239  loss_box_reg: 0.09469  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.003253  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:28:40] d2.utils.events INFO:  eta: 1:04:55  iter: 6919  total_loss: 0.5556  loss_cls: 0.3653  loss_box_reg: 0.07652  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.00286  time: 1.2677  data_time: 0.0084  lr: 2e-05  max_mem: 19009M
[01/31 04:29:05] d2.utils.events INFO:  eta: 1:04:30  iter: 6939  total_loss: 0.5577  loss_cls: 0.3878  loss_box_reg: 0.09945  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.002631  time: 1.2677  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:29:31] d2.utils.events INFO:  eta: 1:04:05  iter: 6959  total_loss: 0.5868  loss_cls: 0.4857  loss_box_reg: 0.06686  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.003461  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:29:56] d2.utils.events INFO:  eta: 1:03:40  iter: 6979  total_loss: 0.5254  loss_cls: 0.3591  loss_box_reg: 0.1324  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.003355  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:30:21] d2.utils.events INFO:  eta: 1:03:14  iter: 6999  total_loss: 0.4753  loss_cls: 0.3982  loss_box_reg: 0.07307  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.002539  time: 1.2677  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:30:47] d2.utils.events INFO:  eta: 1:02:49  iter: 7019  total_loss: 0.5295  loss_cls: 0.3506  loss_box_reg: 0.1072  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.002972  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:31:12] d2.utils.events INFO:  eta: 1:02:23  iter: 7039  total_loss: 0.4703  loss_cls: 0.3818  loss_box_reg: 0.0902  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.001887  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:31:37] d2.utils.events INFO:  eta: 1:01:58  iter: 7059  total_loss: 0.4721  loss_cls: 0.3997  loss_box_reg: 0.07248  loss_rpn_cls: 0.009436  loss_rpn_loc: 0.002341  time: 1.2677  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:32:03] d2.utils.events INFO:  eta: 1:01:33  iter: 7079  total_loss: 0.5395  loss_cls: 0.4265  loss_box_reg: 0.09814  loss_rpn_cls: 0.012  loss_rpn_loc: 0.003197  time: 1.2677  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:32:28] d2.utils.events INFO:  eta: 1:01:07  iter: 7099  total_loss: 0.4969  loss_cls: 0.3997  loss_box_reg: 0.07664  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.0028  time: 1.2677  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:32:53] d2.utils.events INFO:  eta: 1:00:42  iter: 7119  total_loss: 0.5722  loss_cls: 0.3973  loss_box_reg: 0.1254  loss_rpn_cls: 0.02233  loss_rpn_loc: 0.003717  time: 1.2677  data_time: 0.0077  lr: 2e-05  max_mem: 19009M
[01/31 04:33:19] d2.utils.events INFO:  eta: 1:00:16  iter: 7139  total_loss: 0.4861  loss_cls: 0.3811  loss_box_reg: 0.09191  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.002152  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:33:44] d2.utils.events INFO:  eta: 0:59:51  iter: 7159  total_loss: 0.535  loss_cls: 0.4113  loss_box_reg: 0.0915  loss_rpn_cls: 0.009984  loss_rpn_loc: 0.002326  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:34:10] d2.utils.events INFO:  eta: 0:59:26  iter: 7179  total_loss: 0.449  loss_cls: 0.3498  loss_box_reg: 0.08555  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.002175  time: 1.2677  data_time: 0.0084  lr: 2e-05  max_mem: 19009M
[01/31 04:34:35] d2.utils.events INFO:  eta: 0:59:01  iter: 7199  total_loss: 0.4982  loss_cls: 0.3974  loss_box_reg: 0.09164  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.00237  time: 1.2677  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:35:00] d2.utils.events INFO:  eta: 0:58:35  iter: 7219  total_loss: 0.4919  loss_cls: 0.3808  loss_box_reg: 0.09227  loss_rpn_cls: 0.007642  loss_rpn_loc: 0.002647  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:35:26] d2.utils.events INFO:  eta: 0:58:10  iter: 7239  total_loss: 0.4974  loss_cls: 0.401  loss_box_reg: 0.08553  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.002745  time: 1.2677  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:35:51] d2.utils.events INFO:  eta: 0:57:45  iter: 7259  total_loss: 0.5654  loss_cls: 0.435  loss_box_reg: 0.09416  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.003371  time: 1.2677  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:36:17] d2.utils.events INFO:  eta: 0:57:19  iter: 7279  total_loss: 0.4781  loss_cls: 0.3636  loss_box_reg: 0.09074  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.002402  time: 1.2676  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:36:42] d2.utils.events INFO:  eta: 0:56:54  iter: 7299  total_loss: 0.5078  loss_cls: 0.397  loss_box_reg: 0.07685  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.002046  time: 1.2676  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:37:07] d2.utils.events INFO:  eta: 0:56:28  iter: 7319  total_loss: 0.5129  loss_cls: 0.4208  loss_box_reg: 0.08694  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.001932  time: 1.2676  data_time: 0.0083  lr: 2e-05  max_mem: 19009M
[01/31 04:37:33] d2.utils.events INFO:  eta: 0:56:03  iter: 7339  total_loss: 0.489  loss_cls: 0.3298  loss_box_reg: 0.09832  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.002602  time: 1.2676  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:37:58] d2.utils.events INFO:  eta: 0:55:38  iter: 7359  total_loss: 0.4443  loss_cls: 0.337  loss_box_reg: 0.0821  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.002127  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:38:23] d2.utils.events INFO:  eta: 0:55:13  iter: 7379  total_loss: 0.5149  loss_cls: 0.4044  loss_box_reg: 0.09743  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.002285  time: 1.2676  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:38:49] d2.utils.events INFO:  eta: 0:54:47  iter: 7399  total_loss: 0.4795  loss_cls: 0.3753  loss_box_reg: 0.08002  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.00157  time: 1.2676  data_time: 0.0081  lr: 2e-05  max_mem: 19009M
[01/31 04:39:14] d2.utils.events INFO:  eta: 0:54:22  iter: 7419  total_loss: 0.5847  loss_cls: 0.4635  loss_box_reg: 0.1191  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.0025  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:39:39] d2.utils.events INFO:  eta: 0:53:57  iter: 7439  total_loss: 0.4571  loss_cls: 0.3501  loss_box_reg: 0.08218  loss_rpn_cls: 0.007697  loss_rpn_loc: 0.002434  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:40:05] d2.utils.events INFO:  eta: 0:53:32  iter: 7459  total_loss: 0.5017  loss_cls: 0.3509  loss_box_reg: 0.1043  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.001837  time: 1.2676  data_time: 0.0080  lr: 2e-05  max_mem: 19009M
[01/31 04:40:30] d2.utils.events INFO:  eta: 0:53:07  iter: 7479  total_loss: 0.4295  loss_cls: 0.271  loss_box_reg: 0.09352  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.002767  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19009M
[01/31 04:40:56] d2.utils.events INFO:  eta: 0:52:42  iter: 7499  total_loss: 0.4838  loss_cls: 0.3563  loss_box_reg: 0.08558  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.001795  time: 1.2676  data_time: 0.0078  lr: 2e-05  max_mem: 19009M
[01/31 04:41:21] d2.utils.events INFO:  eta: 0:52:17  iter: 7519  total_loss: 0.5479  loss_cls: 0.416  loss_box_reg: 0.0739  loss_rpn_cls: 0.009591  loss_rpn_loc: 0.001745  time: 1.2676  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 04:41:46] d2.utils.events INFO:  eta: 0:51:52  iter: 7539  total_loss: 0.4315  loss_cls: 0.3266  loss_box_reg: 0.07671  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.003181  time: 1.2676  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:42:12] d2.utils.events INFO:  eta: 0:51:27  iter: 7559  total_loss: 0.3766  loss_cls: 0.3126  loss_box_reg: 0.09687  loss_rpn_cls: 0.009207  loss_rpn_loc: 0.00174  time: 1.2676  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:42:37] d2.utils.events INFO:  eta: 0:51:01  iter: 7579  total_loss: 0.4795  loss_cls: 0.3626  loss_box_reg: 0.1209  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.003071  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:43:02] d2.utils.events INFO:  eta: 0:50:36  iter: 7599  total_loss: 0.4589  loss_cls: 0.2985  loss_box_reg: 0.1077  loss_rpn_cls: 0.009318  loss_rpn_loc: 0.002022  time: 1.2676  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:43:28] d2.utils.events INFO:  eta: 0:50:10  iter: 7619  total_loss: 0.4614  loss_cls: 0.3036  loss_box_reg: 0.09931  loss_rpn_cls: 0.009161  loss_rpn_loc: 0.001825  time: 1.2676  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:43:53] d2.utils.events INFO:  eta: 0:49:45  iter: 7639  total_loss: 0.3477  loss_cls: 0.2533  loss_box_reg: 0.08509  loss_rpn_cls: 0.009176  loss_rpn_loc: 0.001664  time: 1.2676  data_time: 0.0084  lr: 2e-06  max_mem: 19009M
[01/31 04:44:19] d2.utils.events INFO:  eta: 0:49:20  iter: 7659  total_loss: 0.5187  loss_cls: 0.4258  loss_box_reg: 0.1062  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.003093  time: 1.2676  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:44:44] d2.utils.events INFO:  eta: 0:48:54  iter: 7679  total_loss: 0.5109  loss_cls: 0.3619  loss_box_reg: 0.09916  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.00296  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:45:09] d2.utils.events INFO:  eta: 0:48:28  iter: 7699  total_loss: 0.5311  loss_cls: 0.3659  loss_box_reg: 0.09421  loss_rpn_cls: 0.009583  loss_rpn_loc: 0.001866  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:45:35] d2.utils.events INFO:  eta: 0:48:03  iter: 7719  total_loss: 0.4583  loss_cls: 0.3544  loss_box_reg: 0.104  loss_rpn_cls: 0.009978  loss_rpn_loc: 0.002213  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:46:00] d2.utils.events INFO:  eta: 0:47:38  iter: 7739  total_loss: 0.4217  loss_cls: 0.3346  loss_box_reg: 0.08802  loss_rpn_cls: 0.01018  loss_rpn_loc: 0.002106  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:46:26] d2.utils.events INFO:  eta: 0:47:13  iter: 7759  total_loss: 0.4858  loss_cls: 0.3054  loss_box_reg: 0.1258  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.002039  time: 1.2676  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:46:51] d2.utils.events INFO:  eta: 0:46:48  iter: 7779  total_loss: 0.4246  loss_cls: 0.2531  loss_box_reg: 0.07496  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.002285  time: 1.2676  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 04:47:17] d2.utils.events INFO:  eta: 0:46:22  iter: 7799  total_loss: 0.4482  loss_cls: 0.3842  loss_box_reg: 0.08067  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.002539  time: 1.2676  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:47:42] d2.utils.events INFO:  eta: 0:45:57  iter: 7819  total_loss: 0.4586  loss_cls: 0.3867  loss_box_reg: 0.05877  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.002202  time: 1.2676  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 04:48:07] d2.utils.events INFO:  eta: 0:45:32  iter: 7839  total_loss: 0.4845  loss_cls: 0.297  loss_box_reg: 0.1075  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.002162  time: 1.2676  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 04:48:33] d2.utils.events INFO:  eta: 0:45:07  iter: 7859  total_loss: 0.4892  loss_cls: 0.366  loss_box_reg: 0.09233  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.002554  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 04:48:58] d2.utils.events INFO:  eta: 0:44:42  iter: 7879  total_loss: 0.4841  loss_cls: 0.3423  loss_box_reg: 0.08582  loss_rpn_cls: 0.008991  loss_rpn_loc: 0.002125  time: 1.2676  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 04:49:23] d2.utils.events INFO:  eta: 0:44:16  iter: 7899  total_loss: 0.468  loss_cls: 0.3921  loss_box_reg: 0.07626  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.002941  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 04:49:49] d2.utils.events INFO:  eta: 0:43:51  iter: 7919  total_loss: 0.4668  loss_cls: 0.3321  loss_box_reg: 0.08997  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.003612  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 04:50:14] d2.utils.events INFO:  eta: 0:43:25  iter: 7939  total_loss: 0.5127  loss_cls: 0.3693  loss_box_reg: 0.08559  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.002799  time: 1.2675  data_time: 0.0076  lr: 2e-06  max_mem: 19009M
[01/31 04:50:40] d2.utils.events INFO:  eta: 0:43:00  iter: 7959  total_loss: 0.513  loss_cls: 0.4062  loss_box_reg: 0.09892  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.002266  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 04:51:05] d2.utils.events INFO:  eta: 0:42:35  iter: 7979  total_loss: 0.5162  loss_cls: 0.3805  loss_box_reg: 0.1036  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.004303  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:51:30] d2.utils.events INFO:  eta: 0:42:09  iter: 7999  total_loss: 0.5703  loss_cls: 0.3969  loss_box_reg: 0.09494  loss_rpn_cls: 0.01841  loss_rpn_loc: 0.003091  time: 1.2675  data_time: 0.0085  lr: 2e-06  max_mem: 19009M
[01/31 04:51:56] d2.utils.events INFO:  eta: 0:41:44  iter: 8019  total_loss: 0.4272  loss_cls: 0.3079  loss_box_reg: 0.08965  loss_rpn_cls: 0.009412  loss_rpn_loc: 0.002202  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 04:52:21] d2.utils.events INFO:  eta: 0:41:19  iter: 8039  total_loss: 0.5379  loss_cls: 0.3893  loss_box_reg: 0.09107  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.002445  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 04:52:46] d2.utils.events INFO:  eta: 0:40:54  iter: 8059  total_loss: 0.505  loss_cls: 0.4081  loss_box_reg: 0.09216  loss_rpn_cls: 0.0183  loss_rpn_loc: 0.003526  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 04:53:12] d2.utils.events INFO:  eta: 0:40:29  iter: 8079  total_loss: 0.4845  loss_cls: 0.3659  loss_box_reg: 0.06664  loss_rpn_cls: 0.01074  loss_rpn_loc: 0.002365  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:53:37] d2.utils.events INFO:  eta: 0:40:03  iter: 8099  total_loss: 0.412  loss_cls: 0.3437  loss_box_reg: 0.06911  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.001943  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:54:02] d2.utils.events INFO:  eta: 0:39:38  iter: 8119  total_loss: 0.4603  loss_cls: 0.349  loss_box_reg: 0.07514  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.003043  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:54:28] d2.utils.events INFO:  eta: 0:39:12  iter: 8139  total_loss: 0.4814  loss_cls: 0.3557  loss_box_reg: 0.09768  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.003267  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 04:54:53] d2.utils.events INFO:  eta: 0:38:47  iter: 8159  total_loss: 0.4663  loss_cls: 0.3431  loss_box_reg: 0.09789  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.003284  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 04:55:18] d2.utils.events INFO:  eta: 0:38:21  iter: 8179  total_loss: 0.4404  loss_cls: 0.2994  loss_box_reg: 0.09041  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.002239  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:55:44] d2.utils.events INFO:  eta: 0:37:56  iter: 8199  total_loss: 0.4103  loss_cls: 0.3189  loss_box_reg: 0.06695  loss_rpn_cls: 0.007896  loss_rpn_loc: 0.001375  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:56:09] d2.utils.events INFO:  eta: 0:37:30  iter: 8219  total_loss: 0.5686  loss_cls: 0.3876  loss_box_reg: 0.07645  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.003568  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:56:34] d2.utils.events INFO:  eta: 0:37:05  iter: 8239  total_loss: 0.4899  loss_cls: 0.3371  loss_box_reg: 0.09586  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.002836  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 04:57:00] d2.utils.events INFO:  eta: 0:36:40  iter: 8259  total_loss: 0.5671  loss_cls: 0.4371  loss_box_reg: 0.1158  loss_rpn_cls: 0.01385  loss_rpn_loc: 0.002132  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 04:57:25] d2.utils.events INFO:  eta: 0:36:15  iter: 8279  total_loss: 0.5326  loss_cls: 0.4104  loss_box_reg: 0.08909  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.002185  time: 1.2674  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 04:57:50] d2.utils.events INFO:  eta: 0:35:49  iter: 8299  total_loss: 0.457  loss_cls: 0.3677  loss_box_reg: 0.07294  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.002631  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 04:58:16] d2.utils.events INFO:  eta: 0:35:24  iter: 8319  total_loss: 0.4438  loss_cls: 0.295  loss_box_reg: 0.08879  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.00174  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 04:58:41] d2.utils.events INFO:  eta: 0:34:59  iter: 8339  total_loss: 0.4249  loss_cls: 0.2967  loss_box_reg: 0.07713  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.001624  time: 1.2674  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:59:06] d2.utils.events INFO:  eta: 0:34:33  iter: 8359  total_loss: 0.469  loss_cls: 0.3421  loss_box_reg: 0.1089  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.002434  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 04:59:32] d2.utils.events INFO:  eta: 0:34:08  iter: 8379  total_loss: 0.468  loss_cls: 0.3704  loss_box_reg: 0.0759  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.003589  time: 1.2674  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 04:59:57] d2.utils.events INFO:  eta: 0:33:42  iter: 8399  total_loss: 0.5282  loss_cls: 0.3728  loss_box_reg: 0.08984  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.002469  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:00:22] d2.utils.events INFO:  eta: 0:33:17  iter: 8419  total_loss: 0.4794  loss_cls: 0.3694  loss_box_reg: 0.1165  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.00198  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:00:48] d2.utils.events INFO:  eta: 0:32:51  iter: 8439  total_loss: 0.4561  loss_cls: 0.355  loss_box_reg: 0.0557  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.001707  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:01:13] d2.utils.events INFO:  eta: 0:32:26  iter: 8459  total_loss: 0.4758  loss_cls: 0.3199  loss_box_reg: 0.094  loss_rpn_cls: 0.01025  loss_rpn_loc: 0.001686  time: 1.2674  data_time: 0.0085  lr: 2e-06  max_mem: 19009M
[01/31 05:01:39] d2.utils.events INFO:  eta: 0:32:01  iter: 8479  total_loss: 0.4864  loss_cls: 0.3826  loss_box_reg: 0.09337  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.003439  time: 1.2674  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 05:02:04] d2.utils.events INFO:  eta: 0:31:36  iter: 8499  total_loss: 0.487  loss_cls: 0.33  loss_box_reg: 0.08841  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.001838  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:02:29] d2.utils.events INFO:  eta: 0:31:10  iter: 8519  total_loss: 0.5048  loss_cls: 0.3574  loss_box_reg: 0.09721  loss_rpn_cls: 0.01179  loss_rpn_loc: 0.002334  time: 1.2673  data_time: 0.0075  lr: 2e-06  max_mem: 19009M
[01/31 05:02:55] d2.utils.events INFO:  eta: 0:30:45  iter: 8539  total_loss: 0.5057  loss_cls: 0.381  loss_box_reg: 0.1178  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.002549  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:03:20] d2.utils.events INFO:  eta: 0:30:20  iter: 8559  total_loss: 0.4868  loss_cls: 0.3541  loss_box_reg: 0.07241  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.002483  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:03:45] d2.utils.events INFO:  eta: 0:29:55  iter: 8579  total_loss: 0.4852  loss_cls: 0.3766  loss_box_reg: 0.07806  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.00244  time: 1.2673  data_time: 0.0086  lr: 2e-06  max_mem: 19009M
[01/31 05:04:11] d2.utils.events INFO:  eta: 0:29:29  iter: 8599  total_loss: 0.4995  loss_cls: 0.3632  loss_box_reg: 0.08372  loss_rpn_cls: 0.009509  loss_rpn_loc: 0.001932  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:04:36] d2.utils.events INFO:  eta: 0:29:04  iter: 8619  total_loss: 0.4571  loss_cls: 0.344  loss_box_reg: 0.07942  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.002759  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:05:02] d2.utils.events INFO:  eta: 0:28:39  iter: 8639  total_loss: 0.474  loss_cls: 0.3211  loss_box_reg: 0.07243  loss_rpn_cls: 0.009064  loss_rpn_loc: 0.002299  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:05:27] d2.utils.events INFO:  eta: 0:28:14  iter: 8659  total_loss: 0.536  loss_cls: 0.3566  loss_box_reg: 0.09246  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.001962  time: 1.2674  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 05:05:53] d2.utils.events INFO:  eta: 0:27:48  iter: 8679  total_loss: 0.4304  loss_cls: 0.3234  loss_box_reg: 0.09031  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.002053  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:06:18] d2.utils.events INFO:  eta: 0:27:23  iter: 8699  total_loss: 0.3878  loss_cls: 0.2983  loss_box_reg: 0.06697  loss_rpn_cls: 0.009108  loss_rpn_loc: 0.001565  time: 1.2674  data_time: 0.0084  lr: 2e-06  max_mem: 19009M
[01/31 05:06:43] d2.utils.events INFO:  eta: 0:26:58  iter: 8719  total_loss: 0.5302  loss_cls: 0.4123  loss_box_reg: 0.0989  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.003214  time: 1.2674  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:07:09] d2.utils.events INFO:  eta: 0:26:33  iter: 8739  total_loss: 0.4938  loss_cls: 0.3821  loss_box_reg: 0.08962  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.002175  time: 1.2674  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:07:34] d2.utils.events INFO:  eta: 0:26:07  iter: 8759  total_loss: 0.4534  loss_cls: 0.3356  loss_box_reg: 0.108  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.002082  time: 1.2673  data_time: 0.0076  lr: 2e-06  max_mem: 19009M
[01/31 05:07:59] d2.utils.events INFO:  eta: 0:25:42  iter: 8779  total_loss: 0.467  loss_cls: 0.3771  loss_box_reg: 0.07919  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.002617  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:08:25] d2.utils.events INFO:  eta: 0:25:16  iter: 8799  total_loss: 0.4366  loss_cls: 0.3127  loss_box_reg: 0.08003  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.002838  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 05:08:50] d2.utils.events INFO:  eta: 0:24:51  iter: 8819  total_loss: 0.4743  loss_cls: 0.3992  loss_box_reg: 0.0734  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.003908  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:09:15] d2.utils.events INFO:  eta: 0:24:26  iter: 8839  total_loss: 0.4912  loss_cls: 0.3839  loss_box_reg: 0.07141  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.002304  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:09:41] d2.utils.events INFO:  eta: 0:24:01  iter: 8859  total_loss: 0.545  loss_cls: 0.421  loss_box_reg: 0.09342  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.002931  time: 1.2673  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 05:10:06] d2.utils.events INFO:  eta: 0:23:35  iter: 8879  total_loss: 0.4705  loss_cls: 0.336  loss_box_reg: 0.1026  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.001976  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 05:10:32] d2.utils.events INFO:  eta: 0:23:10  iter: 8899  total_loss: 0.5604  loss_cls: 0.4686  loss_box_reg: 0.07045  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.003466  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:10:57] d2.utils.events INFO:  eta: 0:22:45  iter: 8919  total_loss: 0.4834  loss_cls: 0.3758  loss_box_reg: 0.08096  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.002686  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:11:22] d2.utils.events INFO:  eta: 0:22:20  iter: 8939  total_loss: 0.5712  loss_cls: 0.4517  loss_box_reg: 0.08824  loss_rpn_cls: 0.0196  loss_rpn_loc: 0.004284  time: 1.2673  data_time: 0.0084  lr: 2e-06  max_mem: 19009M
[01/31 05:11:48] d2.utils.events INFO:  eta: 0:21:54  iter: 8959  total_loss: 0.5253  loss_cls: 0.3828  loss_box_reg: 0.124  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.002305  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:12:13] d2.utils.events INFO:  eta: 0:21:29  iter: 8979  total_loss: 0.5057  loss_cls: 0.3959  loss_box_reg: 0.07865  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.002048  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:12:39] d2.utils.events INFO:  eta: 0:21:04  iter: 8999  total_loss: 0.518  loss_cls: 0.3927  loss_box_reg: 0.07589  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.00203  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 05:13:04] d2.utils.events INFO:  eta: 0:20:38  iter: 9019  total_loss: 0.4426  loss_cls: 0.3208  loss_box_reg: 0.07889  loss_rpn_cls: 0.01599  loss_rpn_loc: 0.003007  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:13:30] d2.utils.events INFO:  eta: 0:20:13  iter: 9039  total_loss: 0.4727  loss_cls: 0.3549  loss_box_reg: 0.09275  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.001564  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:13:55] d2.utils.events INFO:  eta: 0:19:48  iter: 9059  total_loss: 0.4481  loss_cls: 0.3848  loss_box_reg: 0.06788  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.001961  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:14:20] d2.utils.events INFO:  eta: 0:19:23  iter: 9079  total_loss: 0.4212  loss_cls: 0.2936  loss_box_reg: 0.0785  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.0022  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:14:46] d2.utils.events INFO:  eta: 0:18:57  iter: 9099  total_loss: 0.5014  loss_cls: 0.3273  loss_box_reg: 0.1132  loss_rpn_cls: 0.009865  loss_rpn_loc: 0.001945  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:15:11] d2.utils.events INFO:  eta: 0:18:32  iter: 9119  total_loss: 0.4682  loss_cls: 0.3153  loss_box_reg: 0.09291  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.002299  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:15:36] d2.utils.events INFO:  eta: 0:18:07  iter: 9139  total_loss: 0.3873  loss_cls: 0.2994  loss_box_reg: 0.06766  loss_rpn_cls: 0.008459  loss_rpn_loc: 0.001931  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:16:02] d2.utils.events INFO:  eta: 0:17:42  iter: 9159  total_loss: 0.4209  loss_cls: 0.3451  loss_box_reg: 0.08416  loss_rpn_cls: 0.00938  loss_rpn_loc: 0.001851  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:16:27] d2.utils.events INFO:  eta: 0:17:17  iter: 9179  total_loss: 0.4839  loss_cls: 0.3895  loss_box_reg: 0.08587  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.002588  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:16:53] d2.utils.events INFO:  eta: 0:16:52  iter: 9199  total_loss: 0.5162  loss_cls: 0.3652  loss_box_reg: 0.08834  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.003562  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:17:18] d2.utils.events INFO:  eta: 0:16:26  iter: 9219  total_loss: 0.533  loss_cls: 0.3636  loss_box_reg: 0.1117  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.003288  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:17:43] d2.utils.events INFO:  eta: 0:16:01  iter: 9239  total_loss: 0.5102  loss_cls: 0.3368  loss_box_reg: 0.08401  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.002236  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:18:08] d2.utils.events INFO:  eta: 0:15:36  iter: 9259  total_loss: 0.4893  loss_cls: 0.3794  loss_box_reg: 0.0896  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.002297  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:18:34] d2.utils.events INFO:  eta: 0:15:10  iter: 9279  total_loss: 0.5264  loss_cls: 0.4159  loss_box_reg: 0.09335  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.002832  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:18:59] d2.utils.events INFO:  eta: 0:14:45  iter: 9299  total_loss: 0.4941  loss_cls: 0.3412  loss_box_reg: 0.1019  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.002628  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 05:19:25] d2.utils.events INFO:  eta: 0:14:20  iter: 9319  total_loss: 0.4892  loss_cls: 0.3725  loss_box_reg: 0.09571  loss_rpn_cls: 0.01302  loss_rpn_loc: 0.002523  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:19:50] d2.utils.events INFO:  eta: 0:13:55  iter: 9339  total_loss: 0.5363  loss_cls: 0.4172  loss_box_reg: 0.1021  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.002502  time: 1.2673  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 05:20:15] d2.utils.events INFO:  eta: 0:13:29  iter: 9359  total_loss: 0.5116  loss_cls: 0.3762  loss_box_reg: 0.07766  loss_rpn_cls: 0.01197  loss_rpn_loc: 0.002748  time: 1.2673  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 05:20:41] d2.utils.events INFO:  eta: 0:13:04  iter: 9379  total_loss: 0.4432  loss_cls: 0.3615  loss_box_reg: 0.07695  loss_rpn_cls: 0.009693  loss_rpn_loc: 0.001409  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:21:06] d2.utils.events INFO:  eta: 0:12:39  iter: 9399  total_loss: 0.4508  loss_cls: 0.3527  loss_box_reg: 0.06484  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.001735  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:21:31] d2.utils.events INFO:  eta: 0:12:14  iter: 9419  total_loss: 0.4876  loss_cls: 0.3689  loss_box_reg: 0.1057  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.002517  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:21:57] d2.utils.events INFO:  eta: 0:11:48  iter: 9439  total_loss: 0.4808  loss_cls: 0.3584  loss_box_reg: 0.09366  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.002014  time: 1.2673  data_time: 0.0084  lr: 2e-06  max_mem: 19009M
[01/31 05:22:22] d2.utils.events INFO:  eta: 0:11:23  iter: 9459  total_loss: 0.4786  loss_cls: 0.3505  loss_box_reg: 0.09253  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.002113  time: 1.2672  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:22:48] d2.utils.events INFO:  eta: 0:10:58  iter: 9479  total_loss: 0.436  loss_cls: 0.2965  loss_box_reg: 0.1042  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.001924  time: 1.2672  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:23:13] d2.utils.events INFO:  eta: 0:10:32  iter: 9499  total_loss: 0.5025  loss_cls: 0.2806  loss_box_reg: 0.1086  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.002612  time: 1.2672  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:23:38] d2.utils.events INFO:  eta: 0:10:07  iter: 9519  total_loss: 0.3999  loss_cls: 0.3135  loss_box_reg: 0.1029  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.003522  time: 1.2672  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:24:04] d2.utils.events INFO:  eta: 0:09:42  iter: 9539  total_loss: 0.49  loss_cls: 0.3683  loss_box_reg: 0.08925  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.00285  time: 1.2672  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:24:29] d2.utils.events INFO:  eta: 0:09:16  iter: 9559  total_loss: 0.4986  loss_cls: 0.4098  loss_box_reg: 0.08043  loss_rpn_cls: 0.01271  loss_rpn_loc: 0.002365  time: 1.2672  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:24:54] d2.utils.events INFO:  eta: 0:08:51  iter: 9579  total_loss: 0.4475  loss_cls: 0.3615  loss_box_reg: 0.08353  loss_rpn_cls: 0.008826  loss_rpn_loc: 0.002532  time: 1.2672  data_time: 0.0076  lr: 2e-06  max_mem: 19009M
[01/31 05:25:20] d2.utils.events INFO:  eta: 0:08:26  iter: 9599  total_loss: 0.4742  loss_cls: 0.3479  loss_box_reg: 0.08353  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.001752  time: 1.2672  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:25:45] d2.utils.events INFO:  eta: 0:08:00  iter: 9619  total_loss: 0.4215  loss_cls: 0.3413  loss_box_reg: 0.07319  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.001935  time: 1.2672  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:26:11] d2.utils.events INFO:  eta: 0:07:35  iter: 9639  total_loss: 0.4372  loss_cls: 0.3328  loss_box_reg: 0.07843  loss_rpn_cls: 0.009691  loss_rpn_loc: 0.002129  time: 1.2672  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:26:36] d2.utils.events INFO:  eta: 0:07:10  iter: 9659  total_loss: 0.5098  loss_cls: 0.354  loss_box_reg: 0.09494  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.001969  time: 1.2672  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:27:01] d2.utils.events INFO:  eta: 0:06:44  iter: 9679  total_loss: 0.4397  loss_cls: 0.3271  loss_box_reg: 0.07859  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.002489  time: 1.2672  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 05:27:27] d2.utils.events INFO:  eta: 0:06:19  iter: 9699  total_loss: 0.5367  loss_cls: 0.3892  loss_box_reg: 0.08811  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.002759  time: 1.2672  data_time: 0.0077  lr: 2e-06  max_mem: 19009M
[01/31 05:27:52] d2.utils.events INFO:  eta: 0:05:54  iter: 9719  total_loss: 0.4686  loss_cls: 0.3562  loss_box_reg: 0.08328  loss_rpn_cls: 0.008026  loss_rpn_loc: 0.001942  time: 1.2672  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:28:18] d2.utils.events INFO:  eta: 0:05:29  iter: 9739  total_loss: 0.4896  loss_cls: 0.3494  loss_box_reg: 0.09652  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.002875  time: 1.2672  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:28:43] d2.utils.events INFO:  eta: 0:05:03  iter: 9759  total_loss: 0.5086  loss_cls: 0.4057  loss_box_reg: 0.06629  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.002454  time: 1.2672  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:29:08] d2.utils.events INFO:  eta: 0:04:38  iter: 9779  total_loss: 0.423  loss_cls: 0.3152  loss_box_reg: 0.09894  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.002294  time: 1.2672  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:29:34] d2.utils.events INFO:  eta: 0:04:13  iter: 9799  total_loss: 0.4212  loss_cls: 0.3187  loss_box_reg: 0.0633  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.002775  time: 1.2672  data_time: 0.0081  lr: 2e-06  max_mem: 19009M
[01/31 05:29:59] d2.utils.events INFO:  eta: 0:03:47  iter: 9819  total_loss: 0.5357  loss_cls: 0.4114  loss_box_reg: 0.07994  loss_rpn_cls: 0.01266  loss_rpn_loc: 0.002355  time: 1.2672  data_time: 0.0080  lr: 2e-06  max_mem: 19009M
[01/31 05:30:24] d2.utils.events INFO:  eta: 0:03:22  iter: 9839  total_loss: 0.4492  loss_cls: 0.3502  loss_box_reg: 0.07773  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.002651  time: 1.2672  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:30:50] d2.utils.events INFO:  eta: 0:02:57  iter: 9859  total_loss: 0.5097  loss_cls: 0.3538  loss_box_reg: 0.1366  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.002138  time: 1.2672  data_time: 0.0083  lr: 2e-06  max_mem: 19009M
[01/31 05:31:15] d2.utils.events INFO:  eta: 0:02:31  iter: 9879  total_loss: 0.5465  loss_cls: 0.4675  loss_box_reg: 0.06621  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.004661  time: 1.2672  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:31:41] d2.utils.events INFO:  eta: 0:02:06  iter: 9899  total_loss: 0.4399  loss_cls: 0.3243  loss_box_reg: 0.09081  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.001584  time: 1.2672  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:32:06] d2.utils.events INFO:  eta: 0:01:41  iter: 9919  total_loss: 0.4502  loss_cls: 0.3581  loss_box_reg: 0.06328  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.002242  time: 1.2672  data_time: 0.0079  lr: 2e-06  max_mem: 19009M
[01/31 05:32:31] d2.utils.events INFO:  eta: 0:01:15  iter: 9939  total_loss: 0.5004  loss_cls: 0.3982  loss_box_reg: 0.08067  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.003512  time: 1.2672  data_time: 0.0076  lr: 2e-06  max_mem: 19009M
[01/31 05:32:57] d2.utils.events INFO:  eta: 0:00:50  iter: 9959  total_loss: 0.4974  loss_cls: 0.3531  loss_box_reg: 0.0992  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.003663  time: 1.2672  data_time: 0.0082  lr: 2e-06  max_mem: 19009M
[01/31 05:33:22] d2.utils.events INFO:  eta: 0:00:25  iter: 9979  total_loss: 0.4423  loss_cls: 0.3297  loss_box_reg: 0.07911  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.002021  time: 1.2672  data_time: 0.0078  lr: 2e-06  max_mem: 19009M
[01/31 05:33:48] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_0009999.pth
[01/31 05:33:48] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[01/31 05:33:48] d2.utils.events INFO:  eta: 0:00:00  iter: 9999  total_loss: 0.5299  loss_cls: 0.4207  loss_box_reg: 0.07566  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.00219  time: 1.2672  data_time: 0.0079  lr: 2e-07  max_mem: 19009M
[01/31 05:33:48] d2.engine.hooks INFO: Overall training speed: 9998 iterations in 3:31:09 (1.2672 s / it)
[01/31 05:33:48] d2.engine.hooks INFO: Total training time: 3:31:37 (0:00:27 on hooks)
[01/31 05:33:48] d2.data.build INFO: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 285          |   bicycle   | 337          |    boat     | 263          |
|   bottle   | 469          |     car     | 1201         |     cat     | 358          |
|   chair    | 756          | diningtable | 206          |     dog     | 489          |
|   horse    | 348          |   person    | 4528         | pottedplant | 480          |
|   sheep    | 242          |    train    | 282          |  tvmonitor  | 308          |
|    bird    | 459          |     bus     | 213          |     cow     | 244          |
| motorbike  | 325          |    sofa     | 239          |             |              |
|   total    | 12032        |             |              |             |              |
[01/31 05:33:48] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[01/31 05:33:48] d2.data.common INFO: Serialized dataset takes 2.12 MiB
[02/03 15:20:29] detectron2 INFO: Rank of current process: 0. World size: 1
[02/03 15:20:29] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/03 15:20:29] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/03 15:20:29] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/03 15:20:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/03 15:20:29] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/03 15:20:29] d2.utils.env INFO: Using a generated random seed 29916993
[02/03 15:20:48] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/03 15:20:53] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/03 15:20:53] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/03 15:20:54] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/03 15:20:54] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/03 15:20:54] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/03 15:20:54] FCT.data.build INFO: Using training sampler TrainingSampler
[02/03 15:20:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/03 15:20:56] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/03 15:20:56] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/03 15:20:56] d2.engine.train_loop INFO: Starting training from iteration 0
[02/03 15:20:56] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 252, in generate_support
    support_data = utils.read_image(support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'VOC2007/voc_2007_trainval_base1/009087/0006.jpg'

[02/03 15:20:56] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[02/03 15:20:56] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[02/03 15:23:40] detectron2 INFO: Rank of current process: 0. World size: 1
[02/03 15:23:40] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/03 15:23:40] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/03 15:23:40] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/03 15:23:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/03 15:23:40] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/03 15:23:40] d2.utils.env INFO: Using a generated random seed 40690003
[02/03 15:23:43] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/03 15:23:44] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/03 15:23:44] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/03 15:23:45] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/03 15:23:45] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/03 15:23:45] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/03 15:23:45] FCT.data.build INFO: Using training sampler TrainingSampler
[02/03 15:23:45] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/03 15:23:45] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/03 15:23:45] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/03 15:23:45] d2.engine.train_loop INFO: Starting training from iteration 0
[02/03 15:23:45] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 252, in generate_support
    support_data = utils.read_image(support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'VOC2007/voc_2012_trainval_base1/2009_000169/0003.jpg'

[02/03 15:23:45] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[02/03 15:23:45] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[02/03 15:26:14] detectron2 INFO: Rank of current process: 0. World size: 1
[02/03 15:26:14] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/03 15:26:14] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/03 15:26:14] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/03 15:26:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/03 15:26:14] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/03 15:26:14] d2.utils.env INFO: Using a generated random seed 14995981
[02/03 15:26:17] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/03 15:26:18] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/03 15:26:19] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/03 15:26:19] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/03 15:26:19] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/03 15:26:20] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/03 15:26:20] FCT.data.build INFO: Using training sampler TrainingSampler
[02/03 15:26:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/03 15:26:20] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/03 15:26:20] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/03 15:26:20] d2.engine.train_loop INFO: Starting training from iteration 0
[02/03 15:26:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 267, in run_step
    data = next(self._data_loader_iter)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 234, in __iter__
    for d in self.dataset:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 32, in fetch
    data.append(next(self.dataset_iter))
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 201, in __iter__
    yield self.dataset[idx]
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/common.py", line 90, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/utils/serialize.py", line 26, in __call__
    return self._obj(*args, **kwargs)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 129, in __call__
    support_images, support_bboxes, support_cls = self.generate_support(dataset_dict)
  File "/home/rmedu/fct/FCT/FCT/data/dataset_mapper_pascal_voc.py", line 287, in generate_support
    support_data = utils.read_image(support_db["file_path"].tolist()[0], format=self.img_format)
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/data/detection_utils.py", line 180, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 1012, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/iopath/common/file_io.py", line 612, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'VOC2007/voc_2012_trainval_base1/2011_001507/0001.jpg'

[02/03 15:26:20] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[02/03 15:26:20] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 93M
[02/03 15:27:16] detectron2 INFO: Rank of current process: 0. World size: 1
[02/03 15:27:17] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/03 15:27:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/03 15:27:17] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/03 15:27:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/03 15:27:17] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/03 15:27:17] d2.utils.env INFO: Using a generated random seed 17238614
[02/03 15:27:19] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/03 15:27:20] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/03 15:27:21] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/03 15:27:22] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/03 15:27:22] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/03 15:27:22] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/03 15:27:22] FCT.data.build INFO: Using training sampler TrainingSampler
[02/03 15:27:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/03 15:27:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/03 15:27:22] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/03 15:27:22] d2.engine.train_loop INFO: Starting training from iteration 0
[02/03 15:27:56] d2.utils.events INFO:  eta: 3:27:21  iter: 19  total_loss: 1.012  loss_cls: 0.7866  loss_box_reg: 0.1462  loss_rpn_cls: 0.08486  loss_rpn_loc: 0.002982  time: 1.2551  data_time: 0.0897  lr: 2.684e-06  max_mem: 18976M
[02/03 15:28:22] d2.utils.events INFO:  eta: 3:28:44  iter: 39  total_loss: 0.87  loss_cls: 0.6723  loss_box_reg: 0.1129  loss_rpn_cls: 0.08575  loss_rpn_loc: 0.008825  time: 1.2679  data_time: 0.0068  lr: 3.404e-06  max_mem: 18976M
[02/03 15:28:48] d2.utils.events INFO:  eta: 3:28:52  iter: 59  total_loss: 0.8624  loss_cls: 0.6277  loss_box_reg: 0.1414  loss_rpn_cls: 0.07309  loss_rpn_loc: 0.006497  time: 1.2694  data_time: 0.0068  lr: 4.124e-06  max_mem: 18976M
[02/03 15:28:51] d2.engine.hooks INFO: Overall training speed: 60 iterations in 0:01:17 (1.2903 s / it)
[02/03 15:28:51] d2.engine.hooks INFO: Total training time: 0:01:17 (0:00:00 on hooks)
[02/03 15:28:51] d2.utils.events INFO:  eta: 3:28:55  iter: 62  total_loss: 0.8569  loss_cls: 0.6188  loss_box_reg: 0.1414  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.006497  time: 1.2696  data_time: 0.0072  lr: 4.196e-06  max_mem: 18976M
[02/03 21:59:19] detectron2 INFO: Rank of current process: 0. World size: 1
[02/03 21:59:20] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/03 21:59:20] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/03 21:59:20] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/03 21:59:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/03 21:59:20] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/03 21:59:20] d2.utils.env INFO: Using a generated random seed 20247507
[02/03 21:59:22] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/03 21:59:23] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/03 21:59:24] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/03 21:59:25] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/03 21:59:25] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/03 21:59:25] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/03 21:59:25] FCT.data.build INFO: Using training sampler TrainingSampler
[02/03 21:59:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/03 21:59:25] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/03 21:59:25] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/03 21:59:25] d2.engine.train_loop INFO: Starting training from iteration 0
[02/03 21:59:51] d2.utils.events INFO:  eta: 3:26:12  iter: 19  total_loss: 1.012  loss_cls: 0.7925  loss_box_reg: 0.1089  loss_rpn_cls: 0.08481  loss_rpn_loc: 0.0057  time: 1.2439  data_time: 0.0549  lr: 2.684e-06  max_mem: 19010M
[02/03 22:00:17] d2.utils.events INFO:  eta: 3:26:54  iter: 39  total_loss: 0.9714  loss_cls: 0.737  loss_box_reg: 0.09164  loss_rpn_cls: 0.08286  loss_rpn_loc: 0.004563  time: 1.2470  data_time: 0.0069  lr: 3.404e-06  max_mem: 19010M
[02/03 22:00:42] d2.utils.events INFO:  eta: 3:26:26  iter: 59  total_loss: 0.8897  loss_cls: 0.6935  loss_box_reg: 0.1323  loss_rpn_cls: 0.06982  loss_rpn_loc: 0.004047  time: 1.2478  data_time: 0.0070  lr: 4.124e-06  max_mem: 19010M
[02/03 22:01:07] d2.utils.events INFO:  eta: 3:26:01  iter: 79  total_loss: 0.83  loss_cls: 0.6391  loss_box_reg: 0.1151  loss_rpn_cls: 0.04228  loss_rpn_loc: 0.003288  time: 1.2488  data_time: 0.0067  lr: 4.844e-06  max_mem: 19010M
[02/03 22:01:32] d2.utils.events INFO:  eta: 3:25:36  iter: 99  total_loss: 0.821  loss_cls: 0.6162  loss_box_reg: 0.1173  loss_rpn_cls: 0.05505  loss_rpn_loc: 0.006115  time: 1.2485  data_time: 0.0066  lr: 5.564e-06  max_mem: 19010M
[02/03 22:01:57] d2.utils.events INFO:  eta: 3:25:16  iter: 119  total_loss: 0.7901  loss_cls: 0.5891  loss_box_reg: 0.1437  loss_rpn_cls: 0.03668  loss_rpn_loc: 0.003164  time: 1.2486  data_time: 0.0067  lr: 6.284e-06  max_mem: 19010M
[02/03 22:02:22] d2.utils.events INFO:  eta: 3:24:55  iter: 139  total_loss: 0.7586  loss_cls: 0.6036  loss_box_reg: 0.08097  loss_rpn_cls: 0.04349  loss_rpn_loc: 0.004365  time: 1.2502  data_time: 0.0069  lr: 7.004e-06  max_mem: 19010M
[02/03 22:02:47] d2.utils.events INFO:  eta: 3:24:29  iter: 159  total_loss: 0.7803  loss_cls: 0.5829  loss_box_reg: 0.1271  loss_rpn_cls: 0.04292  loss_rpn_loc: 0.005302  time: 1.2501  data_time: 0.0064  lr: 7.724e-06  max_mem: 19010M
[02/03 22:03:12] d2.utils.events INFO:  eta: 3:24:04  iter: 179  total_loss: 0.7651  loss_cls: 0.5782  loss_box_reg: 0.1228  loss_rpn_cls: 0.05666  loss_rpn_loc: 0.006839  time: 1.2502  data_time: 0.0065  lr: 8.444e-06  max_mem: 19010M
[02/03 22:03:37] d2.utils.events INFO:  eta: 3:23:41  iter: 199  total_loss: 0.7788  loss_cls: 0.5899  loss_box_reg: 0.1057  loss_rpn_cls: 0.04578  loss_rpn_loc: 0.006511  time: 1.2505  data_time: 0.0068  lr: 9.164e-06  max_mem: 19010M
[02/03 22:04:02] d2.utils.events INFO:  eta: 3:23:16  iter: 219  total_loss: 0.7601  loss_cls: 0.5366  loss_box_reg: 0.1455  loss_rpn_cls: 0.05542  loss_rpn_loc: 0.006202  time: 1.2505  data_time: 0.0067  lr: 9.884e-06  max_mem: 19010M
[02/03 22:04:27] d2.utils.events INFO:  eta: 3:22:50  iter: 239  total_loss: 0.7795  loss_cls: 0.5322  loss_box_reg: 0.1429  loss_rpn_cls: 0.03761  loss_rpn_loc: 0.004074  time: 1.2502  data_time: 0.0065  lr: 1.0604e-05  max_mem: 19010M
[02/03 22:04:53] d2.utils.events INFO:  eta: 3:22:26  iter: 259  total_loss: 0.7303  loss_cls: 0.5536  loss_box_reg: 0.1221  loss_rpn_cls: 0.04127  loss_rpn_loc: 0.004259  time: 1.2514  data_time: 0.0068  lr: 1.1324e-05  max_mem: 19010M
[02/03 22:05:18] d2.utils.events INFO:  eta: 3:22:01  iter: 279  total_loss: 0.7729  loss_cls: 0.5437  loss_box_reg: 0.156  loss_rpn_cls: 0.05357  loss_rpn_loc: 0.006725  time: 1.2516  data_time: 0.0068  lr: 1.2044e-05  max_mem: 19010M
[02/03 22:05:43] d2.utils.events INFO:  eta: 3:21:38  iter: 299  total_loss: 0.7704  loss_cls: 0.538  loss_box_reg: 0.1474  loss_rpn_cls: 0.04478  loss_rpn_loc: 0.003836  time: 1.2517  data_time: 0.0067  lr: 1.2764e-05  max_mem: 19010M
[02/03 22:06:08] d2.utils.events INFO:  eta: 3:21:16  iter: 319  total_loss: 0.7248  loss_cls: 0.5478  loss_box_reg: 0.09903  loss_rpn_cls: 0.03345  loss_rpn_loc: 0.003764  time: 1.2521  data_time: 0.0069  lr: 1.3484e-05  max_mem: 19010M
[02/03 22:06:33] d2.utils.events INFO:  eta: 3:20:55  iter: 339  total_loss: 0.7197  loss_cls: 0.5671  loss_box_reg: 0.1185  loss_rpn_cls: 0.035  loss_rpn_loc: 0.003516  time: 1.2526  data_time: 0.0067  lr: 1.4204e-05  max_mem: 19010M
[02/03 22:06:58] d2.utils.events INFO:  eta: 3:20:31  iter: 359  total_loss: 0.7245  loss_cls: 0.5291  loss_box_reg: 0.1459  loss_rpn_cls: 0.03374  loss_rpn_loc: 0.002744  time: 1.2523  data_time: 0.0064  lr: 1.4924e-05  max_mem: 19010M
[02/03 22:07:23] d2.utils.events INFO:  eta: 3:20:02  iter: 379  total_loss: 0.6784  loss_cls: 0.4709  loss_box_reg: 0.108  loss_rpn_cls: 0.03067  loss_rpn_loc: 0.003377  time: 1.2521  data_time: 0.0066  lr: 1.5644e-05  max_mem: 19010M
[02/03 22:07:48] d2.utils.events INFO:  eta: 3:19:37  iter: 399  total_loss: 0.6793  loss_cls: 0.4936  loss_box_reg: 0.1518  loss_rpn_cls: 0.02987  loss_rpn_loc: 0.003497  time: 1.2519  data_time: 0.0067  lr: 1.6364e-05  max_mem: 19010M
[02/03 22:08:13] d2.utils.events INFO:  eta: 3:19:10  iter: 419  total_loss: 0.7135  loss_cls: 0.5305  loss_box_reg: 0.122  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.003205  time: 1.2518  data_time: 0.0068  lr: 1.7084e-05  max_mem: 19010M
[02/03 22:08:39] d2.utils.events INFO:  eta: 3:18:47  iter: 439  total_loss: 0.6886  loss_cls: 0.5061  loss_box_reg: 0.1139  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.002865  time: 1.2521  data_time: 0.0070  lr: 1.7804e-05  max_mem: 19010M
[02/03 22:09:04] d2.utils.events INFO:  eta: 3:18:25  iter: 459  total_loss: 0.753  loss_cls: 0.5436  loss_box_reg: 0.1665  loss_rpn_cls: 0.03755  loss_rpn_loc: 0.003788  time: 1.2521  data_time: 0.0069  lr: 1.8524e-05  max_mem: 19010M
[02/03 22:09:29] d2.utils.events INFO:  eta: 3:18:03  iter: 479  total_loss: 0.6757  loss_cls: 0.5111  loss_box_reg: 0.1212  loss_rpn_cls: 0.03023  loss_rpn_loc: 0.003354  time: 1.2524  data_time: 0.0066  lr: 1.9244e-05  max_mem: 19010M
[02/03 22:09:54] d2.utils.events INFO:  eta: 3:17:39  iter: 499  total_loss: 0.638  loss_cls: 0.4869  loss_box_reg: 0.1219  loss_rpn_cls: 0.03174  loss_rpn_loc: 0.003965  time: 1.2526  data_time: 0.0071  lr: 1.9964e-05  max_mem: 19010M
[02/03 22:10:19] d2.utils.events INFO:  eta: 3:17:15  iter: 519  total_loss: 0.7036  loss_cls: 0.484  loss_box_reg: 0.1248  loss_rpn_cls: 0.02871  loss_rpn_loc: 0.002762  time: 1.2528  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:10:44] d2.utils.events INFO:  eta: 3:16:50  iter: 539  total_loss: 0.6906  loss_cls: 0.5005  loss_box_reg: 0.1305  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.004426  time: 1.2527  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:11:10] d2.utils.events INFO:  eta: 3:16:25  iter: 559  total_loss: 0.6696  loss_cls: 0.5185  loss_box_reg: 0.09671  loss_rpn_cls: 0.0273  loss_rpn_loc: 0.003239  time: 1.2527  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:11:35] d2.utils.events INFO:  eta: 3:15:58  iter: 579  total_loss: 0.6761  loss_cls: 0.5479  loss_box_reg: 0.09717  loss_rpn_cls: 0.02591  loss_rpn_loc: 0.002701  time: 1.2527  data_time: 0.0066  lr: 2e-05  max_mem: 19010M
[02/03 22:12:00] d2.utils.events INFO:  eta: 3:15:34  iter: 599  total_loss: 0.6035  loss_cls: 0.5032  loss_box_reg: 0.07953  loss_rpn_cls: 0.02638  loss_rpn_loc: 0.003093  time: 1.2526  data_time: 0.0066  lr: 2e-05  max_mem: 19010M
[02/03 22:12:25] d2.utils.events INFO:  eta: 3:15:11  iter: 619  total_loss: 0.6752  loss_cls: 0.5571  loss_box_reg: 0.1145  loss_rpn_cls: 0.03164  loss_rpn_loc: 0.005122  time: 1.2527  data_time: 0.0066  lr: 2e-05  max_mem: 19010M
[02/03 22:12:50] d2.utils.events INFO:  eta: 3:14:47  iter: 639  total_loss: 0.6645  loss_cls: 0.5196  loss_box_reg: 0.1155  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.003453  time: 1.2528  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:13:15] d2.utils.events INFO:  eta: 3:14:23  iter: 659  total_loss: 0.6713  loss_cls: 0.522  loss_box_reg: 0.101  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.004448  time: 1.2528  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:13:40] d2.utils.events INFO:  eta: 3:13:58  iter: 679  total_loss: 0.6565  loss_cls: 0.5068  loss_box_reg: 0.1188  loss_rpn_cls: 0.02502  loss_rpn_loc: 0.002605  time: 1.2530  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:14:06] d2.utils.events INFO:  eta: 3:13:34  iter: 699  total_loss: 0.6449  loss_cls: 0.4966  loss_box_reg: 0.1337  loss_rpn_cls: 0.03032  loss_rpn_loc: 0.004907  time: 1.2531  data_time: 0.0066  lr: 2e-05  max_mem: 19010M
[02/03 22:14:31] d2.utils.events INFO:  eta: 3:13:10  iter: 719  total_loss: 0.6218  loss_cls: 0.4803  loss_box_reg: 0.1092  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.003852  time: 1.2533  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:14:56] d2.utils.events INFO:  eta: 3:12:46  iter: 739  total_loss: 0.6564  loss_cls: 0.4527  loss_box_reg: 0.1589  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.003561  time: 1.2535  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:15:21] d2.utils.events INFO:  eta: 3:12:24  iter: 759  total_loss: 0.6257  loss_cls: 0.464  loss_box_reg: 0.1179  loss_rpn_cls: 0.02332  loss_rpn_loc: 0.003293  time: 1.2536  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:15:47] d2.utils.events INFO:  eta: 3:12:02  iter: 779  total_loss: 0.5967  loss_cls: 0.4685  loss_box_reg: 0.1197  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.003531  time: 1.2537  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:16:12] d2.utils.events INFO:  eta: 3:11:36  iter: 799  total_loss: 0.6503  loss_cls: 0.4379  loss_box_reg: 0.1617  loss_rpn_cls: 0.0236  loss_rpn_loc: 0.002439  time: 1.2536  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:16:37] d2.utils.events INFO:  eta: 3:11:10  iter: 819  total_loss: 0.6893  loss_cls: 0.5449  loss_box_reg: 0.1088  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.004105  time: 1.2535  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:17:02] d2.utils.events INFO:  eta: 3:10:47  iter: 839  total_loss: 0.6818  loss_cls: 0.5258  loss_box_reg: 0.1371  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.004205  time: 1.2535  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:17:27] d2.utils.events INFO:  eta: 3:10:24  iter: 859  total_loss: 0.6989  loss_cls: 0.5575  loss_box_reg: 0.08119  loss_rpn_cls: 0.02441  loss_rpn_loc: 0.003667  time: 1.2536  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:17:52] d2.utils.events INFO:  eta: 3:10:00  iter: 879  total_loss: 0.6358  loss_cls: 0.4992  loss_box_reg: 0.09351  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.002882  time: 1.2537  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:18:17] d2.utils.events INFO:  eta: 3:09:35  iter: 899  total_loss: 0.6453  loss_cls: 0.4672  loss_box_reg: 0.1235  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.003115  time: 1.2537  data_time: 0.0067  lr: 2e-05  max_mem: 19010M
[02/03 22:18:43] d2.utils.events INFO:  eta: 3:09:10  iter: 919  total_loss: 0.6206  loss_cls: 0.5177  loss_box_reg: 0.0841  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.004655  time: 1.2537  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:19:08] d2.utils.events INFO:  eta: 3:08:45  iter: 939  total_loss: 0.6453  loss_cls: 0.4834  loss_box_reg: 0.1141  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.003157  time: 1.2536  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:19:33] d2.utils.events INFO:  eta: 3:08:19  iter: 959  total_loss: 0.6079  loss_cls: 0.434  loss_box_reg: 0.1366  loss_rpn_cls: 0.02051  loss_rpn_loc: 0.002428  time: 1.2535  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:19:58] d2.utils.events INFO:  eta: 3:07:55  iter: 979  total_loss: 0.5988  loss_cls: 0.4514  loss_box_reg: 0.08396  loss_rpn_cls: 0.02072  loss_rpn_loc: 0.003813  time: 1.2535  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:20:23] d2.utils.events INFO:  eta: 3:07:29  iter: 999  total_loss: 0.6209  loss_cls: 0.4158  loss_box_reg: 0.1313  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.003534  time: 1.2534  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:20:48] d2.utils.events INFO:  eta: 3:07:06  iter: 1019  total_loss: 0.6248  loss_cls: 0.4472  loss_box_reg: 0.1338  loss_rpn_cls: 0.02291  loss_rpn_loc: 0.002636  time: 1.2535  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:21:13] d2.utils.events INFO:  eta: 3:06:42  iter: 1039  total_loss: 0.5965  loss_cls: 0.4325  loss_box_reg: 0.1177  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.00364  time: 1.2536  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:21:39] d2.utils.events INFO:  eta: 3:06:17  iter: 1059  total_loss: 0.6369  loss_cls: 0.4299  loss_box_reg: 0.1502  loss_rpn_cls: 0.01688  loss_rpn_loc: 0.002661  time: 1.2537  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:22:04] d2.utils.events INFO:  eta: 3:05:52  iter: 1079  total_loss: 0.6446  loss_cls: 0.4801  loss_box_reg: 0.146  loss_rpn_cls: 0.02043  loss_rpn_loc: 0.002839  time: 1.2538  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:22:29] d2.utils.events INFO:  eta: 3:05:28  iter: 1099  total_loss: 0.6362  loss_cls: 0.4583  loss_box_reg: 0.1424  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.002196  time: 1.2537  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:22:54] d2.utils.events INFO:  eta: 3:05:04  iter: 1119  total_loss: 0.6035  loss_cls: 0.4458  loss_box_reg: 0.1598  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.002459  time: 1.2539  data_time: 0.0066  lr: 2e-05  max_mem: 19010M
[02/03 22:23:19] d2.utils.events INFO:  eta: 3:04:39  iter: 1139  total_loss: 0.6291  loss_cls: 0.4772  loss_box_reg: 0.1113  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.002822  time: 1.2539  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:23:45] d2.utils.events INFO:  eta: 3:04:15  iter: 1159  total_loss: 0.6205  loss_cls: 0.4868  loss_box_reg: 0.08288  loss_rpn_cls: 0.02597  loss_rpn_loc: 0.00647  time: 1.2540  data_time: 0.0066  lr: 2e-05  max_mem: 19010M
[02/03 22:24:10] d2.utils.events INFO:  eta: 3:03:52  iter: 1179  total_loss: 0.6393  loss_cls: 0.4688  loss_box_reg: 0.1269  loss_rpn_cls: 0.02217  loss_rpn_loc: 0.002995  time: 1.2541  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:24:35] d2.utils.events INFO:  eta: 3:03:29  iter: 1199  total_loss: 0.6093  loss_cls: 0.4934  loss_box_reg: 0.1186  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.002402  time: 1.2543  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:25:00] d2.utils.events INFO:  eta: 3:03:04  iter: 1219  total_loss: 0.6225  loss_cls: 0.4797  loss_box_reg: 0.1093  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.005748  time: 1.2544  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:25:26] d2.utils.events INFO:  eta: 3:02:40  iter: 1239  total_loss: 0.5994  loss_cls: 0.4616  loss_box_reg: 0.111  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.002655  time: 1.2543  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:25:51] d2.utils.events INFO:  eta: 3:02:15  iter: 1259  total_loss: 0.631  loss_cls: 0.4788  loss_box_reg: 0.139  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.002835  time: 1.2544  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:26:16] d2.utils.events INFO:  eta: 3:01:50  iter: 1279  total_loss: 0.6352  loss_cls: 0.4221  loss_box_reg: 0.144  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.003046  time: 1.2544  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:26:41] d2.utils.events INFO:  eta: 3:01:25  iter: 1299  total_loss: 0.6273  loss_cls: 0.4737  loss_box_reg: 0.1248  loss_rpn_cls: 0.02273  loss_rpn_loc: 0.003578  time: 1.2545  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:27:06] d2.utils.events INFO:  eta: 3:00:58  iter: 1319  total_loss: 0.6477  loss_cls: 0.4599  loss_box_reg: 0.1122  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.002352  time: 1.2544  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:27:31] d2.utils.events INFO:  eta: 3:00:33  iter: 1339  total_loss: 0.644  loss_cls: 0.4501  loss_box_reg: 0.1084  loss_rpn_cls: 0.01971  loss_rpn_loc: 0.003596  time: 1.2544  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:27:57] d2.utils.events INFO:  eta: 3:00:09  iter: 1359  total_loss: 0.6324  loss_cls: 0.5159  loss_box_reg: 0.1391  loss_rpn_cls: 0.01992  loss_rpn_loc: 0.002909  time: 1.2544  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:28:22] d2.utils.events INFO:  eta: 2:59:44  iter: 1379  total_loss: 0.6077  loss_cls: 0.4446  loss_box_reg: 0.1069  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.00284  time: 1.2544  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:28:47] d2.utils.events INFO:  eta: 2:59:20  iter: 1399  total_loss: 0.6326  loss_cls: 0.4279  loss_box_reg: 0.1553  loss_rpn_cls: 0.02097  loss_rpn_loc: 0.003262  time: 1.2544  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:29:12] d2.utils.events INFO:  eta: 2:58:56  iter: 1419  total_loss: 0.6036  loss_cls: 0.4051  loss_box_reg: 0.1129  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.003515  time: 1.2544  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:29:37] d2.utils.events INFO:  eta: 2:58:31  iter: 1439  total_loss: 0.6338  loss_cls: 0.4947  loss_box_reg: 0.1116  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.003975  time: 1.2545  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:30:02] d2.utils.events INFO:  eta: 2:58:06  iter: 1459  total_loss: 0.6042  loss_cls: 0.4436  loss_box_reg: 0.1505  loss_rpn_cls: 0.01852  loss_rpn_loc: 0.003573  time: 1.2545  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:30:27] d2.utils.events INFO:  eta: 2:57:40  iter: 1479  total_loss: 0.6021  loss_cls: 0.5155  loss_box_reg: 0.1076  loss_rpn_cls: 0.01832  loss_rpn_loc: 0.003145  time: 1.2544  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:30:53] d2.utils.events INFO:  eta: 2:57:15  iter: 1499  total_loss: 0.6077  loss_cls: 0.4531  loss_box_reg: 0.127  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.002849  time: 1.2544  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:31:18] d2.utils.events INFO:  eta: 2:56:50  iter: 1519  total_loss: 0.5963  loss_cls: 0.4532  loss_box_reg: 0.1564  loss_rpn_cls: 0.01693  loss_rpn_loc: 0.003694  time: 1.2544  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 22:31:43] d2.utils.events INFO:  eta: 2:56:26  iter: 1539  total_loss: 0.5787  loss_cls: 0.5038  loss_box_reg: 0.0959  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.003064  time: 1.2544  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:32:08] d2.utils.events INFO:  eta: 2:56:01  iter: 1559  total_loss: 0.6036  loss_cls: 0.4546  loss_box_reg: 0.1152  loss_rpn_cls: 0.018  loss_rpn_loc: 0.004334  time: 1.2544  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:32:33] d2.utils.events INFO:  eta: 2:55:37  iter: 1579  total_loss: 0.6022  loss_cls: 0.474  loss_box_reg: 0.1034  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.003215  time: 1.2544  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:32:58] d2.utils.events INFO:  eta: 2:55:13  iter: 1599  total_loss: 0.5831  loss_cls: 0.48  loss_box_reg: 0.1159  loss_rpn_cls: 0.01783  loss_rpn_loc: 0.003005  time: 1.2543  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:33:23] d2.utils.events INFO:  eta: 2:54:48  iter: 1619  total_loss: 0.5913  loss_cls: 0.4561  loss_box_reg: 0.1166  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.002547  time: 1.2544  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:33:48] d2.utils.events INFO:  eta: 2:54:22  iter: 1639  total_loss: 0.5939  loss_cls: 0.4382  loss_box_reg: 0.09581  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.003171  time: 1.2544  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 22:34:14] d2.utils.events INFO:  eta: 2:53:59  iter: 1659  total_loss: 0.6334  loss_cls: 0.3928  loss_box_reg: 0.15  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.002592  time: 1.2544  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:34:39] d2.utils.events INFO:  eta: 2:53:34  iter: 1679  total_loss: 0.5495  loss_cls: 0.3874  loss_box_reg: 0.1356  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.002869  time: 1.2544  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 22:35:04] d2.utils.events INFO:  eta: 2:53:09  iter: 1699  total_loss: 0.5532  loss_cls: 0.4226  loss_box_reg: 0.103  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.002459  time: 1.2545  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:35:29] d2.utils.events INFO:  eta: 2:52:43  iter: 1719  total_loss: 0.591  loss_cls: 0.448  loss_box_reg: 0.1454  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.003034  time: 1.2546  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:35:54] d2.utils.events INFO:  eta: 2:52:18  iter: 1739  total_loss: 0.5896  loss_cls: 0.4528  loss_box_reg: 0.09576  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.003781  time: 1.2545  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:36:19] d2.utils.events INFO:  eta: 2:51:52  iter: 1759  total_loss: 0.6095  loss_cls: 0.4463  loss_box_reg: 0.1302  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.002927  time: 1.2545  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:36:45] d2.utils.events INFO:  eta: 2:51:27  iter: 1779  total_loss: 0.5346  loss_cls: 0.4162  loss_box_reg: 0.1056  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.002401  time: 1.2545  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:37:10] d2.utils.events INFO:  eta: 2:51:02  iter: 1799  total_loss: 0.6018  loss_cls: 0.4407  loss_box_reg: 0.1016  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.002396  time: 1.2545  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:37:35] d2.utils.events INFO:  eta: 2:50:38  iter: 1819  total_loss: 0.5713  loss_cls: 0.398  loss_box_reg: 0.1335  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.003109  time: 1.2545  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:38:00] d2.utils.events INFO:  eta: 2:50:13  iter: 1839  total_loss: 0.5539  loss_cls: 0.4074  loss_box_reg: 0.1269  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.002807  time: 1.2546  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 22:38:25] d2.utils.events INFO:  eta: 2:49:47  iter: 1859  total_loss: 0.6087  loss_cls: 0.5064  loss_box_reg: 0.1019  loss_rpn_cls: 0.01657  loss_rpn_loc: 0.004255  time: 1.2545  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:38:50] d2.utils.events INFO:  eta: 2:49:22  iter: 1879  total_loss: 0.6259  loss_cls: 0.5048  loss_box_reg: 0.09378  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.003072  time: 1.2545  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:39:16] d2.utils.events INFO:  eta: 2:48:57  iter: 1899  total_loss: 0.6006  loss_cls: 0.4526  loss_box_reg: 0.09042  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.003586  time: 1.2546  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:39:41] d2.utils.events INFO:  eta: 2:48:32  iter: 1919  total_loss: 0.5944  loss_cls: 0.4204  loss_box_reg: 0.1185  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.003119  time: 1.2546  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:40:06] d2.utils.events INFO:  eta: 2:48:09  iter: 1939  total_loss: 0.5822  loss_cls: 0.4691  loss_box_reg: 0.1205  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.002775  time: 1.2546  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:40:31] d2.utils.events INFO:  eta: 2:47:44  iter: 1959  total_loss: 0.6168  loss_cls: 0.4037  loss_box_reg: 0.1049  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.002682  time: 1.2546  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:40:56] d2.utils.events INFO:  eta: 2:47:19  iter: 1979  total_loss: 0.5507  loss_cls: 0.4377  loss_box_reg: 0.1003  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.002397  time: 1.2546  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:41:22] d2.utils.events INFO:  eta: 2:46:53  iter: 1999  total_loss: 0.5717  loss_cls: 0.4423  loss_box_reg: 0.1168  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.003182  time: 1.2546  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:41:47] d2.utils.events INFO:  eta: 2:46:27  iter: 2019  total_loss: 0.5829  loss_cls: 0.4395  loss_box_reg: 0.1301  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.003208  time: 1.2545  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:42:12] d2.utils.events INFO:  eta: 2:46:02  iter: 2039  total_loss: 0.5941  loss_cls: 0.4407  loss_box_reg: 0.0915  loss_rpn_cls: 0.01721  loss_rpn_loc: 0.003624  time: 1.2545  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:42:37] d2.utils.events INFO:  eta: 2:45:36  iter: 2059  total_loss: 0.5422  loss_cls: 0.4331  loss_box_reg: 0.1167  loss_rpn_cls: 0.02383  loss_rpn_loc: 0.005209  time: 1.2545  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:43:02] d2.utils.events INFO:  eta: 2:45:12  iter: 2079  total_loss: 0.5582  loss_cls: 0.4277  loss_box_reg: 0.1274  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.002459  time: 1.2545  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:43:27] d2.utils.events INFO:  eta: 2:44:47  iter: 2099  total_loss: 0.6353  loss_cls: 0.4661  loss_box_reg: 0.1309  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.00338  time: 1.2545  data_time: 0.0068  lr: 2e-05  max_mem: 19010M
[02/03 22:43:52] d2.utils.events INFO:  eta: 2:44:22  iter: 2119  total_loss: 0.5343  loss_cls: 0.3585  loss_box_reg: 0.1565  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.002663  time: 1.2545  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:44:18] d2.utils.events INFO:  eta: 2:43:57  iter: 2139  total_loss: 0.5194  loss_cls: 0.3411  loss_box_reg: 0.1309  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.003716  time: 1.2545  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:44:43] d2.utils.events INFO:  eta: 2:43:32  iter: 2159  total_loss: 0.5981  loss_cls: 0.403  loss_box_reg: 0.09654  loss_rpn_cls: 0.01792  loss_rpn_loc: 0.003752  time: 1.2545  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:45:08] d2.utils.events INFO:  eta: 2:43:07  iter: 2179  total_loss: 0.6186  loss_cls: 0.4814  loss_box_reg: 0.1195  loss_rpn_cls: 0.02098  loss_rpn_loc: 0.004162  time: 1.2546  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:45:33] d2.utils.events INFO:  eta: 2:42:41  iter: 2199  total_loss: 0.5769  loss_cls: 0.4381  loss_box_reg: 0.1047  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.002949  time: 1.2546  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:45:58] d2.utils.events INFO:  eta: 2:42:16  iter: 2219  total_loss: 0.6115  loss_cls: 0.4576  loss_box_reg: 0.1191  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.003396  time: 1.2546  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:46:23] d2.utils.events INFO:  eta: 2:41:51  iter: 2239  total_loss: 0.56  loss_cls: 0.4451  loss_box_reg: 0.09457  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.002904  time: 1.2546  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:46:48] d2.utils.events INFO:  eta: 2:41:26  iter: 2259  total_loss: 0.5727  loss_cls: 0.4062  loss_box_reg: 0.1012  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.002537  time: 1.2546  data_time: 0.0069  lr: 2e-05  max_mem: 19010M
[02/03 22:47:14] d2.utils.events INFO:  eta: 2:41:01  iter: 2279  total_loss: 0.5041  loss_cls: 0.4073  loss_box_reg: 0.09644  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.002352  time: 1.2546  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:47:39] d2.utils.events INFO:  eta: 2:40:35  iter: 2299  total_loss: 0.5789  loss_cls: 0.421  loss_box_reg: 0.1089  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.004331  time: 1.2545  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:48:04] d2.utils.events INFO:  eta: 2:40:12  iter: 2319  total_loss: 0.5639  loss_cls: 0.3222  loss_box_reg: 0.1532  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.002871  time: 1.2546  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:48:29] d2.utils.events INFO:  eta: 2:39:46  iter: 2339  total_loss: 0.5793  loss_cls: 0.3961  loss_box_reg: 0.1319  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.003138  time: 1.2546  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:48:54] d2.utils.events INFO:  eta: 2:39:21  iter: 2359  total_loss: 0.5561  loss_cls: 0.4284  loss_box_reg: 0.09404  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.003219  time: 1.2546  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 22:49:20] d2.utils.events INFO:  eta: 2:38:57  iter: 2379  total_loss: 0.6018  loss_cls: 0.4453  loss_box_reg: 0.1092  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.001742  time: 1.2547  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:49:45] d2.utils.events INFO:  eta: 2:38:33  iter: 2399  total_loss: 0.5912  loss_cls: 0.4339  loss_box_reg: 0.1048  loss_rpn_cls: 0.01785  loss_rpn_loc: 0.00305  time: 1.2547  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:50:10] d2.utils.events INFO:  eta: 2:38:09  iter: 2419  total_loss: 0.5228  loss_cls: 0.4336  loss_box_reg: 0.0964  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.002668  time: 1.2547  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 22:50:35] d2.utils.events INFO:  eta: 2:37:44  iter: 2439  total_loss: 0.5546  loss_cls: 0.4209  loss_box_reg: 0.07068  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.003867  time: 1.2548  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:51:00] d2.utils.events INFO:  eta: 2:37:20  iter: 2459  total_loss: 0.5422  loss_cls: 0.384  loss_box_reg: 0.1298  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.002649  time: 1.2548  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:51:26] d2.utils.events INFO:  eta: 2:36:55  iter: 2479  total_loss: 0.5469  loss_cls: 0.4237  loss_box_reg: 0.09111  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.003737  time: 1.2548  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:51:51] d2.utils.events INFO:  eta: 2:36:31  iter: 2499  total_loss: 0.5617  loss_cls: 0.4216  loss_box_reg: 0.1321  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.002822  time: 1.2548  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:52:16] d2.utils.events INFO:  eta: 2:36:06  iter: 2519  total_loss: 0.5117  loss_cls: 0.386  loss_box_reg: 0.0889  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.002669  time: 1.2548  data_time: 0.0070  lr: 2e-05  max_mem: 19010M
[02/03 22:52:41] d2.utils.events INFO:  eta: 2:35:40  iter: 2539  total_loss: 0.6285  loss_cls: 0.5003  loss_box_reg: 0.09901  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.00231  time: 1.2547  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:53:06] d2.utils.events INFO:  eta: 2:35:15  iter: 2559  total_loss: 0.6231  loss_cls: 0.4821  loss_box_reg: 0.1054  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.003069  time: 1.2548  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:53:31] d2.utils.events INFO:  eta: 2:34:50  iter: 2579  total_loss: 0.5822  loss_cls: 0.4519  loss_box_reg: 0.09569  loss_rpn_cls: 0.02102  loss_rpn_loc: 0.003372  time: 1.2548  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:53:57] d2.utils.events INFO:  eta: 2:34:25  iter: 2599  total_loss: 0.5921  loss_cls: 0.4544  loss_box_reg: 0.1176  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.002852  time: 1.2549  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 22:54:22] d2.utils.events INFO:  eta: 2:34:01  iter: 2619  total_loss: 0.6074  loss_cls: 0.4201  loss_box_reg: 0.1134  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.003504  time: 1.2550  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:54:47] d2.utils.events INFO:  eta: 2:33:36  iter: 2639  total_loss: 0.5648  loss_cls: 0.4265  loss_box_reg: 0.1194  loss_rpn_cls: 0.01773  loss_rpn_loc: 0.00348  time: 1.2550  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:55:13] d2.utils.events INFO:  eta: 2:33:11  iter: 2659  total_loss: 0.6011  loss_cls: 0.4432  loss_box_reg: 0.1387  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.003482  time: 1.2550  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:55:38] d2.utils.events INFO:  eta: 2:32:46  iter: 2679  total_loss: 0.5422  loss_cls: 0.4177  loss_box_reg: 0.1102  loss_rpn_cls: 0.02297  loss_rpn_loc: 0.004274  time: 1.2550  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:56:03] d2.utils.events INFO:  eta: 2:32:21  iter: 2699  total_loss: 0.5659  loss_cls: 0.4062  loss_box_reg: 0.1084  loss_rpn_cls: 0.01661  loss_rpn_loc: 0.002752  time: 1.2551  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 22:56:28] d2.utils.events INFO:  eta: 2:31:55  iter: 2719  total_loss: 0.5518  loss_cls: 0.4403  loss_box_reg: 0.08381  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.002417  time: 1.2550  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:56:53] d2.utils.events INFO:  eta: 2:31:30  iter: 2739  total_loss: 0.5609  loss_cls: 0.4503  loss_box_reg: 0.09891  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.004007  time: 1.2550  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 22:57:18] d2.utils.events INFO:  eta: 2:31:05  iter: 2759  total_loss: 0.5005  loss_cls: 0.3754  loss_box_reg: 0.1159  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.002698  time: 1.2549  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 22:57:43] d2.utils.events INFO:  eta: 2:30:40  iter: 2779  total_loss: 0.5691  loss_cls: 0.4514  loss_box_reg: 0.112  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.002667  time: 1.2549  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 22:58:09] d2.utils.events INFO:  eta: 2:30:15  iter: 2799  total_loss: 0.6257  loss_cls: 0.3611  loss_box_reg: 0.13  loss_rpn_cls: 0.01515  loss_rpn_loc: 0.002626  time: 1.2550  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 22:58:34] d2.utils.events INFO:  eta: 2:29:50  iter: 2819  total_loss: 0.6371  loss_cls: 0.4635  loss_box_reg: 0.1251  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.003488  time: 1.2550  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 22:58:59] d2.utils.events INFO:  eta: 2:29:24  iter: 2839  total_loss: 0.5151  loss_cls: 0.354  loss_box_reg: 0.1228  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.002794  time: 1.2549  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 22:59:24] d2.utils.events INFO:  eta: 2:28:59  iter: 2859  total_loss: 0.5311  loss_cls: 0.4165  loss_box_reg: 0.1041  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.004041  time: 1.2549  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 22:59:49] d2.utils.events INFO:  eta: 2:28:35  iter: 2879  total_loss: 0.5568  loss_cls: 0.4206  loss_box_reg: 0.08458  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.003206  time: 1.2549  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:00:14] d2.utils.events INFO:  eta: 2:28:09  iter: 2899  total_loss: 0.57  loss_cls: 0.4149  loss_box_reg: 0.1199  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.003152  time: 1.2549  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:00:39] d2.utils.events INFO:  eta: 2:27:43  iter: 2919  total_loss: 0.5193  loss_cls: 0.4044  loss_box_reg: 0.1001  loss_rpn_cls: 0.01548  loss_rpn_loc: 0.003424  time: 1.2548  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:01:04] d2.utils.events INFO:  eta: 2:27:16  iter: 2939  total_loss: 0.5471  loss_cls: 0.4068  loss_box_reg: 0.1003  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.002437  time: 1.2548  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:01:29] d2.utils.events INFO:  eta: 2:26:51  iter: 2959  total_loss: 0.5162  loss_cls: 0.4146  loss_box_reg: 0.08264  loss_rpn_cls: 0.01263  loss_rpn_loc: 0.003608  time: 1.2547  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:01:54] d2.utils.events INFO:  eta: 2:26:25  iter: 2979  total_loss: 0.6093  loss_cls: 0.4545  loss_box_reg: 0.1062  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.003442  time: 1.2547  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:02:19] d2.utils.events INFO:  eta: 2:26:00  iter: 2999  total_loss: 0.5929  loss_cls: 0.4819  loss_box_reg: 0.08477  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.002891  time: 1.2546  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:02:44] d2.utils.events INFO:  eta: 2:25:35  iter: 3019  total_loss: 0.5116  loss_cls: 0.3602  loss_box_reg: 0.1037  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.002508  time: 1.2546  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:03:09] d2.utils.events INFO:  eta: 2:25:08  iter: 3039  total_loss: 0.5333  loss_cls: 0.3722  loss_box_reg: 0.1062  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.00258  time: 1.2545  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 23:03:34] d2.utils.events INFO:  eta: 2:24:43  iter: 3059  total_loss: 0.5242  loss_cls: 0.4146  loss_box_reg: 0.1055  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.002419  time: 1.2544  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:03:59] d2.utils.events INFO:  eta: 2:24:16  iter: 3079  total_loss: 0.5878  loss_cls: 0.4435  loss_box_reg: 0.09908  loss_rpn_cls: 0.01315  loss_rpn_loc: 0.002878  time: 1.2544  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:04:24] d2.utils.events INFO:  eta: 2:23:52  iter: 3099  total_loss: 0.4893  loss_cls: 0.3795  loss_box_reg: 0.09572  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.002226  time: 1.2544  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:04:49] d2.utils.events INFO:  eta: 2:23:25  iter: 3119  total_loss: 0.6061  loss_cls: 0.4867  loss_box_reg: 0.09368  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.003016  time: 1.2544  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:05:14] d2.utils.events INFO:  eta: 2:23:00  iter: 3139  total_loss: 0.5271  loss_cls: 0.382  loss_box_reg: 0.09856  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.002069  time: 1.2543  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:05:39] d2.utils.events INFO:  eta: 2:22:35  iter: 3159  total_loss: 0.5626  loss_cls: 0.3998  loss_box_reg: 0.08874  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.002142  time: 1.2543  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:06:04] d2.utils.events INFO:  eta: 2:22:09  iter: 3179  total_loss: 0.4701  loss_cls: 0.3887  loss_box_reg: 0.06614  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.001774  time: 1.2543  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:06:29] d2.utils.events INFO:  eta: 2:21:45  iter: 3199  total_loss: 0.6526  loss_cls: 0.4593  loss_box_reg: 0.1127  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.003063  time: 1.2543  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:06:54] d2.utils.events INFO:  eta: 2:21:20  iter: 3219  total_loss: 0.5969  loss_cls: 0.4485  loss_box_reg: 0.08395  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.003189  time: 1.2542  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:07:20] d2.utils.events INFO:  eta: 2:20:55  iter: 3239  total_loss: 0.5518  loss_cls: 0.431  loss_box_reg: 0.09244  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.002576  time: 1.2542  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:07:45] d2.utils.events INFO:  eta: 2:20:29  iter: 3259  total_loss: 0.5885  loss_cls: 0.4702  loss_box_reg: 0.09837  loss_rpn_cls: 0.019  loss_rpn_loc: 0.003222  time: 1.2542  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:08:10] d2.utils.events INFO:  eta: 2:20:05  iter: 3279  total_loss: 0.552  loss_cls: 0.4211  loss_box_reg: 0.1011  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.003151  time: 1.2542  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:08:35] d2.utils.events INFO:  eta: 2:19:39  iter: 3299  total_loss: 0.5184  loss_cls: 0.4099  loss_box_reg: 0.08973  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.003216  time: 1.2542  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:09:00] d2.utils.events INFO:  eta: 2:19:14  iter: 3319  total_loss: 0.5307  loss_cls: 0.415  loss_box_reg: 0.097  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.002378  time: 1.2541  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:09:25] d2.utils.events INFO:  eta: 2:18:47  iter: 3339  total_loss: 0.5577  loss_cls: 0.4212  loss_box_reg: 0.08952  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.002961  time: 1.2541  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:09:50] d2.utils.events INFO:  eta: 2:18:22  iter: 3359  total_loss: 0.5446  loss_cls: 0.3667  loss_box_reg: 0.1308  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.003435  time: 1.2541  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:10:15] d2.utils.events INFO:  eta: 2:17:57  iter: 3379  total_loss: 0.621  loss_cls: 0.4278  loss_box_reg: 0.08607  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.002788  time: 1.2541  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:10:40] d2.utils.events INFO:  eta: 2:17:30  iter: 3399  total_loss: 0.5852  loss_cls: 0.438  loss_box_reg: 0.1102  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.003335  time: 1.2541  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:11:05] d2.utils.events INFO:  eta: 2:17:05  iter: 3419  total_loss: 0.5638  loss_cls: 0.4424  loss_box_reg: 0.1033  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.002532  time: 1.2540  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:11:30] d2.utils.events INFO:  eta: 2:16:39  iter: 3439  total_loss: 0.4695  loss_cls: 0.3857  loss_box_reg: 0.08066  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.003274  time: 1.2540  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:11:55] d2.utils.events INFO:  eta: 2:16:13  iter: 3459  total_loss: 0.513  loss_cls: 0.3896  loss_box_reg: 0.1316  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.002939  time: 1.2540  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:12:20] d2.utils.events INFO:  eta: 2:15:48  iter: 3479  total_loss: 0.5578  loss_cls: 0.3979  loss_box_reg: 0.1134  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.003029  time: 1.2540  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:12:45] d2.utils.events INFO:  eta: 2:15:23  iter: 3499  total_loss: 0.5402  loss_cls: 0.4178  loss_box_reg: 0.05989  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.002791  time: 1.2539  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:13:10] d2.utils.events INFO:  eta: 2:14:57  iter: 3519  total_loss: 0.5591  loss_cls: 0.458  loss_box_reg: 0.09116  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.003786  time: 1.2539  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/03 23:13:36] d2.utils.events INFO:  eta: 2:14:34  iter: 3539  total_loss: 0.534  loss_cls: 0.4185  loss_box_reg: 0.07393  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.002556  time: 1.2539  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/03 23:14:01] d2.utils.events INFO:  eta: 2:14:08  iter: 3559  total_loss: 0.5342  loss_cls: 0.3889  loss_box_reg: 0.0878  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.00241  time: 1.2539  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:14:26] d2.utils.events INFO:  eta: 2:13:43  iter: 3579  total_loss: 0.502  loss_cls: 0.4046  loss_box_reg: 0.07458  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.002656  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:14:51] d2.utils.events INFO:  eta: 2:13:16  iter: 3599  total_loss: 0.5162  loss_cls: 0.4065  loss_box_reg: 0.09517  loss_rpn_cls: 0.01311  loss_rpn_loc: 0.002871  time: 1.2538  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:15:16] d2.utils.events INFO:  eta: 2:12:50  iter: 3619  total_loss: 0.5557  loss_cls: 0.4156  loss_box_reg: 0.09679  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.003955  time: 1.2538  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:15:41] d2.utils.events INFO:  eta: 2:12:25  iter: 3639  total_loss: 0.4896  loss_cls: 0.36  loss_box_reg: 0.08354  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.002337  time: 1.2538  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:16:06] d2.utils.events INFO:  eta: 2:11:59  iter: 3659  total_loss: 0.5672  loss_cls: 0.4701  loss_box_reg: 0.08413  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.003307  time: 1.2538  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:16:31] d2.utils.events INFO:  eta: 2:11:33  iter: 3679  total_loss: 0.5481  loss_cls: 0.4383  loss_box_reg: 0.114  loss_rpn_cls: 0.01265  loss_rpn_loc: 0.002752  time: 1.2538  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:16:56] d2.utils.events INFO:  eta: 2:11:09  iter: 3699  total_loss: 0.525  loss_cls: 0.3599  loss_box_reg: 0.1039  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.002724  time: 1.2538  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:17:21] d2.utils.events INFO:  eta: 2:10:45  iter: 3719  total_loss: 0.4599  loss_cls: 0.2998  loss_box_reg: 0.09601  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.003007  time: 1.2538  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:17:46] d2.utils.events INFO:  eta: 2:10:21  iter: 3739  total_loss: 0.5806  loss_cls: 0.4823  loss_box_reg: 0.08167  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.002719  time: 1.2538  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/03 23:18:12] d2.utils.events INFO:  eta: 2:09:57  iter: 3759  total_loss: 0.5251  loss_cls: 0.4408  loss_box_reg: 0.08057  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.00269  time: 1.2538  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:18:37] d2.utils.events INFO:  eta: 2:09:32  iter: 3779  total_loss: 0.5289  loss_cls: 0.3904  loss_box_reg: 0.1076  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.002945  time: 1.2538  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:19:02] d2.utils.events INFO:  eta: 2:09:07  iter: 3799  total_loss: 0.4757  loss_cls: 0.3791  loss_box_reg: 0.07602  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.002355  time: 1.2538  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/03 23:19:27] d2.utils.events INFO:  eta: 2:08:40  iter: 3819  total_loss: 0.4769  loss_cls: 0.3757  loss_box_reg: 0.09774  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.002308  time: 1.2538  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:19:52] d2.utils.events INFO:  eta: 2:08:16  iter: 3839  total_loss: 0.5228  loss_cls: 0.3838  loss_box_reg: 0.08932  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.003617  time: 1.2538  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/03 23:20:17] d2.utils.events INFO:  eta: 2:07:51  iter: 3859  total_loss: 0.5948  loss_cls: 0.4768  loss_box_reg: 0.07581  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.003933  time: 1.2537  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/03 23:20:42] d2.utils.events INFO:  eta: 2:07:26  iter: 3879  total_loss: 0.467  loss_cls: 0.3381  loss_box_reg: 0.105  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.002411  time: 1.2537  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:21:07] d2.utils.events INFO:  eta: 2:07:00  iter: 3899  total_loss: 0.5706  loss_cls: 0.4345  loss_box_reg: 0.1128  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.004189  time: 1.2537  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:21:32] d2.utils.events INFO:  eta: 2:06:37  iter: 3919  total_loss: 0.5001  loss_cls: 0.3948  loss_box_reg: 0.1202  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.003691  time: 1.2537  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/03 23:21:57] d2.utils.events INFO:  eta: 2:06:12  iter: 3939  total_loss: 0.5325  loss_cls: 0.4159  loss_box_reg: 0.08998  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.002784  time: 1.2537  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:22:22] d2.utils.events INFO:  eta: 2:05:48  iter: 3959  total_loss: 0.4979  loss_cls: 0.3872  loss_box_reg: 0.08831  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.002817  time: 1.2537  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:22:47] d2.utils.events INFO:  eta: 2:05:24  iter: 3979  total_loss: 0.566  loss_cls: 0.43  loss_box_reg: 0.07348  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.002492  time: 1.2537  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:23:12] d2.utils.events INFO:  eta: 2:04:59  iter: 3999  total_loss: 0.4986  loss_cls: 0.3947  loss_box_reg: 0.07475  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.002762  time: 1.2536  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:23:38] d2.utils.events INFO:  eta: 2:04:34  iter: 4019  total_loss: 0.5496  loss_cls: 0.4297  loss_box_reg: 0.08413  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.00467  time: 1.2536  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:24:03] d2.utils.events INFO:  eta: 2:04:10  iter: 4039  total_loss: 0.5453  loss_cls: 0.4632  loss_box_reg: 0.08415  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.002334  time: 1.2536  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:24:28] d2.utils.events INFO:  eta: 2:03:46  iter: 4059  total_loss: 0.5418  loss_cls: 0.429  loss_box_reg: 0.06975  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.002148  time: 1.2536  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:24:53] d2.utils.events INFO:  eta: 2:03:22  iter: 4079  total_loss: 0.5577  loss_cls: 0.4707  loss_box_reg: 0.06674  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.002865  time: 1.2536  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/03 23:25:18] d2.utils.events INFO:  eta: 2:02:57  iter: 4099  total_loss: 0.5055  loss_cls: 0.384  loss_box_reg: 0.09468  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.00374  time: 1.2536  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/03 23:25:43] d2.utils.events INFO:  eta: 2:02:31  iter: 4119  total_loss: 0.5186  loss_cls: 0.396  loss_box_reg: 0.1177  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.002966  time: 1.2535  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:26:08] d2.utils.events INFO:  eta: 2:02:06  iter: 4139  total_loss: 0.5009  loss_cls: 0.3704  loss_box_reg: 0.08301  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.002743  time: 1.2535  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:26:33] d2.utils.events INFO:  eta: 2:01:41  iter: 4159  total_loss: 0.5447  loss_cls: 0.4297  loss_box_reg: 0.08694  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.002793  time: 1.2535  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:26:58] d2.utils.events INFO:  eta: 2:01:16  iter: 4179  total_loss: 0.5858  loss_cls: 0.4561  loss_box_reg: 0.1046  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.004529  time: 1.2535  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:27:23] d2.utils.events INFO:  eta: 2:00:50  iter: 4199  total_loss: 0.5133  loss_cls: 0.347  loss_box_reg: 0.09955  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.00245  time: 1.2535  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:27:48] d2.utils.events INFO:  eta: 2:00:25  iter: 4219  total_loss: 0.4915  loss_cls: 0.3724  loss_box_reg: 0.09997  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.002022  time: 1.2535  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/03 23:28:13] d2.utils.events INFO:  eta: 2:00:01  iter: 4239  total_loss: 0.5077  loss_cls: 0.3803  loss_box_reg: 0.08318  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.003257  time: 1.2535  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:28:39] d2.utils.events INFO:  eta: 1:59:36  iter: 4259  total_loss: 0.4925  loss_cls: 0.3611  loss_box_reg: 0.1269  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.002628  time: 1.2535  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:29:04] d2.utils.events INFO:  eta: 1:59:10  iter: 4279  total_loss: 0.5678  loss_cls: 0.4282  loss_box_reg: 0.06548  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.003053  time: 1.2535  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:29:29] d2.utils.events INFO:  eta: 1:58:46  iter: 4299  total_loss: 0.605  loss_cls: 0.4582  loss_box_reg: 0.09978  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.002072  time: 1.2535  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:29:54] d2.utils.events INFO:  eta: 1:58:21  iter: 4319  total_loss: 0.4798  loss_cls: 0.3937  loss_box_reg: 0.0732  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.002709  time: 1.2535  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:30:19] d2.utils.events INFO:  eta: 1:57:57  iter: 4339  total_loss: 0.542  loss_cls: 0.3467  loss_box_reg: 0.1116  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.00307  time: 1.2535  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:30:44] d2.utils.events INFO:  eta: 1:57:32  iter: 4359  total_loss: 0.5051  loss_cls: 0.3889  loss_box_reg: 0.08649  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.004646  time: 1.2535  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:31:09] d2.utils.events INFO:  eta: 1:57:07  iter: 4379  total_loss: 0.5958  loss_cls: 0.4134  loss_box_reg: 0.1121  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.003861  time: 1.2535  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 23:31:35] d2.utils.events INFO:  eta: 1:56:42  iter: 4399  total_loss: 0.4586  loss_cls: 0.3066  loss_box_reg: 0.09716  loss_rpn_cls: 0.009529  loss_rpn_loc: 0.00231  time: 1.2535  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:32:00] d2.utils.events INFO:  eta: 1:56:17  iter: 4419  total_loss: 0.5437  loss_cls: 0.429  loss_box_reg: 0.08483  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.002499  time: 1.2535  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:32:25] d2.utils.events INFO:  eta: 1:55:53  iter: 4439  total_loss: 0.5299  loss_cls: 0.4167  loss_box_reg: 0.1037  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.002832  time: 1.2535  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:32:50] d2.utils.events INFO:  eta: 1:55:28  iter: 4459  total_loss: 0.5217  loss_cls: 0.3817  loss_box_reg: 0.08304  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.002669  time: 1.2536  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:33:15] d2.utils.events INFO:  eta: 1:55:03  iter: 4479  total_loss: 0.5255  loss_cls: 0.4293  loss_box_reg: 0.08291  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.00272  time: 1.2536  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:33:41] d2.utils.events INFO:  eta: 1:54:38  iter: 4499  total_loss: 0.5055  loss_cls: 0.3859  loss_box_reg: 0.06676  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.002676  time: 1.2536  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:34:06] d2.utils.events INFO:  eta: 1:54:14  iter: 4519  total_loss: 0.5118  loss_cls: 0.3466  loss_box_reg: 0.09364  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.002035  time: 1.2537  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:34:31] d2.utils.events INFO:  eta: 1:53:49  iter: 4539  total_loss: 0.5435  loss_cls: 0.4049  loss_box_reg: 0.09156  loss_rpn_cls: 0.01481  loss_rpn_loc: 0.002609  time: 1.2537  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:34:56] d2.utils.events INFO:  eta: 1:53:24  iter: 4559  total_loss: 0.5153  loss_cls: 0.3914  loss_box_reg: 0.09295  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.002058  time: 1.2537  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:35:21] d2.utils.events INFO:  eta: 1:52:59  iter: 4579  total_loss: 0.6043  loss_cls: 0.4298  loss_box_reg: 0.08523  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.003266  time: 1.2537  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:35:47] d2.utils.events INFO:  eta: 1:52:34  iter: 4599  total_loss: 0.4967  loss_cls: 0.4079  loss_box_reg: 0.09364  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.002084  time: 1.2537  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:36:12] d2.utils.events INFO:  eta: 1:52:09  iter: 4619  total_loss: 0.5441  loss_cls: 0.4207  loss_box_reg: 0.07037  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.002621  time: 1.2537  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:36:37] d2.utils.events INFO:  eta: 1:51:44  iter: 4639  total_loss: 0.5354  loss_cls: 0.4247  loss_box_reg: 0.09468  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.003539  time: 1.2537  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:37:02] d2.utils.events INFO:  eta: 1:51:19  iter: 4659  total_loss: 0.4908  loss_cls: 0.3671  loss_box_reg: 0.08101  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.002231  time: 1.2537  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:37:27] d2.utils.events INFO:  eta: 1:50:54  iter: 4679  total_loss: 0.4758  loss_cls: 0.3628  loss_box_reg: 0.09816  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.003003  time: 1.2537  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:37:53] d2.utils.events INFO:  eta: 1:50:29  iter: 4699  total_loss: 0.4747  loss_cls: 0.3429  loss_box_reg: 0.08719  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.00211  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:38:18] d2.utils.events INFO:  eta: 1:50:04  iter: 4719  total_loss: 0.5714  loss_cls: 0.4399  loss_box_reg: 0.1095  loss_rpn_cls: 0.01555  loss_rpn_loc: 0.003156  time: 1.2538  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 23:38:43] d2.utils.events INFO:  eta: 1:49:39  iter: 4739  total_loss: 0.4558  loss_cls: 0.3545  loss_box_reg: 0.08275  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.002625  time: 1.2538  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:39:08] d2.utils.events INFO:  eta: 1:49:14  iter: 4759  total_loss: 0.5241  loss_cls: 0.4159  loss_box_reg: 0.08475  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.002979  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:39:33] d2.utils.events INFO:  eta: 1:48:49  iter: 4779  total_loss: 0.4369  loss_cls: 0.3326  loss_box_reg: 0.09825  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.001988  time: 1.2538  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 23:39:58] d2.utils.events INFO:  eta: 1:48:23  iter: 4799  total_loss: 0.4734  loss_cls: 0.2913  loss_box_reg: 0.08425  loss_rpn_cls: 0.009298  loss_rpn_loc: 0.001749  time: 1.2538  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 23:40:24] d2.utils.events INFO:  eta: 1:47:59  iter: 4819  total_loss: 0.4817  loss_cls: 0.3632  loss_box_reg: 0.08361  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.002467  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:40:49] d2.utils.events INFO:  eta: 1:47:34  iter: 4839  total_loss: 0.5492  loss_cls: 0.4215  loss_box_reg: 0.1105  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.002956  time: 1.2538  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:41:14] d2.utils.events INFO:  eta: 1:47:09  iter: 4859  total_loss: 0.5443  loss_cls: 0.4479  loss_box_reg: 0.08461  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.002581  time: 1.2538  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:41:39] d2.utils.events INFO:  eta: 1:46:44  iter: 4879  total_loss: 0.522  loss_cls: 0.3517  loss_box_reg: 0.111  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.002789  time: 1.2539  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:42:04] d2.utils.events INFO:  eta: 1:46:19  iter: 4899  total_loss: 0.4683  loss_cls: 0.3403  loss_box_reg: 0.09723  loss_rpn_cls: 0.00955  loss_rpn_loc: 0.002328  time: 1.2539  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:42:30] d2.utils.events INFO:  eta: 1:45:54  iter: 4919  total_loss: 0.4792  loss_cls: 0.3662  loss_box_reg: 0.08713  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.005239  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:42:55] d2.utils.events INFO:  eta: 1:45:29  iter: 4939  total_loss: 0.4246  loss_cls: 0.3033  loss_box_reg: 0.1084  loss_rpn_cls: 0.009582  loss_rpn_loc: 0.001596  time: 1.2539  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:43:20] d2.utils.events INFO:  eta: 1:45:04  iter: 4959  total_loss: 0.482  loss_cls: 0.3952  loss_box_reg: 0.07178  loss_rpn_cls: 0.009953  loss_rpn_loc: 0.001657  time: 1.2539  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:43:45] d2.utils.events INFO:  eta: 1:44:39  iter: 4979  total_loss: 0.5171  loss_cls: 0.3634  loss_box_reg: 0.09352  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.003025  time: 1.2539  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:44:10] d2.utils.events INFO:  eta: 1:44:14  iter: 4999  total_loss: 0.5206  loss_cls: 0.3928  loss_box_reg: 0.09041  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.002248  time: 1.2539  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:44:35] d2.utils.events INFO:  eta: 1:43:49  iter: 5019  total_loss: 0.4196  loss_cls: 0.3207  loss_box_reg: 0.09353  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.002225  time: 1.2539  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/03 23:45:00] d2.utils.events INFO:  eta: 1:43:24  iter: 5039  total_loss: 0.4602  loss_cls: 0.3558  loss_box_reg: 0.09069  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.003  time: 1.2539  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:45:26] d2.utils.events INFO:  eta: 1:42:59  iter: 5059  total_loss: 0.5603  loss_cls: 0.4196  loss_box_reg: 0.08431  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.002942  time: 1.2539  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:45:51] d2.utils.events INFO:  eta: 1:42:33  iter: 5079  total_loss: 0.4819  loss_cls: 0.409  loss_box_reg: 0.08878  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.00271  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:46:16] d2.utils.events INFO:  eta: 1:42:08  iter: 5099  total_loss: 0.4952  loss_cls: 0.3716  loss_box_reg: 0.07926  loss_rpn_cls: 0.009012  loss_rpn_loc: 0.002069  time: 1.2538  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/03 23:46:41] d2.utils.events INFO:  eta: 1:41:44  iter: 5119  total_loss: 0.4586  loss_cls: 0.3581  loss_box_reg: 0.073  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.001569  time: 1.2538  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:47:06] d2.utils.events INFO:  eta: 1:41:19  iter: 5139  total_loss: 0.5214  loss_cls: 0.4411  loss_box_reg: 0.08083  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.001886  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:47:31] d2.utils.events INFO:  eta: 1:40:54  iter: 5159  total_loss: 0.4713  loss_cls: 0.3641  loss_box_reg: 0.0598  loss_rpn_cls: 0.01708  loss_rpn_loc: 0.003764  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:47:56] d2.utils.events INFO:  eta: 1:40:29  iter: 5179  total_loss: 0.5106  loss_cls: 0.3908  loss_box_reg: 0.06859  loss_rpn_cls: 0.009263  loss_rpn_loc: 0.001926  time: 1.2538  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:48:21] d2.utils.events INFO:  eta: 1:40:04  iter: 5199  total_loss: 0.4407  loss_cls: 0.3528  loss_box_reg: 0.07156  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.002505  time: 1.2538  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:48:47] d2.utils.events INFO:  eta: 1:39:39  iter: 5219  total_loss: 0.5309  loss_cls: 0.4038  loss_box_reg: 0.08517  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.002191  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:49:12] d2.utils.events INFO:  eta: 1:39:14  iter: 5239  total_loss: 0.5453  loss_cls: 0.3866  loss_box_reg: 0.1196  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.003078  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:49:37] d2.utils.events INFO:  eta: 1:38:49  iter: 5259  total_loss: 0.5571  loss_cls: 0.445  loss_box_reg: 0.0868  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.002622  time: 1.2539  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:50:02] d2.utils.events INFO:  eta: 1:38:24  iter: 5279  total_loss: 0.472  loss_cls: 0.3819  loss_box_reg: 0.09543  loss_rpn_cls: 0.01182  loss_rpn_loc: 0.002366  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:50:27] d2.utils.events INFO:  eta: 1:37:58  iter: 5299  total_loss: 0.5099  loss_cls: 0.3731  loss_box_reg: 0.07638  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.002189  time: 1.2539  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:50:53] d2.utils.events INFO:  eta: 1:37:34  iter: 5319  total_loss: 0.5696  loss_cls: 0.4489  loss_box_reg: 0.1071  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.002642  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:51:18] d2.utils.events INFO:  eta: 1:37:09  iter: 5339  total_loss: 0.4504  loss_cls: 0.3356  loss_box_reg: 0.08354  loss_rpn_cls: 0.009215  loss_rpn_loc: 0.002976  time: 1.2539  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:51:43] d2.utils.events INFO:  eta: 1:36:44  iter: 5359  total_loss: 0.4411  loss_cls: 0.3021  loss_box_reg: 0.09706  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.002866  time: 1.2539  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:52:08] d2.utils.events INFO:  eta: 1:36:20  iter: 5379  total_loss: 0.5205  loss_cls: 0.387  loss_box_reg: 0.08138  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.004435  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:52:34] d2.utils.events INFO:  eta: 1:35:55  iter: 5399  total_loss: 0.5661  loss_cls: 0.4295  loss_box_reg: 0.08899  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.003073  time: 1.2539  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:52:59] d2.utils.events INFO:  eta: 1:35:31  iter: 5419  total_loss: 0.4985  loss_cls: 0.3473  loss_box_reg: 0.1092  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.002434  time: 1.2539  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:53:24] d2.utils.events INFO:  eta: 1:35:06  iter: 5439  total_loss: 0.4699  loss_cls: 0.3211  loss_box_reg: 0.1043  loss_rpn_cls: 0.009597  loss_rpn_loc: 0.001756  time: 1.2539  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:53:49] d2.utils.events INFO:  eta: 1:34:41  iter: 5459  total_loss: 0.443  loss_cls: 0.2789  loss_box_reg: 0.126  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.002715  time: 1.2540  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:54:14] d2.utils.events INFO:  eta: 1:34:16  iter: 5479  total_loss: 0.5355  loss_cls: 0.4422  loss_box_reg: 0.08975  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.003567  time: 1.2540  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:54:39] d2.utils.events INFO:  eta: 1:33:51  iter: 5499  total_loss: 0.5723  loss_cls: 0.4178  loss_box_reg: 0.1279  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.002854  time: 1.2540  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/03 23:55:05] d2.utils.events INFO:  eta: 1:33:26  iter: 5519  total_loss: 0.4764  loss_cls: 0.331  loss_box_reg: 0.07839  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.002255  time: 1.2540  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 23:55:30] d2.utils.events INFO:  eta: 1:33:01  iter: 5539  total_loss: 0.4461  loss_cls: 0.3203  loss_box_reg: 0.09689  loss_rpn_cls: 0.009088  loss_rpn_loc: 0.002116  time: 1.2540  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/03 23:55:55] d2.utils.events INFO:  eta: 1:32:36  iter: 5559  total_loss: 0.5138  loss_cls: 0.3961  loss_box_reg: 0.09368  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.0025  time: 1.2540  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 23:56:20] d2.utils.events INFO:  eta: 1:32:11  iter: 5579  total_loss: 0.5154  loss_cls: 0.367  loss_box_reg: 0.07508  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.002137  time: 1.2540  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 23:56:45] d2.utils.events INFO:  eta: 1:31:46  iter: 5599  total_loss: 0.4534  loss_cls: 0.3232  loss_box_reg: 0.1027  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.002552  time: 1.2540  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:57:11] d2.utils.events INFO:  eta: 1:31:21  iter: 5619  total_loss: 0.5748  loss_cls: 0.4234  loss_box_reg: 0.09627  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.002544  time: 1.2540  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:57:36] d2.utils.events INFO:  eta: 1:30:55  iter: 5639  total_loss: 0.5044  loss_cls: 0.374  loss_box_reg: 0.0893  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.00292  time: 1.2540  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/03 23:58:01] d2.utils.events INFO:  eta: 1:30:30  iter: 5659  total_loss: 0.5389  loss_cls: 0.4456  loss_box_reg: 0.08183  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.00241  time: 1.2540  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/03 23:58:26] d2.utils.events INFO:  eta: 1:30:06  iter: 5679  total_loss: 0.5381  loss_cls: 0.3986  loss_box_reg: 0.1029  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.002376  time: 1.2540  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/03 23:58:51] d2.utils.events INFO:  eta: 1:29:41  iter: 5699  total_loss: 0.5542  loss_cls: 0.4074  loss_box_reg: 0.09705  loss_rpn_cls: 0.013  loss_rpn_loc: 0.002959  time: 1.2540  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/03 23:59:16] d2.utils.events INFO:  eta: 1:29:15  iter: 5719  total_loss: 0.4985  loss_cls: 0.3985  loss_box_reg: 0.08026  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.002111  time: 1.2540  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/03 23:59:41] d2.utils.events INFO:  eta: 1:28:50  iter: 5739  total_loss: 0.5583  loss_cls: 0.3825  loss_box_reg: 0.1251  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.004076  time: 1.2540  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:00:06] d2.utils.events INFO:  eta: 1:28:25  iter: 5759  total_loss: 0.5345  loss_cls: 0.3725  loss_box_reg: 0.1057  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.002088  time: 1.2540  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:00:32] d2.utils.events INFO:  eta: 1:27:59  iter: 5779  total_loss: 0.4924  loss_cls: 0.3647  loss_box_reg: 0.0882  loss_rpn_cls: 0.01349  loss_rpn_loc: 0.002778  time: 1.2540  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 00:00:57] d2.utils.events INFO:  eta: 1:27:34  iter: 5799  total_loss: 0.4603  loss_cls: 0.3865  loss_box_reg: 0.1203  loss_rpn_cls: 0.01056  loss_rpn_loc: 0.002168  time: 1.2540  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:01:22] d2.utils.events INFO:  eta: 1:27:09  iter: 5819  total_loss: 0.5257  loss_cls: 0.3765  loss_box_reg: 0.1233  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.00234  time: 1.2540  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 00:01:47] d2.utils.events INFO:  eta: 1:26:44  iter: 5839  total_loss: 0.5403  loss_cls: 0.3718  loss_box_reg: 0.08384  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.00328  time: 1.2540  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 00:02:12] d2.utils.events INFO:  eta: 1:26:19  iter: 5859  total_loss: 0.5  loss_cls: 0.3694  loss_box_reg: 0.07167  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.00254  time: 1.2540  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:02:37] d2.utils.events INFO:  eta: 1:25:53  iter: 5879  total_loss: 0.5673  loss_cls: 0.4543  loss_box_reg: 0.08864  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.002482  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:03:02] d2.utils.events INFO:  eta: 1:25:28  iter: 5899  total_loss: 0.5169  loss_cls: 0.3839  loss_box_reg: 0.09907  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.002738  time: 1.2539  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:03:27] d2.utils.events INFO:  eta: 1:25:02  iter: 5919  total_loss: 0.4675  loss_cls: 0.4015  loss_box_reg: 0.07481  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.003097  time: 1.2539  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:03:52] d2.utils.events INFO:  eta: 1:24:37  iter: 5939  total_loss: 0.5173  loss_cls: 0.394  loss_box_reg: 0.07696  loss_rpn_cls: 0.01258  loss_rpn_loc: 0.002014  time: 1.2539  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:04:17] d2.utils.events INFO:  eta: 1:24:12  iter: 5959  total_loss: 0.5428  loss_cls: 0.4239  loss_box_reg: 0.0997  loss_rpn_cls: 0.01233  loss_rpn_loc: 0.002398  time: 1.2539  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:04:42] d2.utils.events INFO:  eta: 1:23:47  iter: 5979  total_loss: 0.4825  loss_cls: 0.3635  loss_box_reg: 0.09604  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.00217  time: 1.2538  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:05:07] d2.utils.events INFO:  eta: 1:23:22  iter: 5999  total_loss: 0.5586  loss_cls: 0.4336  loss_box_reg: 0.1024  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.002254  time: 1.2538  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:05:32] d2.utils.events INFO:  eta: 1:22:56  iter: 6019  total_loss: 0.4865  loss_cls: 0.357  loss_box_reg: 0.08026  loss_rpn_cls: 0.01069  loss_rpn_loc: 0.002525  time: 1.2538  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:05:57] d2.utils.events INFO:  eta: 1:22:31  iter: 6039  total_loss: 0.4884  loss_cls: 0.3974  loss_box_reg: 0.08704  loss_rpn_cls: 0.012  loss_rpn_loc: 0.002864  time: 1.2538  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:06:22] d2.utils.events INFO:  eta: 1:22:06  iter: 6059  total_loss: 0.5297  loss_cls: 0.4204  loss_box_reg: 0.06514  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.002716  time: 1.2538  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:06:47] d2.utils.events INFO:  eta: 1:21:41  iter: 6079  total_loss: 0.5609  loss_cls: 0.4409  loss_box_reg: 0.0896  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.002031  time: 1.2538  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:07:12] d2.utils.events INFO:  eta: 1:21:16  iter: 6099  total_loss: 0.4643  loss_cls: 0.2972  loss_box_reg: 0.1021  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.002075  time: 1.2537  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:07:37] d2.utils.events INFO:  eta: 1:20:50  iter: 6119  total_loss: 0.5323  loss_cls: 0.3937  loss_box_reg: 0.07603  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.003427  time: 1.2537  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:08:02] d2.utils.events INFO:  eta: 1:20:25  iter: 6139  total_loss: 0.5457  loss_cls: 0.4149  loss_box_reg: 0.0807  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.002798  time: 1.2537  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:08:27] d2.utils.events INFO:  eta: 1:20:00  iter: 6159  total_loss: 0.4555  loss_cls: 0.3472  loss_box_reg: 0.09655  loss_rpn_cls: 0.009843  loss_rpn_loc: 0.002371  time: 1.2537  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:08:52] d2.utils.events INFO:  eta: 1:19:35  iter: 6179  total_loss: 0.5214  loss_cls: 0.3704  loss_box_reg: 0.06521  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.002844  time: 1.2537  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:09:17] d2.utils.events INFO:  eta: 1:19:10  iter: 6199  total_loss: 0.5152  loss_cls: 0.4362  loss_box_reg: 0.09414  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.00186  time: 1.2537  data_time: 0.0083  lr: 2e-05  max_mem: 19010M
[02/04 00:09:42] d2.utils.events INFO:  eta: 1:18:44  iter: 6219  total_loss: 0.5418  loss_cls: 0.3769  loss_box_reg: 0.101  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.002904  time: 1.2536  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:10:07] d2.utils.events INFO:  eta: 1:18:18  iter: 6239  total_loss: 0.4837  loss_cls: 0.3206  loss_box_reg: 0.08952  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.002285  time: 1.2536  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:10:32] d2.utils.events INFO:  eta: 1:17:53  iter: 6259  total_loss: 0.3869  loss_cls: 0.2902  loss_box_reg: 0.08974  loss_rpn_cls: 0.009024  loss_rpn_loc: 0.001833  time: 1.2536  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:10:57] d2.utils.events INFO:  eta: 1:17:28  iter: 6279  total_loss: 0.4762  loss_cls: 0.3268  loss_box_reg: 0.1019  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.002724  time: 1.2536  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:11:22] d2.utils.events INFO:  eta: 1:17:03  iter: 6299  total_loss: 0.5484  loss_cls: 0.4364  loss_box_reg: 0.09961  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.002298  time: 1.2536  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:11:47] d2.utils.events INFO:  eta: 1:16:37  iter: 6319  total_loss: 0.5345  loss_cls: 0.3801  loss_box_reg: 0.09664  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.002463  time: 1.2536  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:12:12] d2.utils.events INFO:  eta: 1:16:12  iter: 6339  total_loss: 0.4665  loss_cls: 0.3595  loss_box_reg: 0.1009  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.002031  time: 1.2536  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:12:38] d2.utils.events INFO:  eta: 1:15:48  iter: 6359  total_loss: 0.523  loss_cls: 0.4197  loss_box_reg: 0.07732  loss_rpn_cls: 0.01361  loss_rpn_loc: 0.002146  time: 1.2536  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:13:03] d2.utils.events INFO:  eta: 1:15:22  iter: 6379  total_loss: 0.502  loss_cls: 0.3707  loss_box_reg: 0.1034  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.0027  time: 1.2536  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:13:28] d2.utils.events INFO:  eta: 1:14:57  iter: 6399  total_loss: 0.5592  loss_cls: 0.4385  loss_box_reg: 0.07232  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.002403  time: 1.2535  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:13:53] d2.utils.events INFO:  eta: 1:14:31  iter: 6419  total_loss: 0.5362  loss_cls: 0.3901  loss_box_reg: 0.1306  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.002462  time: 1.2535  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:14:18] d2.utils.events INFO:  eta: 1:14:06  iter: 6439  total_loss: 0.5374  loss_cls: 0.4025  loss_box_reg: 0.08574  loss_rpn_cls: 0.009151  loss_rpn_loc: 0.002093  time: 1.2535  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:14:43] d2.utils.events INFO:  eta: 1:13:41  iter: 6459  total_loss: 0.4757  loss_cls: 0.3132  loss_box_reg: 0.0888  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.003189  time: 1.2535  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:15:08] d2.utils.events INFO:  eta: 1:13:15  iter: 6479  total_loss: 0.4508  loss_cls: 0.3288  loss_box_reg: 0.06438  loss_rpn_cls: 0.01378  loss_rpn_loc: 0.002514  time: 1.2535  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:15:33] d2.utils.events INFO:  eta: 1:12:49  iter: 6499  total_loss: 0.5291  loss_cls: 0.3793  loss_box_reg: 0.07887  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.002806  time: 1.2535  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:15:58] d2.utils.events INFO:  eta: 1:12:24  iter: 6519  total_loss: 0.5699  loss_cls: 0.4333  loss_box_reg: 0.07559  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.002382  time: 1.2535  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:16:23] d2.utils.events INFO:  eta: 1:11:59  iter: 6539  total_loss: 0.513  loss_cls: 0.3646  loss_box_reg: 0.08916  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.001783  time: 1.2534  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:16:48] d2.utils.events INFO:  eta: 1:11:34  iter: 6559  total_loss: 0.4617  loss_cls: 0.3551  loss_box_reg: 0.09953  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.002363  time: 1.2534  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:17:13] d2.utils.events INFO:  eta: 1:11:10  iter: 6579  total_loss: 0.5753  loss_cls: 0.4381  loss_box_reg: 0.07491  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.00284  time: 1.2534  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 00:17:38] d2.utils.events INFO:  eta: 1:10:44  iter: 6599  total_loss: 0.4604  loss_cls: 0.3129  loss_box_reg: 0.1342  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.00232  time: 1.2534  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:18:03] d2.utils.events INFO:  eta: 1:10:19  iter: 6619  total_loss: 0.4892  loss_cls: 0.3909  loss_box_reg: 0.09597  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.002483  time: 1.2534  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:18:28] d2.utils.events INFO:  eta: 1:09:54  iter: 6639  total_loss: 0.4884  loss_cls: 0.4068  loss_box_reg: 0.08339  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.002546  time: 1.2534  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:18:53] d2.utils.events INFO:  eta: 1:09:29  iter: 6659  total_loss: 0.4446  loss_cls: 0.3514  loss_box_reg: 0.0823  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.002112  time: 1.2534  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 00:19:18] d2.utils.events INFO:  eta: 1:09:04  iter: 6679  total_loss: 0.5598  loss_cls: 0.3871  loss_box_reg: 0.06135  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.002597  time: 1.2534  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:19:43] d2.utils.events INFO:  eta: 1:08:39  iter: 6699  total_loss: 0.4867  loss_cls: 0.3141  loss_box_reg: 0.06237  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.002845  time: 1.2534  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:20:08] d2.utils.events INFO:  eta: 1:08:14  iter: 6719  total_loss: 0.5421  loss_cls: 0.4136  loss_box_reg: 0.09389  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.002812  time: 1.2534  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:20:34] d2.utils.events INFO:  eta: 1:07:49  iter: 6739  total_loss: 0.517  loss_cls: 0.3805  loss_box_reg: 0.07534  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.002195  time: 1.2534  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:20:59] d2.utils.events INFO:  eta: 1:07:24  iter: 6759  total_loss: 0.5091  loss_cls: 0.3877  loss_box_reg: 0.1003  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.002543  time: 1.2533  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:21:24] d2.utils.events INFO:  eta: 1:06:59  iter: 6779  total_loss: 0.5104  loss_cls: 0.3979  loss_box_reg: 0.1201  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.002722  time: 1.2533  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:21:49] d2.utils.events INFO:  eta: 1:06:34  iter: 6799  total_loss: 0.4777  loss_cls: 0.3555  loss_box_reg: 0.06068  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.002736  time: 1.2533  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:22:14] d2.utils.events INFO:  eta: 1:06:09  iter: 6819  total_loss: 0.5507  loss_cls: 0.3794  loss_box_reg: 0.1178  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.002237  time: 1.2533  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:22:39] d2.utils.events INFO:  eta: 1:05:44  iter: 6839  total_loss: 0.4292  loss_cls: 0.2713  loss_box_reg: 0.09182  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.002629  time: 1.2533  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:23:04] d2.utils.events INFO:  eta: 1:05:19  iter: 6859  total_loss: 0.5758  loss_cls: 0.4453  loss_box_reg: 0.08372  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.002219  time: 1.2533  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:23:29] d2.utils.events INFO:  eta: 1:04:54  iter: 6879  total_loss: 0.4678  loss_cls: 0.3583  loss_box_reg: 0.07532  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.002982  time: 1.2533  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:23:54] d2.utils.events INFO:  eta: 1:04:30  iter: 6899  total_loss: 0.5413  loss_cls: 0.3946  loss_box_reg: 0.08308  loss_rpn_cls: 0.01568  loss_rpn_loc: 0.003096  time: 1.2532  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:24:19] d2.utils.events INFO:  eta: 1:04:05  iter: 6919  total_loss: 0.5391  loss_cls: 0.3689  loss_box_reg: 0.1521  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.002681  time: 1.2532  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:24:44] d2.utils.events INFO:  eta: 1:03:40  iter: 6939  total_loss: 0.5524  loss_cls: 0.4374  loss_box_reg: 0.1005  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.004227  time: 1.2532  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:25:09] d2.utils.events INFO:  eta: 1:03:15  iter: 6959  total_loss: 0.4631  loss_cls: 0.3659  loss_box_reg: 0.08343  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.002029  time: 1.2532  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:25:34] d2.utils.events INFO:  eta: 1:02:50  iter: 6979  total_loss: 0.4269  loss_cls: 0.341  loss_box_reg: 0.1055  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.00246  time: 1.2532  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:25:59] d2.utils.events INFO:  eta: 1:02:25  iter: 6999  total_loss: 0.4914  loss_cls: 0.3675  loss_box_reg: 0.1165  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.002993  time: 1.2532  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:26:24] d2.utils.events INFO:  eta: 1:02:00  iter: 7019  total_loss: 0.4332  loss_cls: 0.3117  loss_box_reg: 0.08425  loss_rpn_cls: 0.009883  loss_rpn_loc: 0.002315  time: 1.2532  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:26:49] d2.utils.events INFO:  eta: 1:01:35  iter: 7039  total_loss: 0.5364  loss_cls: 0.4268  loss_box_reg: 0.06345  loss_rpn_cls: 0.01606  loss_rpn_loc: 0.003269  time: 1.2532  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:27:14] d2.utils.events INFO:  eta: 1:01:10  iter: 7059  total_loss: 0.4554  loss_cls: 0.3435  loss_box_reg: 0.09472  loss_rpn_cls: 0.009549  loss_rpn_loc: 0.001901  time: 1.2531  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:27:39] d2.utils.events INFO:  eta: 1:00:45  iter: 7079  total_loss: 0.4953  loss_cls: 0.3454  loss_box_reg: 0.1119  loss_rpn_cls: 0.00968  loss_rpn_loc: 0.002275  time: 1.2531  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:28:04] d2.utils.events INFO:  eta: 1:00:20  iter: 7099  total_loss: 0.495  loss_cls: 0.3821  loss_box_reg: 0.08175  loss_rpn_cls: 0.009318  loss_rpn_loc: 0.002449  time: 1.2531  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:28:29] d2.utils.events INFO:  eta: 0:59:55  iter: 7119  total_loss: 0.5097  loss_cls: 0.3753  loss_box_reg: 0.116  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.002132  time: 1.2531  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:28:54] d2.utils.events INFO:  eta: 0:59:30  iter: 7139  total_loss: 0.4957  loss_cls: 0.3823  loss_box_reg: 0.07527  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.001489  time: 1.2531  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:29:19] d2.utils.events INFO:  eta: 0:59:05  iter: 7159  total_loss: 0.5138  loss_cls: 0.4332  loss_box_reg: 0.04579  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.002386  time: 1.2531  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:29:44] d2.utils.events INFO:  eta: 0:58:40  iter: 7179  total_loss: 0.5612  loss_cls: 0.4225  loss_box_reg: 0.1004  loss_rpn_cls: 0.009961  loss_rpn_loc: 0.002521  time: 1.2531  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:30:09] d2.utils.events INFO:  eta: 0:58:15  iter: 7199  total_loss: 0.4848  loss_cls: 0.314  loss_box_reg: 0.08519  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.002711  time: 1.2531  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:30:34] d2.utils.events INFO:  eta: 0:57:50  iter: 7219  total_loss: 0.5216  loss_cls: 0.4064  loss_box_reg: 0.09057  loss_rpn_cls: 0.01547  loss_rpn_loc: 0.002894  time: 1.2530  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:30:59] d2.utils.events INFO:  eta: 0:57:25  iter: 7239  total_loss: 0.5753  loss_cls: 0.4428  loss_box_reg: 0.08393  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.002297  time: 1.2530  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:31:24] d2.utils.events INFO:  eta: 0:57:00  iter: 7259  total_loss: 0.5503  loss_cls: 0.473  loss_box_reg: 0.08775  loss_rpn_cls: 0.0166  loss_rpn_loc: 0.001937  time: 1.2530  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:31:49] d2.utils.events INFO:  eta: 0:56:35  iter: 7279  total_loss: 0.4904  loss_cls: 0.3943  loss_box_reg: 0.07658  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.002495  time: 1.2530  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:32:14] d2.utils.events INFO:  eta: 0:56:11  iter: 7299  total_loss: 0.545  loss_cls: 0.416  loss_box_reg: 0.09085  loss_rpn_cls: 0.01674  loss_rpn_loc: 0.002642  time: 1.2530  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:32:39] d2.utils.events INFO:  eta: 0:55:46  iter: 7319  total_loss: 0.5423  loss_cls: 0.4351  loss_box_reg: 0.0851  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.002744  time: 1.2530  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:33:04] d2.utils.events INFO:  eta: 0:55:20  iter: 7339  total_loss: 0.5173  loss_cls: 0.3668  loss_box_reg: 0.1145  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.002411  time: 1.2530  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 00:33:29] d2.utils.events INFO:  eta: 0:54:55  iter: 7359  total_loss: 0.578  loss_cls: 0.4226  loss_box_reg: 0.09596  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.002739  time: 1.2530  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 00:33:54] d2.utils.events INFO:  eta: 0:54:30  iter: 7379  total_loss: 0.4431  loss_cls: 0.3238  loss_box_reg: 0.09626  loss_rpn_cls: 0.009607  loss_rpn_loc: 0.002199  time: 1.2529  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:34:19] d2.utils.events INFO:  eta: 0:54:05  iter: 7399  total_loss: 0.4911  loss_cls: 0.408  loss_box_reg: 0.04901  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.002303  time: 1.2529  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:34:44] d2.utils.events INFO:  eta: 0:53:40  iter: 7419  total_loss: 0.5307  loss_cls: 0.3697  loss_box_reg: 0.09511  loss_rpn_cls: 0.00916  loss_rpn_loc: 0.001828  time: 1.2529  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 00:35:09] d2.utils.events INFO:  eta: 0:53:15  iter: 7439  total_loss: 0.4711  loss_cls: 0.3802  loss_box_reg: 0.08167  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.002205  time: 1.2529  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:35:35] d2.utils.events INFO:  eta: 0:52:50  iter: 7459  total_loss: 0.4707  loss_cls: 0.3703  loss_box_reg: 0.07508  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.001971  time: 1.2529  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:36:00] d2.utils.events INFO:  eta: 0:52:25  iter: 7479  total_loss: 0.4331  loss_cls: 0.315  loss_box_reg: 0.08994  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.00355  time: 1.2529  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 00:36:25] d2.utils.events INFO:  eta: 0:52:00  iter: 7499  total_loss: 0.5001  loss_cls: 0.3515  loss_box_reg: 0.1036  loss_rpn_cls: 0.009825  loss_rpn_loc: 0.002242  time: 1.2529  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 00:36:50] d2.utils.events INFO:  eta: 0:51:36  iter: 7519  total_loss: 0.4751  loss_cls: 0.3369  loss_box_reg: 0.07809  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.002354  time: 1.2529  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:37:15] d2.utils.events INFO:  eta: 0:51:11  iter: 7539  total_loss: 0.5017  loss_cls: 0.345  loss_box_reg: 0.07797  loss_rpn_cls: 0.009739  loss_rpn_loc: 0.002378  time: 1.2529  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:37:40] d2.utils.events INFO:  eta: 0:50:46  iter: 7559  total_loss: 0.5084  loss_cls: 0.3467  loss_box_reg: 0.07565  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.002673  time: 1.2529  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:38:05] d2.utils.events INFO:  eta: 0:50:21  iter: 7579  total_loss: 0.4988  loss_cls: 0.4076  loss_box_reg: 0.06731  loss_rpn_cls: 0.009474  loss_rpn_loc: 0.002624  time: 1.2529  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 00:38:30] d2.utils.events INFO:  eta: 0:49:56  iter: 7599  total_loss: 0.5159  loss_cls: 0.389  loss_box_reg: 0.08092  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.002318  time: 1.2529  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:38:55] d2.utils.events INFO:  eta: 0:49:31  iter: 7619  total_loss: 0.5066  loss_cls: 0.3871  loss_box_reg: 0.06638  loss_rpn_cls: 0.01121  loss_rpn_loc: 0.002381  time: 1.2529  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 00:39:20] d2.utils.events INFO:  eta: 0:49:06  iter: 7639  total_loss: 0.3656  loss_cls: 0.2495  loss_box_reg: 0.1071  loss_rpn_cls: 0.008527  loss_rpn_loc: 0.001799  time: 1.2529  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:39:45] d2.utils.events INFO:  eta: 0:48:41  iter: 7659  total_loss: 0.4393  loss_cls: 0.329  loss_box_reg: 0.09955  loss_rpn_cls: 0.009885  loss_rpn_loc: 0.001609  time: 1.2529  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:40:10] d2.utils.events INFO:  eta: 0:48:16  iter: 7679  total_loss: 0.4638  loss_cls: 0.3135  loss_box_reg: 0.08712  loss_rpn_cls: 0.01098  loss_rpn_loc: 0.002042  time: 1.2529  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:40:35] d2.utils.events INFO:  eta: 0:47:51  iter: 7699  total_loss: 0.4469  loss_cls: 0.3218  loss_box_reg: 0.1008  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.002065  time: 1.2528  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 00:41:00] d2.utils.events INFO:  eta: 0:47:26  iter: 7719  total_loss: 0.5109  loss_cls: 0.4382  loss_box_reg: 0.06536  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.003294  time: 1.2528  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:41:26] d2.utils.events INFO:  eta: 0:47:01  iter: 7739  total_loss: 0.4881  loss_cls: 0.3308  loss_box_reg: 0.0937  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.004282  time: 1.2528  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:41:51] d2.utils.events INFO:  eta: 0:46:36  iter: 7759  total_loss: 0.4698  loss_cls: 0.363  loss_box_reg: 0.07836  loss_rpn_cls: 0.01085  loss_rpn_loc: 0.00187  time: 1.2528  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:42:16] d2.utils.events INFO:  eta: 0:46:11  iter: 7779  total_loss: 0.456  loss_cls: 0.3464  loss_box_reg: 0.07356  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.004352  time: 1.2528  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 00:42:41] d2.utils.events INFO:  eta: 0:45:46  iter: 7799  total_loss: 0.4927  loss_cls: 0.347  loss_box_reg: 0.1097  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.002754  time: 1.2528  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:43:06] d2.utils.events INFO:  eta: 0:45:22  iter: 7819  total_loss: 0.5247  loss_cls: 0.3313  loss_box_reg: 0.0875  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.00196  time: 1.2528  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:43:31] d2.utils.events INFO:  eta: 0:44:57  iter: 7839  total_loss: 0.5343  loss_cls: 0.3795  loss_box_reg: 0.09182  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.002388  time: 1.2528  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:43:56] d2.utils.events INFO:  eta: 0:44:32  iter: 7859  total_loss: 0.4726  loss_cls: 0.3423  loss_box_reg: 0.07961  loss_rpn_cls: 0.009219  loss_rpn_loc: 0.003064  time: 1.2528  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:44:21] d2.utils.events INFO:  eta: 0:44:07  iter: 7879  total_loss: 0.5234  loss_cls: 0.3408  loss_box_reg: 0.1031  loss_rpn_cls: 0.009054  loss_rpn_loc: 0.001871  time: 1.2528  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 00:44:46] d2.utils.events INFO:  eta: 0:43:42  iter: 7899  total_loss: 0.5001  loss_cls: 0.3381  loss_box_reg: 0.111  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.00222  time: 1.2528  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:45:11] d2.utils.events INFO:  eta: 0:43:17  iter: 7919  total_loss: 0.4374  loss_cls: 0.3184  loss_box_reg: 0.09952  loss_rpn_cls: 0.01204  loss_rpn_loc: 0.00212  time: 1.2528  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 00:45:36] d2.utils.events INFO:  eta: 0:42:52  iter: 7939  total_loss: 0.4875  loss_cls: 0.3813  loss_box_reg: 0.1102  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.00219  time: 1.2528  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 00:46:01] d2.utils.events INFO:  eta: 0:42:27  iter: 7959  total_loss: 0.431  loss_cls: 0.3354  loss_box_reg: 0.07161  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.002357  time: 1.2528  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:46:26] d2.utils.events INFO:  eta: 0:42:02  iter: 7979  total_loss: 0.5088  loss_cls: 0.342  loss_box_reg: 0.09504  loss_rpn_cls: 0.009917  loss_rpn_loc: 0.001628  time: 1.2527  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:46:51] d2.utils.events INFO:  eta: 0:41:37  iter: 7999  total_loss: 0.4837  loss_cls: 0.3192  loss_box_reg: 0.08535  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.00243  time: 1.2528  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:47:17] d2.utils.events INFO:  eta: 0:41:12  iter: 8019  total_loss: 0.4818  loss_cls: 0.3403  loss_box_reg: 0.07943  loss_rpn_cls: 0.009559  loss_rpn_loc: 0.002629  time: 1.2528  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:47:42] d2.utils.events INFO:  eta: 0:40:47  iter: 8039  total_loss: 0.5071  loss_cls: 0.3983  loss_box_reg: 0.09314  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.001975  time: 1.2528  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:48:07] d2.utils.events INFO:  eta: 0:40:22  iter: 8059  total_loss: 0.4523  loss_cls: 0.3546  loss_box_reg: 0.08879  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.001932  time: 1.2528  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 00:48:32] d2.utils.events INFO:  eta: 0:39:57  iter: 8079  total_loss: 0.4983  loss_cls: 0.3817  loss_box_reg: 0.09076  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.002485  time: 1.2527  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:48:57] d2.utils.events INFO:  eta: 0:39:32  iter: 8099  total_loss: 0.5442  loss_cls: 0.4409  loss_box_reg: 0.08792  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.003954  time: 1.2527  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:49:22] d2.utils.events INFO:  eta: 0:39:08  iter: 8119  total_loss: 0.5053  loss_cls: 0.3826  loss_box_reg: 0.1011  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.003113  time: 1.2527  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:49:47] d2.utils.events INFO:  eta: 0:38:43  iter: 8139  total_loss: 0.4721  loss_cls: 0.3198  loss_box_reg: 0.08437  loss_rpn_cls: 0.009268  loss_rpn_loc: 0.002014  time: 1.2527  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:50:12] d2.utils.events INFO:  eta: 0:38:18  iter: 8159  total_loss: 0.4811  loss_cls: 0.3672  loss_box_reg: 0.09091  loss_rpn_cls: 0.009016  loss_rpn_loc: 0.002629  time: 1.2527  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:50:37] d2.utils.events INFO:  eta: 0:37:53  iter: 8179  total_loss: 0.5003  loss_cls: 0.4029  loss_box_reg: 0.08492  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.00213  time: 1.2527  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:51:02] d2.utils.events INFO:  eta: 0:37:28  iter: 8199  total_loss: 0.4948  loss_cls: 0.3779  loss_box_reg: 0.09284  loss_rpn_cls: 0.009974  loss_rpn_loc: 0.00209  time: 1.2527  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:51:27] d2.utils.events INFO:  eta: 0:37:03  iter: 8219  total_loss: 0.5357  loss_cls: 0.3652  loss_box_reg: 0.09027  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.002813  time: 1.2527  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:51:52] d2.utils.events INFO:  eta: 0:36:38  iter: 8239  total_loss: 0.4788  loss_cls: 0.3612  loss_box_reg: 0.07055  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.002689  time: 1.2527  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 00:52:17] d2.utils.events INFO:  eta: 0:36:13  iter: 8259  total_loss: 0.5549  loss_cls: 0.4287  loss_box_reg: 0.07745  loss_rpn_cls: 0.01336  loss_rpn_loc: 0.002596  time: 1.2527  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:52:42] d2.utils.events INFO:  eta: 0:35:48  iter: 8279  total_loss: 0.4946  loss_cls: 0.3794  loss_box_reg: 0.09046  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.001435  time: 1.2527  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:53:07] d2.utils.events INFO:  eta: 0:35:23  iter: 8299  total_loss: 0.5004  loss_cls: 0.3319  loss_box_reg: 0.1145  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.001896  time: 1.2526  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 00:53:32] d2.utils.events INFO:  eta: 0:34:58  iter: 8319  total_loss: 0.5364  loss_cls: 0.3633  loss_box_reg: 0.09223  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.002499  time: 1.2526  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:53:57] d2.utils.events INFO:  eta: 0:34:33  iter: 8339  total_loss: 0.4741  loss_cls: 0.3266  loss_box_reg: 0.09859  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.002017  time: 1.2526  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 00:54:22] d2.utils.events INFO:  eta: 0:34:08  iter: 8359  total_loss: 0.5168  loss_cls: 0.354  loss_box_reg: 0.0856  loss_rpn_cls: 0.009086  loss_rpn_loc: 0.002073  time: 1.2526  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:54:47] d2.utils.events INFO:  eta: 0:33:43  iter: 8379  total_loss: 0.4545  loss_cls: 0.3256  loss_box_reg: 0.1019  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.001871  time: 1.2526  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 00:55:12] d2.utils.events INFO:  eta: 0:33:18  iter: 8399  total_loss: 0.5728  loss_cls: 0.4038  loss_box_reg: 0.13  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.00315  time: 1.2526  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 00:55:37] d2.utils.events INFO:  eta: 0:32:53  iter: 8419  total_loss: 0.4525  loss_cls: 0.3239  loss_box_reg: 0.09792  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.002765  time: 1.2526  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 00:56:03] d2.utils.events INFO:  eta: 0:32:28  iter: 8439  total_loss: 0.5234  loss_cls: 0.3873  loss_box_reg: 0.07788  loss_rpn_cls: 0.011  loss_rpn_loc: 0.002337  time: 1.2526  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 00:56:28] d2.utils.events INFO:  eta: 0:32:03  iter: 8459  total_loss: 0.4572  loss_cls: 0.3013  loss_box_reg: 0.08452  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.002373  time: 1.2526  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 00:56:53] d2.utils.events INFO:  eta: 0:31:39  iter: 8479  total_loss: 0.5318  loss_cls: 0.3968  loss_box_reg: 0.08034  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.003488  time: 1.2526  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 00:57:18] d2.utils.events INFO:  eta: 0:31:14  iter: 8499  total_loss: 0.5062  loss_cls: 0.3455  loss_box_reg: 0.1031  loss_rpn_cls: 0.01253  loss_rpn_loc: 0.003088  time: 1.2526  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 00:57:43] d2.utils.events INFO:  eta: 0:30:49  iter: 8519  total_loss: 0.4957  loss_cls: 0.3757  loss_box_reg: 0.08854  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.001473  time: 1.2526  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 00:58:08] d2.utils.events INFO:  eta: 0:30:23  iter: 8539  total_loss: 0.5147  loss_cls: 0.436  loss_box_reg: 0.07787  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.002392  time: 1.2526  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 00:58:33] d2.utils.events INFO:  eta: 0:29:58  iter: 8559  total_loss: 0.4312  loss_cls: 0.3365  loss_box_reg: 0.08333  loss_rpn_cls: 0.009733  loss_rpn_loc: 0.002047  time: 1.2526  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 00:58:58] d2.utils.events INFO:  eta: 0:29:34  iter: 8579  total_loss: 0.5142  loss_cls: 0.3724  loss_box_reg: 0.1053  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.002929  time: 1.2526  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 00:59:23] d2.utils.events INFO:  eta: 0:29:09  iter: 8599  total_loss: 0.4495  loss_cls: 0.3579  loss_box_reg: 0.08026  loss_rpn_cls: 0.007416  loss_rpn_loc: 0.002096  time: 1.2526  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 00:59:48] d2.utils.events INFO:  eta: 0:28:44  iter: 8619  total_loss: 0.4644  loss_cls: 0.3742  loss_box_reg: 0.06692  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.00195  time: 1.2526  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:00:13] d2.utils.events INFO:  eta: 0:28:19  iter: 8639  total_loss: 0.4587  loss_cls: 0.3536  loss_box_reg: 0.1043  loss_rpn_cls: 0.01054  loss_rpn_loc: 0.002013  time: 1.2526  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:00:38] d2.utils.events INFO:  eta: 0:27:53  iter: 8659  total_loss: 0.4651  loss_cls: 0.3232  loss_box_reg: 0.09876  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.002346  time: 1.2526  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:01:03] d2.utils.events INFO:  eta: 0:27:28  iter: 8679  total_loss: 0.4893  loss_cls: 0.3662  loss_box_reg: 0.07878  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.001971  time: 1.2525  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:01:28] d2.utils.events INFO:  eta: 0:27:03  iter: 8699  total_loss: 0.5266  loss_cls: 0.41  loss_box_reg: 0.08933  loss_rpn_cls: 0.0138  loss_rpn_loc: 0.002194  time: 1.2525  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:01:53] d2.utils.events INFO:  eta: 0:26:38  iter: 8719  total_loss: 0.4927  loss_cls: 0.4199  loss_box_reg: 0.07812  loss_rpn_cls: 0.01092  loss_rpn_loc: 0.002263  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:02:18] d2.utils.events INFO:  eta: 0:26:13  iter: 8739  total_loss: 0.5005  loss_cls: 0.4105  loss_box_reg: 0.06022  loss_rpn_cls: 0.013  loss_rpn_loc: 0.002493  time: 1.2525  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:02:43] d2.utils.events INFO:  eta: 0:25:49  iter: 8759  total_loss: 0.4422  loss_cls: 0.3213  loss_box_reg: 0.07505  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.002987  time: 1.2525  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 01:03:08] d2.utils.events INFO:  eta: 0:25:23  iter: 8779  total_loss: 0.4462  loss_cls: 0.3139  loss_box_reg: 0.1231  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.001963  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:03:33] d2.utils.events INFO:  eta: 0:24:58  iter: 8799  total_loss: 0.4781  loss_cls: 0.3913  loss_box_reg: 0.08472  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.001418  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:03:59] d2.utils.events INFO:  eta: 0:24:33  iter: 8819  total_loss: 0.5108  loss_cls: 0.3971  loss_box_reg: 0.1167  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.003706  time: 1.2525  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:04:24] d2.utils.events INFO:  eta: 0:24:08  iter: 8839  total_loss: 0.4285  loss_cls: 0.3033  loss_box_reg: 0.08985  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.002149  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:04:49] d2.utils.events INFO:  eta: 0:23:43  iter: 8859  total_loss: 0.5368  loss_cls: 0.3913  loss_box_reg: 0.07429  loss_rpn_cls: 0.01621  loss_rpn_loc: 0.003584  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:05:14] d2.utils.events INFO:  eta: 0:23:19  iter: 8879  total_loss: 0.5561  loss_cls: 0.4111  loss_box_reg: 0.09854  loss_rpn_cls: 0.01426  loss_rpn_loc: 0.002606  time: 1.2525  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:05:39] d2.utils.events INFO:  eta: 0:22:54  iter: 8899  total_loss: 0.4484  loss_cls: 0.383  loss_box_reg: 0.06576  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.002728  time: 1.2525  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 01:06:04] d2.utils.events INFO:  eta: 0:22:29  iter: 8919  total_loss: 0.4731  loss_cls: 0.3507  loss_box_reg: 0.06757  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.002584  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:06:29] d2.utils.events INFO:  eta: 0:22:04  iter: 8939  total_loss: 0.4699  loss_cls: 0.3411  loss_box_reg: 0.055  loss_rpn_cls: 0.01611  loss_rpn_loc: 0.003435  time: 1.2525  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 01:06:54] d2.utils.events INFO:  eta: 0:21:39  iter: 8959  total_loss: 0.4952  loss_cls: 0.4127  loss_box_reg: 0.07663  loss_rpn_cls: 0.01262  loss_rpn_loc: 0.002453  time: 1.2525  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 01:07:19] d2.utils.events INFO:  eta: 0:21:14  iter: 8979  total_loss: 0.5108  loss_cls: 0.3744  loss_box_reg: 0.07852  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.002512  time: 1.2525  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:07:44] d2.utils.events INFO:  eta: 0:20:49  iter: 8999  total_loss: 0.4884  loss_cls: 0.374  loss_box_reg: 0.05889  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.003545  time: 1.2525  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:08:09] d2.utils.events INFO:  eta: 0:20:23  iter: 9019  total_loss: 0.469  loss_cls: 0.399  loss_box_reg: 0.06836  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.002323  time: 1.2525  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 01:08:34] d2.utils.events INFO:  eta: 0:19:58  iter: 9039  total_loss: 0.5103  loss_cls: 0.4193  loss_box_reg: 0.07106  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.002129  time: 1.2524  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:08:59] d2.utils.events INFO:  eta: 0:19:33  iter: 9059  total_loss: 0.4079  loss_cls: 0.2864  loss_box_reg: 0.06984  loss_rpn_cls: 0.00961  loss_rpn_loc: 0.002256  time: 1.2524  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:09:24] d2.utils.events INFO:  eta: 0:19:08  iter: 9079  total_loss: 0.4432  loss_cls: 0.2877  loss_box_reg: 0.09866  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.001978  time: 1.2524  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:09:49] d2.utils.events INFO:  eta: 0:18:43  iter: 9099  total_loss: 0.4903  loss_cls: 0.3681  loss_box_reg: 0.09449  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.00221  time: 1.2524  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:10:14] d2.utils.events INFO:  eta: 0:18:18  iter: 9119  total_loss: 0.4476  loss_cls: 0.3552  loss_box_reg: 0.07354  loss_rpn_cls: 0.009743  loss_rpn_loc: 0.002641  time: 1.2524  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:10:39] d2.utils.events INFO:  eta: 0:17:53  iter: 9139  total_loss: 0.5163  loss_cls: 0.3319  loss_box_reg: 0.09936  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.001973  time: 1.2524  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:11:04] d2.utils.events INFO:  eta: 0:17:28  iter: 9159  total_loss: 0.4972  loss_cls: 0.3575  loss_box_reg: 0.1002  loss_rpn_cls: 0.00917  loss_rpn_loc: 0.002732  time: 1.2524  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:11:29] d2.utils.events INFO:  eta: 0:17:04  iter: 9179  total_loss: 0.472  loss_cls: 0.3591  loss_box_reg: 0.09045  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.002452  time: 1.2524  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:11:54] d2.utils.events INFO:  eta: 0:16:39  iter: 9199  total_loss: 0.4567  loss_cls: 0.3586  loss_box_reg: 0.08265  loss_rpn_cls: 0.01387  loss_rpn_loc: 0.00257  time: 1.2524  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:12:19] d2.utils.events INFO:  eta: 0:16:14  iter: 9219  total_loss: 0.4922  loss_cls: 0.3563  loss_box_reg: 0.09092  loss_rpn_cls: 0.008745  loss_rpn_loc: 0.002006  time: 1.2524  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:12:45] d2.utils.events INFO:  eta: 0:15:49  iter: 9239  total_loss: 0.4443  loss_cls: 0.3308  loss_box_reg: 0.08975  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.00302  time: 1.2524  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:13:10] d2.utils.events INFO:  eta: 0:15:24  iter: 9259  total_loss: 0.4553  loss_cls: 0.3513  loss_box_reg: 0.07017  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.001696  time: 1.2524  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:13:35] d2.utils.events INFO:  eta: 0:14:59  iter: 9279  total_loss: 0.4243  loss_cls: 0.2929  loss_box_reg: 0.08378  loss_rpn_cls: 0.008338  loss_rpn_loc: 0.001814  time: 1.2524  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:14:00] d2.utils.events INFO:  eta: 0:14:34  iter: 9299  total_loss: 0.5122  loss_cls: 0.37  loss_box_reg: 0.09619  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.002126  time: 1.2524  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:14:25] d2.utils.events INFO:  eta: 0:14:09  iter: 9319  total_loss: 0.5085  loss_cls: 0.3849  loss_box_reg: 0.1044  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.002429  time: 1.2523  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:14:50] d2.utils.events INFO:  eta: 0:13:44  iter: 9339  total_loss: 0.5023  loss_cls: 0.3463  loss_box_reg: 0.0984  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.002993  time: 1.2523  data_time: 0.0074  lr: 2e-06  max_mem: 19010M
[02/04 01:15:15] d2.utils.events INFO:  eta: 0:13:19  iter: 9359  total_loss: 0.4488  loss_cls: 0.3473  loss_box_reg: 0.08248  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.003022  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:15:40] d2.utils.events INFO:  eta: 0:12:54  iter: 9379  total_loss: 0.4731  loss_cls: 0.3651  loss_box_reg: 0.08672  loss_rpn_cls: 0.01075  loss_rpn_loc: 0.002789  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:16:05] d2.utils.events INFO:  eta: 0:12:29  iter: 9399  total_loss: 0.4428  loss_cls: 0.3365  loss_box_reg: 0.06682  loss_rpn_cls: 0.009976  loss_rpn_loc: 0.002291  time: 1.2523  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:16:30] d2.utils.events INFO:  eta: 0:12:04  iter: 9419  total_loss: 0.4549  loss_cls: 0.4025  loss_box_reg: 0.0694  loss_rpn_cls: 0.009259  loss_rpn_loc: 0.002133  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:16:55] d2.utils.events INFO:  eta: 0:11:39  iter: 9439  total_loss: 0.5534  loss_cls: 0.3905  loss_box_reg: 0.1023  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.002719  time: 1.2523  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:17:20] d2.utils.events INFO:  eta: 0:11:14  iter: 9459  total_loss: 0.5309  loss_cls: 0.402  loss_box_reg: 0.1021  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.002663  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:17:45] d2.utils.events INFO:  eta: 0:10:49  iter: 9479  total_loss: 0.5069  loss_cls: 0.4043  loss_box_reg: 0.09581  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.002542  time: 1.2523  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:18:10] d2.utils.events INFO:  eta: 0:10:24  iter: 9499  total_loss: 0.473  loss_cls: 0.2797  loss_box_reg: 0.116  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.002367  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:18:35] d2.utils.events INFO:  eta: 0:09:59  iter: 9519  total_loss: 0.4263  loss_cls: 0.3199  loss_box_reg: 0.09441  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.002661  time: 1.2523  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:19:00] d2.utils.events INFO:  eta: 0:09:34  iter: 9539  total_loss: 0.5069  loss_cls: 0.3481  loss_box_reg: 0.1058  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.003178  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:19:25] d2.utils.events INFO:  eta: 0:09:09  iter: 9559  total_loss: 0.4598  loss_cls: 0.3477  loss_box_reg: 0.09503  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.002296  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:19:50] d2.utils.events INFO:  eta: 0:08:44  iter: 9579  total_loss: 0.4726  loss_cls: 0.3538  loss_box_reg: 0.1041  loss_rpn_cls: 0.01585  loss_rpn_loc: 0.003204  time: 1.2523  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:20:15] d2.utils.events INFO:  eta: 0:08:19  iter: 9599  total_loss: 0.5712  loss_cls: 0.4402  loss_box_reg: 0.09407  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.002208  time: 1.2523  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:20:40] d2.utils.events INFO:  eta: 0:07:54  iter: 9619  total_loss: 0.5023  loss_cls: 0.3997  loss_box_reg: 0.1132  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.002582  time: 1.2523  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 01:21:06] d2.utils.events INFO:  eta: 0:07:29  iter: 9639  total_loss: 0.5393  loss_cls: 0.3735  loss_box_reg: 0.09349  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.002771  time: 1.2522  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:21:31] d2.utils.events INFO:  eta: 0:07:04  iter: 9659  total_loss: 0.4213  loss_cls: 0.3078  loss_box_reg: 0.1082  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.002454  time: 1.2522  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 01:21:56] d2.utils.events INFO:  eta: 0:06:39  iter: 9679  total_loss: 0.575  loss_cls: 0.4386  loss_box_reg: 0.07866  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.002882  time: 1.2522  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:22:21] d2.utils.events INFO:  eta: 0:06:14  iter: 9699  total_loss: 0.4718  loss_cls: 0.365  loss_box_reg: 0.08649  loss_rpn_cls: 0.01489  loss_rpn_loc: 0.002496  time: 1.2522  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:22:46] d2.utils.events INFO:  eta: 0:05:49  iter: 9719  total_loss: 0.4502  loss_cls: 0.3561  loss_box_reg: 0.08361  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.002966  time: 1.2522  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:23:11] d2.utils.events INFO:  eta: 0:05:24  iter: 9739  total_loss: 0.4636  loss_cls: 0.3067  loss_box_reg: 0.08102  loss_rpn_cls: 0.0112  loss_rpn_loc: 0.003033  time: 1.2522  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 01:23:36] d2.utils.events INFO:  eta: 0:04:59  iter: 9759  total_loss: 0.4451  loss_cls: 0.3116  loss_box_reg: 0.1014  loss_rpn_cls: 0.008458  loss_rpn_loc: 0.002171  time: 1.2522  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:24:01] d2.utils.events INFO:  eta: 0:04:34  iter: 9779  total_loss: 0.5436  loss_cls: 0.4386  loss_box_reg: 0.09208  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.002344  time: 1.2522  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:24:26] d2.utils.events INFO:  eta: 0:04:09  iter: 9799  total_loss: 0.5496  loss_cls: 0.4174  loss_box_reg: 0.08546  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.003313  time: 1.2522  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:24:51] d2.utils.events INFO:  eta: 0:03:44  iter: 9819  total_loss: 0.4951  loss_cls: 0.3901  loss_box_reg: 0.07098  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.00295  time: 1.2522  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:25:16] d2.utils.events INFO:  eta: 0:03:19  iter: 9839  total_loss: 0.5431  loss_cls: 0.3652  loss_box_reg: 0.1124  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.002545  time: 1.2522  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 01:25:41] d2.utils.events INFO:  eta: 0:02:54  iter: 9859  total_loss: 0.5257  loss_cls: 0.4033  loss_box_reg: 0.08087  loss_rpn_cls: 0.009994  loss_rpn_loc: 0.001711  time: 1.2522  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 01:26:06] d2.utils.events INFO:  eta: 0:02:29  iter: 9879  total_loss: 0.4532  loss_cls: 0.3729  loss_box_reg: 0.07931  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.003022  time: 1.2522  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 01:26:31] d2.utils.events INFO:  eta: 0:02:04  iter: 9899  total_loss: 0.467  loss_cls: 0.3557  loss_box_reg: 0.08818  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.001956  time: 1.2522  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:26:56] d2.utils.events INFO:  eta: 0:01:39  iter: 9919  total_loss: 0.5188  loss_cls: 0.3895  loss_box_reg: 0.1144  loss_rpn_cls: 0.009647  loss_rpn_loc: 0.001845  time: 1.2522  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 01:27:21] d2.utils.events INFO:  eta: 0:01:14  iter: 9939  total_loss: 0.501  loss_cls: 0.4068  loss_box_reg: 0.07279  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.002031  time: 1.2522  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:27:46] d2.utils.events INFO:  eta: 0:00:49  iter: 9959  total_loss: 0.5355  loss_cls: 0.4323  loss_box_reg: 0.07532  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.002885  time: 1.2521  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:28:11] d2.utils.events INFO:  eta: 0:00:24  iter: 9979  total_loss: 0.4933  loss_cls: 0.3716  loss_box_reg: 0.09139  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.003222  time: 1.2521  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 01:28:36] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_0009999.pth
[02/04 01:28:37] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[02/04 01:28:38] d2.utils.events INFO:  eta: 0:00:00  iter: 9999  total_loss: 0.5171  loss_cls: 0.3952  loss_box_reg: 0.08677  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.002116  time: 1.2521  data_time: 0.0074  lr: 2e-07  max_mem: 19010M
[02/04 01:28:38] d2.engine.hooks INFO: Overall training speed: 9998 iterations in 3:28:38 (1.2521 s / it)
[02/04 01:28:38] d2.engine.hooks INFO: Total training time: 3:29:09 (0:00:30 on hooks)
[02/04 01:28:39] d2.data.build INFO: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 285          |   bicycle   | 337          |    boat     | 263          |
|   bottle   | 469          |     car     | 1201         |     cat     | 358          |
|   chair    | 756          | diningtable | 206          |     dog     | 489          |
|   horse    | 348          |   person    | 4528         | pottedplant | 480          |
|   sheep    | 242          |    train    | 282          |  tvmonitor  | 308          |
|    bird    | 459          |     bus     | 213          |     cow     | 244          |
| motorbike  | 325          |    sofa     | 239          |             |              |
|   total    | 12032        |             |              |             |              |
[02/04 01:28:39] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[02/04 01:28:39] d2.data.common INFO: Serialized dataset takes 2.12 MiB
[02/04 15:03:31] detectron2 INFO: Rank of current process: 0. World size: 1
[02/04 15:03:32] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/04 15:03:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/04 15:03:32] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5,10)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (75, 99)
  MAX_ITER: 100
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/04 15:03:32] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  - 10
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 100
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 75
  - 99
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/04 15:03:32] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/04 15:03:32] d2.utils.env INFO: Using a generated random seed 32425641
[02/04 15:03:34] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/04 15:03:36] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/04 15:03:36] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/04 15:03:37] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/04 15:03:37] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/04 15:03:37] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/04 15:03:37] FCT.data.build INFO: Using training sampler TrainingSampler
[02/04 15:03:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/04 15:03:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/04 15:03:37] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/04 15:03:37] d2.engine.train_loop INFO: Starting training from iteration 0
[02/04 15:04:03] d2.utils.events INFO:  eta: 0:01:39  iter: 19  total_loss: 1.115  loss_cls: 0.8378  loss_box_reg: 0.1319  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.003342  time: 1.2545  data_time: 0.0248  lr: 1.658e-06  max_mem: 18985M
[02/04 15:04:28] d2.utils.events INFO:  eta: 0:01:14  iter: 39  total_loss: 0.9625  loss_cls: 0.7308  loss_box_reg: 0.13  loss_rpn_cls: 0.07744  loss_rpn_loc: 0.004517  time: 1.2531  data_time: 0.0068  lr: 1.298e-06  max_mem: 18985M
[02/04 15:04:53] d2.utils.events INFO:  eta: 0:00:49  iter: 59  total_loss: 0.9356  loss_cls: 0.7365  loss_box_reg: 0.112  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.004335  time: 1.2547  data_time: 0.0067  lr: 9.38e-07  max_mem: 19006M
[02/04 15:05:19] d2.utils.events INFO:  eta: 0:00:25  iter: 79  total_loss: 0.9417  loss_cls: 0.7207  loss_box_reg: 0.1484  loss_rpn_cls: 0.07421  loss_rpn_loc: 0.003102  time: 1.2606  data_time: 0.0066  lr: 5.78e-07  max_mem: 19006M
[02/04 15:05:44] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[02/04 15:05:45] d2.utils.events INFO:  eta: 0:00:00  iter: 99  total_loss: 0.9198  loss_cls: 0.7069  loss_box_reg: 0.1113  loss_rpn_cls: 0.07261  loss_rpn_loc: 0.005305  time: 1.2616  data_time: 0.0070  lr: 2.18e-07  max_mem: 19006M
[02/04 15:05:45] d2.engine.hooks INFO: Overall training speed: 98 iterations in 0:02:03 (1.2616 s / it)
[02/04 15:05:45] d2.engine.hooks INFO: Total training time: 0:02:04 (0:00:01 on hooks)
[02/04 15:05:46] d2.data.build INFO: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 285          |   bicycle   | 337          |    boat     | 263          |
|   bottle   | 469          |     car     | 1201         |     cat     | 358          |
|   chair    | 756          | diningtable | 206          |     dog     | 489          |
|   horse    | 348          |   person    | 4528         | pottedplant | 480          |
|   sheep    | 242          |    train    | 282          |  tvmonitor  | 308          |
|    bird    | 459          |     bus     | 213          |     cow     | 244          |
| motorbike  | 325          |    sofa     | 239          |             |              |
|   total    | 12032        |             |              |             |              |
[02/04 15:05:46] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[02/04 15:05:46] d2.data.common INFO: Serialized dataset takes 2.12 MiB
[02/04 15:05:46] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[02/04 15:05:56] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0005 s/iter. Inference: 0.8507 s/iter. Eval: 0.0008 s/iter. Total: 0.8520 s/iter. ETA=1:10:09
[02/04 15:06:01] d2.evaluation.evaluator INFO: Inference done 17/4952. Dataloading: 0.0004 s/iter. Inference: 0.8471 s/iter. Eval: 0.0008 s/iter. Total: 0.8483 s/iter. ETA=1:09:46
[02/04 15:06:06] d2.evaluation.evaluator INFO: Inference done 23/4952. Dataloading: 0.0005 s/iter. Inference: 0.8487 s/iter. Eval: 0.0008 s/iter. Total: 0.8501 s/iter. ETA=1:09:49
[02/04 15:06:11] d2.evaluation.evaluator INFO: Inference done 29/4952. Dataloading: 0.0005 s/iter. Inference: 0.8560 s/iter. Eval: 0.0008 s/iter. Total: 0.8573 s/iter. ETA=1:10:20
[02/04 15:06:16] d2.evaluation.evaluator INFO: Inference done 35/4952. Dataloading: 0.0006 s/iter. Inference: 0.8577 s/iter. Eval: 0.0008 s/iter. Total: 0.8591 s/iter. ETA=1:10:24
[02/04 15:06:21] d2.evaluation.evaluator INFO: Inference done 41/4952. Dataloading: 0.0006 s/iter. Inference: 0.8574 s/iter. Eval: 0.0008 s/iter. Total: 0.8588 s/iter. ETA=1:10:17
[02/04 15:06:27] d2.evaluation.evaluator INFO: Inference done 47/4952. Dataloading: 0.0006 s/iter. Inference: 0.8580 s/iter. Eval: 0.0008 s/iter. Total: 0.8594 s/iter. ETA=1:10:15
[02/04 15:06:32] d2.evaluation.evaluator INFO: Inference done 53/4952. Dataloading: 0.0006 s/iter. Inference: 0.8570 s/iter. Eval: 0.0008 s/iter. Total: 0.8584 s/iter. ETA=1:10:05
[02/04 15:06:37] d2.evaluation.evaluator INFO: Inference done 59/4952. Dataloading: 0.0006 s/iter. Inference: 0.8558 s/iter. Eval: 0.0008 s/iter. Total: 0.8572 s/iter. ETA=1:09:54
[02/04 15:06:42] d2.evaluation.evaluator INFO: Inference done 65/4952. Dataloading: 0.0006 s/iter. Inference: 0.8548 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=1:09:44
[02/04 15:06:47] d2.evaluation.evaluator INFO: Inference done 71/4952. Dataloading: 0.0006 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8564 s/iter. ETA=1:09:40
[02/04 15:06:52] d2.evaluation.evaluator INFO: Inference done 77/4952. Dataloading: 0.0006 s/iter. Inference: 0.8560 s/iter. Eval: 0.0008 s/iter. Total: 0.8574 s/iter. ETA=1:09:39
[02/04 15:06:57] d2.evaluation.evaluator INFO: Inference done 83/4952. Dataloading: 0.0006 s/iter. Inference: 0.8549 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=1:09:29
[02/04 15:07:02] d2.evaluation.evaluator INFO: Inference done 89/4952. Dataloading: 0.0006 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=1:09:22
[02/04 15:07:08] d2.evaluation.evaluator INFO: Inference done 95/4952. Dataloading: 0.0006 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=1:09:11
[02/04 15:07:13] d2.evaluation.evaluator INFO: Inference done 101/4952. Dataloading: 0.0006 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=1:09:07
[02/04 15:07:18] d2.evaluation.evaluator INFO: Inference done 107/4952. Dataloading: 0.0006 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:08:59
[02/04 15:07:23] d2.evaluation.evaluator INFO: Inference done 113/4952. Dataloading: 0.0006 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:08:54
[02/04 15:07:28] d2.evaluation.evaluator INFO: Inference done 119/4952. Dataloading: 0.0006 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=1:08:47
[02/04 15:07:33] d2.evaluation.evaluator INFO: Inference done 125/4952. Dataloading: 0.0006 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:08:43
[02/04 15:07:38] d2.evaluation.evaluator INFO: Inference done 131/4952. Dataloading: 0.0006 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=1:08:38
[02/04 15:07:43] d2.evaluation.evaluator INFO: Inference done 137/4952. Dataloading: 0.0006 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=1:08:35
[02/04 15:07:48] d2.evaluation.evaluator INFO: Inference done 143/4952. Dataloading: 0.0006 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=1:08:27
[02/04 15:07:54] d2.evaluation.evaluator INFO: Inference done 149/4952. Dataloading: 0.0006 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=1:08:20
[02/04 15:07:59] d2.evaluation.evaluator INFO: Inference done 155/4952. Dataloading: 0.0006 s/iter. Inference: 0.8514 s/iter. Eval: 0.0008 s/iter. Total: 0.8529 s/iter. ETA=1:08:11
[02/04 15:08:04] d2.evaluation.evaluator INFO: Inference done 161/4952. Dataloading: 0.0006 s/iter. Inference: 0.8511 s/iter. Eval: 0.0008 s/iter. Total: 0.8526 s/iter. ETA=1:08:04
[02/04 15:08:09] d2.evaluation.evaluator INFO: Inference done 167/4952. Dataloading: 0.0006 s/iter. Inference: 0.8511 s/iter. Eval: 0.0008 s/iter. Total: 0.8525 s/iter. ETA=1:07:59
[02/04 15:08:14] d2.evaluation.evaluator INFO: Inference done 173/4952. Dataloading: 0.0006 s/iter. Inference: 0.8509 s/iter. Eval: 0.0008 s/iter. Total: 0.8524 s/iter. ETA=1:07:53
[02/04 15:08:19] d2.evaluation.evaluator INFO: Inference done 179/4952. Dataloading: 0.0006 s/iter. Inference: 0.8507 s/iter. Eval: 0.0008 s/iter. Total: 0.8522 s/iter. ETA=1:07:47
[02/04 15:08:24] d2.evaluation.evaluator INFO: Inference done 185/4952. Dataloading: 0.0006 s/iter. Inference: 0.8504 s/iter. Eval: 0.0008 s/iter. Total: 0.8519 s/iter. ETA=1:07:41
[02/04 15:08:29] d2.evaluation.evaluator INFO: Inference done 191/4952. Dataloading: 0.0006 s/iter. Inference: 0.8503 s/iter. Eval: 0.0008 s/iter. Total: 0.8517 s/iter. ETA=1:07:35
[02/04 15:08:34] d2.evaluation.evaluator INFO: Inference done 197/4952. Dataloading: 0.0006 s/iter. Inference: 0.8500 s/iter. Eval: 0.0008 s/iter. Total: 0.8515 s/iter. ETA=1:07:28
[02/04 15:08:39] d2.evaluation.evaluator INFO: Inference done 203/4952. Dataloading: 0.0007 s/iter. Inference: 0.8498 s/iter. Eval: 0.0008 s/iter. Total: 0.8513 s/iter. ETA=1:07:22
[02/04 15:08:44] d2.evaluation.evaluator INFO: Inference done 209/4952. Dataloading: 0.0007 s/iter. Inference: 0.8502 s/iter. Eval: 0.0008 s/iter. Total: 0.8517 s/iter. ETA=1:07:19
[02/04 15:08:49] d2.evaluation.evaluator INFO: Inference done 215/4952. Dataloading: 0.0007 s/iter. Inference: 0.8498 s/iter. Eval: 0.0008 s/iter. Total: 0.8513 s/iter. ETA=1:07:12
[02/04 15:08:54] d2.evaluation.evaluator INFO: Inference done 221/4952. Dataloading: 0.0007 s/iter. Inference: 0.8494 s/iter. Eval: 0.0008 s/iter. Total: 0.8509 s/iter. ETA=1:07:05
[02/04 15:08:59] d2.evaluation.evaluator INFO: Inference done 227/4952. Dataloading: 0.0007 s/iter. Inference: 0.8494 s/iter. Eval: 0.0008 s/iter. Total: 0.8509 s/iter. ETA=1:07:00
[02/04 15:09:05] d2.evaluation.evaluator INFO: Inference done 233/4952. Dataloading: 0.0007 s/iter. Inference: 0.8498 s/iter. Eval: 0.0008 s/iter. Total: 0.8513 s/iter. ETA=1:06:57
[02/04 15:09:10] d2.evaluation.evaluator INFO: Inference done 239/4952. Dataloading: 0.0007 s/iter. Inference: 0.8496 s/iter. Eval: 0.0008 s/iter. Total: 0.8511 s/iter. ETA=1:06:51
[02/04 15:09:15] d2.evaluation.evaluator INFO: Inference done 245/4952. Dataloading: 0.0007 s/iter. Inference: 0.8495 s/iter. Eval: 0.0008 s/iter. Total: 0.8510 s/iter. ETA=1:06:45
[02/04 15:09:20] d2.evaluation.evaluator INFO: Inference done 251/4952. Dataloading: 0.0007 s/iter. Inference: 0.8495 s/iter. Eval: 0.0008 s/iter. Total: 0.8510 s/iter. ETA=1:06:40
[02/04 15:09:25] d2.evaluation.evaluator INFO: Inference done 257/4952. Dataloading: 0.0007 s/iter. Inference: 0.8493 s/iter. Eval: 0.0008 s/iter. Total: 0.8507 s/iter. ETA=1:06:34
[02/04 15:09:30] d2.evaluation.evaluator INFO: Inference done 263/4952. Dataloading: 0.0007 s/iter. Inference: 0.8490 s/iter. Eval: 0.0008 s/iter. Total: 0.8505 s/iter. ETA=1:06:27
[02/04 15:09:36] d2.evaluation.evaluator INFO: Inference done 270/4952. Dataloading: 0.0007 s/iter. Inference: 0.8485 s/iter. Eval: 0.0008 s/iter. Total: 0.8499 s/iter. ETA=1:06:19
[02/04 15:09:41] d2.evaluation.evaluator INFO: Inference done 276/4952. Dataloading: 0.0007 s/iter. Inference: 0.8482 s/iter. Eval: 0.0008 s/iter. Total: 0.8497 s/iter. ETA=1:06:13
[02/04 15:09:46] d2.evaluation.evaluator INFO: Inference done 282/4952. Dataloading: 0.0007 s/iter. Inference: 0.8481 s/iter. Eval: 0.0008 s/iter. Total: 0.8496 s/iter. ETA=1:06:07
[02/04 15:09:51] d2.evaluation.evaluator INFO: Inference done 288/4952. Dataloading: 0.0007 s/iter. Inference: 0.8482 s/iter. Eval: 0.0008 s/iter. Total: 0.8496 s/iter. ETA=1:06:02
[02/04 15:09:56] d2.evaluation.evaluator INFO: Inference done 294/4952. Dataloading: 0.0007 s/iter. Inference: 0.8482 s/iter. Eval: 0.0008 s/iter. Total: 0.8497 s/iter. ETA=1:05:57
[02/04 15:10:01] d2.evaluation.evaluator INFO: Inference done 300/4952. Dataloading: 0.0007 s/iter. Inference: 0.8480 s/iter. Eval: 0.0008 s/iter. Total: 0.8495 s/iter. ETA=1:05:51
[02/04 15:10:06] d2.evaluation.evaluator INFO: Inference done 306/4952. Dataloading: 0.0007 s/iter. Inference: 0.8483 s/iter. Eval: 0.0008 s/iter. Total: 0.8498 s/iter. ETA=1:05:48
[02/04 15:10:12] d2.evaluation.evaluator INFO: Inference done 312/4952. Dataloading: 0.0007 s/iter. Inference: 0.8489 s/iter. Eval: 0.0008 s/iter. Total: 0.8504 s/iter. ETA=1:05:45
[02/04 15:10:17] d2.evaluation.evaluator INFO: Inference done 318/4952. Dataloading: 0.0007 s/iter. Inference: 0.8488 s/iter. Eval: 0.0008 s/iter. Total: 0.8503 s/iter. ETA=1:05:40
[02/04 15:10:22] d2.evaluation.evaluator INFO: Inference done 324/4952. Dataloading: 0.0007 s/iter. Inference: 0.8489 s/iter. Eval: 0.0008 s/iter. Total: 0.8504 s/iter. ETA=1:05:35
[02/04 15:10:27] d2.evaluation.evaluator INFO: Inference done 330/4952. Dataloading: 0.0007 s/iter. Inference: 0.8491 s/iter. Eval: 0.0008 s/iter. Total: 0.8505 s/iter. ETA=1:05:31
[02/04 15:10:32] d2.evaluation.evaluator INFO: Inference done 336/4952. Dataloading: 0.0007 s/iter. Inference: 0.8489 s/iter. Eval: 0.0008 s/iter. Total: 0.8504 s/iter. ETA=1:05:25
[02/04 15:10:37] d2.evaluation.evaluator INFO: Inference done 342/4952. Dataloading: 0.0007 s/iter. Inference: 0.8491 s/iter. Eval: 0.0008 s/iter. Total: 0.8506 s/iter. ETA=1:05:21
[02/04 15:10:42] d2.evaluation.evaluator INFO: Inference done 348/4952. Dataloading: 0.0007 s/iter. Inference: 0.8491 s/iter. Eval: 0.0008 s/iter. Total: 0.8506 s/iter. ETA=1:05:16
[02/04 15:10:48] d2.evaluation.evaluator INFO: Inference done 354/4952. Dataloading: 0.0007 s/iter. Inference: 0.8495 s/iter. Eval: 0.0008 s/iter. Total: 0.8509 s/iter. ETA=1:05:12
[02/04 15:10:53] d2.evaluation.evaluator INFO: Inference done 360/4952. Dataloading: 0.0007 s/iter. Inference: 0.8497 s/iter. Eval: 0.0008 s/iter. Total: 0.8512 s/iter. ETA=1:05:08
[02/04 15:10:58] d2.evaluation.evaluator INFO: Inference done 366/4952. Dataloading: 0.0007 s/iter. Inference: 0.8500 s/iter. Eval: 0.0008 s/iter. Total: 0.8515 s/iter. ETA=1:05:05
[02/04 15:11:03] d2.evaluation.evaluator INFO: Inference done 372/4952. Dataloading: 0.0007 s/iter. Inference: 0.8500 s/iter. Eval: 0.0008 s/iter. Total: 0.8515 s/iter. ETA=1:04:59
[02/04 15:11:08] d2.evaluation.evaluator INFO: Inference done 378/4952. Dataloading: 0.0007 s/iter. Inference: 0.8503 s/iter. Eval: 0.0008 s/iter. Total: 0.8518 s/iter. ETA=1:04:56
[02/04 15:11:14] d2.evaluation.evaluator INFO: Inference done 384/4952. Dataloading: 0.0007 s/iter. Inference: 0.8508 s/iter. Eval: 0.0008 s/iter. Total: 0.8523 s/iter. ETA=1:04:53
[02/04 15:11:19] d2.evaluation.evaluator INFO: Inference done 390/4952. Dataloading: 0.0007 s/iter. Inference: 0.8512 s/iter. Eval: 0.0008 s/iter. Total: 0.8527 s/iter. ETA=1:04:49
[02/04 15:11:24] d2.evaluation.evaluator INFO: Inference done 396/4952. Dataloading: 0.0007 s/iter. Inference: 0.8514 s/iter. Eval: 0.0008 s/iter. Total: 0.8529 s/iter. ETA=1:04:45
[02/04 15:11:29] d2.evaluation.evaluator INFO: Inference done 402/4952. Dataloading: 0.0007 s/iter. Inference: 0.8515 s/iter. Eval: 0.0008 s/iter. Total: 0.8530 s/iter. ETA=1:04:41
[02/04 15:11:34] d2.evaluation.evaluator INFO: Inference done 408/4952. Dataloading: 0.0007 s/iter. Inference: 0.8516 s/iter. Eval: 0.0008 s/iter. Total: 0.8531 s/iter. ETA=1:04:36
[02/04 15:11:40] d2.evaluation.evaluator INFO: Inference done 414/4952. Dataloading: 0.0007 s/iter. Inference: 0.8517 s/iter. Eval: 0.0008 s/iter. Total: 0.8532 s/iter. ETA=1:04:31
[02/04 15:11:45] d2.evaluation.evaluator INFO: Inference done 420/4952. Dataloading: 0.0007 s/iter. Inference: 0.8518 s/iter. Eval: 0.0008 s/iter. Total: 0.8533 s/iter. ETA=1:04:26
[02/04 15:11:50] d2.evaluation.evaluator INFO: Inference done 426/4952. Dataloading: 0.0007 s/iter. Inference: 0.8517 s/iter. Eval: 0.0008 s/iter. Total: 0.8532 s/iter. ETA=1:04:21
[02/04 15:11:55] d2.evaluation.evaluator INFO: Inference done 432/4952. Dataloading: 0.0007 s/iter. Inference: 0.8518 s/iter. Eval: 0.0008 s/iter. Total: 0.8533 s/iter. ETA=1:04:16
[02/04 15:12:00] d2.evaluation.evaluator INFO: Inference done 438/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8534 s/iter. ETA=1:04:12
[02/04 15:12:05] d2.evaluation.evaluator INFO: Inference done 444/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=1:04:08
[02/04 15:12:11] d2.evaluation.evaluator INFO: Inference done 450/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:04:04
[02/04 15:12:16] d2.evaluation.evaluator INFO: Inference done 456/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=1:03:58
[02/04 15:12:21] d2.evaluation.evaluator INFO: Inference done 462/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=1:03:53
[02/04 15:12:26] d2.evaluation.evaluator INFO: Inference done 468/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:03:48
[02/04 15:12:31] d2.evaluation.evaluator INFO: Inference done 474/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=1:03:43
[02/04 15:12:36] d2.evaluation.evaluator INFO: Inference done 480/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:03:38
[02/04 15:12:41] d2.evaluation.evaluator INFO: Inference done 486/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:03:33
[02/04 15:12:46] d2.evaluation.evaluator INFO: Inference done 492/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=1:03:27
[02/04 15:12:51] d2.evaluation.evaluator INFO: Inference done 498/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=1:03:22
[02/04 15:12:57] d2.evaluation.evaluator INFO: Inference done 504/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=1:03:17
[02/04 15:13:02] d2.evaluation.evaluator INFO: Inference done 510/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=1:03:12
[02/04 15:13:07] d2.evaluation.evaluator INFO: Inference done 516/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=1:03:07
[02/04 15:13:12] d2.evaluation.evaluator INFO: Inference done 522/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:03:02
[02/04 15:13:17] d2.evaluation.evaluator INFO: Inference done 528/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:02:57
[02/04 15:13:22] d2.evaluation.evaluator INFO: Inference done 534/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=1:02:53
[02/04 15:13:27] d2.evaluation.evaluator INFO: Inference done 540/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=1:02:48
[02/04 15:13:33] d2.evaluation.evaluator INFO: Inference done 546/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=1:02:42
[02/04 15:13:38] d2.evaluation.evaluator INFO: Inference done 552/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=1:02:37
[02/04 15:13:43] d2.evaluation.evaluator INFO: Inference done 558/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=1:02:32
[02/04 15:13:48] d2.evaluation.evaluator INFO: Inference done 564/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=1:02:27
[02/04 15:13:53] d2.evaluation.evaluator INFO: Inference done 570/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:02:23
[02/04 15:13:58] d2.evaluation.evaluator INFO: Inference done 576/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=1:02:18
[02/04 15:14:03] d2.evaluation.evaluator INFO: Inference done 582/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:02:13
[02/04 15:14:09] d2.evaluation.evaluator INFO: Inference done 588/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=1:02:08
[02/04 15:14:14] d2.evaluation.evaluator INFO: Inference done 594/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:02:03
[02/04 15:14:19] d2.evaluation.evaluator INFO: Inference done 600/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:01:58
[02/04 15:14:24] d2.evaluation.evaluator INFO: Inference done 606/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:01:53
[02/04 15:14:29] d2.evaluation.evaluator INFO: Inference done 612/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:01:47
[02/04 15:14:34] d2.evaluation.evaluator INFO: Inference done 618/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=1:01:43
[02/04 15:14:39] d2.evaluation.evaluator INFO: Inference done 624/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:01:38
[02/04 15:14:45] d2.evaluation.evaluator INFO: Inference done 630/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:01:33
[02/04 15:14:50] d2.evaluation.evaluator INFO: Inference done 636/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=1:01:27
[02/04 15:14:55] d2.evaluation.evaluator INFO: Inference done 642/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:01:22
[02/04 15:15:00] d2.evaluation.evaluator INFO: Inference done 648/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:01:16
[02/04 15:15:05] d2.evaluation.evaluator INFO: Inference done 654/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:01:11
[02/04 15:15:10] d2.evaluation.evaluator INFO: Inference done 660/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:01:06
[02/04 15:15:15] d2.evaluation.evaluator INFO: Inference done 666/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=1:01:01
[02/04 15:15:20] d2.evaluation.evaluator INFO: Inference done 672/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:00:56
[02/04 15:15:25] d2.evaluation.evaluator INFO: Inference done 678/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=1:00:50
[02/04 15:15:31] d2.evaluation.evaluator INFO: Inference done 684/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:00:46
[02/04 15:15:36] d2.evaluation.evaluator INFO: Inference done 690/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:00:41
[02/04 15:15:41] d2.evaluation.evaluator INFO: Inference done 696/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:00:35
[02/04 15:15:46] d2.evaluation.evaluator INFO: Inference done 702/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:00:30
[02/04 15:15:51] d2.evaluation.evaluator INFO: Inference done 708/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=1:00:25
[02/04 15:15:56] d2.evaluation.evaluator INFO: Inference done 714/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:00:21
[02/04 15:16:02] d2.evaluation.evaluator INFO: Inference done 720/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:00:16
[02/04 15:16:07] d2.evaluation.evaluator INFO: Inference done 726/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=1:00:10
[02/04 15:16:12] d2.evaluation.evaluator INFO: Inference done 732/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:00:05
[02/04 15:16:17] d2.evaluation.evaluator INFO: Inference done 738/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=1:00:00
[02/04 15:16:22] d2.evaluation.evaluator INFO: Inference done 744/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:59:55
[02/04 15:16:27] d2.evaluation.evaluator INFO: Inference done 750/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:59:50
[02/04 15:16:32] d2.evaluation.evaluator INFO: Inference done 756/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:59:45
[02/04 15:16:38] d2.evaluation.evaluator INFO: Inference done 762/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:59:41
[02/04 15:16:43] d2.evaluation.evaluator INFO: Inference done 768/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:59:35
[02/04 15:16:48] d2.evaluation.evaluator INFO: Inference done 774/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:59:31
[02/04 15:16:53] d2.evaluation.evaluator INFO: Inference done 780/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:59:26
[02/04 15:16:58] d2.evaluation.evaluator INFO: Inference done 786/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:59:21
[02/04 15:17:03] d2.evaluation.evaluator INFO: Inference done 792/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:59:16
[02/04 15:17:09] d2.evaluation.evaluator INFO: Inference done 798/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:59:11
[02/04 15:17:14] d2.evaluation.evaluator INFO: Inference done 804/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:59:06
[02/04 15:17:19] d2.evaluation.evaluator INFO: Inference done 810/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:59:01
[02/04 15:17:24] d2.evaluation.evaluator INFO: Inference done 816/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:56
[02/04 15:17:29] d2.evaluation.evaluator INFO: Inference done 822/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:58:51
[02/04 15:17:34] d2.evaluation.evaluator INFO: Inference done 828/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:58:46
[02/04 15:17:39] d2.evaluation.evaluator INFO: Inference done 834/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:40
[02/04 15:17:44] d2.evaluation.evaluator INFO: Inference done 840/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:35
[02/04 15:17:50] d2.evaluation.evaluator INFO: Inference done 846/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:30
[02/04 15:17:55] d2.evaluation.evaluator INFO: Inference done 852/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:58:25
[02/04 15:18:00] d2.evaluation.evaluator INFO: Inference done 858/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:20
[02/04 15:18:05] d2.evaluation.evaluator INFO: Inference done 864/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:15
[02/04 15:18:10] d2.evaluation.evaluator INFO: Inference done 870/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:10
[02/04 15:18:15] d2.evaluation.evaluator INFO: Inference done 876/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:58:04
[02/04 15:18:20] d2.evaluation.evaluator INFO: Inference done 882/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:57:59
[02/04 15:18:26] d2.evaluation.evaluator INFO: Inference done 888/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:57:54
[02/04 15:18:31] d2.evaluation.evaluator INFO: Inference done 894/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:57:49
[02/04 15:18:36] d2.evaluation.evaluator INFO: Inference done 900/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:57:44
[02/04 15:18:41] d2.evaluation.evaluator INFO: Inference done 906/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:57:39
[02/04 15:18:46] d2.evaluation.evaluator INFO: Inference done 912/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:34
[02/04 15:18:51] d2.evaluation.evaluator INFO: Inference done 918/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:29
[02/04 15:18:56] d2.evaluation.evaluator INFO: Inference done 924/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:24
[02/04 15:19:02] d2.evaluation.evaluator INFO: Inference done 930/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:19
[02/04 15:19:07] d2.evaluation.evaluator INFO: Inference done 936/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:14
[02/04 15:19:12] d2.evaluation.evaluator INFO: Inference done 942/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:09
[02/04 15:19:17] d2.evaluation.evaluator INFO: Inference done 948/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:57:03
[02/04 15:19:22] d2.evaluation.evaluator INFO: Inference done 954/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:56:58
[02/04 15:19:27] d2.evaluation.evaluator INFO: Inference done 960/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:56:53
[02/04 15:19:32] d2.evaluation.evaluator INFO: Inference done 966/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:56:48
[02/04 15:19:38] d2.evaluation.evaluator INFO: Inference done 972/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:56:43
[02/04 15:19:43] d2.evaluation.evaluator INFO: Inference done 978/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:56:38
[02/04 15:19:48] d2.evaluation.evaluator INFO: Inference done 984/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:56:33
[02/04 15:19:53] d2.evaluation.evaluator INFO: Inference done 990/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:56:28
[02/04 15:19:58] d2.evaluation.evaluator INFO: Inference done 996/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:56:23
[02/04 15:20:03] d2.evaluation.evaluator INFO: Inference done 1002/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:56:17
[02/04 15:20:08] d2.evaluation.evaluator INFO: Inference done 1008/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:56:12
[02/04 15:20:13] d2.evaluation.evaluator INFO: Inference done 1014/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:56:07
[02/04 15:20:18] d2.evaluation.evaluator INFO: Inference done 1020/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:56:02
[02/04 15:20:24] d2.evaluation.evaluator INFO: Inference done 1027/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:55:55
[02/04 15:20:30] d2.evaluation.evaluator INFO: Inference done 1033/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:55:50
[02/04 15:20:35] d2.evaluation.evaluator INFO: Inference done 1039/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:55:45
[02/04 15:20:40] d2.evaluation.evaluator INFO: Inference done 1045/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:55:40
[02/04 15:20:45] d2.evaluation.evaluator INFO: Inference done 1051/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:55:35
[02/04 15:20:50] d2.evaluation.evaluator INFO: Inference done 1057/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:55:30
[02/04 15:20:55] d2.evaluation.evaluator INFO: Inference done 1063/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:55:25
[02/04 15:21:00] d2.evaluation.evaluator INFO: Inference done 1069/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:55:20
[02/04 15:21:06] d2.evaluation.evaluator INFO: Inference done 1075/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:55:15
[02/04 15:21:11] d2.evaluation.evaluator INFO: Inference done 1081/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:55:10
[02/04 15:21:16] d2.evaluation.evaluator INFO: Inference done 1087/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:55:05
[02/04 15:21:21] d2.evaluation.evaluator INFO: Inference done 1093/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:55:00
[02/04 15:21:26] d2.evaluation.evaluator INFO: Inference done 1099/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:54:55
[02/04 15:21:31] d2.evaluation.evaluator INFO: Inference done 1105/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:54:50
[02/04 15:21:36] d2.evaluation.evaluator INFO: Inference done 1111/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:54:44
[02/04 15:21:42] d2.evaluation.evaluator INFO: Inference done 1117/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:54:39
[02/04 15:21:47] d2.evaluation.evaluator INFO: Inference done 1123/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:54:34
[02/04 15:21:52] d2.evaluation.evaluator INFO: Inference done 1129/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:54:30
[02/04 15:21:57] d2.evaluation.evaluator INFO: Inference done 1135/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:54:25
[02/04 15:22:02] d2.evaluation.evaluator INFO: Inference done 1141/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:54:20
[02/04 15:22:07] d2.evaluation.evaluator INFO: Inference done 1147/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:54:14
[02/04 15:22:13] d2.evaluation.evaluator INFO: Inference done 1153/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:54:09
[02/04 15:22:18] d2.evaluation.evaluator INFO: Inference done 1159/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:54:04
[02/04 15:22:23] d2.evaluation.evaluator INFO: Inference done 1165/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:59
[02/04 15:22:28] d2.evaluation.evaluator INFO: Inference done 1171/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:54
[02/04 15:22:33] d2.evaluation.evaluator INFO: Inference done 1177/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:49
[02/04 15:22:38] d2.evaluation.evaluator INFO: Inference done 1183/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:53:43
[02/04 15:22:43] d2.evaluation.evaluator INFO: Inference done 1189/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:38
[02/04 15:22:48] d2.evaluation.evaluator INFO: Inference done 1195/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:33
[02/04 15:22:54] d2.evaluation.evaluator INFO: Inference done 1201/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:28
[02/04 15:22:59] d2.evaluation.evaluator INFO: Inference done 1207/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:53:23
[02/04 15:23:04] d2.evaluation.evaluator INFO: Inference done 1213/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:53:18
[02/04 15:23:09] d2.evaluation.evaluator INFO: Inference done 1219/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:53:12
[02/04 15:23:14] d2.evaluation.evaluator INFO: Inference done 1225/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:53:07
[02/04 15:23:19] d2.evaluation.evaluator INFO: Inference done 1231/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:53:02
[02/04 15:23:24] d2.evaluation.evaluator INFO: Inference done 1237/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:52:56
[02/04 15:23:29] d2.evaluation.evaluator INFO: Inference done 1243/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:52:52
[02/04 15:23:35] d2.evaluation.evaluator INFO: Inference done 1249/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:52:47
[02/04 15:23:40] d2.evaluation.evaluator INFO: Inference done 1255/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:42
[02/04 15:23:45] d2.evaluation.evaluator INFO: Inference done 1261/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:37
[02/04 15:23:50] d2.evaluation.evaluator INFO: Inference done 1267/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:32
[02/04 15:23:55] d2.evaluation.evaluator INFO: Inference done 1273/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:27
[02/04 15:24:00] d2.evaluation.evaluator INFO: Inference done 1279/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:22
[02/04 15:24:06] d2.evaluation.evaluator INFO: Inference done 1285/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:16
[02/04 15:24:11] d2.evaluation.evaluator INFO: Inference done 1291/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:52:11
[02/04 15:24:16] d2.evaluation.evaluator INFO: Inference done 1297/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:52:06
[02/04 15:24:21] d2.evaluation.evaluator INFO: Inference done 1303/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:52:02
[02/04 15:24:26] d2.evaluation.evaluator INFO: Inference done 1309/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:51:56
[02/04 15:24:31] d2.evaluation.evaluator INFO: Inference done 1315/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:51:51
[02/04 15:24:37] d2.evaluation.evaluator INFO: Inference done 1321/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:51:46
[02/04 15:24:42] d2.evaluation.evaluator INFO: Inference done 1327/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:51:41
[02/04 15:24:47] d2.evaluation.evaluator INFO: Inference done 1333/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:51:36
[02/04 15:24:52] d2.evaluation.evaluator INFO: Inference done 1339/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:51:31
[02/04 15:24:57] d2.evaluation.evaluator INFO: Inference done 1345/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:51:26
[02/04 15:25:02] d2.evaluation.evaluator INFO: Inference done 1351/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:51:21
[02/04 15:25:07] d2.evaluation.evaluator INFO: Inference done 1357/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:51:16
[02/04 15:25:13] d2.evaluation.evaluator INFO: Inference done 1363/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:51:11
[02/04 15:25:18] d2.evaluation.evaluator INFO: Inference done 1369/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:51:05
[02/04 15:25:23] d2.evaluation.evaluator INFO: Inference done 1375/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:51:00
[02/04 15:25:28] d2.evaluation.evaluator INFO: Inference done 1381/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:55
[02/04 15:25:33] d2.evaluation.evaluator INFO: Inference done 1387/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:50
[02/04 15:25:38] d2.evaluation.evaluator INFO: Inference done 1393/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:45
[02/04 15:25:43] d2.evaluation.evaluator INFO: Inference done 1399/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:40
[02/04 15:25:49] d2.evaluation.evaluator INFO: Inference done 1405/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:35
[02/04 15:25:54] d2.evaluation.evaluator INFO: Inference done 1411/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:29
[02/04 15:25:59] d2.evaluation.evaluator INFO: Inference done 1417/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:50:24
[02/04 15:26:04] d2.evaluation.evaluator INFO: Inference done 1423/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:50:20
[02/04 15:26:09] d2.evaluation.evaluator INFO: Inference done 1429/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:50:15
[02/04 15:26:15] d2.evaluation.evaluator INFO: Inference done 1435/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:50:10
[02/04 15:26:20] d2.evaluation.evaluator INFO: Inference done 1441/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:50:05
[02/04 15:26:25] d2.evaluation.evaluator INFO: Inference done 1447/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8560 s/iter. ETA=0:50:00
[02/04 15:26:30] d2.evaluation.evaluator INFO: Inference done 1453/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:49:54
[02/04 15:26:35] d2.evaluation.evaluator INFO: Inference done 1459/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8560 s/iter. ETA=0:49:49
[02/04 15:26:40] d2.evaluation.evaluator INFO: Inference done 1465/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8560 s/iter. ETA=0:49:45
[02/04 15:26:46] d2.evaluation.evaluator INFO: Inference done 1471/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:49:40
[02/04 15:26:51] d2.evaluation.evaluator INFO: Inference done 1477/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:49:35
[02/04 15:26:56] d2.evaluation.evaluator INFO: Inference done 1483/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:49:30
[02/04 15:27:01] d2.evaluation.evaluator INFO: Inference done 1489/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:49:24
[02/04 15:27:06] d2.evaluation.evaluator INFO: Inference done 1495/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:49:19
[02/04 15:27:11] d2.evaluation.evaluator INFO: Inference done 1501/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:49:14
[02/04 15:27:16] d2.evaluation.evaluator INFO: Inference done 1507/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:49:09
[02/04 15:27:22] d2.evaluation.evaluator INFO: Inference done 1513/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:49:04
[02/04 15:27:27] d2.evaluation.evaluator INFO: Inference done 1519/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:48:59
[02/04 15:27:32] d2.evaluation.evaluator INFO: Inference done 1525/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:54
[02/04 15:27:37] d2.evaluation.evaluator INFO: Inference done 1531/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:48
[02/04 15:27:42] d2.evaluation.evaluator INFO: Inference done 1537/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:48:43
[02/04 15:27:47] d2.evaluation.evaluator INFO: Inference done 1543/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:38
[02/04 15:27:53] d2.evaluation.evaluator INFO: Inference done 1549/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:33
[02/04 15:27:58] d2.evaluation.evaluator INFO: Inference done 1555/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:48:28
[02/04 15:28:03] d2.evaluation.evaluator INFO: Inference done 1561/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:23
[02/04 15:28:08] d2.evaluation.evaluator INFO: Inference done 1567/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:18
[02/04 15:28:13] d2.evaluation.evaluator INFO: Inference done 1573/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:48:13
[02/04 15:28:18] d2.evaluation.evaluator INFO: Inference done 1579/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=0:48:08
[02/04 15:28:24] d2.evaluation.evaluator INFO: Inference done 1585/4952. Dataloading: 0.0007 s/iter. Inference: 0.8548 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=0:48:03
[02/04 15:28:29] d2.evaluation.evaluator INFO: Inference done 1591/4952. Dataloading: 0.0007 s/iter. Inference: 0.8549 s/iter. Eval: 0.0008 s/iter. Total: 0.8564 s/iter. ETA=0:47:58
[02/04 15:28:34] d2.evaluation.evaluator INFO: Inference done 1597/4952. Dataloading: 0.0007 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8565 s/iter. ETA=0:47:53
[02/04 15:28:40] d2.evaluation.evaluator INFO: Inference done 1603/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:47:49
[02/04 15:28:45] d2.evaluation.evaluator INFO: Inference done 1609/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:47:44
[02/04 15:28:50] d2.evaluation.evaluator INFO: Inference done 1615/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:47:38
[02/04 15:28:55] d2.evaluation.evaluator INFO: Inference done 1621/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:47:34
[02/04 15:29:00] d2.evaluation.evaluator INFO: Inference done 1627/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:47:29
[02/04 15:29:06] d2.evaluation.evaluator INFO: Inference done 1633/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:47:23
[02/04 15:29:11] d2.evaluation.evaluator INFO: Inference done 1639/4952. Dataloading: 0.0007 s/iter. Inference: 0.8554 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:47:18
[02/04 15:29:16] d2.evaluation.evaluator INFO: Inference done 1645/4952. Dataloading: 0.0007 s/iter. Inference: 0.8554 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:47:13
[02/04 15:29:21] d2.evaluation.evaluator INFO: Inference done 1651/4952. Dataloading: 0.0007 s/iter. Inference: 0.8554 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:47:08
[02/04 15:29:26] d2.evaluation.evaluator INFO: Inference done 1657/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:47:03
[02/04 15:29:31] d2.evaluation.evaluator INFO: Inference done 1663/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:46:58
[02/04 15:29:36] d2.evaluation.evaluator INFO: Inference done 1669/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:46:52
[02/04 15:29:41] d2.evaluation.evaluator INFO: Inference done 1675/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:46:47
[02/04 15:29:47] d2.evaluation.evaluator INFO: Inference done 1681/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:46:42
[02/04 15:29:52] d2.evaluation.evaluator INFO: Inference done 1687/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:46:37
[02/04 15:29:57] d2.evaluation.evaluator INFO: Inference done 1693/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:32
[02/04 15:30:02] d2.evaluation.evaluator INFO: Inference done 1699/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:26
[02/04 15:30:07] d2.evaluation.evaluator INFO: Inference done 1705/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:21
[02/04 15:30:12] d2.evaluation.evaluator INFO: Inference done 1711/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:16
[02/04 15:30:17] d2.evaluation.evaluator INFO: Inference done 1717/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:11
[02/04 15:30:22] d2.evaluation.evaluator INFO: Inference done 1723/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:06
[02/04 15:30:28] d2.evaluation.evaluator INFO: Inference done 1729/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:46:01
[02/04 15:30:33] d2.evaluation.evaluator INFO: Inference done 1735/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:45:56
[02/04 15:30:38] d2.evaluation.evaluator INFO: Inference done 1741/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:45:51
[02/04 15:30:43] d2.evaluation.evaluator INFO: Inference done 1747/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:45:45
[02/04 15:30:48] d2.evaluation.evaluator INFO: Inference done 1753/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:45:40
[02/04 15:30:53] d2.evaluation.evaluator INFO: Inference done 1759/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:45:35
[02/04 15:30:59] d2.evaluation.evaluator INFO: Inference done 1765/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:45:30
[02/04 15:31:04] d2.evaluation.evaluator INFO: Inference done 1771/4952. Dataloading: 0.0007 s/iter. Inference: 0.8554 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:45:25
[02/04 15:31:09] d2.evaluation.evaluator INFO: Inference done 1777/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:45:20
[02/04 15:31:14] d2.evaluation.evaluator INFO: Inference done 1783/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8569 s/iter. ETA=0:45:15
[02/04 15:31:19] d2.evaluation.evaluator INFO: Inference done 1789/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:45:10
[02/04 15:31:24] d2.evaluation.evaluator INFO: Inference done 1795/4952. Dataloading: 0.0007 s/iter. Inference: 0.8553 s/iter. Eval: 0.0008 s/iter. Total: 0.8568 s/iter. ETA=0:45:04
[02/04 15:31:29] d2.evaluation.evaluator INFO: Inference done 1801/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:44:59
[02/04 15:31:34] d2.evaluation.evaluator INFO: Inference done 1807/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:44:54
[02/04 15:31:39] d2.evaluation.evaluator INFO: Inference done 1813/4952. Dataloading: 0.0007 s/iter. Inference: 0.8552 s/iter. Eval: 0.0008 s/iter. Total: 0.8567 s/iter. ETA=0:44:49
[02/04 15:31:45] d2.evaluation.evaluator INFO: Inference done 1819/4952. Dataloading: 0.0007 s/iter. Inference: 0.8551 s/iter. Eval: 0.0008 s/iter. Total: 0.8566 s/iter. ETA=0:44:43
[02/04 15:31:50] d2.evaluation.evaluator INFO: Inference done 1825/4952. Dataloading: 0.0007 s/iter. Inference: 0.8551 s/iter. Eval: 0.0008 s/iter. Total: 0.8566 s/iter. ETA=0:44:38
[02/04 15:31:55] d2.evaluation.evaluator INFO: Inference done 1831/4952. Dataloading: 0.0007 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8565 s/iter. ETA=0:44:33
[02/04 15:32:00] d2.evaluation.evaluator INFO: Inference done 1837/4952. Dataloading: 0.0007 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8565 s/iter. ETA=0:44:28
[02/04 15:32:05] d2.evaluation.evaluator INFO: Inference done 1843/4952. Dataloading: 0.0007 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8565 s/iter. ETA=0:44:22
[02/04 15:32:10] d2.evaluation.evaluator INFO: Inference done 1849/4952. Dataloading: 0.0007 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8565 s/iter. ETA=0:44:17
[02/04 15:32:15] d2.evaluation.evaluator INFO: Inference done 1855/4952. Dataloading: 0.0007 s/iter. Inference: 0.8550 s/iter. Eval: 0.0008 s/iter. Total: 0.8565 s/iter. ETA=0:44:12
[02/04 15:32:21] d2.evaluation.evaluator INFO: Inference done 1862/4952. Dataloading: 0.0007 s/iter. Inference: 0.8549 s/iter. Eval: 0.0008 s/iter. Total: 0.8564 s/iter. ETA=0:44:06
[02/04 15:32:26] d2.evaluation.evaluator INFO: Inference done 1868/4952. Dataloading: 0.0007 s/iter. Inference: 0.8548 s/iter. Eval: 0.0008 s/iter. Total: 0.8564 s/iter. ETA=0:44:01
[02/04 15:32:31] d2.evaluation.evaluator INFO: Inference done 1874/4952. Dataloading: 0.0007 s/iter. Inference: 0.8548 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=0:43:55
[02/04 15:32:36] d2.evaluation.evaluator INFO: Inference done 1880/4952. Dataloading: 0.0007 s/iter. Inference: 0.8548 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=0:43:50
[02/04 15:32:41] d2.evaluation.evaluator INFO: Inference done 1886/4952. Dataloading: 0.0007 s/iter. Inference: 0.8548 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=0:43:45
[02/04 15:32:46] d2.evaluation.evaluator INFO: Inference done 1892/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8563 s/iter. ETA=0:43:40
[02/04 15:32:51] d2.evaluation.evaluator INFO: Inference done 1898/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:43:34
[02/04 15:32:57] d2.evaluation.evaluator INFO: Inference done 1904/4952. Dataloading: 0.0007 s/iter. Inference: 0.8547 s/iter. Eval: 0.0008 s/iter. Total: 0.8562 s/iter. ETA=0:43:29
[02/04 15:33:02] d2.evaluation.evaluator INFO: Inference done 1911/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:43:23
[02/04 15:33:07] d2.evaluation.evaluator INFO: Inference done 1917/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:43:18
[02/04 15:33:13] d2.evaluation.evaluator INFO: Inference done 1923/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:43:13
[02/04 15:33:18] d2.evaluation.evaluator INFO: Inference done 1929/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:43:07
[02/04 15:33:23] d2.evaluation.evaluator INFO: Inference done 1935/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:43:02
[02/04 15:33:28] d2.evaluation.evaluator INFO: Inference done 1941/4952. Dataloading: 0.0007 s/iter. Inference: 0.8546 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:42:57
[02/04 15:33:33] d2.evaluation.evaluator INFO: Inference done 1947/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:42:52
[02/04 15:33:38] d2.evaluation.evaluator INFO: Inference done 1953/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8561 s/iter. ETA=0:42:47
[02/04 15:33:43] d2.evaluation.evaluator INFO: Inference done 1959/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8560 s/iter. ETA=0:42:42
[02/04 15:33:48] d2.evaluation.evaluator INFO: Inference done 1965/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8560 s/iter. ETA=0:42:36
[02/04 15:33:53] d2.evaluation.evaluator INFO: Inference done 1971/4952. Dataloading: 0.0007 s/iter. Inference: 0.8545 s/iter. Eval: 0.0008 s/iter. Total: 0.8560 s/iter. ETA=0:42:31
[02/04 15:33:59] d2.evaluation.evaluator INFO: Inference done 1977/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:42:26
[02/04 15:34:04] d2.evaluation.evaluator INFO: Inference done 1983/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:42:21
[02/04 15:34:09] d2.evaluation.evaluator INFO: Inference done 1989/4952. Dataloading: 0.0007 s/iter. Inference: 0.8544 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:42:16
[02/04 15:34:14] d2.evaluation.evaluator INFO: Inference done 1995/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:42:10
[02/04 15:34:19] d2.evaluation.evaluator INFO: Inference done 2001/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8559 s/iter. ETA=0:42:05
[02/04 15:34:24] d2.evaluation.evaluator INFO: Inference done 2007/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:42:00
[02/04 15:34:29] d2.evaluation.evaluator INFO: Inference done 2013/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:55
[02/04 15:34:34] d2.evaluation.evaluator INFO: Inference done 2019/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:50
[02/04 15:34:39] d2.evaluation.evaluator INFO: Inference done 2025/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:44
[02/04 15:34:44] d2.evaluation.evaluator INFO: Inference done 2031/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:39
[02/04 15:34:49] d2.evaluation.evaluator INFO: Inference done 2037/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:34
[02/04 15:34:55] d2.evaluation.evaluator INFO: Inference done 2043/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:41:29
[02/04 15:35:00] d2.evaluation.evaluator INFO: Inference done 2049/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:41:24
[02/04 15:35:05] d2.evaluation.evaluator INFO: Inference done 2055/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:19
[02/04 15:35:10] d2.evaluation.evaluator INFO: Inference done 2061/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:13
[02/04 15:35:15] d2.evaluation.evaluator INFO: Inference done 2067/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:41:08
[02/04 15:35:20] d2.evaluation.evaluator INFO: Inference done 2073/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:41:03
[02/04 15:35:25] d2.evaluation.evaluator INFO: Inference done 2079/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:58
[02/04 15:35:31] d2.evaluation.evaluator INFO: Inference done 2085/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:40:53
[02/04 15:35:36] d2.evaluation.evaluator INFO: Inference done 2091/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:48
[02/04 15:35:41] d2.evaluation.evaluator INFO: Inference done 2097/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:40:43
[02/04 15:35:46] d2.evaluation.evaluator INFO: Inference done 2103/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:38
[02/04 15:35:51] d2.evaluation.evaluator INFO: Inference done 2109/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:32
[02/04 15:35:56] d2.evaluation.evaluator INFO: Inference done 2115/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:27
[02/04 15:36:01] d2.evaluation.evaluator INFO: Inference done 2121/4952. Dataloading: 0.0007 s/iter. Inference: 0.8543 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:22
[02/04 15:36:06] d2.evaluation.evaluator INFO: Inference done 2127/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8558 s/iter. ETA=0:40:17
[02/04 15:36:12] d2.evaluation.evaluator INFO: Inference done 2133/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:40:12
[02/04 15:36:17] d2.evaluation.evaluator INFO: Inference done 2139/4952. Dataloading: 0.0007 s/iter. Inference: 0.8542 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:40:07
[02/04 15:36:22] d2.evaluation.evaluator INFO: Inference done 2145/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:40:01
[02/04 15:36:27] d2.evaluation.evaluator INFO: Inference done 2151/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:39:56
[02/04 15:36:32] d2.evaluation.evaluator INFO: Inference done 2157/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:39:51
[02/04 15:36:37] d2.evaluation.evaluator INFO: Inference done 2163/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8557 s/iter. ETA=0:39:46
[02/04 15:36:42] d2.evaluation.evaluator INFO: Inference done 2169/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:41
[02/04 15:36:47] d2.evaluation.evaluator INFO: Inference done 2175/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:35
[02/04 15:36:52] d2.evaluation.evaluator INFO: Inference done 2181/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:30
[02/04 15:36:57] d2.evaluation.evaluator INFO: Inference done 2187/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:25
[02/04 15:37:03] d2.evaluation.evaluator INFO: Inference done 2193/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:20
[02/04 15:37:08] d2.evaluation.evaluator INFO: Inference done 2199/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:15
[02/04 15:37:13] d2.evaluation.evaluator INFO: Inference done 2205/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:10
[02/04 15:37:18] d2.evaluation.evaluator INFO: Inference done 2211/4952. Dataloading: 0.0007 s/iter. Inference: 0.8541 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:39:05
[02/04 15:37:23] d2.evaluation.evaluator INFO: Inference done 2217/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:38:59
[02/04 15:37:28] d2.evaluation.evaluator INFO: Inference done 2223/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:54
[02/04 15:37:33] d2.evaluation.evaluator INFO: Inference done 2229/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:49
[02/04 15:37:38] d2.evaluation.evaluator INFO: Inference done 2235/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:44
[02/04 15:37:43] d2.evaluation.evaluator INFO: Inference done 2241/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:39
[02/04 15:37:49] d2.evaluation.evaluator INFO: Inference done 2247/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:34
[02/04 15:37:54] d2.evaluation.evaluator INFO: Inference done 2253/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:29
[02/04 15:37:59] d2.evaluation.evaluator INFO: Inference done 2259/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:23
[02/04 15:38:04] d2.evaluation.evaluator INFO: Inference done 2265/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:18
[02/04 15:38:09] d2.evaluation.evaluator INFO: Inference done 2271/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:13
[02/04 15:38:14] d2.evaluation.evaluator INFO: Inference done 2277/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:08
[02/04 15:38:19] d2.evaluation.evaluator INFO: Inference done 2283/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:38:03
[02/04 15:38:25] d2.evaluation.evaluator INFO: Inference done 2289/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:58
[02/04 15:38:30] d2.evaluation.evaluator INFO: Inference done 2295/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:53
[02/04 15:38:35] d2.evaluation.evaluator INFO: Inference done 2301/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:47
[02/04 15:38:40] d2.evaluation.evaluator INFO: Inference done 2307/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8556 s/iter. ETA=0:37:42
[02/04 15:38:45] d2.evaluation.evaluator INFO: Inference done 2313/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:37
[02/04 15:38:50] d2.evaluation.evaluator INFO: Inference done 2319/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:32
[02/04 15:38:55] d2.evaluation.evaluator INFO: Inference done 2325/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:27
[02/04 15:39:00] d2.evaluation.evaluator INFO: Inference done 2331/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:22
[02/04 15:39:06] d2.evaluation.evaluator INFO: Inference done 2337/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:17
[02/04 15:39:11] d2.evaluation.evaluator INFO: Inference done 2343/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:11
[02/04 15:39:16] d2.evaluation.evaluator INFO: Inference done 2349/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:37:06
[02/04 15:39:21] d2.evaluation.evaluator INFO: Inference done 2355/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:37:01
[02/04 15:39:26] d2.evaluation.evaluator INFO: Inference done 2361/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:56
[02/04 15:39:31] d2.evaluation.evaluator INFO: Inference done 2367/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:51
[02/04 15:39:36] d2.evaluation.evaluator INFO: Inference done 2373/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:46
[02/04 15:39:42] d2.evaluation.evaluator INFO: Inference done 2379/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:41
[02/04 15:39:47] d2.evaluation.evaluator INFO: Inference done 2385/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:36
[02/04 15:39:52] d2.evaluation.evaluator INFO: Inference done 2391/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:30
[02/04 15:39:57] d2.evaluation.evaluator INFO: Inference done 2397/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:25
[02/04 15:40:02] d2.evaluation.evaluator INFO: Inference done 2403/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:20
[02/04 15:40:07] d2.evaluation.evaluator INFO: Inference done 2409/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:15
[02/04 15:40:12] d2.evaluation.evaluator INFO: Inference done 2415/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:10
[02/04 15:40:18] d2.evaluation.evaluator INFO: Inference done 2421/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:05
[02/04 15:40:23] d2.evaluation.evaluator INFO: Inference done 2427/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:36:00
[02/04 15:40:28] d2.evaluation.evaluator INFO: Inference done 2433/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:35:55
[02/04 15:40:33] d2.evaluation.evaluator INFO: Inference done 2439/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:35:49
[02/04 15:40:38] d2.evaluation.evaluator INFO: Inference done 2445/4952. Dataloading: 0.0007 s/iter. Inference: 0.8540 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:35:44
[02/04 15:40:43] d2.evaluation.evaluator INFO: Inference done 2451/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:35:39
[02/04 15:40:48] d2.evaluation.evaluator INFO: Inference done 2457/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:35:34
[02/04 15:40:53] d2.evaluation.evaluator INFO: Inference done 2463/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:35:29
[02/04 15:40:58] d2.evaluation.evaluator INFO: Inference done 2469/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:35:24
[02/04 15:41:03] d2.evaluation.evaluator INFO: Inference done 2475/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:35:18
[02/04 15:41:09] d2.evaluation.evaluator INFO: Inference done 2481/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8555 s/iter. ETA=0:35:13
[02/04 15:41:14] d2.evaluation.evaluator INFO: Inference done 2487/4952. Dataloading: 0.0007 s/iter. Inference: 0.8539 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:35:08
[02/04 15:41:19] d2.evaluation.evaluator INFO: Inference done 2493/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:35:03
[02/04 15:41:24] d2.evaluation.evaluator INFO: Inference done 2499/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:34:58
[02/04 15:41:29] d2.evaluation.evaluator INFO: Inference done 2505/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8554 s/iter. ETA=0:34:53
[02/04 15:41:34] d2.evaluation.evaluator INFO: Inference done 2511/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:47
[02/04 15:41:39] d2.evaluation.evaluator INFO: Inference done 2517/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:42
[02/04 15:41:44] d2.evaluation.evaluator INFO: Inference done 2523/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:37
[02/04 15:41:49] d2.evaluation.evaluator INFO: Inference done 2529/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:32
[02/04 15:41:54] d2.evaluation.evaluator INFO: Inference done 2535/4952. Dataloading: 0.0007 s/iter. Inference: 0.8538 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:27
[02/04 15:42:00] d2.evaluation.evaluator INFO: Inference done 2541/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:22
[02/04 15:42:05] d2.evaluation.evaluator INFO: Inference done 2547/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8553 s/iter. ETA=0:34:16
[02/04 15:42:10] d2.evaluation.evaluator INFO: Inference done 2553/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:34:11
[02/04 15:42:15] d2.evaluation.evaluator INFO: Inference done 2559/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:34:06
[02/04 15:42:20] d2.evaluation.evaluator INFO: Inference done 2565/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:34:01
[02/04 15:42:25] d2.evaluation.evaluator INFO: Inference done 2571/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:33:56
[02/04 15:42:30] d2.evaluation.evaluator INFO: Inference done 2577/4952. Dataloading: 0.0007 s/iter. Inference: 0.8537 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:33:51
[02/04 15:42:35] d2.evaluation.evaluator INFO: Inference done 2583/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:33:45
[02/04 15:42:40] d2.evaluation.evaluator INFO: Inference done 2589/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:33:40
[02/04 15:42:45] d2.evaluation.evaluator INFO: Inference done 2595/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:33:35
[02/04 15:42:51] d2.evaluation.evaluator INFO: Inference done 2601/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8552 s/iter. ETA=0:33:30
[02/04 15:42:56] d2.evaluation.evaluator INFO: Inference done 2607/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:33:25
[02/04 15:43:01] d2.evaluation.evaluator INFO: Inference done 2613/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:33:20
[02/04 15:43:06] d2.evaluation.evaluator INFO: Inference done 2619/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:33:15
[02/04 15:43:11] d2.evaluation.evaluator INFO: Inference done 2625/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:33:09
[02/04 15:43:16] d2.evaluation.evaluator INFO: Inference done 2631/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:33:04
[02/04 15:43:21] d2.evaluation.evaluator INFO: Inference done 2637/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:59
[02/04 15:43:26] d2.evaluation.evaluator INFO: Inference done 2643/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:54
[02/04 15:43:31] d2.evaluation.evaluator INFO: Inference done 2649/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:49
[02/04 15:43:37] d2.evaluation.evaluator INFO: Inference done 2655/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:44
[02/04 15:43:42] d2.evaluation.evaluator INFO: Inference done 2661/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:39
[02/04 15:43:47] d2.evaluation.evaluator INFO: Inference done 2667/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:33
[02/04 15:43:52] d2.evaluation.evaluator INFO: Inference done 2673/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:28
[02/04 15:43:57] d2.evaluation.evaluator INFO: Inference done 2679/4952. Dataloading: 0.0007 s/iter. Inference: 0.8536 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:23
[02/04 15:44:02] d2.evaluation.evaluator INFO: Inference done 2685/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:18
[02/04 15:44:07] d2.evaluation.evaluator INFO: Inference done 2691/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:13
[02/04 15:44:12] d2.evaluation.evaluator INFO: Inference done 2697/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:08
[02/04 15:44:18] d2.evaluation.evaluator INFO: Inference done 2703/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:32:03
[02/04 15:44:23] d2.evaluation.evaluator INFO: Inference done 2709/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:31:57
[02/04 15:44:28] d2.evaluation.evaluator INFO: Inference done 2715/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:31:52
[02/04 15:44:33] d2.evaluation.evaluator INFO: Inference done 2721/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:31:47
[02/04 15:44:38] d2.evaluation.evaluator INFO: Inference done 2727/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8551 s/iter. ETA=0:31:42
[02/04 15:44:43] d2.evaluation.evaluator INFO: Inference done 2733/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:37
[02/04 15:44:48] d2.evaluation.evaluator INFO: Inference done 2739/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:32
[02/04 15:44:53] d2.evaluation.evaluator INFO: Inference done 2745/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:27
[02/04 15:44:58] d2.evaluation.evaluator INFO: Inference done 2751/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:21
[02/04 15:45:04] d2.evaluation.evaluator INFO: Inference done 2757/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:16
[02/04 15:45:09] d2.evaluation.evaluator INFO: Inference done 2763/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:11
[02/04 15:45:14] d2.evaluation.evaluator INFO: Inference done 2769/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:06
[02/04 15:45:19] d2.evaluation.evaluator INFO: Inference done 2775/4952. Dataloading: 0.0007 s/iter. Inference: 0.8535 s/iter. Eval: 0.0008 s/iter. Total: 0.8550 s/iter. ETA=0:31:01
[02/04 15:45:25] d2.evaluation.evaluator INFO: Inference done 2782/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:55
[02/04 15:45:30] d2.evaluation.evaluator INFO: Inference done 2788/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:50
[02/04 15:45:35] d2.evaluation.evaluator INFO: Inference done 2794/4952. Dataloading: 0.0007 s/iter. Inference: 0.8534 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:44
[02/04 15:45:40] d2.evaluation.evaluator INFO: Inference done 2800/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:39
[02/04 15:45:45] d2.evaluation.evaluator INFO: Inference done 2806/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:34
[02/04 15:45:50] d2.evaluation.evaluator INFO: Inference done 2812/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:29
[02/04 15:45:55] d2.evaluation.evaluator INFO: Inference done 2818/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:30:24
[02/04 15:46:00] d2.evaluation.evaluator INFO: Inference done 2824/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8549 s/iter. ETA=0:30:19
[02/04 15:46:05] d2.evaluation.evaluator INFO: Inference done 2830/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:30:13
[02/04 15:46:11] d2.evaluation.evaluator INFO: Inference done 2836/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:30:08
[02/04 15:46:16] d2.evaluation.evaluator INFO: Inference done 2842/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:30:03
[02/04 15:46:21] d2.evaluation.evaluator INFO: Inference done 2848/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:58
[02/04 15:46:26] d2.evaluation.evaluator INFO: Inference done 2854/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:53
[02/04 15:46:31] d2.evaluation.evaluator INFO: Inference done 2860/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:48
[02/04 15:46:36] d2.evaluation.evaluator INFO: Inference done 2866/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:43
[02/04 15:46:41] d2.evaluation.evaluator INFO: Inference done 2872/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:38
[02/04 15:46:46] d2.evaluation.evaluator INFO: Inference done 2878/4952. Dataloading: 0.0007 s/iter. Inference: 0.8533 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:32
[02/04 15:46:52] d2.evaluation.evaluator INFO: Inference done 2884/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:27
[02/04 15:46:57] d2.evaluation.evaluator INFO: Inference done 2890/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:22
[02/04 15:47:02] d2.evaluation.evaluator INFO: Inference done 2896/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:17
[02/04 15:47:07] d2.evaluation.evaluator INFO: Inference done 2902/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:12
[02/04 15:47:12] d2.evaluation.evaluator INFO: Inference done 2908/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:07
[02/04 15:47:17] d2.evaluation.evaluator INFO: Inference done 2914/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:29:02
[02/04 15:47:22] d2.evaluation.evaluator INFO: Inference done 2920/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:56
[02/04 15:47:27] d2.evaluation.evaluator INFO: Inference done 2926/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:51
[02/04 15:47:32] d2.evaluation.evaluator INFO: Inference done 2932/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:46
[02/04 15:47:37] d2.evaluation.evaluator INFO: Inference done 2938/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:41
[02/04 15:47:43] d2.evaluation.evaluator INFO: Inference done 2944/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:36
[02/04 15:47:48] d2.evaluation.evaluator INFO: Inference done 2950/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:31
[02/04 15:47:53] d2.evaluation.evaluator INFO: Inference done 2956/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:26
[02/04 15:47:58] d2.evaluation.evaluator INFO: Inference done 2962/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:20
[02/04 15:48:03] d2.evaluation.evaluator INFO: Inference done 2968/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8548 s/iter. ETA=0:28:15
[02/04 15:48:08] d2.evaluation.evaluator INFO: Inference done 2974/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:10
[02/04 15:48:13] d2.evaluation.evaluator INFO: Inference done 2980/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:05
[02/04 15:48:18] d2.evaluation.evaluator INFO: Inference done 2986/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:28:00
[02/04 15:48:24] d2.evaluation.evaluator INFO: Inference done 2992/4952. Dataloading: 0.0007 s/iter. Inference: 0.8532 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:27:55
[02/04 15:48:29] d2.evaluation.evaluator INFO: Inference done 2998/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8547 s/iter. ETA=0:27:50
[02/04 15:48:34] d2.evaluation.evaluator INFO: Inference done 3004/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:44
[02/04 15:48:39] d2.evaluation.evaluator INFO: Inference done 3010/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:39
[02/04 15:48:44] d2.evaluation.evaluator INFO: Inference done 3016/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:34
[02/04 15:48:49] d2.evaluation.evaluator INFO: Inference done 3022/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:29
[02/04 15:48:54] d2.evaluation.evaluator INFO: Inference done 3028/4952. Dataloading: 0.0007 s/iter. Inference: 0.8531 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:24
[02/04 15:48:59] d2.evaluation.evaluator INFO: Inference done 3034/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:19
[02/04 15:49:04] d2.evaluation.evaluator INFO: Inference done 3040/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:27:13
[02/04 15:49:09] d2.evaluation.evaluator INFO: Inference done 3046/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:27:08
[02/04 15:49:14] d2.evaluation.evaluator INFO: Inference done 3052/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8546 s/iter. ETA=0:27:03
[02/04 15:49:20] d2.evaluation.evaluator INFO: Inference done 3058/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:58
[02/04 15:49:25] d2.evaluation.evaluator INFO: Inference done 3064/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:53
[02/04 15:49:30] d2.evaluation.evaluator INFO: Inference done 3070/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:48
[02/04 15:49:35] d2.evaluation.evaluator INFO: Inference done 3076/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:43
[02/04 15:49:40] d2.evaluation.evaluator INFO: Inference done 3082/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:37
[02/04 15:49:45] d2.evaluation.evaluator INFO: Inference done 3088/4952. Dataloading: 0.0007 s/iter. Inference: 0.8530 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:32
[02/04 15:49:50] d2.evaluation.evaluator INFO: Inference done 3094/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:27
[02/04 15:49:55] d2.evaluation.evaluator INFO: Inference done 3100/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:22
[02/04 15:50:00] d2.evaluation.evaluator INFO: Inference done 3106/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:17
[02/04 15:50:05] d2.evaluation.evaluator INFO: Inference done 3112/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:12
[02/04 15:50:11] d2.evaluation.evaluator INFO: Inference done 3118/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:07
[02/04 15:50:16] d2.evaluation.evaluator INFO: Inference done 3124/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:26:01
[02/04 15:50:21] d2.evaluation.evaluator INFO: Inference done 3130/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:25:56
[02/04 15:50:26] d2.evaluation.evaluator INFO: Inference done 3136/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:51
[02/04 15:50:31] d2.evaluation.evaluator INFO: Inference done 3142/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:46
[02/04 15:50:36] d2.evaluation.evaluator INFO: Inference done 3148/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:41
[02/04 15:50:41] d2.evaluation.evaluator INFO: Inference done 3154/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:36
[02/04 15:50:46] d2.evaluation.evaluator INFO: Inference done 3160/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:31
[02/04 15:50:51] d2.evaluation.evaluator INFO: Inference done 3166/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:25
[02/04 15:50:56] d2.evaluation.evaluator INFO: Inference done 3172/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:20
[02/04 15:51:02] d2.evaluation.evaluator INFO: Inference done 3178/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:15
[02/04 15:51:07] d2.evaluation.evaluator INFO: Inference done 3184/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:10
[02/04 15:51:12] d2.evaluation.evaluator INFO: Inference done 3190/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:05
[02/04 15:51:17] d2.evaluation.evaluator INFO: Inference done 3196/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:25:00
[02/04 15:51:22] d2.evaluation.evaluator INFO: Inference done 3202/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:24:55
[02/04 15:51:27] d2.evaluation.evaluator INFO: Inference done 3208/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:49
[02/04 15:51:32] d2.evaluation.evaluator INFO: Inference done 3214/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:44
[02/04 15:51:37] d2.evaluation.evaluator INFO: Inference done 3220/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:39
[02/04 15:51:42] d2.evaluation.evaluator INFO: Inference done 3226/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:34
[02/04 15:51:47] d2.evaluation.evaluator INFO: Inference done 3232/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:29
[02/04 15:51:52] d2.evaluation.evaluator INFO: Inference done 3238/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:24
[02/04 15:51:58] d2.evaluation.evaluator INFO: Inference done 3244/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:19
[02/04 15:52:03] d2.evaluation.evaluator INFO: Inference done 3250/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:13
[02/04 15:52:08] d2.evaluation.evaluator INFO: Inference done 3256/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:08
[02/04 15:52:13] d2.evaluation.evaluator INFO: Inference done 3262/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:24:03
[02/04 15:52:18] d2.evaluation.evaluator INFO: Inference done 3268/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:58
[02/04 15:52:23] d2.evaluation.evaluator INFO: Inference done 3274/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:53
[02/04 15:52:28] d2.evaluation.evaluator INFO: Inference done 3280/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:48
[02/04 15:52:33] d2.evaluation.evaluator INFO: Inference done 3286/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:43
[02/04 15:52:38] d2.evaluation.evaluator INFO: Inference done 3292/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:37
[02/04 15:52:43] d2.evaluation.evaluator INFO: Inference done 3298/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:32
[02/04 15:52:49] d2.evaluation.evaluator INFO: Inference done 3304/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:27
[02/04 15:52:54] d2.evaluation.evaluator INFO: Inference done 3310/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:22
[02/04 15:52:59] d2.evaluation.evaluator INFO: Inference done 3316/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:17
[02/04 15:53:04] d2.evaluation.evaluator INFO: Inference done 3322/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:12
[02/04 15:53:09] d2.evaluation.evaluator INFO: Inference done 3328/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:23:07
[02/04 15:53:14] d2.evaluation.evaluator INFO: Inference done 3334/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:23:02
[02/04 15:53:19] d2.evaluation.evaluator INFO: Inference done 3340/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:56
[02/04 15:53:24] d2.evaluation.evaluator INFO: Inference done 3346/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:51
[02/04 15:53:29] d2.evaluation.evaluator INFO: Inference done 3352/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:46
[02/04 15:53:34] d2.evaluation.evaluator INFO: Inference done 3358/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:41
[02/04 15:53:40] d2.evaluation.evaluator INFO: Inference done 3364/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:36
[02/04 15:53:45] d2.evaluation.evaluator INFO: Inference done 3370/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:31
[02/04 15:53:50] d2.evaluation.evaluator INFO: Inference done 3376/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:26
[02/04 15:53:55] d2.evaluation.evaluator INFO: Inference done 3382/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:20
[02/04 15:54:00] d2.evaluation.evaluator INFO: Inference done 3388/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:15
[02/04 15:54:05] d2.evaluation.evaluator INFO: Inference done 3394/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:10
[02/04 15:54:10] d2.evaluation.evaluator INFO: Inference done 3400/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:05
[02/04 15:54:15] d2.evaluation.evaluator INFO: Inference done 3406/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:22:00
[02/04 15:54:20] d2.evaluation.evaluator INFO: Inference done 3412/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:21:55
[02/04 15:54:25] d2.evaluation.evaluator INFO: Inference done 3418/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:50
[02/04 15:54:31] d2.evaluation.evaluator INFO: Inference done 3424/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:44
[02/04 15:54:36] d2.evaluation.evaluator INFO: Inference done 3430/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:39
[02/04 15:54:41] d2.evaluation.evaluator INFO: Inference done 3436/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:34
[02/04 15:54:46] d2.evaluation.evaluator INFO: Inference done 3442/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:29
[02/04 15:54:51] d2.evaluation.evaluator INFO: Inference done 3448/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:24
[02/04 15:54:56] d2.evaluation.evaluator INFO: Inference done 3454/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:19
[02/04 15:55:01] d2.evaluation.evaluator INFO: Inference done 3460/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:14
[02/04 15:55:06] d2.evaluation.evaluator INFO: Inference done 3466/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:09
[02/04 15:55:11] d2.evaluation.evaluator INFO: Inference done 3472/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:21:03
[02/04 15:55:16] d2.evaluation.evaluator INFO: Inference done 3478/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:20:58
[02/04 15:55:22] d2.evaluation.evaluator INFO: Inference done 3484/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:20:53
[02/04 15:55:27] d2.evaluation.evaluator INFO: Inference done 3490/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:20:48
[02/04 15:55:32] d2.evaluation.evaluator INFO: Inference done 3496/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:43
[02/04 15:55:37] d2.evaluation.evaluator INFO: Inference done 3502/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:38
[02/04 15:55:42] d2.evaluation.evaluator INFO: Inference done 3508/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:33
[02/04 15:55:47] d2.evaluation.evaluator INFO: Inference done 3514/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:27
[02/04 15:55:52] d2.evaluation.evaluator INFO: Inference done 3520/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:22
[02/04 15:55:57] d2.evaluation.evaluator INFO: Inference done 3526/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:17
[02/04 15:56:02] d2.evaluation.evaluator INFO: Inference done 3532/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:12
[02/04 15:56:07] d2.evaluation.evaluator INFO: Inference done 3538/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:07
[02/04 15:56:13] d2.evaluation.evaluator INFO: Inference done 3544/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:20:02
[02/04 15:56:18] d2.evaluation.evaluator INFO: Inference done 3550/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:19:57
[02/04 15:56:23] d2.evaluation.evaluator INFO: Inference done 3556/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:19:52
[02/04 15:56:28] d2.evaluation.evaluator INFO: Inference done 3562/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:19:46
[02/04 15:56:33] d2.evaluation.evaluator INFO: Inference done 3568/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:19:41
[02/04 15:56:38] d2.evaluation.evaluator INFO: Inference done 3574/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:19:36
[02/04 15:56:43] d2.evaluation.evaluator INFO: Inference done 3580/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:31
[02/04 15:56:48] d2.evaluation.evaluator INFO: Inference done 3586/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:26
[02/04 15:56:53] d2.evaluation.evaluator INFO: Inference done 3592/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:21
[02/04 15:56:58] d2.evaluation.evaluator INFO: Inference done 3598/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:16
[02/04 15:57:04] d2.evaluation.evaluator INFO: Inference done 3604/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:10
[02/04 15:57:09] d2.evaluation.evaluator INFO: Inference done 3610/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:05
[02/04 15:57:14] d2.evaluation.evaluator INFO: Inference done 3616/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:19:00
[02/04 15:57:19] d2.evaluation.evaluator INFO: Inference done 3622/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:18:55
[02/04 15:57:24] d2.evaluation.evaluator INFO: Inference done 3628/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:18:50
[02/04 15:57:29] d2.evaluation.evaluator INFO: Inference done 3634/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:18:45
[02/04 15:57:34] d2.evaluation.evaluator INFO: Inference done 3640/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:18:40
[02/04 15:57:39] d2.evaluation.evaluator INFO: Inference done 3646/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:18:35
[02/04 15:57:44] d2.evaluation.evaluator INFO: Inference done 3652/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:18:29
[02/04 15:57:49] d2.evaluation.evaluator INFO: Inference done 3658/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:18:24
[02/04 15:57:54] d2.evaluation.evaluator INFO: Inference done 3664/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:18:19
[02/04 15:58:00] d2.evaluation.evaluator INFO: Inference done 3670/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:18:14
[02/04 15:58:05] d2.evaluation.evaluator INFO: Inference done 3676/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:18:09
[02/04 15:58:10] d2.evaluation.evaluator INFO: Inference done 3682/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:18:04
[02/04 15:58:15] d2.evaluation.evaluator INFO: Inference done 3688/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:17:59
[02/04 15:58:20] d2.evaluation.evaluator INFO: Inference done 3694/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:17:53
[02/04 15:58:25] d2.evaluation.evaluator INFO: Inference done 3700/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:17:48
[02/04 15:58:31] d2.evaluation.evaluator INFO: Inference done 3707/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:42
[02/04 15:58:36] d2.evaluation.evaluator INFO: Inference done 3713/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:37
[02/04 15:58:41] d2.evaluation.evaluator INFO: Inference done 3719/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:32
[02/04 15:58:46] d2.evaluation.evaluator INFO: Inference done 3725/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:27
[02/04 15:58:51] d2.evaluation.evaluator INFO: Inference done 3731/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:22
[02/04 15:58:56] d2.evaluation.evaluator INFO: Inference done 3737/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:17
[02/04 15:59:01] d2.evaluation.evaluator INFO: Inference done 3743/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:11
[02/04 15:59:06] d2.evaluation.evaluator INFO: Inference done 3749/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:06
[02/04 15:59:11] d2.evaluation.evaluator INFO: Inference done 3755/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:17:01
[02/04 15:59:17] d2.evaluation.evaluator INFO: Inference done 3761/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:16:56
[02/04 15:59:22] d2.evaluation.evaluator INFO: Inference done 3767/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:16:51
[02/04 15:59:27] d2.evaluation.evaluator INFO: Inference done 3773/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:16:46
[02/04 15:59:32] d2.evaluation.evaluator INFO: Inference done 3779/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:16:41
[02/04 15:59:37] d2.evaluation.evaluator INFO: Inference done 3785/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:16:36
[02/04 15:59:42] d2.evaluation.evaluator INFO: Inference done 3791/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:30
[02/04 15:59:47] d2.evaluation.evaluator INFO: Inference done 3797/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:25
[02/04 15:59:52] d2.evaluation.evaluator INFO: Inference done 3803/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:20
[02/04 15:59:57] d2.evaluation.evaluator INFO: Inference done 3809/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:15
[02/04 16:00:03] d2.evaluation.evaluator INFO: Inference done 3815/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:10
[02/04 16:00:08] d2.evaluation.evaluator INFO: Inference done 3821/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:05
[02/04 16:00:13] d2.evaluation.evaluator INFO: Inference done 3827/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:16:00
[02/04 16:00:18] d2.evaluation.evaluator INFO: Inference done 3833/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:55
[02/04 16:00:23] d2.evaluation.evaluator INFO: Inference done 3839/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:49
[02/04 16:00:28] d2.evaluation.evaluator INFO: Inference done 3845/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:44
[02/04 16:00:33] d2.evaluation.evaluator INFO: Inference done 3851/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:39
[02/04 16:00:38] d2.evaluation.evaluator INFO: Inference done 3857/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:34
[02/04 16:00:43] d2.evaluation.evaluator INFO: Inference done 3863/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:29
[02/04 16:00:48] d2.evaluation.evaluator INFO: Inference done 3869/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:24
[02/04 16:00:53] d2.evaluation.evaluator INFO: Inference done 3875/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:19
[02/04 16:00:59] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8534 s/iter. ETA=0:15:14
[02/04 16:01:04] d2.evaluation.evaluator INFO: Inference done 3887/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:08
[02/04 16:01:09] d2.evaluation.evaluator INFO: Inference done 3893/4952. Dataloading: 0.0007 s/iter. Inference: 0.8519 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:15:03
[02/04 16:01:14] d2.evaluation.evaluator INFO: Inference done 3899/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:58
[02/04 16:01:19] d2.evaluation.evaluator INFO: Inference done 3905/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:53
[02/04 16:01:24] d2.evaluation.evaluator INFO: Inference done 3911/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:48
[02/04 16:01:30] d2.evaluation.evaluator INFO: Inference done 3917/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:43
[02/04 16:01:35] d2.evaluation.evaluator INFO: Inference done 3923/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:38
[02/04 16:01:40] d2.evaluation.evaluator INFO: Inference done 3929/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:33
[02/04 16:01:45] d2.evaluation.evaluator INFO: Inference done 3935/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:28
[02/04 16:01:50] d2.evaluation.evaluator INFO: Inference done 3941/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:22
[02/04 16:01:55] d2.evaluation.evaluator INFO: Inference done 3947/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:17
[02/04 16:02:00] d2.evaluation.evaluator INFO: Inference done 3953/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:12
[02/04 16:02:06] d2.evaluation.evaluator INFO: Inference done 3959/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8535 s/iter. ETA=0:14:07
[02/04 16:02:11] d2.evaluation.evaluator INFO: Inference done 3965/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:14:02
[02/04 16:02:16] d2.evaluation.evaluator INFO: Inference done 3971/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:57
[02/04 16:02:21] d2.evaluation.evaluator INFO: Inference done 3977/4952. Dataloading: 0.0007 s/iter. Inference: 0.8520 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:52
[02/04 16:02:26] d2.evaluation.evaluator INFO: Inference done 3983/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:47
[02/04 16:02:31] d2.evaluation.evaluator INFO: Inference done 3989/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:42
[02/04 16:02:37] d2.evaluation.evaluator INFO: Inference done 3995/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:36
[02/04 16:02:42] d2.evaluation.evaluator INFO: Inference done 4001/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:31
[02/04 16:02:47] d2.evaluation.evaluator INFO: Inference done 4007/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:26
[02/04 16:02:52] d2.evaluation.evaluator INFO: Inference done 4013/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:21
[02/04 16:02:57] d2.evaluation.evaluator INFO: Inference done 4019/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:16
[02/04 16:03:02] d2.evaluation.evaluator INFO: Inference done 4025/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:11
[02/04 16:03:07] d2.evaluation.evaluator INFO: Inference done 4031/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8536 s/iter. ETA=0:13:06
[02/04 16:03:13] d2.evaluation.evaluator INFO: Inference done 4037/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:13:01
[02/04 16:03:18] d2.evaluation.evaluator INFO: Inference done 4043/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:55
[02/04 16:03:23] d2.evaluation.evaluator INFO: Inference done 4049/4952. Dataloading: 0.0007 s/iter. Inference: 0.8521 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:50
[02/04 16:03:28] d2.evaluation.evaluator INFO: Inference done 4055/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:45
[02/04 16:03:33] d2.evaluation.evaluator INFO: Inference done 4061/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:40
[02/04 16:03:38] d2.evaluation.evaluator INFO: Inference done 4067/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:35
[02/04 16:03:43] d2.evaluation.evaluator INFO: Inference done 4073/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:30
[02/04 16:03:49] d2.evaluation.evaluator INFO: Inference done 4079/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:25
[02/04 16:03:54] d2.evaluation.evaluator INFO: Inference done 4085/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:20
[02/04 16:03:59] d2.evaluation.evaluator INFO: Inference done 4091/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:15
[02/04 16:04:04] d2.evaluation.evaluator INFO: Inference done 4097/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:09
[02/04 16:04:09] d2.evaluation.evaluator INFO: Inference done 4103/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:12:04
[02/04 16:04:14] d2.evaluation.evaluator INFO: Inference done 4109/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8537 s/iter. ETA=0:11:59
[02/04 16:04:20] d2.evaluation.evaluator INFO: Inference done 4115/4952. Dataloading: 0.0007 s/iter. Inference: 0.8522 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:54
[02/04 16:04:25] d2.evaluation.evaluator INFO: Inference done 4121/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:49
[02/04 16:04:30] d2.evaluation.evaluator INFO: Inference done 4127/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:44
[02/04 16:04:35] d2.evaluation.evaluator INFO: Inference done 4133/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:39
[02/04 16:04:40] d2.evaluation.evaluator INFO: Inference done 4139/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:34
[02/04 16:04:45] d2.evaluation.evaluator INFO: Inference done 4145/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:29
[02/04 16:04:51] d2.evaluation.evaluator INFO: Inference done 4151/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:23
[02/04 16:04:56] d2.evaluation.evaluator INFO: Inference done 4157/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:18
[02/04 16:05:01] d2.evaluation.evaluator INFO: Inference done 4163/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:13
[02/04 16:05:06] d2.evaluation.evaluator INFO: Inference done 4169/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:08
[02/04 16:05:11] d2.evaluation.evaluator INFO: Inference done 4175/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:11:03
[02/04 16:05:16] d2.evaluation.evaluator INFO: Inference done 4181/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:10:58
[02/04 16:05:21] d2.evaluation.evaluator INFO: Inference done 4187/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:10:53
[02/04 16:05:26] d2.evaluation.evaluator INFO: Inference done 4193/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:10:48
[02/04 16:05:32] d2.evaluation.evaluator INFO: Inference done 4199/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:42
[02/04 16:05:37] d2.evaluation.evaluator INFO: Inference done 4205/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:37
[02/04 16:05:42] d2.evaluation.evaluator INFO: Inference done 4211/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:32
[02/04 16:05:47] d2.evaluation.evaluator INFO: Inference done 4217/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:27
[02/04 16:05:52] d2.evaluation.evaluator INFO: Inference done 4223/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:22
[02/04 16:05:57] d2.evaluation.evaluator INFO: Inference done 4229/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:17
[02/04 16:06:02] d2.evaluation.evaluator INFO: Inference done 4235/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:12
[02/04 16:06:08] d2.evaluation.evaluator INFO: Inference done 4241/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:07
[02/04 16:06:13] d2.evaluation.evaluator INFO: Inference done 4247/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:10:01
[02/04 16:06:18] d2.evaluation.evaluator INFO: Inference done 4253/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8538 s/iter. ETA=0:09:56
[02/04 16:06:23] d2.evaluation.evaluator INFO: Inference done 4259/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:09:51
[02/04 16:06:28] d2.evaluation.evaluator INFO: Inference done 4265/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:09:46
[02/04 16:06:33] d2.evaluation.evaluator INFO: Inference done 4271/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:09:41
[02/04 16:06:38] d2.evaluation.evaluator INFO: Inference done 4277/4952. Dataloading: 0.0007 s/iter. Inference: 0.8523 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:09:36
[02/04 16:06:44] d2.evaluation.evaluator INFO: Inference done 4283/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:09:31
[02/04 16:06:49] d2.evaluation.evaluator INFO: Inference done 4289/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8539 s/iter. ETA=0:09:26
[02/04 16:06:54] d2.evaluation.evaluator INFO: Inference done 4295/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:09:21
[02/04 16:06:59] d2.evaluation.evaluator INFO: Inference done 4301/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:09:15
[02/04 16:07:04] d2.evaluation.evaluator INFO: Inference done 4307/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:09:10
[02/04 16:07:10] d2.evaluation.evaluator INFO: Inference done 4313/4952. Dataloading: 0.0007 s/iter. Inference: 0.8524 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:09:05
[02/04 16:07:15] d2.evaluation.evaluator INFO: Inference done 4319/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:09:00
[02/04 16:07:20] d2.evaluation.evaluator INFO: Inference done 4325/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:08:55
[02/04 16:07:25] d2.evaluation.evaluator INFO: Inference done 4331/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:08:50
[02/04 16:07:30] d2.evaluation.evaluator INFO: Inference done 4337/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:08:45
[02/04 16:07:35] d2.evaluation.evaluator INFO: Inference done 4343/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:08:40
[02/04 16:07:41] d2.evaluation.evaluator INFO: Inference done 4349/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:08:34
[02/04 16:07:46] d2.evaluation.evaluator INFO: Inference done 4355/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8540 s/iter. ETA=0:08:29
[02/04 16:07:51] d2.evaluation.evaluator INFO: Inference done 4361/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:08:24
[02/04 16:07:56] d2.evaluation.evaluator INFO: Inference done 4367/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:08:19
[02/04 16:08:01] d2.evaluation.evaluator INFO: Inference done 4373/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:08:14
[02/04 16:08:06] d2.evaluation.evaluator INFO: Inference done 4379/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:08:09
[02/04 16:08:12] d2.evaluation.evaluator INFO: Inference done 4385/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:08:04
[02/04 16:08:17] d2.evaluation.evaluator INFO: Inference done 4391/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:59
[02/04 16:08:22] d2.evaluation.evaluator INFO: Inference done 4397/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:54
[02/04 16:08:27] d2.evaluation.evaluator INFO: Inference done 4403/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:48
[02/04 16:08:32] d2.evaluation.evaluator INFO: Inference done 4409/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:43
[02/04 16:08:37] d2.evaluation.evaluator INFO: Inference done 4415/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:38
[02/04 16:08:42] d2.evaluation.evaluator INFO: Inference done 4421/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:33
[02/04 16:08:47] d2.evaluation.evaluator INFO: Inference done 4427/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:28
[02/04 16:08:53] d2.evaluation.evaluator INFO: Inference done 4433/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:23
[02/04 16:08:58] d2.evaluation.evaluator INFO: Inference done 4439/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:18
[02/04 16:09:03] d2.evaluation.evaluator INFO: Inference done 4445/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:13
[02/04 16:09:08] d2.evaluation.evaluator INFO: Inference done 4451/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:07
[02/04 16:09:13] d2.evaluation.evaluator INFO: Inference done 4457/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:07:02
[02/04 16:09:18] d2.evaluation.evaluator INFO: Inference done 4463/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:57
[02/04 16:09:23] d2.evaluation.evaluator INFO: Inference done 4469/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:52
[02/04 16:09:28] d2.evaluation.evaluator INFO: Inference done 4475/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:47
[02/04 16:09:34] d2.evaluation.evaluator INFO: Inference done 4481/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:42
[02/04 16:09:39] d2.evaluation.evaluator INFO: Inference done 4487/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:37
[02/04 16:09:44] d2.evaluation.evaluator INFO: Inference done 4493/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:32
[02/04 16:09:49] d2.evaluation.evaluator INFO: Inference done 4499/4952. Dataloading: 0.0007 s/iter. Inference: 0.8525 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:26
[02/04 16:09:54] d2.evaluation.evaluator INFO: Inference done 4505/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:21
[02/04 16:09:59] d2.evaluation.evaluator INFO: Inference done 4511/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:16
[02/04 16:10:04] d2.evaluation.evaluator INFO: Inference done 4517/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:11
[02/04 16:10:09] d2.evaluation.evaluator INFO: Inference done 4523/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:06
[02/04 16:10:15] d2.evaluation.evaluator INFO: Inference done 4529/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:06:01
[02/04 16:10:20] d2.evaluation.evaluator INFO: Inference done 4535/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:56
[02/04 16:10:25] d2.evaluation.evaluator INFO: Inference done 4541/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:51
[02/04 16:10:30] d2.evaluation.evaluator INFO: Inference done 4547/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:45
[02/04 16:10:35] d2.evaluation.evaluator INFO: Inference done 4553/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:40
[02/04 16:10:40] d2.evaluation.evaluator INFO: Inference done 4559/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:35
[02/04 16:10:45] d2.evaluation.evaluator INFO: Inference done 4565/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:30
[02/04 16:10:51] d2.evaluation.evaluator INFO: Inference done 4571/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:05:25
[02/04 16:10:56] d2.evaluation.evaluator INFO: Inference done 4577/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:05:20
[02/04 16:11:01] d2.evaluation.evaluator INFO: Inference done 4583/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8541 s/iter. ETA=0:05:15
[02/04 16:11:06] d2.evaluation.evaluator INFO: Inference done 4589/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:05:10
[02/04 16:11:11] d2.evaluation.evaluator INFO: Inference done 4595/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:05:04
[02/04 16:11:16] d2.evaluation.evaluator INFO: Inference done 4601/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:59
[02/04 16:11:21] d2.evaluation.evaluator INFO: Inference done 4607/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:54
[02/04 16:11:27] d2.evaluation.evaluator INFO: Inference done 4613/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:49
[02/04 16:11:32] d2.evaluation.evaluator INFO: Inference done 4619/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:44
[02/04 16:11:37] d2.evaluation.evaluator INFO: Inference done 4625/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:39
[02/04 16:11:42] d2.evaluation.evaluator INFO: Inference done 4631/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:34
[02/04 16:11:47] d2.evaluation.evaluator INFO: Inference done 4637/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:29
[02/04 16:11:52] d2.evaluation.evaluator INFO: Inference done 4643/4952. Dataloading: 0.0007 s/iter. Inference: 0.8526 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:23
[02/04 16:11:58] d2.evaluation.evaluator INFO: Inference done 4649/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:18
[02/04 16:12:03] d2.evaluation.evaluator INFO: Inference done 4655/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:13
[02/04 16:12:08] d2.evaluation.evaluator INFO: Inference done 4661/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:08
[02/04 16:12:13] d2.evaluation.evaluator INFO: Inference done 4667/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:04:03
[02/04 16:12:18] d2.evaluation.evaluator INFO: Inference done 4673/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8542 s/iter. ETA=0:03:58
[02/04 16:12:23] d2.evaluation.evaluator INFO: Inference done 4679/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:53
[02/04 16:12:29] d2.evaluation.evaluator INFO: Inference done 4685/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:48
[02/04 16:12:34] d2.evaluation.evaluator INFO: Inference done 4691/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:42
[02/04 16:12:39] d2.evaluation.evaluator INFO: Inference done 4697/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:37
[02/04 16:12:44] d2.evaluation.evaluator INFO: Inference done 4703/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:32
[02/04 16:12:49] d2.evaluation.evaluator INFO: Inference done 4709/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:27
[02/04 16:12:54] d2.evaluation.evaluator INFO: Inference done 4715/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:22
[02/04 16:12:59] d2.evaluation.evaluator INFO: Inference done 4721/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:17
[02/04 16:13:05] d2.evaluation.evaluator INFO: Inference done 4727/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:12
[02/04 16:13:10] d2.evaluation.evaluator INFO: Inference done 4733/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:07
[02/04 16:13:15] d2.evaluation.evaluator INFO: Inference done 4739/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:03:01
[02/04 16:13:20] d2.evaluation.evaluator INFO: Inference done 4745/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:56
[02/04 16:13:25] d2.evaluation.evaluator INFO: Inference done 4751/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:51
[02/04 16:13:30] d2.evaluation.evaluator INFO: Inference done 4757/4952. Dataloading: 0.0007 s/iter. Inference: 0.8527 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:46
[02/04 16:13:35] d2.evaluation.evaluator INFO: Inference done 4763/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:41
[02/04 16:13:40] d2.evaluation.evaluator INFO: Inference done 4769/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:36
[02/04 16:13:46] d2.evaluation.evaluator INFO: Inference done 4775/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:31
[02/04 16:13:51] d2.evaluation.evaluator INFO: Inference done 4781/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:26
[02/04 16:13:56] d2.evaluation.evaluator INFO: Inference done 4787/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:20
[02/04 16:14:01] d2.evaluation.evaluator INFO: Inference done 4793/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:15
[02/04 16:14:06] d2.evaluation.evaluator INFO: Inference done 4799/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:10
[02/04 16:14:11] d2.evaluation.evaluator INFO: Inference done 4805/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:02:05
[02/04 16:14:17] d2.evaluation.evaluator INFO: Inference done 4811/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:02:00
[02/04 16:14:22] d2.evaluation.evaluator INFO: Inference done 4817/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:01:55
[02/04 16:14:27] d2.evaluation.evaluator INFO: Inference done 4823/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:01:50
[02/04 16:14:32] d2.evaluation.evaluator INFO: Inference done 4829/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:01:45
[02/04 16:14:37] d2.evaluation.evaluator INFO: Inference done 4835/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:01:39
[02/04 16:14:42] d2.evaluation.evaluator INFO: Inference done 4841/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:01:34
[02/04 16:14:47] d2.evaluation.evaluator INFO: Inference done 4847/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:01:29
[02/04 16:14:52] d2.evaluation.evaluator INFO: Inference done 4853/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:01:24
[02/04 16:14:57] d2.evaluation.evaluator INFO: Inference done 4859/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:01:19
[02/04 16:15:03] d2.evaluation.evaluator INFO: Inference done 4865/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:01:14
[02/04 16:15:08] d2.evaluation.evaluator INFO: Inference done 4871/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:01:09
[02/04 16:15:13] d2.evaluation.evaluator INFO: Inference done 4877/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:01:04
[02/04 16:15:18] d2.evaluation.evaluator INFO: Inference done 4883/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:00:58
[02/04 16:15:23] d2.evaluation.evaluator INFO: Inference done 4889/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:00:53
[02/04 16:15:28] d2.evaluation.evaluator INFO: Inference done 4895/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8543 s/iter. ETA=0:00:48
[02/04 16:15:34] d2.evaluation.evaluator INFO: Inference done 4901/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:43
[02/04 16:15:39] d2.evaluation.evaluator INFO: Inference done 4907/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:38
[02/04 16:15:44] d2.evaluation.evaluator INFO: Inference done 4913/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:33
[02/04 16:15:49] d2.evaluation.evaluator INFO: Inference done 4919/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:28
[02/04 16:15:54] d2.evaluation.evaluator INFO: Inference done 4925/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:23
[02/04 16:15:59] d2.evaluation.evaluator INFO: Inference done 4931/4952. Dataloading: 0.0007 s/iter. Inference: 0.8528 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:17
[02/04 16:16:05] d2.evaluation.evaluator INFO: Inference done 4937/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:12
[02/04 16:16:10] d2.evaluation.evaluator INFO: Inference done 4943/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8544 s/iter. ETA=0:00:07
[02/04 16:16:15] d2.evaluation.evaluator INFO: Inference done 4949/4952. Dataloading: 0.0007 s/iter. Inference: 0.8529 s/iter. Eval: 0.0008 s/iter. Total: 0.8545 s/iter. ETA=0:00:02
[02/04 16:16:18] d2.evaluation.evaluator INFO: Total inference time: 1:10:27.095361 (0.854477 s / iter per device, on 1 devices)
[02/04 16:16:18] d2.evaluation.evaluator INFO: Total inference pure compute time: 1:10:19 (0.852914 s / iter per device, on 1 devices)
[02/04 16:16:18] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[02/04 16:17:01] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car  |  cat  |  chair  |  diningtable  |  dog  |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow  |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:-----:|:-----:|:-------:|:-------------:|:-----:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:-----:|:-----------:|:------:|
|    0.008    |   0.082   | 0.006  |  0.001   | 0.000 | 0.108 |  0.048  |     0.009     | 0.000 |  0.273  |  0.167   |     0.053     |  0.112  |  0.024  |    0.001    | 0.026  | 0.000 | 0.004 |    0.022    | 0.003  |
[02/04 16:17:01] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|  AP   |  AP50  |  AP75  |  bAP  |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:-----:|:------:|:------:|:-----:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 0.008 | 0.047  | 0.000  | 0.010 |  0.060  |  0.001  | 0.002 |  0.011  |  0.000  |
[02/04 16:17:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/04 16:17:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[02/04 16:17:01] d2.evaluation.testing INFO: copypaste: 0.0083,0.0474,0.0005,0.0102,0.0595,0.0006,0.0024,0.0109,0.0001
[02/04 16:17:01] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[02/04 16:17:11] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0003 s/iter. Inference: 0.9082 s/iter. Eval: 0.0008 s/iter. Total: 0.9093 s/iter. ETA=1:14:52
[02/04 16:17:17] d2.evaluation.evaluator INFO: Inference done 17/4952. Dataloading: 0.0003 s/iter. Inference: 0.9039 s/iter. Eval: 0.0008 s/iter. Total: 0.9050 s/iter. ETA=1:14:26
[02/04 16:17:22] d2.evaluation.evaluator INFO: Inference done 23/4952. Dataloading: 0.0004 s/iter. Inference: 0.9083 s/iter. Eval: 0.0008 s/iter. Total: 0.9096 s/iter. ETA=1:14:43
[02/04 16:17:28] d2.evaluation.evaluator INFO: Inference done 29/4952. Dataloading: 0.0005 s/iter. Inference: 0.9113 s/iter. Eval: 0.0008 s/iter. Total: 0.9126 s/iter. ETA=1:14:52
[02/04 16:17:33] d2.evaluation.evaluator INFO: Inference done 35/4952. Dataloading: 0.0005 s/iter. Inference: 0.9108 s/iter. Eval: 0.0008 s/iter. Total: 0.9122 s/iter. ETA=1:14:45
[02/04 16:17:39] d2.evaluation.evaluator INFO: Inference done 41/4952. Dataloading: 0.0005 s/iter. Inference: 0.9106 s/iter. Eval: 0.0008 s/iter. Total: 0.9120 s/iter. ETA=1:14:38
[02/04 16:17:44] d2.evaluation.evaluator INFO: Inference done 47/4952. Dataloading: 0.0006 s/iter. Inference: 0.9133 s/iter. Eval: 0.0008 s/iter. Total: 0.9147 s/iter. ETA=1:14:46
[02/04 16:17:50] d2.evaluation.evaluator INFO: Inference done 53/4952. Dataloading: 0.0006 s/iter. Inference: 0.9151 s/iter. Eval: 0.0008 s/iter. Total: 0.9165 s/iter. ETA=1:14:50
[02/04 16:17:55] d2.evaluation.evaluator INFO: Inference done 59/4952. Dataloading: 0.0006 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=1:14:53
[02/04 16:18:01] d2.evaluation.evaluator INFO: Inference done 65/4952. Dataloading: 0.0006 s/iter. Inference: 0.9160 s/iter. Eval: 0.0008 s/iter. Total: 0.9174 s/iter. ETA=1:14:43
[02/04 16:18:06] d2.evaluation.evaluator INFO: Inference done 71/4952. Dataloading: 0.0006 s/iter. Inference: 0.9149 s/iter. Eval: 0.0008 s/iter. Total: 0.9164 s/iter. ETA=1:14:32
[02/04 16:18:12] d2.evaluation.evaluator INFO: Inference done 77/4952. Dataloading: 0.0006 s/iter. Inference: 0.9153 s/iter. Eval: 0.0008 s/iter. Total: 0.9168 s/iter. ETA=1:14:29
[02/04 16:18:17] d2.evaluation.evaluator INFO: Inference done 83/4952. Dataloading: 0.0006 s/iter. Inference: 0.9150 s/iter. Eval: 0.0008 s/iter. Total: 0.9164 s/iter. ETA=1:14:22
[02/04 16:18:23] d2.evaluation.evaluator INFO: Inference done 89/4952. Dataloading: 0.0006 s/iter. Inference: 0.9156 s/iter. Eval: 0.0008 s/iter. Total: 0.9171 s/iter. ETA=1:14:19
[02/04 16:18:28] d2.evaluation.evaluator INFO: Inference done 95/4952. Dataloading: 0.0006 s/iter. Inference: 0.9157 s/iter. Eval: 0.0008 s/iter. Total: 0.9172 s/iter. ETA=1:14:14
[02/04 16:18:34] d2.evaluation.evaluator INFO: Inference done 101/4952. Dataloading: 0.0006 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:14:12
[02/04 16:18:39] d2.evaluation.evaluator INFO: Inference done 107/4952. Dataloading: 0.0006 s/iter. Inference: 0.9168 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=1:14:09
[02/04 16:18:45] d2.evaluation.evaluator INFO: Inference done 113/4952. Dataloading: 0.0007 s/iter. Inference: 0.9167 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=1:14:03
[02/04 16:18:50] d2.evaluation.evaluator INFO: Inference done 119/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9177 s/iter. ETA=1:13:55
[02/04 16:18:56] d2.evaluation.evaluator INFO: Inference done 125/4952. Dataloading: 0.0007 s/iter. Inference: 0.9168 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=1:13:52
[02/04 16:19:01] d2.evaluation.evaluator INFO: Inference done 131/4952. Dataloading: 0.0007 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9184 s/iter. ETA=1:13:47
[02/04 16:19:07] d2.evaluation.evaluator INFO: Inference done 137/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:13:43
[02/04 16:19:12] d2.evaluation.evaluator INFO: Inference done 143/4952. Dataloading: 0.0007 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9184 s/iter. ETA=1:13:36
[02/04 16:19:18] d2.evaluation.evaluator INFO: Inference done 149/4952. Dataloading: 0.0007 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9184 s/iter. ETA=1:13:31
[02/04 16:19:24] d2.evaluation.evaluator INFO: Inference done 155/4952. Dataloading: 0.0007 s/iter. Inference: 0.9185 s/iter. Eval: 0.0008 s/iter. Total: 0.9200 s/iter. ETA=1:13:33
[02/04 16:19:29] d2.evaluation.evaluator INFO: Inference done 161/4952. Dataloading: 0.0007 s/iter. Inference: 0.9200 s/iter. Eval: 0.0008 s/iter. Total: 0.9215 s/iter. ETA=1:13:34
[02/04 16:19:35] d2.evaluation.evaluator INFO: Inference done 167/4952. Dataloading: 0.0007 s/iter. Inference: 0.9202 s/iter. Eval: 0.0008 s/iter. Total: 0.9217 s/iter. ETA=1:13:30
[02/04 16:19:41] d2.evaluation.evaluator INFO: Inference done 173/4952. Dataloading: 0.0007 s/iter. Inference: 0.9204 s/iter. Eval: 0.0008 s/iter. Total: 0.9219 s/iter. ETA=1:13:25
[02/04 16:19:46] d2.evaluation.evaluator INFO: Inference done 179/4952. Dataloading: 0.0007 s/iter. Inference: 0.9207 s/iter. Eval: 0.0008 s/iter. Total: 0.9222 s/iter. ETA=1:13:21
[02/04 16:19:52] d2.evaluation.evaluator INFO: Inference done 185/4952. Dataloading: 0.0007 s/iter. Inference: 0.9208 s/iter. Eval: 0.0008 s/iter. Total: 0.9223 s/iter. ETA=1:13:16
[02/04 16:19:57] d2.evaluation.evaluator INFO: Inference done 191/4952. Dataloading: 0.0007 s/iter. Inference: 0.9209 s/iter. Eval: 0.0008 s/iter. Total: 0.9225 s/iter. ETA=1:13:11
[02/04 16:20:03] d2.evaluation.evaluator INFO: Inference done 197/4952. Dataloading: 0.0007 s/iter. Inference: 0.9209 s/iter. Eval: 0.0008 s/iter. Total: 0.9224 s/iter. ETA=1:13:06
[02/04 16:20:08] d2.evaluation.evaluator INFO: Inference done 203/4952. Dataloading: 0.0007 s/iter. Inference: 0.9207 s/iter. Eval: 0.0008 s/iter. Total: 0.9222 s/iter. ETA=1:12:59
[02/04 16:20:14] d2.evaluation.evaluator INFO: Inference done 209/4952. Dataloading: 0.0007 s/iter. Inference: 0.9210 s/iter. Eval: 0.0008 s/iter. Total: 0.9225 s/iter. ETA=1:12:55
[02/04 16:20:19] d2.evaluation.evaluator INFO: Inference done 215/4952. Dataloading: 0.0007 s/iter. Inference: 0.9204 s/iter. Eval: 0.0008 s/iter. Total: 0.9219 s/iter. ETA=1:12:47
[02/04 16:20:25] d2.evaluation.evaluator INFO: Inference done 221/4952. Dataloading: 0.0007 s/iter. Inference: 0.9200 s/iter. Eval: 0.0008 s/iter. Total: 0.9215 s/iter. ETA=1:12:39
[02/04 16:20:30] d2.evaluation.evaluator INFO: Inference done 227/4952. Dataloading: 0.0007 s/iter. Inference: 0.9202 s/iter. Eval: 0.0008 s/iter. Total: 0.9217 s/iter. ETA=1:12:35
[02/04 16:20:36] d2.evaluation.evaluator INFO: Inference done 233/4952. Dataloading: 0.0007 s/iter. Inference: 0.9207 s/iter. Eval: 0.0008 s/iter. Total: 0.9222 s/iter. ETA=1:12:31
[02/04 16:20:41] d2.evaluation.evaluator INFO: Inference done 239/4952. Dataloading: 0.0007 s/iter. Inference: 0.9205 s/iter. Eval: 0.0008 s/iter. Total: 0.9220 s/iter. ETA=1:12:25
[02/04 16:20:47] d2.evaluation.evaluator INFO: Inference done 245/4952. Dataloading: 0.0007 s/iter. Inference: 0.9203 s/iter. Eval: 0.0008 s/iter. Total: 0.9218 s/iter. ETA=1:12:18
[02/04 16:20:52] d2.evaluation.evaluator INFO: Inference done 251/4952. Dataloading: 0.0007 s/iter. Inference: 0.9201 s/iter. Eval: 0.0008 s/iter. Total: 0.9217 s/iter. ETA=1:12:12
[02/04 16:20:58] d2.evaluation.evaluator INFO: Inference done 257/4952. Dataloading: 0.0007 s/iter. Inference: 0.9198 s/iter. Eval: 0.0008 s/iter. Total: 0.9213 s/iter. ETA=1:12:05
[02/04 16:21:03] d2.evaluation.evaluator INFO: Inference done 263/4952. Dataloading: 0.0007 s/iter. Inference: 0.9196 s/iter. Eval: 0.0008 s/iter. Total: 0.9211 s/iter. ETA=1:11:59
[02/04 16:21:09] d2.evaluation.evaluator INFO: Inference done 269/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9204 s/iter. ETA=1:11:50
[02/04 16:21:14] d2.evaluation.evaluator INFO: Inference done 275/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9204 s/iter. ETA=1:11:44
[02/04 16:21:20] d2.evaluation.evaluator INFO: Inference done 281/4952. Dataloading: 0.0007 s/iter. Inference: 0.9188 s/iter. Eval: 0.0008 s/iter. Total: 0.9203 s/iter. ETA=1:11:38
[02/04 16:21:25] d2.evaluation.evaluator INFO: Inference done 287/4952. Dataloading: 0.0007 s/iter. Inference: 0.9187 s/iter. Eval: 0.0008 s/iter. Total: 0.9202 s/iter. ETA=1:11:32
[02/04 16:21:31] d2.evaluation.evaluator INFO: Inference done 293/4952. Dataloading: 0.0007 s/iter. Inference: 0.9183 s/iter. Eval: 0.0008 s/iter. Total: 0.9199 s/iter. ETA=1:11:25
[02/04 16:21:36] d2.evaluation.evaluator INFO: Inference done 299/4952. Dataloading: 0.0007 s/iter. Inference: 0.9182 s/iter. Eval: 0.0008 s/iter. Total: 0.9198 s/iter. ETA=1:11:19
[02/04 16:21:42] d2.evaluation.evaluator INFO: Inference done 305/4952. Dataloading: 0.0007 s/iter. Inference: 0.9180 s/iter. Eval: 0.0008 s/iter. Total: 0.9196 s/iter. ETA=1:11:13
[02/04 16:21:47] d2.evaluation.evaluator INFO: Inference done 311/4952. Dataloading: 0.0007 s/iter. Inference: 0.9182 s/iter. Eval: 0.0008 s/iter. Total: 0.9197 s/iter. ETA=1:11:08
[02/04 16:21:53] d2.evaluation.evaluator INFO: Inference done 317/4952. Dataloading: 0.0007 s/iter. Inference: 0.9180 s/iter. Eval: 0.0008 s/iter. Total: 0.9196 s/iter. ETA=1:11:02
[02/04 16:21:58] d2.evaluation.evaluator INFO: Inference done 323/4952. Dataloading: 0.0007 s/iter. Inference: 0.9179 s/iter. Eval: 0.0008 s/iter. Total: 0.9195 s/iter. ETA=1:10:56
[02/04 16:22:04] d2.evaluation.evaluator INFO: Inference done 329/4952. Dataloading: 0.0007 s/iter. Inference: 0.9178 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:10:50
[02/04 16:22:09] d2.evaluation.evaluator INFO: Inference done 335/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:10:43
[02/04 16:22:14] d2.evaluation.evaluator INFO: Inference done 341/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9188 s/iter. ETA=1:10:36
[02/04 16:22:20] d2.evaluation.evaluator INFO: Inference done 347/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:10:30
[02/04 16:22:25] d2.evaluation.evaluator INFO: Inference done 353/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:10:25
[02/04 16:22:31] d2.evaluation.evaluator INFO: Inference done 359/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=1:10:20
[02/04 16:22:37] d2.evaluation.evaluator INFO: Inference done 365/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=1:10:14
[02/04 16:22:42] d2.evaluation.evaluator INFO: Inference done 371/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:10:08
[02/04 16:22:47] d2.evaluation.evaluator INFO: Inference done 377/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:10:02
[02/04 16:22:53] d2.evaluation.evaluator INFO: Inference done 383/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=1:09:58
[02/04 16:22:59] d2.evaluation.evaluator INFO: Inference done 389/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:09:54
[02/04 16:23:04] d2.evaluation.evaluator INFO: Inference done 395/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:09:48
[02/04 16:23:10] d2.evaluation.evaluator INFO: Inference done 401/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=1:09:42
[02/04 16:23:15] d2.evaluation.evaluator INFO: Inference done 407/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=1:09:36
[02/04 16:23:21] d2.evaluation.evaluator INFO: Inference done 413/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:09:32
[02/04 16:23:26] d2.evaluation.evaluator INFO: Inference done 419/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:09:26
[02/04 16:23:32] d2.evaluation.evaluator INFO: Inference done 425/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:09:21
[02/04 16:23:37] d2.evaluation.evaluator INFO: Inference done 431/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:09:15
[02/04 16:23:43] d2.evaluation.evaluator INFO: Inference done 437/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:09:10
[02/04 16:23:48] d2.evaluation.evaluator INFO: Inference done 443/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:09:04
[02/04 16:23:54] d2.evaluation.evaluator INFO: Inference done 449/4952. Dataloading: 0.0007 s/iter. Inference: 0.9180 s/iter. Eval: 0.0008 s/iter. Total: 0.9195 s/iter. ETA=1:09:00
[02/04 16:23:59] d2.evaluation.evaluator INFO: Inference done 455/4952. Dataloading: 0.0007 s/iter. Inference: 0.9179 s/iter. Eval: 0.0008 s/iter. Total: 0.9195 s/iter. ETA=1:08:54
[02/04 16:24:05] d2.evaluation.evaluator INFO: Inference done 461/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:08:48
[02/04 16:24:10] d2.evaluation.evaluator INFO: Inference done 467/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:08:42
[02/04 16:24:16] d2.evaluation.evaluator INFO: Inference done 473/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:08:37
[02/04 16:24:21] d2.evaluation.evaluator INFO: Inference done 479/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:08:31
[02/04 16:24:27] d2.evaluation.evaluator INFO: Inference done 485/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:08:26
[02/04 16:24:32] d2.evaluation.evaluator INFO: Inference done 491/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:08:19
[02/04 16:24:38] d2.evaluation.evaluator INFO: Inference done 497/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:08:15
[02/04 16:24:44] d2.evaluation.evaluator INFO: Inference done 503/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:08:09
[02/04 16:24:49] d2.evaluation.evaluator INFO: Inference done 509/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:08:04
[02/04 16:24:55] d2.evaluation.evaluator INFO: Inference done 515/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:07:58
[02/04 16:25:00] d2.evaluation.evaluator INFO: Inference done 521/4952. Dataloading: 0.0007 s/iter. Inference: 0.9178 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:07:53
[02/04 16:25:06] d2.evaluation.evaluator INFO: Inference done 527/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:07:47
[02/04 16:25:11] d2.evaluation.evaluator INFO: Inference done 533/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:07:41
[02/04 16:25:17] d2.evaluation.evaluator INFO: Inference done 539/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=1:07:36
[02/04 16:25:22] d2.evaluation.evaluator INFO: Inference done 545/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:07:30
[02/04 16:25:28] d2.evaluation.evaluator INFO: Inference done 551/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:07:25
[02/04 16:25:33] d2.evaluation.evaluator INFO: Inference done 557/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:07:19
[02/04 16:25:39] d2.evaluation.evaluator INFO: Inference done 563/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:07:13
[02/04 16:25:44] d2.evaluation.evaluator INFO: Inference done 569/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:07:08
[02/04 16:25:50] d2.evaluation.evaluator INFO: Inference done 575/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:07:03
[02/04 16:25:55] d2.evaluation.evaluator INFO: Inference done 581/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:06:57
[02/04 16:26:01] d2.evaluation.evaluator INFO: Inference done 587/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:06:51
[02/04 16:26:06] d2.evaluation.evaluator INFO: Inference done 593/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=1:06:46
[02/04 16:26:12] d2.evaluation.evaluator INFO: Inference done 599/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:06:41
[02/04 16:26:17] d2.evaluation.evaluator INFO: Inference done 605/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=1:06:35
[02/04 16:26:23] d2.evaluation.evaluator INFO: Inference done 611/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=1:06:29
[02/04 16:26:28] d2.evaluation.evaluator INFO: Inference done 617/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=1:06:23
[02/04 16:26:34] d2.evaluation.evaluator INFO: Inference done 623/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=1:06:18
[02/04 16:26:39] d2.evaluation.evaluator INFO: Inference done 629/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=1:06:12
[02/04 16:26:45] d2.evaluation.evaluator INFO: Inference done 635/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:06:06
[02/04 16:26:50] d2.evaluation.evaluator INFO: Inference done 641/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:06:00
[02/04 16:26:56] d2.evaluation.evaluator INFO: Inference done 647/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:05:55
[02/04 16:27:01] d2.evaluation.evaluator INFO: Inference done 653/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:05:49
[02/04 16:27:07] d2.evaluation.evaluator INFO: Inference done 659/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:05:43
[02/04 16:27:12] d2.evaluation.evaluator INFO: Inference done 665/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:05:38
[02/04 16:27:18] d2.evaluation.evaluator INFO: Inference done 671/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:05:32
[02/04 16:27:23] d2.evaluation.evaluator INFO: Inference done 677/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=1:05:26
[02/04 16:27:29] d2.evaluation.evaluator INFO: Inference done 683/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:05:21
[02/04 16:27:34] d2.evaluation.evaluator INFO: Inference done 689/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:05:15
[02/04 16:27:40] d2.evaluation.evaluator INFO: Inference done 695/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:05:10
[02/04 16:27:45] d2.evaluation.evaluator INFO: Inference done 701/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:05:05
[02/04 16:27:51] d2.evaluation.evaluator INFO: Inference done 707/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:04:59
[02/04 16:27:56] d2.evaluation.evaluator INFO: Inference done 713/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:04:54
[02/04 16:28:02] d2.evaluation.evaluator INFO: Inference done 719/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9188 s/iter. ETA=1:04:49
[02/04 16:28:07] d2.evaluation.evaluator INFO: Inference done 725/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:04:43
[02/04 16:28:13] d2.evaluation.evaluator INFO: Inference done 731/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:04:37
[02/04 16:28:18] d2.evaluation.evaluator INFO: Inference done 737/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=1:04:32
[02/04 16:28:24] d2.evaluation.evaluator INFO: Inference done 743/4952. Dataloading: 0.0007 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=1:04:25
[02/04 16:28:29] d2.evaluation.evaluator INFO: Inference done 749/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:04:20
[02/04 16:28:35] d2.evaluation.evaluator INFO: Inference done 755/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=1:04:15
[02/04 16:28:40] d2.evaluation.evaluator INFO: Inference done 761/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=1:04:09
[02/04 16:28:46] d2.evaluation.evaluator INFO: Inference done 767/4952. Dataloading: 0.0007 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9184 s/iter. ETA=1:04:03
[02/04 16:28:51] d2.evaluation.evaluator INFO: Inference done 773/4952. Dataloading: 0.0007 s/iter. Inference: 0.9168 s/iter. Eval: 0.0008 s/iter. Total: 0.9184 s/iter. ETA=1:03:57
[02/04 16:28:57] d2.evaluation.evaluator INFO: Inference done 779/4952. Dataloading: 0.0007 s/iter. Inference: 0.9168 s/iter. Eval: 0.0008 s/iter. Total: 0.9184 s/iter. ETA=1:03:52
[02/04 16:29:02] d2.evaluation.evaluator INFO: Inference done 785/4952. Dataloading: 0.0007 s/iter. Inference: 0.9167 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=1:03:46
[02/04 16:29:07] d2.evaluation.evaluator INFO: Inference done 791/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=1:03:40
[02/04 16:29:13] d2.evaluation.evaluator INFO: Inference done 797/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=1:03:35
[02/04 16:29:18] d2.evaluation.evaluator INFO: Inference done 803/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=1:03:29
[02/04 16:29:24] d2.evaluation.evaluator INFO: Inference done 809/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:03:23
[02/04 16:29:29] d2.evaluation.evaluator INFO: Inference done 815/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:03:17
[02/04 16:29:35] d2.evaluation.evaluator INFO: Inference done 821/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:03:12
[02/04 16:29:40] d2.evaluation.evaluator INFO: Inference done 827/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:03:06
[02/04 16:29:46] d2.evaluation.evaluator INFO: Inference done 833/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:03:01
[02/04 16:29:51] d2.evaluation.evaluator INFO: Inference done 839/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:02:55
[02/04 16:29:57] d2.evaluation.evaluator INFO: Inference done 845/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:02:49
[02/04 16:30:02] d2.evaluation.evaluator INFO: Inference done 851/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:02:44
[02/04 16:30:08] d2.evaluation.evaluator INFO: Inference done 857/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:02:39
[02/04 16:30:13] d2.evaluation.evaluator INFO: Inference done 863/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:02:33
[02/04 16:30:19] d2.evaluation.evaluator INFO: Inference done 869/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:02:28
[02/04 16:30:24] d2.evaluation.evaluator INFO: Inference done 875/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:02:22
[02/04 16:30:30] d2.evaluation.evaluator INFO: Inference done 881/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:02:16
[02/04 16:30:35] d2.evaluation.evaluator INFO: Inference done 887/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:02:11
[02/04 16:30:41] d2.evaluation.evaluator INFO: Inference done 893/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:02:05
[02/04 16:30:46] d2.evaluation.evaluator INFO: Inference done 899/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:59
[02/04 16:30:52] d2.evaluation.evaluator INFO: Inference done 905/4952. Dataloading: 0.0007 s/iter. Inference: 0.9161 s/iter. Eval: 0.0008 s/iter. Total: 0.9177 s/iter. ETA=1:01:53
[02/04 16:30:57] d2.evaluation.evaluator INFO: Inference done 911/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:48
[02/04 16:31:03] d2.evaluation.evaluator INFO: Inference done 917/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9177 s/iter. ETA=1:01:43
[02/04 16:31:08] d2.evaluation.evaluator INFO: Inference done 923/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:37
[02/04 16:31:14] d2.evaluation.evaluator INFO: Inference done 929/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9177 s/iter. ETA=1:01:31
[02/04 16:31:19] d2.evaluation.evaluator INFO: Inference done 935/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:26
[02/04 16:31:25] d2.evaluation.evaluator INFO: Inference done 941/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:21
[02/04 16:31:30] d2.evaluation.evaluator INFO: Inference done 947/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:15
[02/04 16:31:36] d2.evaluation.evaluator INFO: Inference done 953/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:01:10
[02/04 16:31:41] d2.evaluation.evaluator INFO: Inference done 959/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9177 s/iter. ETA=1:01:04
[02/04 16:31:47] d2.evaluation.evaluator INFO: Inference done 965/4952. Dataloading: 0.0007 s/iter. Inference: 0.9162 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:00:59
[02/04 16:31:52] d2.evaluation.evaluator INFO: Inference done 971/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:00:53
[02/04 16:31:58] d2.evaluation.evaluator INFO: Inference done 977/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=1:00:48
[02/04 16:32:03] d2.evaluation.evaluator INFO: Inference done 983/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:43
[02/04 16:32:09] d2.evaluation.evaluator INFO: Inference done 989/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=1:00:37
[02/04 16:32:14] d2.evaluation.evaluator INFO: Inference done 995/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:32
[02/04 16:32:20] d2.evaluation.evaluator INFO: Inference done 1001/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:26
[02/04 16:32:26] d2.evaluation.evaluator INFO: Inference done 1007/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:21
[02/04 16:32:31] d2.evaluation.evaluator INFO: Inference done 1013/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:15
[02/04 16:32:36] d2.evaluation.evaluator INFO: Inference done 1019/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:10
[02/04 16:32:42] d2.evaluation.evaluator INFO: Inference done 1025/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=1:00:04
[02/04 16:32:47] d2.evaluation.evaluator INFO: Inference done 1031/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:58
[02/04 16:32:53] d2.evaluation.evaluator INFO: Inference done 1037/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9178 s/iter. ETA=0:59:53
[02/04 16:32:58] d2.evaluation.evaluator INFO: Inference done 1043/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:48
[02/04 16:33:04] d2.evaluation.evaluator INFO: Inference done 1049/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:42
[02/04 16:33:09] d2.evaluation.evaluator INFO: Inference done 1055/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:36
[02/04 16:33:15] d2.evaluation.evaluator INFO: Inference done 1061/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:31
[02/04 16:33:21] d2.evaluation.evaluator INFO: Inference done 1067/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:25
[02/04 16:33:26] d2.evaluation.evaluator INFO: Inference done 1073/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:20
[02/04 16:33:32] d2.evaluation.evaluator INFO: Inference done 1079/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:15
[02/04 16:33:37] d2.evaluation.evaluator INFO: Inference done 1085/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:09
[02/04 16:33:43] d2.evaluation.evaluator INFO: Inference done 1091/4952. Dataloading: 0.0007 s/iter. Inference: 0.9163 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:59:03
[02/04 16:33:48] d2.evaluation.evaluator INFO: Inference done 1097/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:58:58
[02/04 16:33:54] d2.evaluation.evaluator INFO: Inference done 1103/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9179 s/iter. ETA=0:58:53
[02/04 16:33:59] d2.evaluation.evaluator INFO: Inference done 1109/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=0:58:47
[02/04 16:34:05] d2.evaluation.evaluator INFO: Inference done 1115/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=0:58:42
[02/04 16:34:10] d2.evaluation.evaluator INFO: Inference done 1121/4952. Dataloading: 0.0007 s/iter. Inference: 0.9164 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=0:58:36
[02/04 16:34:16] d2.evaluation.evaluator INFO: Inference done 1127/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9180 s/iter. ETA=0:58:31
[02/04 16:34:21] d2.evaluation.evaluator INFO: Inference done 1133/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:58:26
[02/04 16:34:27] d2.evaluation.evaluator INFO: Inference done 1139/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:58:20
[02/04 16:34:32] d2.evaluation.evaluator INFO: Inference done 1145/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=0:58:15
[02/04 16:34:38] d2.evaluation.evaluator INFO: Inference done 1151/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=0:58:09
[02/04 16:34:43] d2.evaluation.evaluator INFO: Inference done 1157/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=0:58:04
[02/04 16:34:49] d2.evaluation.evaluator INFO: Inference done 1163/4952. Dataloading: 0.0007 s/iter. Inference: 0.9166 s/iter. Eval: 0.0008 s/iter. Total: 0.9182 s/iter. ETA=0:57:58
[02/04 16:34:54] d2.evaluation.evaluator INFO: Inference done 1169/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:53
[02/04 16:35:00] d2.evaluation.evaluator INFO: Inference done 1175/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:47
[02/04 16:35:05] d2.evaluation.evaluator INFO: Inference done 1181/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:42
[02/04 16:35:11] d2.evaluation.evaluator INFO: Inference done 1187/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:36
[02/04 16:35:16] d2.evaluation.evaluator INFO: Inference done 1193/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:31
[02/04 16:35:22] d2.evaluation.evaluator INFO: Inference done 1199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:25
[02/04 16:35:27] d2.evaluation.evaluator INFO: Inference done 1205/4952. Dataloading: 0.0007 s/iter. Inference: 0.9165 s/iter. Eval: 0.0008 s/iter. Total: 0.9181 s/iter. ETA=0:57:20
[02/04 16:35:33] d2.evaluation.evaluator INFO: Inference done 1211/4952. Dataloading: 0.0007 s/iter. Inference: 0.9168 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=0:57:15
[02/04 16:35:39] d2.evaluation.evaluator INFO: Inference done 1217/4952. Dataloading: 0.0007 s/iter. Inference: 0.9168 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=0:57:09
[02/04 16:35:44] d2.evaluation.evaluator INFO: Inference done 1223/4952. Dataloading: 0.0007 s/iter. Inference: 0.9167 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=0:57:04
[02/04 16:35:50] d2.evaluation.evaluator INFO: Inference done 1229/4952. Dataloading: 0.0007 s/iter. Inference: 0.9167 s/iter. Eval: 0.0008 s/iter. Total: 0.9183 s/iter. ETA=0:56:58
[02/04 16:35:55] d2.evaluation.evaluator INFO: Inference done 1235/4952. Dataloading: 0.0007 s/iter. Inference: 0.9169 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=0:56:53
[02/04 16:36:01] d2.evaluation.evaluator INFO: Inference done 1241/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=0:56:49
[02/04 16:36:07] d2.evaluation.evaluator INFO: Inference done 1247/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=0:56:44
[02/04 16:36:13] d2.evaluation.evaluator INFO: Inference done 1253/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=0:56:39
[02/04 16:36:19] d2.evaluation.evaluator INFO: Inference done 1259/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=0:56:34
[02/04 16:36:24] d2.evaluation.evaluator INFO: Inference done 1265/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=0:56:29
[02/04 16:36:30] d2.evaluation.evaluator INFO: Inference done 1271/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=0:56:23
[02/04 16:36:35] d2.evaluation.evaluator INFO: Inference done 1277/4952. Dataloading: 0.0007 s/iter. Inference: 0.9177 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=0:56:18
[02/04 16:36:40] d2.evaluation.evaluator INFO: Inference done 1283/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=0:56:12
[02/04 16:36:46] d2.evaluation.evaluator INFO: Inference done 1289/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=0:56:06
[02/04 16:36:51] d2.evaluation.evaluator INFO: Inference done 1295/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9192 s/iter. ETA=0:56:01
[02/04 16:36:57] d2.evaluation.evaluator INFO: Inference done 1301/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=0:55:55
[02/04 16:37:02] d2.evaluation.evaluator INFO: Inference done 1307/4952. Dataloading: 0.0007 s/iter. Inference: 0.9176 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=0:55:50
[02/04 16:37:08] d2.evaluation.evaluator INFO: Inference done 1313/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=0:55:44
[02/04 16:37:13] d2.evaluation.evaluator INFO: Inference done 1319/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=0:55:38
[02/04 16:37:19] d2.evaluation.evaluator INFO: Inference done 1325/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=0:55:33
[02/04 16:37:24] d2.evaluation.evaluator INFO: Inference done 1331/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=0:55:27
[02/04 16:37:30] d2.evaluation.evaluator INFO: Inference done 1337/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=0:55:21
[02/04 16:37:35] d2.evaluation.evaluator INFO: Inference done 1343/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9188 s/iter. ETA=0:55:16
[02/04 16:37:41] d2.evaluation.evaluator INFO: Inference done 1349/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9188 s/iter. ETA=0:55:10
[02/04 16:37:46] d2.evaluation.evaluator INFO: Inference done 1355/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=0:55:04
[02/04 16:37:51] d2.evaluation.evaluator INFO: Inference done 1361/4952. Dataloading: 0.0007 s/iter. Inference: 0.9171 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=0:54:59
[02/04 16:37:57] d2.evaluation.evaluator INFO: Inference done 1367/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=0:54:53
[02/04 16:38:02] d2.evaluation.evaluator INFO: Inference done 1373/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=0:54:47
[02/04 16:38:08] d2.evaluation.evaluator INFO: Inference done 1379/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=0:54:42
[02/04 16:38:13] d2.evaluation.evaluator INFO: Inference done 1385/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=0:54:36
[02/04 16:38:19] d2.evaluation.evaluator INFO: Inference done 1391/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9185 s/iter. ETA=0:54:30
[02/04 16:38:24] d2.evaluation.evaluator INFO: Inference done 1397/4952. Dataloading: 0.0007 s/iter. Inference: 0.9170 s/iter. Eval: 0.0008 s/iter. Total: 0.9186 s/iter. ETA=0:54:25
[02/04 16:38:30] d2.evaluation.evaluator INFO: Inference done 1403/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9187 s/iter. ETA=0:54:20
[02/04 16:38:36] d2.evaluation.evaluator INFO: Inference done 1409/4952. Dataloading: 0.0007 s/iter. Inference: 0.9172 s/iter. Eval: 0.0008 s/iter. Total: 0.9188 s/iter. ETA=0:54:15
[02/04 16:38:41] d2.evaluation.evaluator INFO: Inference done 1415/4952. Dataloading: 0.0007 s/iter. Inference: 0.9173 s/iter. Eval: 0.0008 s/iter. Total: 0.9189 s/iter. ETA=0:54:10
[02/04 16:38:47] d2.evaluation.evaluator INFO: Inference done 1421/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=0:54:04
[02/04 16:38:53] d2.evaluation.evaluator INFO: Inference done 1427/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=0:53:59
[02/04 16:38:58] d2.evaluation.evaluator INFO: Inference done 1433/4952. Dataloading: 0.0007 s/iter. Inference: 0.9174 s/iter. Eval: 0.0008 s/iter. Total: 0.9190 s/iter. ETA=0:53:53
[02/04 16:39:04] d2.evaluation.evaluator INFO: Inference done 1439/4952. Dataloading: 0.0007 s/iter. Inference: 0.9175 s/iter. Eval: 0.0008 s/iter. Total: 0.9191 s/iter. ETA=0:53:48
[02/04 16:39:10] d2.evaluation.evaluator INFO: Inference done 1445/4952. Dataloading: 0.0007 s/iter. Inference: 0.9178 s/iter. Eval: 0.0008 s/iter. Total: 0.9193 s/iter. ETA=0:53:44
[02/04 16:39:15] d2.evaluation.evaluator INFO: Inference done 1451/4952. Dataloading: 0.0007 s/iter. Inference: 0.9179 s/iter. Eval: 0.0008 s/iter. Total: 0.9195 s/iter. ETA=0:53:38
[02/04 16:39:21] d2.evaluation.evaluator INFO: Inference done 1457/4952. Dataloading: 0.0007 s/iter. Inference: 0.9181 s/iter. Eval: 0.0008 s/iter. Total: 0.9196 s/iter. ETA=0:53:34
[02/04 16:39:27] d2.evaluation.evaluator INFO: Inference done 1463/4952. Dataloading: 0.0007 s/iter. Inference: 0.9181 s/iter. Eval: 0.0008 s/iter. Total: 0.9197 s/iter. ETA=0:53:28
[02/04 16:39:32] d2.evaluation.evaluator INFO: Inference done 1469/4952. Dataloading: 0.0007 s/iter. Inference: 0.9183 s/iter. Eval: 0.0008 s/iter. Total: 0.9199 s/iter. ETA=0:53:23
[02/04 16:39:38] d2.evaluation.evaluator INFO: Inference done 1475/4952. Dataloading: 0.0007 s/iter. Inference: 0.9185 s/iter. Eval: 0.0008 s/iter. Total: 0.9200 s/iter. ETA=0:53:18
[02/04 16:39:44] d2.evaluation.evaluator INFO: Inference done 1481/4952. Dataloading: 0.0007 s/iter. Inference: 0.9185 s/iter. Eval: 0.0008 s/iter. Total: 0.9200 s/iter. ETA=0:53:13
[02/04 16:39:49] d2.evaluation.evaluator INFO: Inference done 1487/4952. Dataloading: 0.0007 s/iter. Inference: 0.9186 s/iter. Eval: 0.0008 s/iter. Total: 0.9201 s/iter. ETA=0:53:08
[02/04 16:39:55] d2.evaluation.evaluator INFO: Inference done 1493/4952. Dataloading: 0.0007 s/iter. Inference: 0.9187 s/iter. Eval: 0.0008 s/iter. Total: 0.9203 s/iter. ETA=0:53:03
[02/04 16:40:01] d2.evaluation.evaluator INFO: Inference done 1499/4952. Dataloading: 0.0007 s/iter. Inference: 0.9188 s/iter. Eval: 0.0008 s/iter. Total: 0.9203 s/iter. ETA=0:52:57
[02/04 16:40:06] d2.evaluation.evaluator INFO: Inference done 1505/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9204 s/iter. ETA=0:52:52
[02/04 16:40:12] d2.evaluation.evaluator INFO: Inference done 1511/4952. Dataloading: 0.0007 s/iter. Inference: 0.9188 s/iter. Eval: 0.0008 s/iter. Total: 0.9204 s/iter. ETA=0:52:47
[02/04 16:40:17] d2.evaluation.evaluator INFO: Inference done 1517/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9204 s/iter. ETA=0:52:41
[02/04 16:40:23] d2.evaluation.evaluator INFO: Inference done 1523/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9205 s/iter. ETA=0:52:36
[02/04 16:40:29] d2.evaluation.evaluator INFO: Inference done 1529/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9205 s/iter. ETA=0:52:30
[02/04 16:40:34] d2.evaluation.evaluator INFO: Inference done 1535/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9204 s/iter. ETA=0:52:25
[02/04 16:40:40] d2.evaluation.evaluator INFO: Inference done 1541/4952. Dataloading: 0.0007 s/iter. Inference: 0.9189 s/iter. Eval: 0.0008 s/iter. Total: 0.9205 s/iter. ETA=0:52:19
[02/04 16:40:45] d2.evaluation.evaluator INFO: Inference done 1547/4952. Dataloading: 0.0007 s/iter. Inference: 0.9190 s/iter. Eval: 0.0008 s/iter. Total: 0.9205 s/iter. ETA=0:52:14
[02/04 16:40:51] d2.evaluation.evaluator INFO: Inference done 1553/4952. Dataloading: 0.0007 s/iter. Inference: 0.9190 s/iter. Eval: 0.0008 s/iter. Total: 0.9205 s/iter. ETA=0:52:08
[02/04 16:40:56] d2.evaluation.evaluator INFO: Inference done 1559/4952. Dataloading: 0.0007 s/iter. Inference: 0.9191 s/iter. Eval: 0.0008 s/iter. Total: 0.9206 s/iter. ETA=0:52:03
[02/04 16:41:02] d2.evaluation.evaluator INFO: Inference done 1565/4952. Dataloading: 0.0007 s/iter. Inference: 0.9192 s/iter. Eval: 0.0008 s/iter. Total: 0.9208 s/iter. ETA=0:51:58
[02/04 16:41:08] d2.evaluation.evaluator INFO: Inference done 1571/4952. Dataloading: 0.0007 s/iter. Inference: 0.9192 s/iter. Eval: 0.0008 s/iter. Total: 0.9208 s/iter. ETA=0:51:53
[02/04 16:41:13] d2.evaluation.evaluator INFO: Inference done 1577/4952. Dataloading: 0.0007 s/iter. Inference: 0.9192 s/iter. Eval: 0.0008 s/iter. Total: 0.9208 s/iter. ETA=0:51:47
[02/04 16:41:19] d2.evaluation.evaluator INFO: Inference done 1583/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9208 s/iter. ETA=0:51:42
[02/04 16:41:24] d2.evaluation.evaluator INFO: Inference done 1589/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:36
[02/04 16:41:30] d2.evaluation.evaluator INFO: Inference done 1595/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:31
[02/04 16:41:35] d2.evaluation.evaluator INFO: Inference done 1601/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:25
[02/04 16:41:41] d2.evaluation.evaluator INFO: Inference done 1607/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:20
[02/04 16:41:46] d2.evaluation.evaluator INFO: Inference done 1613/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:14
[02/04 16:41:52] d2.evaluation.evaluator INFO: Inference done 1619/4952. Dataloading: 0.0007 s/iter. Inference: 0.9193 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:09
[02/04 16:41:58] d2.evaluation.evaluator INFO: Inference done 1625/4952. Dataloading: 0.0007 s/iter. Inference: 0.9194 s/iter. Eval: 0.0008 s/iter. Total: 0.9209 s/iter. ETA=0:51:03
[02/04 16:42:03] d2.evaluation.evaluator INFO: Inference done 1631/4952. Dataloading: 0.0007 s/iter. Inference: 0.9194 s/iter. Eval: 0.0008 s/iter. Total: 0.9210 s/iter. ETA=0:50:58
[02/04 16:42:09] d2.evaluation.evaluator INFO: Inference done 1637/4952. Dataloading: 0.0007 s/iter. Inference: 0.9196 s/iter. Eval: 0.0008 s/iter. Total: 0.9211 s/iter. ETA=0:50:53
[02/04 16:42:15] d2.evaluation.evaluator INFO: Inference done 1643/4952. Dataloading: 0.0007 s/iter. Inference: 0.9197 s/iter. Eval: 0.0008 s/iter. Total: 0.9213 s/iter. ETA=0:50:48
[02/04 16:42:20] d2.evaluation.evaluator INFO: Inference done 1649/4952. Dataloading: 0.0007 s/iter. Inference: 0.9198 s/iter. Eval: 0.0008 s/iter. Total: 0.9214 s/iter. ETA=0:50:43
[02/04 16:42:26] d2.evaluation.evaluator INFO: Inference done 1655/4952. Dataloading: 0.0007 s/iter. Inference: 0.9198 s/iter. Eval: 0.0008 s/iter. Total: 0.9213 s/iter. ETA=0:50:37
[02/04 16:42:32] d2.evaluation.evaluator INFO: Inference done 1661/4952. Dataloading: 0.0007 s/iter. Inference: 0.9198 s/iter. Eval: 0.0008 s/iter. Total: 0.9214 s/iter. ETA=0:50:32
[02/04 16:42:37] d2.evaluation.evaluator INFO: Inference done 1667/4952. Dataloading: 0.0007 s/iter. Inference: 0.9198 s/iter. Eval: 0.0008 s/iter. Total: 0.9214 s/iter. ETA=0:50:26
[02/04 16:42:43] d2.evaluation.evaluator INFO: Inference done 1673/4952. Dataloading: 0.0007 s/iter. Inference: 0.9199 s/iter. Eval: 0.0008 s/iter. Total: 0.9215 s/iter. ETA=0:50:21
[02/04 16:42:48] d2.evaluation.evaluator INFO: Inference done 1679/4952. Dataloading: 0.0007 s/iter. Inference: 0.9199 s/iter. Eval: 0.0008 s/iter. Total: 0.9214 s/iter. ETA=0:50:15
[02/04 16:42:54] d2.evaluation.evaluator INFO: Inference done 1685/4952. Dataloading: 0.0007 s/iter. Inference: 0.9199 s/iter. Eval: 0.0008 s/iter. Total: 0.9215 s/iter. ETA=0:50:10
[02/04 16:42:59] d2.evaluation.evaluator INFO: Inference done 1691/4952. Dataloading: 0.0007 s/iter. Inference: 0.9199 s/iter. Eval: 0.0008 s/iter. Total: 0.9215 s/iter. ETA=0:50:04
[02/04 16:46:08] detectron2 INFO: Rank of current process: 0. World size: 1
[02/04 16:46:09] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/04 16:46:09] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/04 16:46:09] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)  
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/04 16:46:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/04 16:46:09] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/04 16:46:09] d2.utils.env INFO: Using a generated random seed 9433290
[02/04 16:46:12] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/04 16:46:13] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/04 16:46:13] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/04 16:46:14] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/04 16:46:14] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/04 16:46:14] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/04 16:46:14] FCT.data.build INFO: Using training sampler TrainingSampler
[02/04 16:46:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/04 16:46:14] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/04 16:46:14] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/04 16:46:14] d2.engine.train_loop INFO: Starting training from iteration 0
[02/04 16:46:27] d2.engine.hooks INFO: Overall training speed: 6 iterations in 0:00:08 (1.4636 s / it)
[02/04 16:46:27] d2.engine.hooks INFO: Total training time: 0:00:08 (0:00:00 on hooks)
[02/04 16:46:27] d2.utils.events INFO:  eta: 3:27:49  iter: 8  total_loss: 1.032  loss_cls: 0.8262  loss_box_reg: 0.1024  loss_rpn_cls: 0.06718  loss_rpn_loc: 0.004281  time: 1.2573  data_time: 0.0529  lr: 2.252e-06  max_mem: 18960M
[02/04 16:46:49] detectron2 INFO: Rank of current process: 0. World size: 1
[02/04 16:46:49] detectron2 INFO: Environment info:
----------------------  --------------------------------------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.5
detectron2              0.6 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          510.108.03
CUDA_HOME               /usr/local/cuda - invalid!
Pillow                  8.3.2
torchvision             0.11.0 @/home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision
torchvision arch flags  /home/rmedu/miniconda3/envs/fct/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.4.0
----------------------  --------------------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/04 16:46:49] detectron2 INFO: Command line arguments: Namespace(config_file='configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '2'], resume=False)
[02/04 16:46:49] detectron2 INFO: Contents of args.config_file=configs/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  PIXEL_MEAN: [103.530, 116.280, 123.675]
  PIXEL_STD: [57.375, 57.120, 58.395]
  WEIGHTS: "./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 1
    NAME: "build_FCT_backbone"
    TYPE: "pvt_v2_b2_li"
  ROI_HEADS:
    SCORE_THRESH_TEST: 0.0
  RPN:
    PRE_NMS_TOPK_TEST: 12000
    POST_NMS_TOPK_TEST: 100
OUTPUT_DIR: './output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li'
DATASETS:
  TRAIN: ("voc_2007_trainval_base1", "voc_2012_trainval_base1")
  TEST: ("voc_2007_test_all1",)
  TEST_KEEPCLASSES: 'all1'
  TEST_SHOTS: (1,2,3,5)
INPUT:
  FS:
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 10
  MIN_SIZE_TRAIN: (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.00002
  STEPS: (7500, 9999)  
  MAX_ITER: 10000
  WARMUP_ITERS: 500
  WARMUP_FACTOR: 0.1
  CHECKPOINT_PERIOD: 10000
  HEAD_LR_FACTOR: 2.0
TEST:
  EVAL_PERIOD: 10000

[02/04 16:46:49] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  SEEDS: 0
  TEST:
  - voc_2007_test_all1
  TEST_KEEPCLASSES: all1
  TEST_SHOTS:
  - 1
  - 2
  - 3
  - 5
  TRAIN:
  - voc_2007_trainval_base1
  - voc_2012_trainval_base1
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: false
    SUPPORT_EXCLUDE_QUERY: false
    SUPPORT_SHOT: 10
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 200
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN:
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  - 100
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 1
    NAME: build_FCT_backbone
    ONLY_TRAIN_NORM: false
    TRAIN_BRANCH_EMBED: true
    TYPE: pvt_v2_b2_li
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 57.375
  - 57.12
  - 58.395
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id001
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    FREEZE_ROI_FEATURE_EXTRACTOR: false
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    ONLY_TRAIN_NORM: false
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.0
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    FREEZE_RPN: false
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 12000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
OUTPUT_DIR: ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 2.0e-05
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 2
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 10000
  MOMENTUM: 0.9
  NESTEROV: false
  REFERENCE_WORLD_SIZE: 0
  SOLVER_TYPE: adamw
  STEPS:
  - 7500
  - 9999
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[02/04 16:46:49] detectron2 INFO: Full config saved to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/config.yaml
[02/04 16:46:49] d2.utils.env INFO: Using a generated random seed 49726503
[02/04 16:46:52] d2.engine.defaults INFO: Model:
FsodRCNN(
  (backbone): pvt_v2_b2_li(
    (branch_embed1): Embedding(2, 64)
    (patch_embed1): OverlapPatchEmbed(
      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (block1): ModuleList(
      (0): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): Identity()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=64, out_features=64, bias=True)
          (kv): Linear(in_features=64, out_features=128, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=64, out_features=64, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=64, out_features=512, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
          )
          (act): GELU()
          (fc2): Linear(in_features=512, out_features=64, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
    (branch_embed2): Embedding(2, 128)
    (patch_embed2): OverlapPatchEmbed(
      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (block2): ModuleList(
      (0): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=128, out_features=128, bias=True)
          (kv): Linear(in_features=128, out_features=256, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=128, out_features=128, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=128, out_features=1024, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
          )
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=128, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
    (branch_embed3): Embedding(2, 320)
    (patch_embed3): OverlapPatchEmbed(
      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
    )
    (block3): ModuleList(
      (0): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (3): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (4): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Block(
        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=320, out_features=320, bias=True)
          (kv): Linear(in_features=320, out_features=640, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=320, out_features=320, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=320, out_features=1280, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
          )
          (act): GELU()
          (fc2): Linear(in_features=1280, out_features=320, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(320, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(320, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (branch_embed4): Embedding(2, 512)
    (patch_embed4): OverlapPatchEmbed(
      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
    (block4): ModuleList(
      (0): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (1): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
      (2): Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (q): Linear(in_features=512, out_features=512, bias=True)
          (kv): Linear(in_features=512, out_features=1024, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (pool): AdaptiveAvgPool2d(output_size=7)
          (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (act): GELU()
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (dwconv): DWConv(
            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
          )
          (act): GELU()
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=512, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=512, out_features=2, bias=True)
      (conv_cor): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=512, out_features=2, bias=True)
      (fc_1): Linear(in_features=1024, out_features=512, bias=True)
      (fc_2): Linear(in_features=512, out_features=512, bias=True)
      (cls_score_fc): Linear(in_features=512, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[02/04 16:46:53] d2.data.build INFO: Removed 1997 images with no usable annotations. 14554 images left.
[02/04 16:46:54] d2.data.build INFO: Removed 0 images with no usable annotations. 20335 images left.
[02/04 16:46:54] d2.data.build INFO: Distribution of instances among all 15 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 1171         |   bicycle   | 1064         |    boat     | 1140         |
|   bottle   | 1764         |     car     | 3267         |     cat     | 1593         |
|   chair    | 3152         | diningtable | 824          |     dog     | 2025         |
|   horse    | 1072         |   person    | 13256        | pottedplant | 1487         |
|   sheep    | 1070         |    train    | 925          |  tvmonitor  | 1108         |
|            |              |             |              |             |              |
|   total    | 34918        |             |              |             |              |
[02/04 16:46:54] d2.data.common INFO: Serializing 20335 elements to byte tensors and concatenating them all ...
[02/04 16:46:54] d2.data.common INFO: Serialized dataset takes 11.86 MiB
[02/04 16:46:54] FCT.data.build INFO: Using training sampler TrainingSampler
[02/04 16:46:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./output/fsod/single_branch_pretraining_pascalvoc_split1_pvt_v2_b2_li/model_final.pth ...
[02/04 16:46:54] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.branch_embed1.weight
backbone.branch_embed2.weight
backbone.branch_embed3.weight
roi_heads.box_predictor.bbox_pred_pr.{bias, weight}
roi_heads.box_predictor.cls_score_cor.{bias, weight}
roi_heads.box_predictor.cls_score_fc.{bias, weight}
roi_heads.box_predictor.cls_score_pr.{bias, weight}
roi_heads.box_predictor.conv_1.weight
roi_heads.box_predictor.conv_2.weight
roi_heads.box_predictor.conv_3.weight
roi_heads.box_predictor.conv_cor.weight
roi_heads.box_predictor.fc_1.{bias, weight}
roi_heads.box_predictor.fc_2.{bias, weight}
roi_heads.branch_embed4.weight
[02/04 16:46:54] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  roi_heads.box_predictor.cls_score.{bias, weight}
  roi_heads.box_predictor.bbox_pred.{bias, weight}
[02/04 16:46:54] d2.engine.train_loop INFO: Starting training from iteration 0
[02/04 16:47:21] d2.utils.events INFO:  eta: 3:28:45  iter: 19  total_loss: 1.011  loss_cls: 0.7957  loss_box_reg: 0.1036  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.004864  time: 1.2581  data_time: 0.0267  lr: 2.684e-06  max_mem: 19010M
[02/04 16:47:46] d2.utils.events INFO:  eta: 3:29:34  iter: 39  total_loss: 0.8844  loss_cls: 0.6872  loss_box_reg: 0.1227  loss_rpn_cls: 0.06792  loss_rpn_loc: 0.006221  time: 1.2667  data_time: 0.0070  lr: 3.404e-06  max_mem: 19010M
[02/04 16:48:12] d2.utils.events INFO:  eta: 3:29:23  iter: 59  total_loss: 0.8954  loss_cls: 0.6498  loss_box_reg: 0.132  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.006201  time: 1.2671  data_time: 0.0069  lr: 4.124e-06  max_mem: 19010M
[02/04 16:48:37] d2.utils.events INFO:  eta: 3:29:01  iter: 79  total_loss: 0.8096  loss_cls: 0.6503  loss_box_reg: 0.1028  loss_rpn_cls: 0.04387  loss_rpn_loc: 0.006451  time: 1.2688  data_time: 0.0069  lr: 4.844e-06  max_mem: 19010M
[02/04 16:49:03] d2.utils.events INFO:  eta: 3:28:28  iter: 99  total_loss: 0.7868  loss_cls: 0.6137  loss_box_reg: 0.1192  loss_rpn_cls: 0.05229  loss_rpn_loc: 0.006196  time: 1.2677  data_time: 0.0069  lr: 5.564e-06  max_mem: 19010M
[02/04 16:49:28] d2.utils.events INFO:  eta: 3:28:18  iter: 119  total_loss: 0.7752  loss_cls: 0.5936  loss_box_reg: 0.1108  loss_rpn_cls: 0.05586  loss_rpn_loc: 0.007376  time: 1.2703  data_time: 0.0071  lr: 6.284e-06  max_mem: 19010M
[02/04 16:49:54] d2.utils.events INFO:  eta: 3:28:00  iter: 139  total_loss: 0.7847  loss_cls: 0.5847  loss_box_reg: 0.1421  loss_rpn_cls: 0.0478  loss_rpn_loc: 0.005028  time: 1.2704  data_time: 0.0070  lr: 7.004e-06  max_mem: 19010M
[02/04 16:50:19] d2.utils.events INFO:  eta: 3:27:43  iter: 159  total_loss: 0.7999  loss_cls: 0.6067  loss_box_reg: 0.1079  loss_rpn_cls: 0.04612  loss_rpn_loc: 0.007203  time: 1.2715  data_time: 0.0070  lr: 7.724e-06  max_mem: 19010M
[02/04 16:50:45] d2.utils.events INFO:  eta: 3:27:18  iter: 179  total_loss: 0.7793  loss_cls: 0.5821  loss_box_reg: 0.138  loss_rpn_cls: 0.04691  loss_rpn_loc: 0.005526  time: 1.2711  data_time: 0.0070  lr: 8.444e-06  max_mem: 19010M
[02/04 16:51:10] d2.utils.events INFO:  eta: 3:26:48  iter: 199  total_loss: 0.7536  loss_cls: 0.5903  loss_box_reg: 0.1117  loss_rpn_cls: 0.03996  loss_rpn_loc: 0.00531  time: 1.2709  data_time: 0.0070  lr: 9.164e-06  max_mem: 19010M
[02/04 16:51:36] d2.utils.events INFO:  eta: 3:26:18  iter: 219  total_loss: 0.7506  loss_cls: 0.5869  loss_box_reg: 0.1045  loss_rpn_cls: 0.04704  loss_rpn_loc: 0.006372  time: 1.2705  data_time: 0.0073  lr: 9.884e-06  max_mem: 19010M
[02/04 16:52:01] d2.utils.events INFO:  eta: 3:25:48  iter: 239  total_loss: 0.6995  loss_cls: 0.5532  loss_box_reg: 0.05858  loss_rpn_cls: 0.03076  loss_rpn_loc: 0.003449  time: 1.2698  data_time: 0.0071  lr: 1.0604e-05  max_mem: 19010M
[02/04 16:52:26] d2.utils.events INFO:  eta: 3:25:24  iter: 259  total_loss: 0.7361  loss_cls: 0.5605  loss_box_reg: 0.1002  loss_rpn_cls: 0.0392  loss_rpn_loc: 0.004003  time: 1.2698  data_time: 0.0071  lr: 1.1324e-05  max_mem: 19010M
[02/04 16:52:52] d2.utils.events INFO:  eta: 3:24:58  iter: 279  total_loss: 0.7286  loss_cls: 0.5514  loss_box_reg: 0.1327  loss_rpn_cls: 0.04242  loss_rpn_loc: 0.004259  time: 1.2697  data_time: 0.0073  lr: 1.2044e-05  max_mem: 19010M
[02/04 16:53:17] d2.utils.events INFO:  eta: 3:24:33  iter: 299  total_loss: 0.6864  loss_cls: 0.5696  loss_box_reg: 0.08426  loss_rpn_cls: 0.0355  loss_rpn_loc: 0.003329  time: 1.2699  data_time: 0.0073  lr: 1.2764e-05  max_mem: 19010M
[02/04 16:53:43] d2.utils.events INFO:  eta: 3:24:08  iter: 319  total_loss: 0.7396  loss_cls: 0.565  loss_box_reg: 0.12  loss_rpn_cls: 0.03857  loss_rpn_loc: 0.004798  time: 1.2697  data_time: 0.0074  lr: 1.3484e-05  max_mem: 19010M
[02/04 16:54:08] d2.utils.events INFO:  eta: 3:23:43  iter: 339  total_loss: 0.7272  loss_cls: 0.5705  loss_box_reg: 0.1211  loss_rpn_cls: 0.02933  loss_rpn_loc: 0.004377  time: 1.2697  data_time: 0.0072  lr: 1.4204e-05  max_mem: 19010M
[02/04 16:54:34] d2.utils.events INFO:  eta: 3:23:22  iter: 359  total_loss: 0.7128  loss_cls: 0.5584  loss_box_reg: 0.1013  loss_rpn_cls: 0.04835  loss_rpn_loc: 0.00635  time: 1.2697  data_time: 0.0077  lr: 1.4924e-05  max_mem: 19010M
[02/04 16:54:59] d2.utils.events INFO:  eta: 3:22:58  iter: 379  total_loss: 0.6683  loss_cls: 0.5313  loss_box_reg: 0.1066  loss_rpn_cls: 0.03368  loss_rpn_loc: 0.002869  time: 1.2701  data_time: 0.0078  lr: 1.5644e-05  max_mem: 19010M
[02/04 16:55:25] d2.utils.events INFO:  eta: 3:22:36  iter: 399  total_loss: 0.6997  loss_cls: 0.5542  loss_box_reg: 0.1195  loss_rpn_cls: 0.03137  loss_rpn_loc: 0.004887  time: 1.2705  data_time: 0.0071  lr: 1.6364e-05  max_mem: 19010M
[02/04 16:55:50] d2.utils.events INFO:  eta: 3:22:08  iter: 419  total_loss: 0.671  loss_cls: 0.5447  loss_box_reg: 0.09813  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.002584  time: 1.2704  data_time: 0.0071  lr: 1.7084e-05  max_mem: 19010M
[02/04 16:56:16] d2.utils.events INFO:  eta: 3:21:45  iter: 439  total_loss: 0.6978  loss_cls: 0.5276  loss_box_reg: 0.1002  loss_rpn_cls: 0.03563  loss_rpn_loc: 0.003269  time: 1.2705  data_time: 0.0077  lr: 1.7804e-05  max_mem: 19010M
[02/04 16:56:41] d2.utils.events INFO:  eta: 3:21:19  iter: 459  total_loss: 0.6579  loss_cls: 0.514  loss_box_reg: 0.1066  loss_rpn_cls: 0.03508  loss_rpn_loc: 0.006742  time: 1.2704  data_time: 0.0072  lr: 1.8524e-05  max_mem: 19010M
[02/04 16:57:07] d2.utils.events INFO:  eta: 3:20:54  iter: 479  total_loss: 0.6622  loss_cls: 0.4877  loss_box_reg: 0.1196  loss_rpn_cls: 0.03422  loss_rpn_loc: 0.004307  time: 1.2706  data_time: 0.0071  lr: 1.9244e-05  max_mem: 19010M
[02/04 16:57:32] d2.utils.events INFO:  eta: 3:20:30  iter: 499  total_loss: 0.6867  loss_cls: 0.5116  loss_box_reg: 0.1168  loss_rpn_cls: 0.02532  loss_rpn_loc: 0.003357  time: 1.2707  data_time: 0.0073  lr: 1.9964e-05  max_mem: 19010M
[02/04 16:57:58] d2.utils.events INFO:  eta: 3:20:06  iter: 519  total_loss: 0.6572  loss_cls: 0.4812  loss_box_reg: 0.1047  loss_rpn_cls: 0.02711  loss_rpn_loc: 0.002668  time: 1.2709  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/04 16:58:23] d2.utils.events INFO:  eta: 3:19:41  iter: 539  total_loss: 0.6383  loss_cls: 0.516  loss_box_reg: 0.1018  loss_rpn_cls: 0.02485  loss_rpn_loc: 0.002596  time: 1.2708  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/04 16:58:49] d2.utils.events INFO:  eta: 3:19:18  iter: 559  total_loss: 0.6155  loss_cls: 0.4847  loss_box_reg: 0.1184  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.003329  time: 1.2710  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 16:59:15] d2.utils.events INFO:  eta: 3:18:53  iter: 579  total_loss: 0.7118  loss_cls: 0.4861  loss_box_reg: 0.141  loss_rpn_cls: 0.02738  loss_rpn_loc: 0.004313  time: 1.2712  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 16:59:40] d2.utils.events INFO:  eta: 3:18:28  iter: 599  total_loss: 0.6776  loss_cls: 0.5153  loss_box_reg: 0.1013  loss_rpn_cls: 0.029  loss_rpn_loc: 0.004049  time: 1.2713  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:00:06] d2.utils.events INFO:  eta: 3:18:03  iter: 619  total_loss: 0.625  loss_cls: 0.4928  loss_box_reg: 0.102  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.003495  time: 1.2713  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:00:31] d2.utils.events INFO:  eta: 3:17:37  iter: 639  total_loss: 0.6585  loss_cls: 0.5093  loss_box_reg: 0.1181  loss_rpn_cls: 0.02747  loss_rpn_loc: 0.003665  time: 1.2712  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:00:56] d2.utils.events INFO:  eta: 3:17:12  iter: 659  total_loss: 0.6679  loss_cls: 0.5055  loss_box_reg: 0.1249  loss_rpn_cls: 0.02247  loss_rpn_loc: 0.002695  time: 1.2710  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:01:22] d2.utils.events INFO:  eta: 3:16:47  iter: 679  total_loss: 0.6615  loss_cls: 0.4773  loss_box_reg: 0.1279  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.003806  time: 1.2713  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:01:47] d2.utils.events INFO:  eta: 3:16:21  iter: 699  total_loss: 0.6294  loss_cls: 0.4857  loss_box_reg: 0.09395  loss_rpn_cls: 0.02429  loss_rpn_loc: 0.002981  time: 1.2713  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:02:13] d2.utils.events INFO:  eta: 3:15:56  iter: 719  total_loss: 0.5851  loss_cls: 0.4585  loss_box_reg: 0.09465  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.003165  time: 1.2712  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:02:38] d2.utils.events INFO:  eta: 3:15:31  iter: 739  total_loss: 0.6361  loss_cls: 0.489  loss_box_reg: 0.08342  loss_rpn_cls: 0.02346  loss_rpn_loc: 0.002935  time: 1.2713  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:03:04] d2.utils.events INFO:  eta: 3:15:07  iter: 759  total_loss: 0.6269  loss_cls: 0.4636  loss_box_reg: 0.138  loss_rpn_cls: 0.02619  loss_rpn_loc: 0.003783  time: 1.2714  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:03:29] d2.utils.events INFO:  eta: 3:14:41  iter: 779  total_loss: 0.6289  loss_cls: 0.4957  loss_box_reg: 0.0885  loss_rpn_cls: 0.02041  loss_rpn_loc: 0.003166  time: 1.2714  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:03:55] d2.utils.events INFO:  eta: 3:14:15  iter: 799  total_loss: 0.6407  loss_cls: 0.496  loss_box_reg: 0.08214  loss_rpn_cls: 0.02934  loss_rpn_loc: 0.003175  time: 1.2712  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:04:20] d2.utils.events INFO:  eta: 3:13:50  iter: 819  total_loss: 0.6318  loss_cls: 0.4918  loss_box_reg: 0.1005  loss_rpn_cls: 0.02381  loss_rpn_loc: 0.004188  time: 1.2713  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:04:46] d2.utils.events INFO:  eta: 3:13:25  iter: 839  total_loss: 0.6289  loss_cls: 0.4224  loss_box_reg: 0.1445  loss_rpn_cls: 0.02345  loss_rpn_loc: 0.002515  time: 1.2715  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:05:11] d2.utils.events INFO:  eta: 3:13:00  iter: 859  total_loss: 0.5993  loss_cls: 0.4196  loss_box_reg: 0.1312  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.003079  time: 1.2714  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:05:37] d2.utils.events INFO:  eta: 3:12:37  iter: 879  total_loss: 0.5851  loss_cls: 0.4432  loss_box_reg: 0.1218  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.002601  time: 1.2714  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:06:02] d2.utils.events INFO:  eta: 3:12:11  iter: 899  total_loss: 0.653  loss_cls: 0.4945  loss_box_reg: 0.115  loss_rpn_cls: 0.02343  loss_rpn_loc: 0.004249  time: 1.2714  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:06:28] d2.utils.events INFO:  eta: 3:11:46  iter: 919  total_loss: 0.6585  loss_cls: 0.4867  loss_box_reg: 0.1261  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.002613  time: 1.2713  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:06:53] d2.utils.events INFO:  eta: 3:11:22  iter: 939  total_loss: 0.6565  loss_cls: 0.527  loss_box_reg: 0.1053  loss_rpn_cls: 0.02393  loss_rpn_loc: 0.003141  time: 1.2713  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:07:19] d2.utils.events INFO:  eta: 3:10:56  iter: 959  total_loss: 0.6209  loss_cls: 0.4881  loss_box_reg: 0.1057  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.004506  time: 1.2713  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/04 17:07:44] d2.utils.events INFO:  eta: 3:10:29  iter: 979  total_loss: 0.6597  loss_cls: 0.4835  loss_box_reg: 0.1335  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.002752  time: 1.2712  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:08:09] d2.utils.events INFO:  eta: 3:10:03  iter: 999  total_loss: 0.6395  loss_cls: 0.4952  loss_box_reg: 0.138  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.002944  time: 1.2712  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:08:35] d2.utils.events INFO:  eta: 3:09:39  iter: 1019  total_loss: 0.6247  loss_cls: 0.4585  loss_box_reg: 0.09198  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.003817  time: 1.2711  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:09:00] d2.utils.events INFO:  eta: 3:09:13  iter: 1039  total_loss: 0.6222  loss_cls: 0.5025  loss_box_reg: 0.103  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.003026  time: 1.2711  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/04 17:09:26] d2.utils.events INFO:  eta: 3:08:47  iter: 1059  total_loss: 0.6732  loss_cls: 0.518  loss_box_reg: 0.1032  loss_rpn_cls: 0.01793  loss_rpn_loc: 0.003081  time: 1.2711  data_time: 0.0072  lr: 2e-05  max_mem: 19010M
[02/04 17:09:51] d2.utils.events INFO:  eta: 3:08:22  iter: 1079  total_loss: 0.6268  loss_cls: 0.517  loss_box_reg: 0.1013  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.003389  time: 1.2711  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:10:17] d2.utils.events INFO:  eta: 3:07:59  iter: 1099  total_loss: 0.6276  loss_cls: 0.4792  loss_box_reg: 0.129  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.00313  time: 1.2712  data_time: 0.0071  lr: 2e-05  max_mem: 19010M
[02/04 17:10:42] d2.utils.events INFO:  eta: 3:07:34  iter: 1119  total_loss: 0.634  loss_cls: 0.473  loss_box_reg: 0.1315  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.003478  time: 1.2712  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:11:08] d2.utils.events INFO:  eta: 3:07:08  iter: 1139  total_loss: 0.633  loss_cls: 0.4569  loss_box_reg: 0.1189  loss_rpn_cls: 0.01943  loss_rpn_loc: 0.003698  time: 1.2713  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:11:33] d2.utils.events INFO:  eta: 3:06:43  iter: 1159  total_loss: 0.6744  loss_cls: 0.5041  loss_box_reg: 0.1162  loss_rpn_cls: 0.02127  loss_rpn_loc: 0.003713  time: 1.2714  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:11:59] d2.utils.events INFO:  eta: 3:06:19  iter: 1179  total_loss: 0.6507  loss_cls: 0.4535  loss_box_reg: 0.1711  loss_rpn_cls: 0.02228  loss_rpn_loc: 0.004353  time: 1.2714  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:12:24] d2.utils.events INFO:  eta: 3:05:53  iter: 1199  total_loss: 0.6161  loss_cls: 0.4656  loss_box_reg: 0.134  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.004005  time: 1.2714  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:12:50] d2.utils.events INFO:  eta: 3:05:29  iter: 1219  total_loss: 0.6293  loss_cls: 0.4819  loss_box_reg: 0.11  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.003598  time: 1.2714  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:13:15] d2.utils.events INFO:  eta: 3:05:04  iter: 1239  total_loss: 0.6507  loss_cls: 0.4559  loss_box_reg: 0.1391  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.002941  time: 1.2715  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:13:41] d2.utils.events INFO:  eta: 3:04:39  iter: 1259  total_loss: 0.6249  loss_cls: 0.4824  loss_box_reg: 0.09842  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.0034  time: 1.2715  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:14:07] d2.utils.events INFO:  eta: 3:04:15  iter: 1279  total_loss: 0.5887  loss_cls: 0.4149  loss_box_reg: 0.1728  loss_rpn_cls: 0.01864  loss_rpn_loc: 0.003195  time: 1.2717  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:14:32] d2.utils.events INFO:  eta: 3:03:50  iter: 1299  total_loss: 0.6738  loss_cls: 0.473  loss_box_reg: 0.1139  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.003321  time: 1.2716  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:14:58] d2.utils.events INFO:  eta: 3:03:24  iter: 1319  total_loss: 0.6923  loss_cls: 0.4356  loss_box_reg: 0.166  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.005179  time: 1.2716  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:15:23] d2.utils.events INFO:  eta: 3:02:59  iter: 1339  total_loss: 0.5837  loss_cls: 0.3995  loss_box_reg: 0.1464  loss_rpn_cls: 0.02051  loss_rpn_loc: 0.003233  time: 1.2716  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:15:49] d2.utils.events INFO:  eta: 3:02:34  iter: 1359  total_loss: 0.6113  loss_cls: 0.5023  loss_box_reg: 0.08627  loss_rpn_cls: 0.02108  loss_rpn_loc: 0.003593  time: 1.2717  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:16:14] d2.utils.events INFO:  eta: 3:02:08  iter: 1379  total_loss: 0.5977  loss_cls: 0.3726  loss_box_reg: 0.1526  loss_rpn_cls: 0.01695  loss_rpn_loc: 0.003122  time: 1.2717  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:16:40] d2.utils.events INFO:  eta: 3:01:41  iter: 1399  total_loss: 0.6245  loss_cls: 0.4208  loss_box_reg: 0.1169  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.005105  time: 1.2717  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:17:05] d2.utils.events INFO:  eta: 3:01:16  iter: 1419  total_loss: 0.6079  loss_cls: 0.4409  loss_box_reg: 0.1333  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.00457  time: 1.2718  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:17:31] d2.utils.events INFO:  eta: 3:00:52  iter: 1439  total_loss: 0.6096  loss_cls: 0.4561  loss_box_reg: 0.1287  loss_rpn_cls: 0.02202  loss_rpn_loc: 0.003465  time: 1.2719  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:17:56] d2.utils.events INFO:  eta: 3:00:27  iter: 1459  total_loss: 0.5933  loss_cls: 0.4375  loss_box_reg: 0.1409  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.003519  time: 1.2718  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:18:22] d2.utils.events INFO:  eta: 3:00:01  iter: 1479  total_loss: 0.6367  loss_cls: 0.4864  loss_box_reg: 0.1085  loss_rpn_cls: 0.01823  loss_rpn_loc: 0.003332  time: 1.2718  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:18:47] d2.utils.events INFO:  eta: 2:59:36  iter: 1499  total_loss: 0.5769  loss_cls: 0.4239  loss_box_reg: 0.1308  loss_rpn_cls: 0.0179  loss_rpn_loc: 0.002799  time: 1.2718  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:19:13] d2.utils.events INFO:  eta: 2:59:10  iter: 1519  total_loss: 0.6536  loss_cls: 0.4932  loss_box_reg: 0.1317  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.004934  time: 1.2717  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:19:38] d2.utils.events INFO:  eta: 2:58:46  iter: 1539  total_loss: 0.6396  loss_cls: 0.5101  loss_box_reg: 0.1051  loss_rpn_cls: 0.01822  loss_rpn_loc: 0.003492  time: 1.2718  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:20:04] d2.utils.events INFO:  eta: 2:58:20  iter: 1559  total_loss: 0.6182  loss_cls: 0.4752  loss_box_reg: 0.1056  loss_rpn_cls: 0.01988  loss_rpn_loc: 0.004044  time: 1.2717  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:20:29] d2.utils.events INFO:  eta: 2:57:53  iter: 1579  total_loss: 0.5384  loss_cls: 0.3784  loss_box_reg: 0.1052  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.002934  time: 1.2717  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:20:55] d2.utils.events INFO:  eta: 2:57:28  iter: 1599  total_loss: 0.5709  loss_cls: 0.452  loss_box_reg: 0.09812  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.002844  time: 1.2716  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:21:20] d2.utils.events INFO:  eta: 2:57:03  iter: 1619  total_loss: 0.6065  loss_cls: 0.4541  loss_box_reg: 0.105  loss_rpn_cls: 0.01932  loss_rpn_loc: 0.004653  time: 1.2716  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:21:46] d2.utils.events INFO:  eta: 2:56:38  iter: 1639  total_loss: 0.6136  loss_cls: 0.3989  loss_box_reg: 0.1264  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.002802  time: 1.2716  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:22:11] d2.utils.events INFO:  eta: 2:56:13  iter: 1659  total_loss: 0.6197  loss_cls: 0.5069  loss_box_reg: 0.115  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.003204  time: 1.2716  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:22:37] d2.utils.events INFO:  eta: 2:55:46  iter: 1679  total_loss: 0.6424  loss_cls: 0.4801  loss_box_reg: 0.1217  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.002749  time: 1.2716  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:23:02] d2.utils.events INFO:  eta: 2:55:22  iter: 1699  total_loss: 0.6265  loss_cls: 0.4368  loss_box_reg: 0.09815  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.002674  time: 1.2717  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:23:28] d2.utils.events INFO:  eta: 2:54:57  iter: 1719  total_loss: 0.5811  loss_cls: 0.4348  loss_box_reg: 0.09228  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.00279  time: 1.2717  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:23:53] d2.utils.events INFO:  eta: 2:54:31  iter: 1739  total_loss: 0.564  loss_cls: 0.4123  loss_box_reg: 0.1135  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.002801  time: 1.2717  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:24:19] d2.utils.events INFO:  eta: 2:54:06  iter: 1759  total_loss: 0.5744  loss_cls: 0.4439  loss_box_reg: 0.1181  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.002569  time: 1.2718  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:24:44] d2.utils.events INFO:  eta: 2:53:41  iter: 1779  total_loss: 0.5918  loss_cls: 0.4247  loss_box_reg: 0.1358  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.002581  time: 1.2718  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 17:25:10] d2.utils.events INFO:  eta: 2:53:16  iter: 1799  total_loss: 0.563  loss_cls: 0.4184  loss_box_reg: 0.1304  loss_rpn_cls: 0.02483  loss_rpn_loc: 0.00477  time: 1.2718  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:25:35] d2.utils.events INFO:  eta: 2:52:51  iter: 1819  total_loss: 0.5408  loss_cls: 0.4169  loss_box_reg: 0.1157  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.002494  time: 1.2717  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:26:01] d2.utils.events INFO:  eta: 2:52:24  iter: 1839  total_loss: 0.5906  loss_cls: 0.3977  loss_box_reg: 0.1149  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.00255  time: 1.2717  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:26:26] d2.utils.events INFO:  eta: 2:51:59  iter: 1859  total_loss: 0.5802  loss_cls: 0.4463  loss_box_reg: 0.1065  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.003226  time: 1.2717  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:26:52] d2.utils.events INFO:  eta: 2:51:34  iter: 1879  total_loss: 0.5987  loss_cls: 0.4582  loss_box_reg: 0.1065  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.003078  time: 1.2718  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:27:17] d2.utils.events INFO:  eta: 2:51:09  iter: 1899  total_loss: 0.6231  loss_cls: 0.464  loss_box_reg: 0.1176  loss_rpn_cls: 0.0219  loss_rpn_loc: 0.004409  time: 1.2718  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:27:43] d2.utils.events INFO:  eta: 2:50:43  iter: 1919  total_loss: 0.6082  loss_cls: 0.4791  loss_box_reg: 0.1046  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.003035  time: 1.2718  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:28:08] d2.utils.events INFO:  eta: 2:50:18  iter: 1939  total_loss: 0.5428  loss_cls: 0.3964  loss_box_reg: 0.1371  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.003399  time: 1.2719  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:28:34] d2.utils.events INFO:  eta: 2:49:53  iter: 1959  total_loss: 0.5708  loss_cls: 0.429  loss_box_reg: 0.1222  loss_rpn_cls: 0.01914  loss_rpn_loc: 0.003158  time: 1.2719  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:28:59] d2.utils.events INFO:  eta: 2:49:28  iter: 1979  total_loss: 0.5551  loss_cls: 0.4154  loss_box_reg: 0.1236  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.00297  time: 1.2718  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:29:25] d2.utils.events INFO:  eta: 2:49:02  iter: 1999  total_loss: 0.5635  loss_cls: 0.4563  loss_box_reg: 0.1285  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.001972  time: 1.2718  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:29:50] d2.utils.events INFO:  eta: 2:48:36  iter: 2019  total_loss: 0.5429  loss_cls: 0.4516  loss_box_reg: 0.1238  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.002658  time: 1.2718  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:30:16] d2.utils.events INFO:  eta: 2:48:13  iter: 2039  total_loss: 0.6725  loss_cls: 0.5551  loss_box_reg: 0.1098  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.002647  time: 1.2719  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:30:41] d2.utils.events INFO:  eta: 2:47:48  iter: 2059  total_loss: 0.5552  loss_cls: 0.441  loss_box_reg: 0.08248  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.003554  time: 1.2718  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:31:07] d2.utils.events INFO:  eta: 2:47:23  iter: 2079  total_loss: 0.5518  loss_cls: 0.3968  loss_box_reg: 0.098  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.00325  time: 1.2718  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:31:32] d2.utils.events INFO:  eta: 2:46:58  iter: 2099  total_loss: 0.5652  loss_cls: 0.424  loss_box_reg: 0.1269  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.002213  time: 1.2719  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:31:58] d2.utils.events INFO:  eta: 2:46:31  iter: 2119  total_loss: 0.5319  loss_cls: 0.3944  loss_box_reg: 0.1176  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.002829  time: 1.2719  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:32:24] d2.utils.events INFO:  eta: 2:46:07  iter: 2139  total_loss: 0.4942  loss_cls: 0.3672  loss_box_reg: 0.1038  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.002694  time: 1.2720  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:32:49] d2.utils.events INFO:  eta: 2:45:42  iter: 2159  total_loss: 0.5114  loss_cls: 0.4047  loss_box_reg: 0.1263  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.00284  time: 1.2720  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:33:15] d2.utils.events INFO:  eta: 2:45:16  iter: 2179  total_loss: 0.5731  loss_cls: 0.421  loss_box_reg: 0.1222  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.002648  time: 1.2720  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:33:40] d2.utils.events INFO:  eta: 2:44:52  iter: 2199  total_loss: 0.5648  loss_cls: 0.4335  loss_box_reg: 0.09892  loss_rpn_cls: 0.02044  loss_rpn_loc: 0.00498  time: 1.2720  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:34:06] d2.utils.events INFO:  eta: 2:44:27  iter: 2219  total_loss: 0.5884  loss_cls: 0.4261  loss_box_reg: 0.1241  loss_rpn_cls: 0.01871  loss_rpn_loc: 0.003348  time: 1.2721  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:34:31] d2.utils.events INFO:  eta: 2:44:02  iter: 2239  total_loss: 0.6133  loss_cls: 0.4129  loss_box_reg: 0.1168  loss_rpn_cls: 0.01791  loss_rpn_loc: 0.003622  time: 1.2720  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:34:57] d2.utils.events INFO:  eta: 2:43:35  iter: 2259  total_loss: 0.6051  loss_cls: 0.4575  loss_box_reg: 0.1051  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.002498  time: 1.2720  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:35:22] d2.utils.events INFO:  eta: 2:43:09  iter: 2279  total_loss: 0.5604  loss_cls: 0.4224  loss_box_reg: 0.0896  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.002703  time: 1.2720  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:35:48] d2.utils.events INFO:  eta: 2:42:43  iter: 2299  total_loss: 0.6374  loss_cls: 0.4976  loss_box_reg: 0.1004  loss_rpn_cls: 0.01934  loss_rpn_loc: 0.002766  time: 1.2721  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:36:13] d2.utils.events INFO:  eta: 2:42:18  iter: 2319  total_loss: 0.5963  loss_cls: 0.4437  loss_box_reg: 0.1053  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.002892  time: 1.2721  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:36:39] d2.utils.events INFO:  eta: 2:41:53  iter: 2339  total_loss: 0.5541  loss_cls: 0.4319  loss_box_reg: 0.1083  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.002128  time: 1.2721  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:37:04] d2.utils.events INFO:  eta: 2:41:28  iter: 2359  total_loss: 0.5763  loss_cls: 0.4481  loss_box_reg: 0.09596  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.003771  time: 1.2721  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:37:30] d2.utils.events INFO:  eta: 2:41:03  iter: 2379  total_loss: 0.5414  loss_cls: 0.4194  loss_box_reg: 0.1074  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.003352  time: 1.2721  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:37:55] d2.utils.events INFO:  eta: 2:40:37  iter: 2399  total_loss: 0.5932  loss_cls: 0.4732  loss_box_reg: 0.1136  loss_rpn_cls: 0.01755  loss_rpn_loc: 0.004231  time: 1.2721  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:38:21] d2.utils.events INFO:  eta: 2:40:12  iter: 2419  total_loss: 0.5988  loss_cls: 0.4402  loss_box_reg: 0.1078  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.003725  time: 1.2722  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:38:47] d2.utils.events INFO:  eta: 2:39:45  iter: 2439  total_loss: 0.5338  loss_cls: 0.3896  loss_box_reg: 0.07903  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.003044  time: 1.2721  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:39:12] d2.utils.events INFO:  eta: 2:39:19  iter: 2459  total_loss: 0.6391  loss_cls: 0.4482  loss_box_reg: 0.09653  loss_rpn_cls: 0.02125  loss_rpn_loc: 0.004117  time: 1.2721  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:39:37] d2.utils.events INFO:  eta: 2:38:53  iter: 2479  total_loss: 0.5808  loss_cls: 0.4192  loss_box_reg: 0.09376  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.003366  time: 1.2720  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:40:02] d2.utils.events INFO:  eta: 2:38:25  iter: 2499  total_loss: 0.5482  loss_cls: 0.3939  loss_box_reg: 0.09443  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.003034  time: 1.2719  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:40:28] d2.utils.events INFO:  eta: 2:37:59  iter: 2519  total_loss: 0.543  loss_cls: 0.4037  loss_box_reg: 0.103  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.003146  time: 1.2718  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:40:53] d2.utils.events INFO:  eta: 2:37:33  iter: 2539  total_loss: 0.5862  loss_cls: 0.4323  loss_box_reg: 0.1159  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.002975  time: 1.2717  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:41:18] d2.utils.events INFO:  eta: 2:37:08  iter: 2559  total_loss: 0.5705  loss_cls: 0.4263  loss_box_reg: 0.1035  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.003086  time: 1.2717  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:41:44] d2.utils.events INFO:  eta: 2:36:43  iter: 2579  total_loss: 0.5343  loss_cls: 0.3849  loss_box_reg: 0.1388  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.002863  time: 1.2717  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:42:09] d2.utils.events INFO:  eta: 2:36:16  iter: 2599  total_loss: 0.6175  loss_cls: 0.5127  loss_box_reg: 0.08251  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.003833  time: 1.2716  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:42:34] d2.utils.events INFO:  eta: 2:35:50  iter: 2619  total_loss: 0.5303  loss_cls: 0.4246  loss_box_reg: 0.08773  loss_rpn_cls: 0.01747  loss_rpn_loc: 0.003524  time: 1.2715  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:43:00] d2.utils.events INFO:  eta: 2:35:24  iter: 2639  total_loss: 0.5276  loss_cls: 0.4193  loss_box_reg: 0.1072  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.003256  time: 1.2715  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:43:25] d2.utils.events INFO:  eta: 2:34:58  iter: 2659  total_loss: 0.5966  loss_cls: 0.4356  loss_box_reg: 0.1219  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.002252  time: 1.2714  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:43:50] d2.utils.events INFO:  eta: 2:34:32  iter: 2679  total_loss: 0.5601  loss_cls: 0.4262  loss_box_reg: 0.09254  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.001857  time: 1.2713  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:44:16] d2.utils.events INFO:  eta: 2:34:06  iter: 2699  total_loss: 0.6041  loss_cls: 0.4526  loss_box_reg: 0.1045  loss_rpn_cls: 0.02208  loss_rpn_loc: 0.00475  time: 1.2713  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:44:41] d2.utils.events INFO:  eta: 2:33:40  iter: 2719  total_loss: 0.5562  loss_cls: 0.3819  loss_box_reg: 0.1073  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.00331  time: 1.2713  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 17:45:06] d2.utils.events INFO:  eta: 2:33:14  iter: 2739  total_loss: 0.5882  loss_cls: 0.4477  loss_box_reg: 0.08878  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.002921  time: 1.2712  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:45:32] d2.utils.events INFO:  eta: 2:32:47  iter: 2759  total_loss: 0.5617  loss_cls: 0.4302  loss_box_reg: 0.09898  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.002612  time: 1.2712  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:45:57] d2.utils.events INFO:  eta: 2:32:22  iter: 2779  total_loss: 0.5038  loss_cls: 0.3393  loss_box_reg: 0.1242  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.001862  time: 1.2711  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:46:22] d2.utils.events INFO:  eta: 2:31:55  iter: 2799  total_loss: 0.5638  loss_cls: 0.4412  loss_box_reg: 0.09621  loss_rpn_cls: 0.01864  loss_rpn_loc: 0.003527  time: 1.2711  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:46:48] d2.utils.events INFO:  eta: 2:31:30  iter: 2819  total_loss: 0.539  loss_cls: 0.3738  loss_box_reg: 0.1282  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.00239  time: 1.2711  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:47:13] d2.utils.events INFO:  eta: 2:31:04  iter: 2839  total_loss: 0.5038  loss_cls: 0.3474  loss_box_reg: 0.08753  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.002435  time: 1.2710  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:47:39] d2.utils.events INFO:  eta: 2:30:39  iter: 2859  total_loss: 0.606  loss_cls: 0.4664  loss_box_reg: 0.08226  loss_rpn_cls: 0.0166  loss_rpn_loc: 0.003422  time: 1.2710  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:48:04] d2.utils.events INFO:  eta: 2:30:14  iter: 2879  total_loss: 0.5275  loss_cls: 0.3567  loss_box_reg: 0.1288  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.002211  time: 1.2710  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:48:30] d2.utils.events INFO:  eta: 2:29:48  iter: 2899  total_loss: 0.5328  loss_cls: 0.403  loss_box_reg: 0.07351  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.003751  time: 1.2710  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:48:55] d2.utils.events INFO:  eta: 2:29:22  iter: 2919  total_loss: 0.5191  loss_cls: 0.4111  loss_box_reg: 0.08049  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.003958  time: 1.2710  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:49:20] d2.utils.events INFO:  eta: 2:28:57  iter: 2939  total_loss: 0.5199  loss_cls: 0.3704  loss_box_reg: 0.1023  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.003081  time: 1.2709  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:49:46] d2.utils.events INFO:  eta: 2:28:32  iter: 2959  total_loss: 0.4876  loss_cls: 0.3634  loss_box_reg: 0.1014  loss_rpn_cls: 0.01218  loss_rpn_loc: 0.00202  time: 1.2709  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:50:11] d2.utils.events INFO:  eta: 2:28:06  iter: 2979  total_loss: 0.4528  loss_cls: 0.3346  loss_box_reg: 0.0927  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.001957  time: 1.2709  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:50:37] d2.utils.events INFO:  eta: 2:27:41  iter: 2999  total_loss: 0.537  loss_cls: 0.3925  loss_box_reg: 0.1149  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.002599  time: 1.2708  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 17:51:02] d2.utils.events INFO:  eta: 2:27:15  iter: 3019  total_loss: 0.581  loss_cls: 0.4863  loss_box_reg: 0.08492  loss_rpn_cls: 0.01202  loss_rpn_loc: 0.002771  time: 1.2708  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:51:27] d2.utils.events INFO:  eta: 2:26:49  iter: 3039  total_loss: 0.5666  loss_cls: 0.4291  loss_box_reg: 0.1016  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.002402  time: 1.2708  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:51:52] d2.utils.events INFO:  eta: 2:26:22  iter: 3059  total_loss: 0.5799  loss_cls: 0.4511  loss_box_reg: 0.1026  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.003564  time: 1.2707  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:52:18] d2.utils.events INFO:  eta: 2:25:55  iter: 3079  total_loss: 0.5306  loss_cls: 0.4172  loss_box_reg: 0.0952  loss_rpn_cls: 0.0171  loss_rpn_loc: 0.002977  time: 1.2707  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:52:43] d2.utils.events INFO:  eta: 2:25:29  iter: 3099  total_loss: 0.5619  loss_cls: 0.4319  loss_box_reg: 0.07204  loss_rpn_cls: 0.01797  loss_rpn_loc: 0.003108  time: 1.2706  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:53:09] d2.utils.events INFO:  eta: 2:25:04  iter: 3119  total_loss: 0.5266  loss_cls: 0.4071  loss_box_reg: 0.08526  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.002837  time: 1.2706  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 17:53:34] d2.utils.events INFO:  eta: 2:24:38  iter: 3139  total_loss: 0.5947  loss_cls: 0.4628  loss_box_reg: 0.07929  loss_rpn_cls: 0.01213  loss_rpn_loc: 0.002388  time: 1.2706  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:53:59] d2.utils.events INFO:  eta: 2:24:12  iter: 3159  total_loss: 0.562  loss_cls: 0.4575  loss_box_reg: 0.08853  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.002407  time: 1.2705  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:54:25] d2.utils.events INFO:  eta: 2:23:45  iter: 3179  total_loss: 0.535  loss_cls: 0.4063  loss_box_reg: 0.08558  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.003684  time: 1.2705  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:54:50] d2.utils.events INFO:  eta: 2:23:19  iter: 3199  total_loss: 0.6054  loss_cls: 0.4507  loss_box_reg: 0.1309  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.002413  time: 1.2705  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:55:15] d2.utils.events INFO:  eta: 2:22:53  iter: 3219  total_loss: 0.5323  loss_cls: 0.4053  loss_box_reg: 0.114  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.002934  time: 1.2704  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:55:41] d2.utils.events INFO:  eta: 2:22:27  iter: 3239  total_loss: 0.5918  loss_cls: 0.4233  loss_box_reg: 0.1024  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.003134  time: 1.2704  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:56:06] d2.utils.events INFO:  eta: 2:22:03  iter: 3259  total_loss: 0.5032  loss_cls: 0.3929  loss_box_reg: 0.1058  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.003431  time: 1.2704  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 17:56:32] d2.utils.events INFO:  eta: 2:21:38  iter: 3279  total_loss: 0.5395  loss_cls: 0.3766  loss_box_reg: 0.1266  loss_rpn_cls: 0.01567  loss_rpn_loc: 0.003757  time: 1.2704  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:56:57] d2.utils.events INFO:  eta: 2:21:13  iter: 3299  total_loss: 0.5696  loss_cls: 0.4089  loss_box_reg: 0.1103  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.002772  time: 1.2704  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 17:57:22] d2.utils.events INFO:  eta: 2:20:47  iter: 3319  total_loss: 0.5252  loss_cls: 0.4022  loss_box_reg: 0.1008  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.00242  time: 1.2704  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 17:57:48] d2.utils.events INFO:  eta: 2:20:21  iter: 3339  total_loss: 0.5699  loss_cls: 0.4128  loss_box_reg: 0.09863  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.001879  time: 1.2703  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 17:58:13] d2.utils.events INFO:  eta: 2:19:56  iter: 3359  total_loss: 0.6309  loss_cls: 0.5256  loss_box_reg: 0.1018  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.004075  time: 1.2703  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 17:58:38] d2.utils.events INFO:  eta: 2:19:29  iter: 3379  total_loss: 0.555  loss_cls: 0.4073  loss_box_reg: 0.1206  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.003194  time: 1.2703  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:59:04] d2.utils.events INFO:  eta: 2:19:03  iter: 3399  total_loss: 0.5068  loss_cls: 0.3656  loss_box_reg: 0.1136  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.003188  time: 1.2702  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 17:59:29] d2.utils.events INFO:  eta: 2:18:37  iter: 3419  total_loss: 0.5259  loss_cls: 0.4522  loss_box_reg: 0.0889  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.002511  time: 1.2702  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 17:59:54] d2.utils.events INFO:  eta: 2:18:11  iter: 3439  total_loss: 0.5435  loss_cls: 0.3977  loss_box_reg: 0.1101  loss_rpn_cls: 0.009817  loss_rpn_loc: 0.002241  time: 1.2701  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:00:20] d2.utils.events INFO:  eta: 2:17:46  iter: 3459  total_loss: 0.5512  loss_cls: 0.419  loss_box_reg: 0.09254  loss_rpn_cls: 0.01345  loss_rpn_loc: 0.00254  time: 1.2701  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:00:45] d2.utils.events INFO:  eta: 2:17:21  iter: 3479  total_loss: 0.549  loss_cls: 0.3515  loss_box_reg: 0.1091  loss_rpn_cls: 0.01623  loss_rpn_loc: 0.003279  time: 1.2701  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:01:10] d2.utils.events INFO:  eta: 2:16:56  iter: 3499  total_loss: 0.5399  loss_cls: 0.4042  loss_box_reg: 0.08171  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.003414  time: 1.2700  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:01:36] d2.utils.events INFO:  eta: 2:16:30  iter: 3519  total_loss: 0.5004  loss_cls: 0.3733  loss_box_reg: 0.1042  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.002434  time: 1.2700  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 18:02:01] d2.utils.events INFO:  eta: 2:16:04  iter: 3539  total_loss: 0.4821  loss_cls: 0.3602  loss_box_reg: 0.1005  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.003133  time: 1.2699  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:02:26] d2.utils.events INFO:  eta: 2:15:38  iter: 3559  total_loss: 0.5665  loss_cls: 0.4109  loss_box_reg: 0.09108  loss_rpn_cls: 0.01852  loss_rpn_loc: 0.003098  time: 1.2699  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:02:51] d2.utils.events INFO:  eta: 2:15:13  iter: 3579  total_loss: 0.5425  loss_cls: 0.3859  loss_box_reg: 0.1011  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.002181  time: 1.2698  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:03:17] d2.utils.events INFO:  eta: 2:14:46  iter: 3599  total_loss: 0.4485  loss_cls: 0.3175  loss_box_reg: 0.09268  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.002197  time: 1.2698  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:03:42] d2.utils.events INFO:  eta: 2:14:21  iter: 3619  total_loss: 0.5178  loss_cls: 0.4286  loss_box_reg: 0.09076  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.003374  time: 1.2697  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 18:04:07] d2.utils.events INFO:  eta: 2:13:55  iter: 3639  total_loss: 0.4919  loss_cls: 0.4031  loss_box_reg: 0.08049  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.003123  time: 1.2697  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:04:33] d2.utils.events INFO:  eta: 2:13:30  iter: 3659  total_loss: 0.5372  loss_cls: 0.4136  loss_box_reg: 0.06898  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.002588  time: 1.2697  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:04:58] d2.utils.events INFO:  eta: 2:13:04  iter: 3679  total_loss: 0.6225  loss_cls: 0.415  loss_box_reg: 0.1095  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.00369  time: 1.2696  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:05:23] d2.utils.events INFO:  eta: 2:12:38  iter: 3699  total_loss: 0.5266  loss_cls: 0.4123  loss_box_reg: 0.07103  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.002179  time: 1.2695  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:05:48] d2.utils.events INFO:  eta: 2:12:12  iter: 3719  total_loss: 0.5148  loss_cls: 0.4255  loss_box_reg: 0.1075  loss_rpn_cls: 0.01357  loss_rpn_loc: 0.003206  time: 1.2695  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:06:14] d2.utils.events INFO:  eta: 2:11:47  iter: 3739  total_loss: 0.5102  loss_cls: 0.3867  loss_box_reg: 0.1115  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.002387  time: 1.2695  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:06:39] d2.utils.events INFO:  eta: 2:11:22  iter: 3759  total_loss: 0.517  loss_cls: 0.3951  loss_box_reg: 0.1126  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.002556  time: 1.2694  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:07:04] d2.utils.events INFO:  eta: 2:10:56  iter: 3779  total_loss: 0.6071  loss_cls: 0.4517  loss_box_reg: 0.1079  loss_rpn_cls: 0.01564  loss_rpn_loc: 0.0033  time: 1.2694  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:07:30] d2.utils.events INFO:  eta: 2:10:31  iter: 3799  total_loss: 0.5575  loss_cls: 0.429  loss_box_reg: 0.1089  loss_rpn_cls: 0.01577  loss_rpn_loc: 0.002899  time: 1.2694  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 18:07:55] d2.utils.events INFO:  eta: 2:10:05  iter: 3819  total_loss: 0.5639  loss_cls: 0.4184  loss_box_reg: 0.1299  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.003103  time: 1.2693  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:08:20] d2.utils.events INFO:  eta: 2:09:40  iter: 3839  total_loss: 0.618  loss_cls: 0.457  loss_box_reg: 0.09646  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.002285  time: 1.2693  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:08:46] d2.utils.events INFO:  eta: 2:09:14  iter: 3859  total_loss: 0.4691  loss_cls: 0.3337  loss_box_reg: 0.1179  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.00287  time: 1.2693  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:09:11] d2.utils.events INFO:  eta: 2:08:48  iter: 3879  total_loss: 0.4999  loss_cls: 0.4002  loss_box_reg: 0.07139  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.00268  time: 1.2693  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:09:36] d2.utils.events INFO:  eta: 2:08:23  iter: 3899  total_loss: 0.5585  loss_cls: 0.3925  loss_box_reg: 0.0948  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.002683  time: 1.2693  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:10:02] d2.utils.events INFO:  eta: 2:07:58  iter: 3919  total_loss: 0.5764  loss_cls: 0.4493  loss_box_reg: 0.09614  loss_rpn_cls: 0.01057  loss_rpn_loc: 0.002478  time: 1.2693  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:10:27] d2.utils.events INFO:  eta: 2:07:32  iter: 3939  total_loss: 0.4993  loss_cls: 0.3787  loss_box_reg: 0.08369  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.003074  time: 1.2693  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:10:53] d2.utils.events INFO:  eta: 2:07:07  iter: 3959  total_loss: 0.5333  loss_cls: 0.4064  loss_box_reg: 0.09513  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.002829  time: 1.2693  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:11:18] d2.utils.events INFO:  eta: 2:06:42  iter: 3979  total_loss: 0.5206  loss_cls: 0.4016  loss_box_reg: 0.08458  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.002099  time: 1.2692  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:11:43] d2.utils.events INFO:  eta: 2:06:16  iter: 3999  total_loss: 0.5661  loss_cls: 0.4254  loss_box_reg: 0.08652  loss_rpn_cls: 0.01399  loss_rpn_loc: 0.003082  time: 1.2692  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 18:12:09] d2.utils.events INFO:  eta: 2:05:50  iter: 4019  total_loss: 0.4965  loss_cls: 0.3344  loss_box_reg: 0.1019  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.002341  time: 1.2692  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:12:34] d2.utils.events INFO:  eta: 2:05:25  iter: 4039  total_loss: 0.4747  loss_cls: 0.3792  loss_box_reg: 0.07157  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.003233  time: 1.2691  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:12:59] d2.utils.events INFO:  eta: 2:05:00  iter: 4059  total_loss: 0.4496  loss_cls: 0.3471  loss_box_reg: 0.1075  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.002388  time: 1.2691  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:13:25] d2.utils.events INFO:  eta: 2:04:36  iter: 4079  total_loss: 0.5464  loss_cls: 0.4285  loss_box_reg: 0.09915  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.001813  time: 1.2691  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:13:50] d2.utils.events INFO:  eta: 2:04:11  iter: 4099  total_loss: 0.5449  loss_cls: 0.3937  loss_box_reg: 0.1232  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.003163  time: 1.2691  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:14:16] d2.utils.events INFO:  eta: 2:03:45  iter: 4119  total_loss: 0.5058  loss_cls: 0.4485  loss_box_reg: 0.07336  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.002519  time: 1.2691  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:14:41] d2.utils.events INFO:  eta: 2:03:20  iter: 4139  total_loss: 0.5422  loss_cls: 0.4173  loss_box_reg: 0.1  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.002206  time: 1.2691  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:15:06] d2.utils.events INFO:  eta: 2:02:55  iter: 4159  total_loss: 0.5281  loss_cls: 0.4266  loss_box_reg: 0.09833  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.003174  time: 1.2691  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:15:32] d2.utils.events INFO:  eta: 2:02:30  iter: 4179  total_loss: 0.5422  loss_cls: 0.4392  loss_box_reg: 0.09361  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.002595  time: 1.2691  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:15:57] d2.utils.events INFO:  eta: 2:02:06  iter: 4199  total_loss: 0.5144  loss_cls: 0.3823  loss_box_reg: 0.09196  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.001797  time: 1.2691  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:16:23] d2.utils.events INFO:  eta: 2:01:41  iter: 4219  total_loss: 0.5141  loss_cls: 0.3739  loss_box_reg: 0.1368  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.002667  time: 1.2691  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:16:48] d2.utils.events INFO:  eta: 2:01:14  iter: 4239  total_loss: 0.5287  loss_cls: 0.3802  loss_box_reg: 0.09634  loss_rpn_cls: 0.01  loss_rpn_loc: 0.002456  time: 1.2690  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:17:13] d2.utils.events INFO:  eta: 2:00:48  iter: 4259  total_loss: 0.5121  loss_cls: 0.3671  loss_box_reg: 0.1112  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.003288  time: 1.2690  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:17:39] d2.utils.events INFO:  eta: 2:00:23  iter: 4279  total_loss: 0.4845  loss_cls: 0.3337  loss_box_reg: 0.09571  loss_rpn_cls: 0.01289  loss_rpn_loc: 0.002111  time: 1.2690  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:18:04] d2.utils.events INFO:  eta: 1:59:58  iter: 4299  total_loss: 0.5105  loss_cls: 0.4591  loss_box_reg: 0.07943  loss_rpn_cls: 0.009977  loss_rpn_loc: 0.002531  time: 1.2690  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:18:29] d2.utils.events INFO:  eta: 1:59:32  iter: 4319  total_loss: 0.5692  loss_cls: 0.4303  loss_box_reg: 0.07403  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.003241  time: 1.2690  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:18:55] d2.utils.events INFO:  eta: 1:59:06  iter: 4339  total_loss: 0.5797  loss_cls: 0.434  loss_box_reg: 0.09073  loss_rpn_cls: 0.01288  loss_rpn_loc: 0.003899  time: 1.2689  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:19:20] d2.utils.events INFO:  eta: 1:58:40  iter: 4359  total_loss: 0.5116  loss_cls: 0.3539  loss_box_reg: 0.1128  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.002542  time: 1.2689  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:19:45] d2.utils.events INFO:  eta: 1:58:15  iter: 4379  total_loss: 0.5089  loss_cls: 0.3739  loss_box_reg: 0.09671  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.002009  time: 1.2688  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 18:20:11] d2.utils.events INFO:  eta: 1:57:50  iter: 4399  total_loss: 0.5494  loss_cls: 0.4417  loss_box_reg: 0.0977  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.002767  time: 1.2688  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:20:36] d2.utils.events INFO:  eta: 1:57:26  iter: 4419  total_loss: 0.5943  loss_cls: 0.4468  loss_box_reg: 0.1233  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.003539  time: 1.2688  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:21:01] d2.utils.events INFO:  eta: 1:57:01  iter: 4439  total_loss: 0.548  loss_cls: 0.4319  loss_box_reg: 0.1077  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.002648  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:21:27] d2.utils.events INFO:  eta: 1:56:37  iter: 4459  total_loss: 0.5003  loss_cls: 0.4139  loss_box_reg: 0.0858  loss_rpn_cls: 0.0125  loss_rpn_loc: 0.002238  time: 1.2688  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:21:52] d2.utils.events INFO:  eta: 1:56:11  iter: 4479  total_loss: 0.5639  loss_cls: 0.4484  loss_box_reg: 0.1232  loss_rpn_cls: 0.01505  loss_rpn_loc: 0.003003  time: 1.2688  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:22:18] d2.utils.events INFO:  eta: 1:55:47  iter: 4499  total_loss: 0.4658  loss_cls: 0.3803  loss_box_reg: 0.07926  loss_rpn_cls: 0.01005  loss_rpn_loc: 0.001668  time: 1.2688  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:22:43] d2.utils.events INFO:  eta: 1:55:23  iter: 4519  total_loss: 0.5745  loss_cls: 0.447  loss_box_reg: 0.09726  loss_rpn_cls: 0.01657  loss_rpn_loc: 0.005228  time: 1.2688  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:23:08] d2.utils.events INFO:  eta: 1:54:59  iter: 4539  total_loss: 0.5311  loss_cls: 0.3701  loss_box_reg: 0.115  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.002252  time: 1.2688  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:23:34] d2.utils.events INFO:  eta: 1:54:34  iter: 4559  total_loss: 0.4945  loss_cls: 0.3849  loss_box_reg: 0.08758  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.002207  time: 1.2688  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:23:59] d2.utils.events INFO:  eta: 1:54:09  iter: 4579  total_loss: 0.5683  loss_cls: 0.4197  loss_box_reg: 0.1233  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.0029  time: 1.2688  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:24:25] d2.utils.events INFO:  eta: 1:53:45  iter: 4599  total_loss: 0.5387  loss_cls: 0.4048  loss_box_reg: 0.1105  loss_rpn_cls: 0.01046  loss_rpn_loc: 0.001955  time: 1.2688  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:24:50] d2.utils.events INFO:  eta: 1:53:21  iter: 4619  total_loss: 0.5244  loss_cls: 0.4092  loss_box_reg: 0.08798  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.001975  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:25:15] d2.utils.events INFO:  eta: 1:52:56  iter: 4639  total_loss: 0.507  loss_cls: 0.3908  loss_box_reg: 0.08781  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.002982  time: 1.2688  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:25:41] d2.utils.events INFO:  eta: 1:52:31  iter: 4659  total_loss: 0.4942  loss_cls: 0.3666  loss_box_reg: 0.08092  loss_rpn_cls: 0.01434  loss_rpn_loc: 0.00252  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:26:06] d2.utils.events INFO:  eta: 1:52:07  iter: 4679  total_loss: 0.582  loss_cls: 0.3942  loss_box_reg: 0.08962  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.00226  time: 1.2688  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 18:26:32] d2.utils.events INFO:  eta: 1:51:43  iter: 4699  total_loss: 0.5145  loss_cls: 0.3954  loss_box_reg: 0.09148  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.001918  time: 1.2688  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:26:57] d2.utils.events INFO:  eta: 1:51:18  iter: 4719  total_loss: 0.5545  loss_cls: 0.4327  loss_box_reg: 0.09349  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.002687  time: 1.2688  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:27:22] d2.utils.events INFO:  eta: 1:50:52  iter: 4739  total_loss: 0.5718  loss_cls: 0.4487  loss_box_reg: 0.1257  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.003014  time: 1.2687  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:27:48] d2.utils.events INFO:  eta: 1:50:27  iter: 4759  total_loss: 0.5527  loss_cls: 0.4376  loss_box_reg: 0.07631  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.003707  time: 1.2687  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:28:13] d2.utils.events INFO:  eta: 1:50:02  iter: 4779  total_loss: 0.5226  loss_cls: 0.4606  loss_box_reg: 0.06578  loss_rpn_cls: 0.01442  loss_rpn_loc: 0.002554  time: 1.2687  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:28:38] d2.utils.events INFO:  eta: 1:49:36  iter: 4799  total_loss: 0.5264  loss_cls: 0.3624  loss_box_reg: 0.08314  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.002411  time: 1.2686  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:29:03] d2.utils.events INFO:  eta: 1:49:10  iter: 4819  total_loss: 0.625  loss_cls: 0.4584  loss_box_reg: 0.102  loss_rpn_cls: 0.01633  loss_rpn_loc: 0.003368  time: 1.2686  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:29:29] d2.utils.events INFO:  eta: 1:48:45  iter: 4839  total_loss: 0.4815  loss_cls: 0.3727  loss_box_reg: 0.09649  loss_rpn_cls: 0.01083  loss_rpn_loc: 0.00201  time: 1.2686  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:29:54] d2.utils.events INFO:  eta: 1:48:19  iter: 4859  total_loss: 0.497  loss_cls: 0.4045  loss_box_reg: 0.07172  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.001947  time: 1.2686  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:30:20] d2.utils.events INFO:  eta: 1:47:53  iter: 4879  total_loss: 0.5855  loss_cls: 0.4249  loss_box_reg: 0.1091  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.003119  time: 1.2686  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:30:45] d2.utils.events INFO:  eta: 1:47:28  iter: 4899  total_loss: 0.5382  loss_cls: 0.4297  loss_box_reg: 0.09999  loss_rpn_cls: 0.0135  loss_rpn_loc: 0.002036  time: 1.2686  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:31:10] d2.utils.events INFO:  eta: 1:47:03  iter: 4919  total_loss: 0.5337  loss_cls: 0.3781  loss_box_reg: 0.08228  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.002355  time: 1.2686  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:31:36] d2.utils.events INFO:  eta: 1:46:36  iter: 4939  total_loss: 0.5153  loss_cls: 0.3406  loss_box_reg: 0.07216  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.002612  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:32:01] d2.utils.events INFO:  eta: 1:46:11  iter: 4959  total_loss: 0.597  loss_cls: 0.4791  loss_box_reg: 0.0845  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.002281  time: 1.2685  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:32:26] d2.utils.events INFO:  eta: 1:45:46  iter: 4979  total_loss: 0.4607  loss_cls: 0.3564  loss_box_reg: 0.0644  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.00211  time: 1.2685  data_time: 0.0073  lr: 2e-05  max_mem: 19010M
[02/04 18:32:52] d2.utils.events INFO:  eta: 1:45:22  iter: 4999  total_loss: 0.4949  loss_cls: 0.3618  loss_box_reg: 0.1028  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.004121  time: 1.2685  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:33:17] d2.utils.events INFO:  eta: 1:44:57  iter: 5019  total_loss: 0.4756  loss_cls: 0.3832  loss_box_reg: 0.08177  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.00248  time: 1.2685  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:33:42] d2.utils.events INFO:  eta: 1:44:32  iter: 5039  total_loss: 0.5918  loss_cls: 0.5001  loss_box_reg: 0.07165  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.002671  time: 1.2685  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:34:08] d2.utils.events INFO:  eta: 1:44:06  iter: 5059  total_loss: 0.5275  loss_cls: 0.3644  loss_box_reg: 0.1109  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.002373  time: 1.2685  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:34:33] d2.utils.events INFO:  eta: 1:43:39  iter: 5079  total_loss: 0.5361  loss_cls: 0.4323  loss_box_reg: 0.09237  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.002839  time: 1.2684  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:34:58] d2.utils.events INFO:  eta: 1:43:14  iter: 5099  total_loss: 0.5226  loss_cls: 0.3974  loss_box_reg: 0.09439  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.002517  time: 1.2684  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 18:35:24] d2.utils.events INFO:  eta: 1:42:48  iter: 5119  total_loss: 0.5025  loss_cls: 0.3584  loss_box_reg: 0.08744  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.002937  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:35:49] d2.utils.events INFO:  eta: 1:42:23  iter: 5139  total_loss: 0.5219  loss_cls: 0.3674  loss_box_reg: 0.08961  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.003844  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:36:15] d2.utils.events INFO:  eta: 1:41:58  iter: 5159  total_loss: 0.5438  loss_cls: 0.3495  loss_box_reg: 0.1238  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.002032  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:36:40] d2.utils.events INFO:  eta: 1:41:32  iter: 5179  total_loss: 0.4794  loss_cls: 0.3062  loss_box_reg: 0.1037  loss_rpn_cls: 0.01114  loss_rpn_loc: 0.002369  time: 1.2684  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:37:05] d2.utils.events INFO:  eta: 1:41:07  iter: 5199  total_loss: 0.5347  loss_cls: 0.3512  loss_box_reg: 0.08694  loss_rpn_cls: 0.01132  loss_rpn_loc: 0.003006  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:37:31] d2.utils.events INFO:  eta: 1:40:42  iter: 5219  total_loss: 0.5985  loss_cls: 0.4672  loss_box_reg: 0.09752  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.002597  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:37:56] d2.utils.events INFO:  eta: 1:40:17  iter: 5239  total_loss: 0.4844  loss_cls: 0.382  loss_box_reg: 0.09339  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.002221  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:38:22] d2.utils.events INFO:  eta: 1:39:53  iter: 5259  total_loss: 0.5108  loss_cls: 0.354  loss_box_reg: 0.08656  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.001884  time: 1.2684  data_time: 0.0084  lr: 2e-05  max_mem: 19010M
[02/04 18:38:47] d2.utils.events INFO:  eta: 1:39:28  iter: 5279  total_loss: 0.4566  loss_cls: 0.3484  loss_box_reg: 0.07286  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.001737  time: 1.2684  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:39:13] d2.utils.events INFO:  eta: 1:39:03  iter: 5299  total_loss: 0.5521  loss_cls: 0.4138  loss_box_reg: 0.1057  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.002152  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:39:38] d2.utils.events INFO:  eta: 1:38:38  iter: 5319  total_loss: 0.4942  loss_cls: 0.412  loss_box_reg: 0.07998  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.002521  time: 1.2684  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:40:03] d2.utils.events INFO:  eta: 1:38:15  iter: 5339  total_loss: 0.4857  loss_cls: 0.3967  loss_box_reg: 0.1007  loss_rpn_cls: 0.01047  loss_rpn_loc: 0.002288  time: 1.2684  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:40:29] d2.utils.events INFO:  eta: 1:37:51  iter: 5359  total_loss: 0.5287  loss_cls: 0.3821  loss_box_reg: 0.1099  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.003075  time: 1.2684  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:40:54] d2.utils.events INFO:  eta: 1:37:26  iter: 5379  total_loss: 0.5136  loss_cls: 0.3625  loss_box_reg: 0.09109  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.002772  time: 1.2684  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:41:20] d2.utils.events INFO:  eta: 1:37:00  iter: 5399  total_loss: 0.5381  loss_cls: 0.4323  loss_box_reg: 0.09681  loss_rpn_cls: 0.01424  loss_rpn_loc: 0.003668  time: 1.2684  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:41:45] d2.utils.events INFO:  eta: 1:36:34  iter: 5419  total_loss: 0.4912  loss_cls: 0.3833  loss_box_reg: 0.07973  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.002317  time: 1.2684  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:42:10] d2.utils.events INFO:  eta: 1:36:08  iter: 5439  total_loss: 0.5287  loss_cls: 0.3986  loss_box_reg: 0.1051  loss_rpn_cls: 0.01405  loss_rpn_loc: 0.002218  time: 1.2684  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:42:36] d2.utils.events INFO:  eta: 1:35:41  iter: 5459  total_loss: 0.5053  loss_cls: 0.3562  loss_box_reg: 0.0893  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.002358  time: 1.2683  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:43:01] d2.utils.events INFO:  eta: 1:35:16  iter: 5479  total_loss: 0.5287  loss_cls: 0.4263  loss_box_reg: 0.08014  loss_rpn_cls: 0.015  loss_rpn_loc: 0.002987  time: 1.2683  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:43:26] d2.utils.events INFO:  eta: 1:34:50  iter: 5499  total_loss: 0.5064  loss_cls: 0.3952  loss_box_reg: 0.07718  loss_rpn_cls: 0.01016  loss_rpn_loc: 0.001781  time: 1.2683  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:43:52] d2.utils.events INFO:  eta: 1:34:24  iter: 5519  total_loss: 0.4708  loss_cls: 0.3299  loss_box_reg: 0.08703  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.002351  time: 1.2683  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 18:44:17] d2.utils.events INFO:  eta: 1:34:00  iter: 5539  total_loss: 0.4753  loss_cls: 0.3612  loss_box_reg: 0.09473  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.001991  time: 1.2683  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:44:43] d2.utils.events INFO:  eta: 1:33:36  iter: 5559  total_loss: 0.5139  loss_cls: 0.3466  loss_box_reg: 0.1093  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.002584  time: 1.2683  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:45:08] d2.utils.events INFO:  eta: 1:33:10  iter: 5579  total_loss: 0.496  loss_cls: 0.3592  loss_box_reg: 0.1079  loss_rpn_cls: 0.01012  loss_rpn_loc: 0.002549  time: 1.2683  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:45:33] d2.utils.events INFO:  eta: 1:32:43  iter: 5599  total_loss: 0.5462  loss_cls: 0.3938  loss_box_reg: 0.1056  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.002462  time: 1.2683  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:45:59] d2.utils.events INFO:  eta: 1:32:17  iter: 5619  total_loss: 0.5324  loss_cls: 0.3561  loss_box_reg: 0.08194  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.003492  time: 1.2683  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:46:24] d2.utils.events INFO:  eta: 1:31:52  iter: 5639  total_loss: 0.5366  loss_cls: 0.4269  loss_box_reg: 0.0721  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.002565  time: 1.2683  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:46:49] d2.utils.events INFO:  eta: 1:31:27  iter: 5659  total_loss: 0.5406  loss_cls: 0.3936  loss_box_reg: 0.1123  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.002643  time: 1.2683  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:47:15] d2.utils.events INFO:  eta: 1:31:01  iter: 5679  total_loss: 0.5386  loss_cls: 0.4143  loss_box_reg: 0.1094  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.003221  time: 1.2682  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:47:40] d2.utils.events INFO:  eta: 1:30:36  iter: 5699  total_loss: 0.5978  loss_cls: 0.4256  loss_box_reg: 0.1225  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.003625  time: 1.2682  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:48:05] d2.utils.events INFO:  eta: 1:30:11  iter: 5719  total_loss: 0.4829  loss_cls: 0.3595  loss_box_reg: 0.0946  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.002996  time: 1.2682  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 18:48:31] d2.utils.events INFO:  eta: 1:29:46  iter: 5739  total_loss: 0.4863  loss_cls: 0.4036  loss_box_reg: 0.07225  loss_rpn_cls: 0.01166  loss_rpn_loc: 0.002043  time: 1.2682  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:48:56] d2.utils.events INFO:  eta: 1:29:21  iter: 5759  total_loss: 0.5343  loss_cls: 0.4217  loss_box_reg: 0.09007  loss_rpn_cls: 0.01568  loss_rpn_loc: 0.00329  time: 1.2682  data_time: 0.0083  lr: 2e-05  max_mem: 19010M
[02/04 18:49:22] d2.utils.events INFO:  eta: 1:28:57  iter: 5779  total_loss: 0.5097  loss_cls: 0.3925  loss_box_reg: 0.1016  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.002539  time: 1.2682  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:49:47] d2.utils.events INFO:  eta: 1:28:32  iter: 5799  total_loss: 0.4989  loss_cls: 0.3468  loss_box_reg: 0.1046  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.003586  time: 1.2682  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:50:12] d2.utils.events INFO:  eta: 1:28:07  iter: 5819  total_loss: 0.4374  loss_cls: 0.3219  loss_box_reg: 0.07615  loss_rpn_cls: 0.009431  loss_rpn_loc: 0.002186  time: 1.2682  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:50:38] d2.utils.events INFO:  eta: 1:27:42  iter: 5839  total_loss: 0.5395  loss_cls: 0.409  loss_box_reg: 0.05787  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.002421  time: 1.2682  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:51:03] d2.utils.events INFO:  eta: 1:27:17  iter: 5859  total_loss: 0.459  loss_cls: 0.3532  loss_box_reg: 0.06443  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.003947  time: 1.2682  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 18:51:29] d2.utils.events INFO:  eta: 1:26:52  iter: 5879  total_loss: 0.5039  loss_cls: 0.4245  loss_box_reg: 0.09556  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.002331  time: 1.2682  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:51:54] d2.utils.events INFO:  eta: 1:26:27  iter: 5899  total_loss: 0.4313  loss_cls: 0.3348  loss_box_reg: 0.07159  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.001927  time: 1.2682  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:52:19] d2.utils.events INFO:  eta: 1:26:02  iter: 5919  total_loss: 0.4833  loss_cls: 0.3732  loss_box_reg: 0.07259  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.002038  time: 1.2682  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:52:45] d2.utils.events INFO:  eta: 1:25:36  iter: 5939  total_loss: 0.4649  loss_cls: 0.3247  loss_box_reg: 0.09183  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.002315  time: 1.2682  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:53:10] d2.utils.events INFO:  eta: 1:25:11  iter: 5959  total_loss: 0.4221  loss_cls: 0.2751  loss_box_reg: 0.07431  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.001939  time: 1.2682  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:53:35] d2.utils.events INFO:  eta: 1:24:45  iter: 5979  total_loss: 0.4973  loss_cls: 0.356  loss_box_reg: 0.1008  loss_rpn_cls: 0.01058  loss_rpn_loc: 0.002686  time: 1.2681  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:54:01] d2.utils.events INFO:  eta: 1:24:20  iter: 5999  total_loss: 0.5601  loss_cls: 0.4155  loss_box_reg: 0.09425  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.004189  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:54:26] d2.utils.events INFO:  eta: 1:23:55  iter: 6019  total_loss: 0.5297  loss_cls: 0.3741  loss_box_reg: 0.1116  loss_rpn_cls: 0.009448  loss_rpn_loc: 0.002115  time: 1.2681  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:54:51] d2.utils.events INFO:  eta: 1:23:29  iter: 6039  total_loss: 0.5169  loss_cls: 0.3784  loss_box_reg: 0.09142  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.002682  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:55:17] d2.utils.events INFO:  eta: 1:23:04  iter: 6059  total_loss: 0.528  loss_cls: 0.4066  loss_box_reg: 0.07462  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.002999  time: 1.2681  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:55:42] d2.utils.events INFO:  eta: 1:22:39  iter: 6079  total_loss: 0.5369  loss_cls: 0.3772  loss_box_reg: 0.1026  loss_rpn_cls: 0.01397  loss_rpn_loc: 0.002577  time: 1.2681  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:56:08] d2.utils.events INFO:  eta: 1:22:14  iter: 6099  total_loss: 0.5147  loss_cls: 0.3982  loss_box_reg: 0.08247  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.002228  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:56:33] d2.utils.events INFO:  eta: 1:21:48  iter: 6119  total_loss: 0.5582  loss_cls: 0.4115  loss_box_reg: 0.05741  loss_rpn_cls: 0.01246  loss_rpn_loc: 0.002998  time: 1.2681  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:56:58] d2.utils.events INFO:  eta: 1:21:22  iter: 6139  total_loss: 0.4945  loss_cls: 0.3354  loss_box_reg: 0.07461  loss_rpn_cls: 0.009611  loss_rpn_loc: 0.002176  time: 1.2681  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 18:57:24] d2.utils.events INFO:  eta: 1:20:57  iter: 6159  total_loss: 0.6081  loss_cls: 0.4218  loss_box_reg: 0.1144  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.00169  time: 1.2681  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 18:57:49] d2.utils.events INFO:  eta: 1:20:31  iter: 6179  total_loss: 0.4996  loss_cls: 0.3707  loss_box_reg: 0.1294  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.00319  time: 1.2680  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:58:14] d2.utils.events INFO:  eta: 1:20:06  iter: 6199  total_loss: 0.5191  loss_cls: 0.3818  loss_box_reg: 0.1086  loss_rpn_cls: 0.01244  loss_rpn_loc: 0.00194  time: 1.2680  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 18:58:39] d2.utils.events INFO:  eta: 1:19:39  iter: 6219  total_loss: 0.4482  loss_cls: 0.3335  loss_box_reg: 0.08088  loss_rpn_cls: 0.01183  loss_rpn_loc: 0.002144  time: 1.2680  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 18:59:05] d2.utils.events INFO:  eta: 1:19:15  iter: 6239  total_loss: 0.6122  loss_cls: 0.4595  loss_box_reg: 0.085  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.003103  time: 1.2680  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:59:30] d2.utils.events INFO:  eta: 1:18:49  iter: 6259  total_loss: 0.468  loss_cls: 0.3608  loss_box_reg: 0.1119  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.002507  time: 1.2680  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 18:59:56] d2.utils.events INFO:  eta: 1:18:24  iter: 6279  total_loss: 0.478  loss_cls: 0.3561  loss_box_reg: 0.0739  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.001861  time: 1.2680  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:00:21] d2.utils.events INFO:  eta: 1:17:58  iter: 6299  total_loss: 0.5489  loss_cls: 0.4396  loss_box_reg: 0.07041  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.003954  time: 1.2680  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:00:46] d2.utils.events INFO:  eta: 1:17:33  iter: 6319  total_loss: 0.4812  loss_cls: 0.3704  loss_box_reg: 0.07904  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.002086  time: 1.2680  data_time: 0.0084  lr: 2e-05  max_mem: 19010M
[02/04 19:01:12] d2.utils.events INFO:  eta: 1:17:08  iter: 6339  total_loss: 0.5666  loss_cls: 0.3994  loss_box_reg: 0.1092  loss_rpn_cls: 0.01335  loss_rpn_loc: 0.003685  time: 1.2680  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:01:37] d2.utils.events INFO:  eta: 1:16:42  iter: 6359  total_loss: 0.5795  loss_cls: 0.4676  loss_box_reg: 0.08343  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.00219  time: 1.2680  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:02:03] d2.utils.events INFO:  eta: 1:16:16  iter: 6379  total_loss: 0.487  loss_cls: 0.3762  loss_box_reg: 0.08406  loss_rpn_cls: 0.009871  loss_rpn_loc: 0.002369  time: 1.2680  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:02:28] d2.utils.events INFO:  eta: 1:15:51  iter: 6399  total_loss: 0.4699  loss_cls: 0.3437  loss_box_reg: 0.0574  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.002617  time: 1.2679  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 19:02:53] d2.utils.events INFO:  eta: 1:15:26  iter: 6419  total_loss: 0.512  loss_cls: 0.3798  loss_box_reg: 0.08609  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.00269  time: 1.2679  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:03:19] d2.utils.events INFO:  eta: 1:15:00  iter: 6439  total_loss: 0.5388  loss_cls: 0.4056  loss_box_reg: 0.07016  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.003042  time: 1.2679  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:03:44] d2.utils.events INFO:  eta: 1:14:35  iter: 6459  total_loss: 0.5114  loss_cls: 0.3986  loss_box_reg: 0.1097  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.002462  time: 1.2679  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:04:09] d2.utils.events INFO:  eta: 1:14:09  iter: 6479  total_loss: 0.5587  loss_cls: 0.4367  loss_box_reg: 0.08097  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.002368  time: 1.2679  data_time: 0.0075  lr: 2e-05  max_mem: 19010M
[02/04 19:04:34] d2.utils.events INFO:  eta: 1:13:43  iter: 6499  total_loss: 0.5625  loss_cls: 0.447  loss_box_reg: 0.08175  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.00224  time: 1.2679  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:05:00] d2.utils.events INFO:  eta: 1:13:18  iter: 6519  total_loss: 0.4517  loss_cls: 0.3211  loss_box_reg: 0.1046  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.003209  time: 1.2679  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:05:25] d2.utils.events INFO:  eta: 1:12:52  iter: 6539  total_loss: 0.5402  loss_cls: 0.4208  loss_box_reg: 0.08742  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.003109  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:05:50] d2.utils.events INFO:  eta: 1:12:27  iter: 6559  total_loss: 0.5074  loss_cls: 0.4199  loss_box_reg: 0.09622  loss_rpn_cls: 0.01272  loss_rpn_loc: 0.003064  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 19:06:16] d2.utils.events INFO:  eta: 1:12:02  iter: 6579  total_loss: 0.4934  loss_cls: 0.3148  loss_box_reg: 0.1203  loss_rpn_cls: 0.01099  loss_rpn_loc: 0.002517  time: 1.2678  data_time: 0.0087  lr: 2e-05  max_mem: 19010M
[02/04 19:06:41] d2.utils.events INFO:  eta: 1:11:37  iter: 6599  total_loss: 0.5333  loss_cls: 0.4095  loss_box_reg: 0.08218  loss_rpn_cls: 0.013  loss_rpn_loc: 0.002113  time: 1.2678  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 19:07:07] d2.utils.events INFO:  eta: 1:11:11  iter: 6619  total_loss: 0.504  loss_cls: 0.4129  loss_box_reg: 0.07419  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.002936  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:07:32] d2.utils.events INFO:  eta: 1:10:46  iter: 6639  total_loss: 0.5883  loss_cls: 0.4477  loss_box_reg: 0.1097  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.002663  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:07:57] d2.utils.events INFO:  eta: 1:10:21  iter: 6659  total_loss: 0.559  loss_cls: 0.4325  loss_box_reg: 0.07928  loss_rpn_cls: 0.01009  loss_rpn_loc: 0.002014  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:08:23] d2.utils.events INFO:  eta: 1:09:55  iter: 6679  total_loss: 0.5101  loss_cls: 0.4125  loss_box_reg: 0.07513  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.003252  time: 1.2678  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:08:48] d2.utils.events INFO:  eta: 1:09:30  iter: 6699  total_loss: 0.4793  loss_cls: 0.368  loss_box_reg: 0.07652  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.002008  time: 1.2678  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:09:13] d2.utils.events INFO:  eta: 1:09:05  iter: 6719  total_loss: 0.4621  loss_cls: 0.3328  loss_box_reg: 0.06899  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.002701  time: 1.2678  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:09:39] d2.utils.events INFO:  eta: 1:08:39  iter: 6739  total_loss: 0.4609  loss_cls: 0.3591  loss_box_reg: 0.08635  loss_rpn_cls: 0.008941  loss_rpn_loc: 0.001888  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:10:04] d2.utils.events INFO:  eta: 1:08:14  iter: 6759  total_loss: 0.4552  loss_cls: 0.3289  loss_box_reg: 0.07806  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.002281  time: 1.2677  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:10:29] d2.utils.events INFO:  eta: 1:07:48  iter: 6779  total_loss: 0.5108  loss_cls: 0.3789  loss_box_reg: 0.0805  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.001834  time: 1.2677  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:10:55] d2.utils.events INFO:  eta: 1:07:23  iter: 6799  total_loss: 0.4937  loss_cls: 0.3592  loss_box_reg: 0.06483  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.002427  time: 1.2677  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:11:20] d2.utils.events INFO:  eta: 1:06:58  iter: 6819  total_loss: 0.4851  loss_cls: 0.3634  loss_box_reg: 0.1151  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.002971  time: 1.2677  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:11:45] d2.utils.events INFO:  eta: 1:06:33  iter: 6839  total_loss: 0.5078  loss_cls: 0.3746  loss_box_reg: 0.08836  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.002881  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:12:11] d2.utils.events INFO:  eta: 1:06:07  iter: 6859  total_loss: 0.5168  loss_cls: 0.4146  loss_box_reg: 0.08018  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.00251  time: 1.2677  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:12:36] d2.utils.events INFO:  eta: 1:05:42  iter: 6879  total_loss: 0.509  loss_cls: 0.3664  loss_box_reg: 0.1037  loss_rpn_cls: 0.0126  loss_rpn_loc: 0.002146  time: 1.2677  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:13:02] d2.utils.events INFO:  eta: 1:05:17  iter: 6899  total_loss: 0.5798  loss_cls: 0.4638  loss_box_reg: 0.06522  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.002921  time: 1.2677  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:13:27] d2.utils.events INFO:  eta: 1:04:52  iter: 6919  total_loss: 0.4122  loss_cls: 0.2955  loss_box_reg: 0.08119  loss_rpn_cls: 0.008317  loss_rpn_loc: 0.001838  time: 1.2677  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:13:52] d2.utils.events INFO:  eta: 1:04:26  iter: 6939  total_loss: 0.4851  loss_cls: 0.3494  loss_box_reg: 0.07023  loss_rpn_cls: 0.009457  loss_rpn_loc: 0.001823  time: 1.2677  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:14:18] d2.utils.events INFO:  eta: 1:04:01  iter: 6959  total_loss: 0.5316  loss_cls: 0.3885  loss_box_reg: 0.1147  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.002913  time: 1.2677  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:14:43] d2.utils.events INFO:  eta: 1:03:36  iter: 6979  total_loss: 0.449  loss_cls: 0.3416  loss_box_reg: 0.07923  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.002199  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:15:08] d2.utils.events INFO:  eta: 1:03:11  iter: 6999  total_loss: 0.5078  loss_cls: 0.3116  loss_box_reg: 0.08743  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.00203  time: 1.2677  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:15:34] d2.utils.events INFO:  eta: 1:02:46  iter: 7019  total_loss: 0.4773  loss_cls: 0.3782  loss_box_reg: 0.0936  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.001724  time: 1.2677  data_time: 0.0076  lr: 2e-05  max_mem: 19010M
[02/04 19:15:59] d2.utils.events INFO:  eta: 1:02:20  iter: 7039  total_loss: 0.4825  loss_cls: 0.4057  loss_box_reg: 0.0721  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.001983  time: 1.2677  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:16:24] d2.utils.events INFO:  eta: 1:01:55  iter: 7059  total_loss: 0.4962  loss_cls: 0.407  loss_box_reg: 0.1032  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.0045  time: 1.2677  data_time: 0.0074  lr: 2e-05  max_mem: 19010M
[02/04 19:16:50] d2.utils.events INFO:  eta: 1:01:29  iter: 7079  total_loss: 0.4174  loss_cls: 0.2683  loss_box_reg: 0.09816  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.001942  time: 1.2676  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:17:15] d2.utils.events INFO:  eta: 1:01:04  iter: 7099  total_loss: 0.5826  loss_cls: 0.4187  loss_box_reg: 0.08232  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.004032  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:17:40] d2.utils.events INFO:  eta: 1:00:39  iter: 7119  total_loss: 0.516  loss_cls: 0.4201  loss_box_reg: 0.09661  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.004051  time: 1.2676  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:18:06] d2.utils.events INFO:  eta: 1:00:14  iter: 7139  total_loss: 0.4711  loss_cls: 0.3524  loss_box_reg: 0.08007  loss_rpn_cls: 0.008709  loss_rpn_loc: 0.001611  time: 1.2676  data_time: 0.0083  lr: 2e-05  max_mem: 19010M
[02/04 19:18:31] d2.utils.events INFO:  eta: 0:59:48  iter: 7159  total_loss: 0.5401  loss_cls: 0.4484  loss_box_reg: 0.09542  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.003667  time: 1.2676  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:18:57] d2.utils.events INFO:  eta: 0:59:23  iter: 7179  total_loss: 0.5607  loss_cls: 0.4328  loss_box_reg: 0.1099  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.002957  time: 1.2676  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:19:22] d2.utils.events INFO:  eta: 0:58:58  iter: 7199  total_loss: 0.4591  loss_cls: 0.3366  loss_box_reg: 0.09393  loss_rpn_cls: 0.01314  loss_rpn_loc: 0.00191  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:19:47] d2.utils.events INFO:  eta: 0:58:33  iter: 7219  total_loss: 0.5016  loss_cls: 0.397  loss_box_reg: 0.07048  loss_rpn_cls: 0.009599  loss_rpn_loc: 0.001921  time: 1.2676  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:20:13] d2.utils.events INFO:  eta: 0:58:08  iter: 7239  total_loss: 0.5243  loss_cls: 0.3558  loss_box_reg: 0.1132  loss_rpn_cls: 0.008705  loss_rpn_loc: 0.002018  time: 1.2676  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:20:38] d2.utils.events INFO:  eta: 0:57:43  iter: 7259  total_loss: 0.4997  loss_cls: 0.3434  loss_box_reg: 0.1008  loss_rpn_cls: 0.014  loss_rpn_loc: 0.002589  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:21:04] d2.utils.events INFO:  eta: 0:57:17  iter: 7279  total_loss: 0.5509  loss_cls: 0.3531  loss_box_reg: 0.1339  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.002515  time: 1.2676  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:21:29] d2.utils.events INFO:  eta: 0:56:52  iter: 7299  total_loss: 0.5804  loss_cls: 0.4196  loss_box_reg: 0.08021  loss_rpn_cls: 0.00855  loss_rpn_loc: 0.001697  time: 1.2676  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:21:54] d2.utils.events INFO:  eta: 0:56:27  iter: 7319  total_loss: 0.4735  loss_cls: 0.3372  loss_box_reg: 0.08404  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.002814  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:22:20] d2.utils.events INFO:  eta: 0:56:02  iter: 7339  total_loss: 0.4542  loss_cls: 0.3337  loss_box_reg: 0.09939  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.002289  time: 1.2676  data_time: 0.0078  lr: 2e-05  max_mem: 19010M
[02/04 19:22:45] d2.utils.events INFO:  eta: 0:55:36  iter: 7359  total_loss: 0.4602  loss_cls: 0.3528  loss_box_reg: 0.09186  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.0022  time: 1.2676  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:23:10] d2.utils.events INFO:  eta: 0:55:12  iter: 7379  total_loss: 0.4942  loss_cls: 0.3884  loss_box_reg: 0.0969  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.002691  time: 1.2676  data_time: 0.0082  lr: 2e-05  max_mem: 19010M
[02/04 19:23:36] d2.utils.events INFO:  eta: 0:54:47  iter: 7399  total_loss: 0.5658  loss_cls: 0.4606  loss_box_reg: 0.06726  loss_rpn_cls: 0.01174  loss_rpn_loc: 0.002436  time: 1.2676  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:24:01] d2.utils.events INFO:  eta: 0:54:22  iter: 7419  total_loss: 0.5523  loss_cls: 0.3743  loss_box_reg: 0.1053  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.003591  time: 1.2676  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:24:26] d2.utils.events INFO:  eta: 0:53:57  iter: 7439  total_loss: 0.4574  loss_cls: 0.3509  loss_box_reg: 0.06254  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.002026  time: 1.2676  data_time: 0.0077  lr: 2e-05  max_mem: 19010M
[02/04 19:24:52] d2.utils.events INFO:  eta: 0:53:32  iter: 7459  total_loss: 0.5433  loss_cls: 0.3476  loss_box_reg: 0.08031  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.00284  time: 1.2676  data_time: 0.0080  lr: 2e-05  max_mem: 19010M
[02/04 19:25:17] d2.utils.events INFO:  eta: 0:53:07  iter: 7479  total_loss: 0.5563  loss_cls: 0.3974  loss_box_reg: 0.0934  loss_rpn_cls: 0.01207  loss_rpn_loc: 0.002758  time: 1.2676  data_time: 0.0079  lr: 2e-05  max_mem: 19010M
[02/04 19:25:42] d2.utils.events INFO:  eta: 0:52:42  iter: 7499  total_loss: 0.4703  loss_cls: 0.417  loss_box_reg: 0.1004  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.002899  time: 1.2675  data_time: 0.0081  lr: 2e-05  max_mem: 19010M
[02/04 19:26:08] d2.utils.events INFO:  eta: 0:52:16  iter: 7519  total_loss: 0.4022  loss_cls: 0.2931  loss_box_reg: 0.07885  loss_rpn_cls: 0.008678  loss_rpn_loc: 0.001552  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:26:33] d2.utils.events INFO:  eta: 0:51:51  iter: 7539  total_loss: 0.4879  loss_cls: 0.3551  loss_box_reg: 0.07006  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.00242  time: 1.2675  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 19:26:59] d2.utils.events INFO:  eta: 0:51:26  iter: 7559  total_loss: 0.4494  loss_cls: 0.3894  loss_box_reg: 0.08187  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.002214  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:27:24] d2.utils.events INFO:  eta: 0:51:01  iter: 7579  total_loss: 0.4956  loss_cls: 0.3886  loss_box_reg: 0.07775  loss_rpn_cls: 0.0146  loss_rpn_loc: 0.003903  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:27:50] d2.utils.events INFO:  eta: 0:50:36  iter: 7599  total_loss: 0.5019  loss_cls: 0.357  loss_box_reg: 0.1009  loss_rpn_cls: 0.01107  loss_rpn_loc: 0.001974  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:28:15] d2.utils.events INFO:  eta: 0:50:10  iter: 7619  total_loss: 0.428  loss_cls: 0.3169  loss_box_reg: 0.08089  loss_rpn_cls: 0.008321  loss_rpn_loc: 0.001365  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:28:40] d2.utils.events INFO:  eta: 0:49:45  iter: 7639  total_loss: 0.5009  loss_cls: 0.3254  loss_box_reg: 0.1123  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.002589  time: 1.2675  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 19:29:06] d2.utils.events INFO:  eta: 0:49:20  iter: 7659  total_loss: 0.4902  loss_cls: 0.335  loss_box_reg: 0.09831  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.002426  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:29:31] d2.utils.events INFO:  eta: 0:48:54  iter: 7679  total_loss: 0.4594  loss_cls: 0.349  loss_box_reg: 0.06474  loss_rpn_cls: 0.009071  loss_rpn_loc: 0.002234  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 19:29:56] d2.utils.events INFO:  eta: 0:48:29  iter: 7699  total_loss: 0.5231  loss_cls: 0.4053  loss_box_reg: 0.09634  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.002344  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:30:22] d2.utils.events INFO:  eta: 0:48:04  iter: 7719  total_loss: 0.4728  loss_cls: 0.3838  loss_box_reg: 0.0874  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.00223  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 19:30:47] d2.utils.events INFO:  eta: 0:47:39  iter: 7739  total_loss: 0.535  loss_cls: 0.4101  loss_box_reg: 0.08015  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.002359  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:31:12] d2.utils.events INFO:  eta: 0:47:14  iter: 7759  total_loss: 0.4369  loss_cls: 0.3069  loss_box_reg: 0.1113  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.002298  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:31:38] d2.utils.events INFO:  eta: 0:46:48  iter: 7779  total_loss: 0.5108  loss_cls: 0.3927  loss_box_reg: 0.07518  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.001874  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:32:03] d2.utils.events INFO:  eta: 0:46:23  iter: 7799  total_loss: 0.5423  loss_cls: 0.3948  loss_box_reg: 0.09188  loss_rpn_cls: 0.01002  loss_rpn_loc: 0.002474  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:32:29] d2.utils.events INFO:  eta: 0:45:57  iter: 7819  total_loss: 0.4843  loss_cls: 0.3526  loss_box_reg: 0.0926  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.001505  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:32:54] d2.utils.events INFO:  eta: 0:45:32  iter: 7839  total_loss: 0.4744  loss_cls: 0.3147  loss_box_reg: 0.08621  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.002415  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:33:19] d2.utils.events INFO:  eta: 0:45:07  iter: 7859  total_loss: 0.4729  loss_cls: 0.3207  loss_box_reg: 0.107  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.002383  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:33:45] d2.utils.events INFO:  eta: 0:44:41  iter: 7879  total_loss: 0.4225  loss_cls: 0.2958  loss_box_reg: 0.1088  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.00232  time: 1.2675  data_time: 0.0074  lr: 2e-06  max_mem: 19010M
[02/04 19:34:10] d2.utils.events INFO:  eta: 0:44:16  iter: 7899  total_loss: 0.5299  loss_cls: 0.4287  loss_box_reg: 0.1067  loss_rpn_cls: 0.01635  loss_rpn_loc: 0.002808  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:34:36] d2.utils.events INFO:  eta: 0:43:51  iter: 7919  total_loss: 0.5342  loss_cls: 0.3982  loss_box_reg: 0.08022  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.003325  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:35:01] d2.utils.events INFO:  eta: 0:43:26  iter: 7939  total_loss: 0.4734  loss_cls: 0.3228  loss_box_reg: 0.1231  loss_rpn_cls: 0.0124  loss_rpn_loc: 0.001635  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:35:26] d2.utils.events INFO:  eta: 0:43:01  iter: 7959  total_loss: 0.4973  loss_cls: 0.41  loss_box_reg: 0.07119  loss_rpn_cls: 0.009447  loss_rpn_loc: 0.001974  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:35:52] d2.utils.events INFO:  eta: 0:42:36  iter: 7979  total_loss: 0.5182  loss_cls: 0.3598  loss_box_reg: 0.06457  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.002348  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:36:17] d2.utils.events INFO:  eta: 0:42:11  iter: 7999  total_loss: 0.4835  loss_cls: 0.3676  loss_box_reg: 0.0937  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.00274  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:36:43] d2.utils.events INFO:  eta: 0:41:45  iter: 8019  total_loss: 0.5066  loss_cls: 0.3983  loss_box_reg: 0.08921  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.002311  time: 1.2675  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 19:37:08] d2.utils.events INFO:  eta: 0:41:20  iter: 8039  total_loss: 0.4743  loss_cls: 0.3521  loss_box_reg: 0.1275  loss_rpn_cls: 0.009385  loss_rpn_loc: 0.0022  time: 1.2675  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 19:37:33] d2.utils.events INFO:  eta: 0:40:55  iter: 8059  total_loss: 0.5116  loss_cls: 0.3898  loss_box_reg: 0.07901  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.002561  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:37:59] d2.utils.events INFO:  eta: 0:40:30  iter: 8079  total_loss: 0.4559  loss_cls: 0.3433  loss_box_reg: 0.08414  loss_rpn_cls: 0.01118  loss_rpn_loc: 0.002897  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:38:24] d2.utils.events INFO:  eta: 0:40:04  iter: 8099  total_loss: 0.4146  loss_cls: 0.2833  loss_box_reg: 0.08955  loss_rpn_cls: 0.00982  loss_rpn_loc: 0.001813  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 19:38:50] d2.utils.events INFO:  eta: 0:39:39  iter: 8119  total_loss: 0.4438  loss_cls: 0.323  loss_box_reg: 0.0774  loss_rpn_cls: 0.01084  loss_rpn_loc: 0.002535  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:39:15] d2.utils.events INFO:  eta: 0:39:14  iter: 8139  total_loss: 0.5494  loss_cls: 0.3761  loss_box_reg: 0.09474  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.002137  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:39:40] d2.utils.events INFO:  eta: 0:38:49  iter: 8159  total_loss: 0.4962  loss_cls: 0.3737  loss_box_reg: 0.1041  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.002554  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:40:06] d2.utils.events INFO:  eta: 0:38:23  iter: 8179  total_loss: 0.4361  loss_cls: 0.3586  loss_box_reg: 0.0726  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.003287  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:40:31] d2.utils.events INFO:  eta: 0:37:58  iter: 8199  total_loss: 0.4156  loss_cls: 0.2863  loss_box_reg: 0.1143  loss_rpn_cls: 0.009157  loss_rpn_loc: 0.001971  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:40:57] d2.utils.events INFO:  eta: 0:37:33  iter: 8219  total_loss: 0.5549  loss_cls: 0.4333  loss_box_reg: 0.1067  loss_rpn_cls: 0.01267  loss_rpn_loc: 0.002713  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:41:22] d2.utils.events INFO:  eta: 0:37:07  iter: 8239  total_loss: 0.5577  loss_cls: 0.4322  loss_box_reg: 0.09272  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.003009  time: 1.2675  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 19:41:47] d2.utils.events INFO:  eta: 0:36:42  iter: 8259  total_loss: 0.4858  loss_cls: 0.3217  loss_box_reg: 0.1131  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.002345  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:42:13] d2.utils.events INFO:  eta: 0:36:17  iter: 8279  total_loss: 0.4728  loss_cls: 0.3263  loss_box_reg: 0.08844  loss_rpn_cls: 0.009526  loss_rpn_loc: 0.001908  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:42:38] d2.utils.events INFO:  eta: 0:35:51  iter: 8299  total_loss: 0.5181  loss_cls: 0.3778  loss_box_reg: 0.1045  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.002674  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:43:04] d2.utils.events INFO:  eta: 0:35:26  iter: 8319  total_loss: 0.504  loss_cls: 0.4031  loss_box_reg: 0.08154  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.00298  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:43:29] d2.utils.events INFO:  eta: 0:35:01  iter: 8339  total_loss: 0.5055  loss_cls: 0.3903  loss_box_reg: 0.1015  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.002955  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:43:54] d2.utils.events INFO:  eta: 0:34:35  iter: 8359  total_loss: 0.5275  loss_cls: 0.3883  loss_box_reg: 0.1002  loss_rpn_cls: 0.01318  loss_rpn_loc: 0.002648  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:44:20] d2.utils.events INFO:  eta: 0:34:10  iter: 8379  total_loss: 0.5015  loss_cls: 0.3929  loss_box_reg: 0.08104  loss_rpn_cls: 0.009279  loss_rpn_loc: 0.00239  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:44:45] d2.utils.events INFO:  eta: 0:33:45  iter: 8399  total_loss: 0.4429  loss_cls: 0.3729  loss_box_reg: 0.08253  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.002171  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:45:10] d2.utils.events INFO:  eta: 0:33:19  iter: 8419  total_loss: 0.6087  loss_cls: 0.425  loss_box_reg: 0.1257  loss_rpn_cls: 0.01497  loss_rpn_loc: 0.004232  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:45:36] d2.utils.events INFO:  eta: 0:32:54  iter: 8439  total_loss: 0.4938  loss_cls: 0.3665  loss_box_reg: 0.0798  loss_rpn_cls: 0.008892  loss_rpn_loc: 0.001924  time: 1.2675  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:46:01] d2.utils.events INFO:  eta: 0:32:29  iter: 8459  total_loss: 0.4261  loss_cls: 0.307  loss_box_reg: 0.09039  loss_rpn_cls: 0.00953  loss_rpn_loc: 0.001936  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:46:27] d2.utils.events INFO:  eta: 0:32:04  iter: 8479  total_loss: 0.525  loss_cls: 0.3656  loss_box_reg: 0.09145  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.001438  time: 1.2675  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 19:46:52] d2.utils.events INFO:  eta: 0:31:38  iter: 8499  total_loss: 0.5135  loss_cls: 0.3959  loss_box_reg: 0.08128  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.002256  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:47:17] d2.utils.events INFO:  eta: 0:31:13  iter: 8519  total_loss: 0.4791  loss_cls: 0.4024  loss_box_reg: 0.08095  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.002119  time: 1.2675  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 19:47:43] d2.utils.events INFO:  eta: 0:30:48  iter: 8539  total_loss: 0.4333  loss_cls: 0.3403  loss_box_reg: 0.1006  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.002385  time: 1.2675  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:48:08] d2.utils.events INFO:  eta: 0:30:23  iter: 8559  total_loss: 0.4115  loss_cls: 0.3085  loss_box_reg: 0.1137  loss_rpn_cls: 0.008198  loss_rpn_loc: 0.002416  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:48:34] d2.utils.events INFO:  eta: 0:29:57  iter: 8579  total_loss: 0.4345  loss_cls: 0.3522  loss_box_reg: 0.07601  loss_rpn_cls: 0.008356  loss_rpn_loc: 0.0018  time: 1.2675  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 19:48:59] d2.utils.events INFO:  eta: 0:29:32  iter: 8599  total_loss: 0.5517  loss_cls: 0.423  loss_box_reg: 0.07779  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.002587  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:49:24] d2.utils.events INFO:  eta: 0:29:07  iter: 8619  total_loss: 0.5659  loss_cls: 0.447  loss_box_reg: 0.08176  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.002651  time: 1.2675  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:49:50] d2.utils.events INFO:  eta: 0:28:41  iter: 8639  total_loss: 0.5263  loss_cls: 0.3847  loss_box_reg: 0.09548  loss_rpn_cls: 0.008894  loss_rpn_loc: 0.001739  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:50:15] d2.utils.events INFO:  eta: 0:28:16  iter: 8659  total_loss: 0.4833  loss_cls: 0.3753  loss_box_reg: 0.07523  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.002991  time: 1.2675  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:50:41] d2.utils.events INFO:  eta: 0:27:51  iter: 8679  total_loss: 0.5134  loss_cls: 0.4182  loss_box_reg: 0.07383  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.002102  time: 1.2675  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:51:06] d2.utils.events INFO:  eta: 0:27:25  iter: 8699  total_loss: 0.5014  loss_cls: 0.3373  loss_box_reg: 0.103  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.002843  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:51:31] d2.utils.events INFO:  eta: 0:27:00  iter: 8719  total_loss: 0.4295  loss_cls: 0.2912  loss_box_reg: 0.07969  loss_rpn_cls: 0.008082  loss_rpn_loc: 0.001429  time: 1.2674  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 19:51:57] d2.utils.events INFO:  eta: 0:26:34  iter: 8739  total_loss: 0.5545  loss_cls: 0.4369  loss_box_reg: 0.07752  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.001766  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:52:22] d2.utils.events INFO:  eta: 0:26:09  iter: 8759  total_loss: 0.4852  loss_cls: 0.3211  loss_box_reg: 0.1096  loss_rpn_cls: 0.008062  loss_rpn_loc: 0.001864  time: 1.2674  data_time: 0.0084  lr: 2e-06  max_mem: 19010M
[02/04 19:52:47] d2.utils.events INFO:  eta: 0:25:44  iter: 8779  total_loss: 0.4395  loss_cls: 0.3299  loss_box_reg: 0.06076  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.003304  time: 1.2674  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 19:53:13] d2.utils.events INFO:  eta: 0:25:19  iter: 8799  total_loss: 0.4904  loss_cls: 0.3705  loss_box_reg: 0.1046  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.002635  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:53:38] d2.utils.events INFO:  eta: 0:24:53  iter: 8819  total_loss: 0.4887  loss_cls: 0.3655  loss_box_reg: 0.09412  loss_rpn_cls: 0.01175  loss_rpn_loc: 0.002665  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:54:04] d2.utils.events INFO:  eta: 0:24:28  iter: 8839  total_loss: 0.4559  loss_cls: 0.3662  loss_box_reg: 0.1003  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.002406  time: 1.2674  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:54:29] d2.utils.events INFO:  eta: 0:24:03  iter: 8859  total_loss: 0.579  loss_cls: 0.3895  loss_box_reg: 0.09859  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.002911  time: 1.2674  data_time: 0.0084  lr: 2e-06  max_mem: 19010M
[02/04 19:54:54] d2.utils.events INFO:  eta: 0:23:38  iter: 8879  total_loss: 0.4757  loss_cls: 0.3597  loss_box_reg: 0.08507  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.002079  time: 1.2674  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 19:55:20] d2.utils.events INFO:  eta: 0:23:12  iter: 8899  total_loss: 0.4595  loss_cls: 0.3496  loss_box_reg: 0.09179  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.002581  time: 1.2674  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 19:55:45] d2.utils.events INFO:  eta: 0:22:47  iter: 8919  total_loss: 0.4964  loss_cls: 0.3758  loss_box_reg: 0.1002  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.002756  time: 1.2674  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:56:10] d2.utils.events INFO:  eta: 0:22:21  iter: 8939  total_loss: 0.4934  loss_cls: 0.4204  loss_box_reg: 0.06513  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.003199  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:56:36] d2.utils.events INFO:  eta: 0:21:56  iter: 8959  total_loss: 0.5521  loss_cls: 0.425  loss_box_reg: 0.08767  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.001903  time: 1.2674  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 19:57:01] d2.utils.events INFO:  eta: 0:21:30  iter: 8979  total_loss: 0.4501  loss_cls: 0.3121  loss_box_reg: 0.09117  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.002101  time: 1.2674  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 19:57:26] d2.utils.events INFO:  eta: 0:21:05  iter: 8999  total_loss: 0.5299  loss_cls: 0.4167  loss_box_reg: 0.08111  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.002492  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:57:52] d2.utils.events INFO:  eta: 0:20:40  iter: 9019  total_loss: 0.5163  loss_cls: 0.3477  loss_box_reg: 0.1077  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.003254  time: 1.2674  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:58:17] d2.utils.events INFO:  eta: 0:20:14  iter: 9039  total_loss: 0.5291  loss_cls: 0.3798  loss_box_reg: 0.08746  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.002129  time: 1.2674  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 19:58:43] d2.utils.events INFO:  eta: 0:19:49  iter: 9059  total_loss: 0.5054  loss_cls: 0.3643  loss_box_reg: 0.09531  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.004453  time: 1.2674  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:59:08] d2.utils.events INFO:  eta: 0:19:24  iter: 9079  total_loss: 0.4424  loss_cls: 0.3382  loss_box_reg: 0.07335  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.002471  time: 1.2674  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 19:59:33] d2.utils.events INFO:  eta: 0:18:58  iter: 9099  total_loss: 0.5306  loss_cls: 0.3642  loss_box_reg: 0.1028  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.002485  time: 1.2674  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 19:59:59] d2.utils.events INFO:  eta: 0:18:33  iter: 9119  total_loss: 0.4607  loss_cls: 0.3538  loss_box_reg: 0.08264  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.002276  time: 1.2674  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 20:00:24] d2.utils.events INFO:  eta: 0:18:08  iter: 9139  total_loss: 0.5196  loss_cls: 0.3268  loss_box_reg: 0.1134  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.002978  time: 1.2674  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 20:00:49] d2.utils.events INFO:  eta: 0:17:42  iter: 9159  total_loss: 0.5234  loss_cls: 0.4171  loss_box_reg: 0.05149  loss_rpn_cls: 0.01376  loss_rpn_loc: 0.00325  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 20:01:15] d2.utils.events INFO:  eta: 0:17:17  iter: 9179  total_loss: 0.4996  loss_cls: 0.3934  loss_box_reg: 0.08821  loss_rpn_cls: 0.01186  loss_rpn_loc: 0.002837  time: 1.2673  data_time: 0.0075  lr: 2e-06  max_mem: 19010M
[02/04 20:01:40] d2.utils.events INFO:  eta: 0:16:52  iter: 9199  total_loss: 0.4993  loss_cls: 0.3412  loss_box_reg: 0.1299  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.002965  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 20:02:05] d2.utils.events INFO:  eta: 0:16:26  iter: 9219  total_loss: 0.4861  loss_cls: 0.3784  loss_box_reg: 0.09128  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.002663  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 20:02:31] d2.utils.events INFO:  eta: 0:16:01  iter: 9239  total_loss: 0.4866  loss_cls: 0.3559  loss_box_reg: 0.08615  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.002829  time: 1.2673  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 20:02:56] d2.utils.events INFO:  eta: 0:15:36  iter: 9259  total_loss: 0.5252  loss_cls: 0.3783  loss_box_reg: 0.0809  loss_rpn_cls: 0.01407  loss_rpn_loc: 0.002844  time: 1.2673  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 20:03:22] d2.utils.events INFO:  eta: 0:15:11  iter: 9279  total_loss: 0.4863  loss_cls: 0.3868  loss_box_reg: 0.06763  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.002763  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:03:47] d2.utils.events INFO:  eta: 0:14:45  iter: 9299  total_loss: 0.4622  loss_cls: 0.3215  loss_box_reg: 0.06938  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.002604  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:04:12] d2.utils.events INFO:  eta: 0:14:20  iter: 9319  total_loss: 0.5018  loss_cls: 0.3703  loss_box_reg: 0.09152  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.001999  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 20:04:38] d2.utils.events INFO:  eta: 0:13:54  iter: 9339  total_loss: 0.4265  loss_cls: 0.3055  loss_box_reg: 0.07297  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.00259  time: 1.2673  data_time: 0.0082  lr: 2e-06  max_mem: 19010M
[02/04 20:05:03] d2.utils.events INFO:  eta: 0:13:29  iter: 9359  total_loss: 0.4434  loss_cls: 0.3287  loss_box_reg: 0.09403  loss_rpn_cls: 0.009657  loss_rpn_loc: 0.001825  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 20:05:28] d2.utils.events INFO:  eta: 0:13:04  iter: 9379  total_loss: 0.4409  loss_cls: 0.3255  loss_box_reg: 0.06263  loss_rpn_cls: 0.00961  loss_rpn_loc: 0.002085  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 20:05:54] d2.utils.events INFO:  eta: 0:12:38  iter: 9399  total_loss: 0.4599  loss_cls: 0.313  loss_box_reg: 0.09451  loss_rpn_cls: 0.008923  loss_rpn_loc: 0.001702  time: 1.2673  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 20:06:19] d2.utils.events INFO:  eta: 0:12:13  iter: 9419  total_loss: 0.5576  loss_cls: 0.3853  loss_box_reg: 0.07753  loss_rpn_cls: 0.01155  loss_rpn_loc: 0.002366  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 20:06:45] d2.utils.events INFO:  eta: 0:11:48  iter: 9439  total_loss: 0.4541  loss_cls: 0.3165  loss_box_reg: 0.1148  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.003723  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 20:07:10] d2.utils.events INFO:  eta: 0:11:22  iter: 9459  total_loss: 0.5049  loss_cls: 0.3847  loss_box_reg: 0.08389  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.00227  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:07:35] d2.utils.events INFO:  eta: 0:10:57  iter: 9479  total_loss: 0.4178  loss_cls: 0.3054  loss_box_reg: 0.1025  loss_rpn_cls: 0.01324  loss_rpn_loc: 0.002978  time: 1.2673  data_time: 0.0074  lr: 2e-06  max_mem: 19010M
[02/04 20:08:01] d2.utils.events INFO:  eta: 0:10:32  iter: 9499  total_loss: 0.4642  loss_cls: 0.3414  loss_box_reg: 0.06418  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.002601  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 20:08:26] d2.utils.events INFO:  eta: 0:10:06  iter: 9519  total_loss: 0.4373  loss_cls: 0.343  loss_box_reg: 0.08265  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.002373  time: 1.2673  data_time: 0.0084  lr: 2e-06  max_mem: 19010M
[02/04 20:08:51] d2.utils.events INFO:  eta: 0:09:41  iter: 9539  total_loss: 0.4804  loss_cls: 0.3271  loss_box_reg: 0.0978  loss_rpn_cls: 0.01048  loss_rpn_loc: 0.002086  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:09:17] d2.utils.events INFO:  eta: 0:09:16  iter: 9559  total_loss: 0.4922  loss_cls: 0.4023  loss_box_reg: 0.09551  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.003546  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:09:42] d2.utils.events INFO:  eta: 0:08:51  iter: 9579  total_loss: 0.4885  loss_cls: 0.3595  loss_box_reg: 0.07182  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.002152  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 20:10:08] d2.utils.events INFO:  eta: 0:08:25  iter: 9599  total_loss: 0.5145  loss_cls: 0.3928  loss_box_reg: 0.07602  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.001921  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 20:10:33] d2.utils.events INFO:  eta: 0:08:00  iter: 9619  total_loss: 0.4776  loss_cls: 0.2953  loss_box_reg: 0.09598  loss_rpn_cls: 0.01131  loss_rpn_loc: 0.00269  time: 1.2673  data_time: 0.0084  lr: 2e-06  max_mem: 19010M
[02/04 20:10:58] d2.utils.events INFO:  eta: 0:07:35  iter: 9639  total_loss: 0.48  loss_cls: 0.3785  loss_box_reg: 0.09519  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.003061  time: 1.2673  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 20:11:24] d2.utils.events INFO:  eta: 0:07:09  iter: 9659  total_loss: 0.4612  loss_cls: 0.3279  loss_box_reg: 0.09827  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.002092  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:11:49] d2.utils.events INFO:  eta: 0:06:44  iter: 9679  total_loss: 0.4761  loss_cls: 0.35  loss_box_reg: 0.08998  loss_rpn_cls: 0.01391  loss_rpn_loc: 0.002257  time: 1.2673  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 20:12:14] d2.utils.events INFO:  eta: 0:06:19  iter: 9699  total_loss: 0.5238  loss_cls: 0.4049  loss_box_reg: 0.08614  loss_rpn_cls: 0.00879  loss_rpn_loc: 0.001794  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 20:12:40] d2.utils.events INFO:  eta: 0:05:54  iter: 9719  total_loss: 0.49  loss_cls: 0.3373  loss_box_reg: 0.1013  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.002503  time: 1.2673  data_time: 0.0081  lr: 2e-06  max_mem: 19010M
[02/04 20:13:05] d2.utils.events INFO:  eta: 0:05:28  iter: 9739  total_loss: 0.513  loss_cls: 0.3918  loss_box_reg: 0.1044  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.002633  time: 1.2673  data_time: 0.0083  lr: 2e-06  max_mem: 19010M
[02/04 20:13:31] d2.utils.events INFO:  eta: 0:05:03  iter: 9759  total_loss: 0.5273  loss_cls: 0.3941  loss_box_reg: 0.1022  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.002831  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:13:56] d2.utils.events INFO:  eta: 0:04:38  iter: 9779  total_loss: 0.433  loss_cls: 0.3298  loss_box_reg: 0.07992  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.001894  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:14:22] d2.utils.events INFO:  eta: 0:04:12  iter: 9799  total_loss: 0.4816  loss_cls: 0.3764  loss_box_reg: 0.07516  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.002669  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 20:14:47] d2.utils.events INFO:  eta: 0:03:47  iter: 9819  total_loss: 0.4303  loss_cls: 0.3438  loss_box_reg: 0.06531  loss_rpn_cls: 0.01019  loss_rpn_loc: 0.002754  time: 1.2673  data_time: 0.0087  lr: 2e-06  max_mem: 19010M
[02/04 20:15:12] d2.utils.events INFO:  eta: 0:03:22  iter: 9839  total_loss: 0.4644  loss_cls: 0.3652  loss_box_reg: 0.06931  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.002148  time: 1.2673  data_time: 0.0077  lr: 2e-06  max_mem: 19010M
[02/04 20:15:38] d2.utils.events INFO:  eta: 0:02:57  iter: 9859  total_loss: 0.5563  loss_cls: 0.4048  loss_box_reg: 0.09979  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.002639  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:16:03] d2.utils.events INFO:  eta: 0:02:31  iter: 9879  total_loss: 0.389  loss_cls: 0.2701  loss_box_reg: 0.0857  loss_rpn_cls: 0.009017  loss_rpn_loc: 0.001343  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 20:16:28] d2.utils.events INFO:  eta: 0:02:06  iter: 9899  total_loss: 0.577  loss_cls: 0.459  loss_box_reg: 0.07908  loss_rpn_cls: 0.01388  loss_rpn_loc: 0.002614  time: 1.2673  data_time: 0.0080  lr: 2e-06  max_mem: 19010M
[02/04 20:16:54] d2.utils.events INFO:  eta: 0:01:41  iter: 9919  total_loss: 0.4549  loss_cls: 0.3242  loss_box_reg: 0.08262  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.002201  time: 1.2673  data_time: 0.0079  lr: 2e-06  max_mem: 19010M
[02/04 20:17:19] d2.utils.events INFO:  eta: 0:01:15  iter: 9939  total_loss: 0.4922  loss_cls: 0.3472  loss_box_reg: 0.08347  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.001893  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 20:17:45] d2.utils.events INFO:  eta: 0:00:50  iter: 9959  total_loss: 0.4899  loss_cls: 0.3729  loss_box_reg: 0.1014  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.001958  time: 1.2673  data_time: 0.0078  lr: 2e-06  max_mem: 19010M
[02/04 20:18:10] d2.utils.events INFO:  eta: 0:00:25  iter: 9979  total_loss: 0.5301  loss_cls: 0.3495  loss_box_reg: 0.09601  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.002533  time: 1.2673  data_time: 0.0076  lr: 2e-06  max_mem: 19010M
[02/04 20:18:35] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_0009999.pth
[02/04 20:18:36] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/fsod/two_branch_training_pascalvoc_split1_pvt_v2_b2_li/model_final.pth
[02/04 20:18:37] d2.utils.events INFO:  eta: 0:00:00  iter: 9999  total_loss: 0.4921  loss_cls: 0.3802  loss_box_reg: 0.07777  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.002641  time: 1.2673  data_time: 0.0079  lr: 2e-07  max_mem: 19010M
[02/04 20:18:37] d2.engine.hooks INFO: Overall training speed: 9998 iterations in 3:31:10 (1.2673 s / it)
[02/04 20:18:37] d2.engine.hooks INFO: Total training time: 3:31:39 (0:00:28 on hooks)
[02/04 20:18:38] d2.data.build INFO: Distribution of instances among all 20 categories:
|  category  | #instances   |  category   | #instances   |  category   | #instances   |
|:----------:|:-------------|:-----------:|:-------------|:-----------:|:-------------|
| aeroplane  | 285          |   bicycle   | 337          |    boat     | 263          |
|   bottle   | 469          |     car     | 1201         |     cat     | 358          |
|   chair    | 756          | diningtable | 206          |     dog     | 489          |
|   horse    | 348          |   person    | 4528         | pottedplant | 480          |
|   sheep    | 242          |    train    | 282          |  tvmonitor  | 308          |
|    bird    | 459          |     bus     | 213          |     cow     | 244          |
| motorbike  | 325          |    sofa     | 239          |             |              |
|   total    | 12032        |             |              |             |              |
[02/04 20:18:38] d2.data.common INFO: Serializing 4952 elements to byte tensors and concatenating them all ...
[02/04 20:18:38] d2.data.common INFO: Serialized dataset takes 2.12 MiB
[02/04 20:18:38] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[02/04 20:18:48] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0006 s/iter. Inference: 0.8844 s/iter. Eval: 0.0008 s/iter. Total: 0.8858 s/iter. ETA=1:12:56
[02/04 20:18:53] d2.evaluation.evaluator INFO: Inference done 17/4952. Dataloading: 0.0004 s/iter. Inference: 0.8777 s/iter. Eval: 0.0008 s/iter. Total: 0.8790 s/iter. ETA=1:12:17
[02/04 20:18:58] d2.evaluation.evaluator INFO: Inference done 23/4952. Dataloading: 0.0005 s/iter. Inference: 0.8782 s/iter. Eval: 0.0008 s/iter. Total: 0.8796 s/iter. ETA=1:12:15
[02/04 20:19:04] d2.evaluation.evaluator INFO: Inference done 29/4952. Dataloading: 0.0006 s/iter. Inference: 0.8788 s/iter. Eval: 0.0008 s/iter. Total: 0.8802 s/iter. ETA=1:12:13
[02/04 20:19:09] d2.evaluation.evaluator INFO: Inference done 35/4952. Dataloading: 0.0006 s/iter. Inference: 0.8792 s/iter. Eval: 0.0008 s/iter. Total: 0.8806 s/iter. ETA=1:12:10
[02/04 20:19:14] d2.evaluation.evaluator INFO: Inference done 41/4952. Dataloading: 0.0006 s/iter. Inference: 0.8789 s/iter. Eval: 0.0008 s/iter. Total: 0.8804 s/iter. ETA=1:12:03
[02/04 20:19:19] d2.evaluation.evaluator INFO: Inference done 47/4952. Dataloading: 0.0006 s/iter. Inference: 0.8813 s/iter. Eval: 0.0008 s/iter. Total: 0.8828 s/iter. ETA=1:12:09
[02/04 20:19:25] d2.evaluation.evaluator INFO: Inference done 53/4952. Dataloading: 0.0006 s/iter. Inference: 0.8813 s/iter. Eval: 0.0008 s/iter. Total: 0.8828 s/iter. ETA=1:12:04
[02/04 20:19:30] d2.evaluation.evaluator INFO: Inference done 59/4952. Dataloading: 0.0006 s/iter. Inference: 0.8824 s/iter. Eval: 0.0008 s/iter. Total: 0.8839 s/iter. ETA=1:12:04
[02/04 20:19:35] d2.evaluation.evaluator INFO: Inference done 65/4952. Dataloading: 0.0006 s/iter. Inference: 0.8806 s/iter. Eval: 0.0008 s/iter. Total: 0.8821 s/iter. ETA=1:11:50
[02/04 20:19:41] d2.evaluation.evaluator INFO: Inference done 71/4952. Dataloading: 0.0006 s/iter. Inference: 0.8799 s/iter. Eval: 0.0008 s/iter. Total: 0.8814 s/iter. ETA=1:11:41
[02/04 20:19:46] d2.evaluation.evaluator INFO: Inference done 77/4952. Dataloading: 0.0006 s/iter. Inference: 0.8798 s/iter. Eval: 0.0008 s/iter. Total: 0.8813 s/iter. ETA=1:11:36
[02/04 20:19:51] d2.evaluation.evaluator INFO: Inference done 83/4952. Dataloading: 0.0006 s/iter. Inference: 0.8796 s/iter. Eval: 0.0008 s/iter. Total: 0.8811 s/iter. ETA=1:11:30
[02/04 20:19:56] d2.evaluation.evaluator INFO: Inference done 89/4952. Dataloading: 0.0007 s/iter. Inference: 0.8797 s/iter. Eval: 0.0008 s/iter. Total: 0.8812 s/iter. ETA=1:11:25
[02/04 20:20:02] d2.evaluation.evaluator INFO: Inference done 95/4952. Dataloading: 0.0007 s/iter. Inference: 0.8787 s/iter. Eval: 0.0008 s/iter. Total: 0.8802 s/iter. ETA=1:11:15
[02/04 20:20:07] d2.evaluation.evaluator INFO: Inference done 101/4952. Dataloading: 0.0007 s/iter. Inference: 0.8789 s/iter. Eval: 0.0008 s/iter. Total: 0.8804 s/iter. ETA=1:11:10
[02/04 20:20:12] d2.evaluation.evaluator INFO: Inference done 107/4952. Dataloading: 0.0007 s/iter. Inference: 0.8784 s/iter. Eval: 0.0008 s/iter. Total: 0.8799 s/iter. ETA=1:11:03
[02/04 20:20:17] d2.evaluation.evaluator INFO: Inference done 113/4952. Dataloading: 0.0007 s/iter. Inference: 0.8788 s/iter. Eval: 0.0008 s/iter. Total: 0.8803 s/iter. ETA=1:10:59
[02/04 20:20:23] d2.evaluation.evaluator INFO: Inference done 119/4952. Dataloading: 0.0007 s/iter. Inference: 0.8787 s/iter. Eval: 0.0008 s/iter. Total: 0.8802 s/iter. ETA=1:10:53
[02/04 20:20:28] d2.evaluation.evaluator INFO: Inference done 125/4952. Dataloading: 0.0007 s/iter. Inference: 0.8795 s/iter. Eval: 0.0008 s/iter. Total: 0.8810 s/iter. ETA=1:10:52
[02/04 20:20:33] d2.evaluation.evaluator INFO: Inference done 131/4952. Dataloading: 0.0007 s/iter. Inference: 0.8799 s/iter. Eval: 0.0008 s/iter. Total: 0.8814 s/iter. ETA=1:10:49
[02/04 20:20:39] d2.evaluation.evaluator INFO: Inference done 137/4952. Dataloading: 0.0007 s/iter. Inference: 0.8803 s/iter. Eval: 0.0008 s/iter. Total: 0.8818 s/iter. ETA=1:10:45
[02/04 20:20:44] d2.evaluation.evaluator INFO: Inference done 143/4952. Dataloading: 0.0007 s/iter. Inference: 0.8801 s/iter. Eval: 0.0008 s/iter. Total: 0.8816 s/iter. ETA=1:10:39
[02/04 20:20:49] d2.evaluation.evaluator INFO: Inference done 149/4952. Dataloading: 0.0007 s/iter. Inference: 0.8799 s/iter. Eval: 0.0008 s/iter. Total: 0.8815 s/iter. ETA=1:10:33
[02/04 20:20:55] d2.evaluation.evaluator INFO: Inference done 155/4952. Dataloading: 0.0007 s/iter. Inference: 0.8793 s/iter. Eval: 0.0008 s/iter. Total: 0.8808 s/iter. ETA=1:10:25
[02/04 20:21:00] d2.evaluation.evaluator INFO: Inference done 161/4952. Dataloading: 0.0007 s/iter. Inference: 0.8794 s/iter. Eval: 0.0008 s/iter. Total: 0.8809 s/iter. ETA=1:10:20
[02/04 20:21:05] d2.evaluation.evaluator INFO: Inference done 167/4952. Dataloading: 0.0007 s/iter. Inference: 0.8792 s/iter. Eval: 0.0008 s/iter. Total: 0.8807 s/iter. ETA=1:10:14
[02/04 20:21:10] d2.evaluation.evaluator INFO: Inference done 173/4952. Dataloading: 0.0007 s/iter. Inference: 0.8794 s/iter. Eval: 0.0008 s/iter. Total: 0.8809 s/iter. ETA=1:10:09
[02/04 20:21:16] d2.evaluation.evaluator INFO: Inference done 179/4952. Dataloading: 0.0007 s/iter. Inference: 0.8794 s/iter. Eval: 0.0008 s/iter. Total: 0.8809 s/iter. ETA=1:10:04
[02/04 20:21:21] d2.evaluation.evaluator INFO: Inference done 185/4952. Dataloading: 0.0007 s/iter. Inference: 0.8795 s/iter. Eval: 0.0008 s/iter. Total: 0.8810 s/iter. ETA=1:09:59
[02/04 20:21:26] d2.evaluation.evaluator INFO: Inference done 191/4952. Dataloading: 0.0007 s/iter. Inference: 0.8796 s/iter. Eval: 0.0008 s/iter. Total: 0.8811 s/iter. ETA=1:09:55
[02/04 20:21:32] d2.evaluation.evaluator INFO: Inference done 197/4952. Dataloading: 0.0007 s/iter. Inference: 0.8795 s/iter. Eval: 0.0008 s/iter. Total: 0.8810 s/iter. ETA=1:09:49
[02/04 20:21:37] d2.evaluation.evaluator INFO: Inference done 203/4952. Dataloading: 0.0007 s/iter. Inference: 0.8795 s/iter. Eval: 0.0008 s/iter. Total: 0.8810 s/iter. ETA=1:09:43
[02/04 20:21:42] d2.evaluation.evaluator INFO: Inference done 209/4952. Dataloading: 0.0007 s/iter. Inference: 0.8798 s/iter. Eval: 0.0008 s/iter. Total: 0.8813 s/iter. ETA=1:09:40
[02/04 20:21:47] d2.evaluation.evaluator INFO: Inference done 215/4952. Dataloading: 0.0007 s/iter. Inference: 0.8793 s/iter. Eval: 0.0008 s/iter. Total: 0.8809 s/iter. ETA=1:09:32
[02/04 20:21:53] d2.evaluation.evaluator INFO: Inference done 221/4952. Dataloading: 0.0007 s/iter. Inference: 0.8792 s/iter. Eval: 0.0008 s/iter. Total: 0.8807 s/iter. ETA=1:09:26
[02/04 20:21:58] d2.evaluation.evaluator INFO: Inference done 227/4952. Dataloading: 0.0007 s/iter. Inference: 0.8794 s/iter. Eval: 0.0008 s/iter. Total: 0.8809 s/iter. ETA=1:09:22
[02/04 20:22:03] d2.evaluation.evaluator INFO: Inference done 233/4952. Dataloading: 0.0007 s/iter. Inference: 0.8797 s/iter. Eval: 0.0008 s/iter. Total: 0.8812 s/iter. ETA=1:09:18
[02/04 20:22:09] d2.evaluation.evaluator INFO: Inference done 239/4952. Dataloading: 0.0007 s/iter. Inference: 0.8796 s/iter. Eval: 0.0008 s/iter. Total: 0.8811 s/iter. ETA=1:09:12
[02/04 20:22:14] d2.evaluation.evaluator INFO: Inference done 245/4952. Dataloading: 0.0007 s/iter. Inference: 0.8797 s/iter. Eval: 0.0008 s/iter. Total: 0.8812 s/iter. ETA=1:09:07
[02/04 20:22:19] d2.evaluation.evaluator INFO: Inference done 251/4952. Dataloading: 0.0007 s/iter. Inference: 0.8797 s/iter. Eval: 0.0008 s/iter. Total: 0.8812 s/iter. ETA=1:09:02
[02/04 20:22:24] d2.evaluation.evaluator INFO: Inference done 257/4952. Dataloading: 0.0007 s/iter. Inference: 0.8796 s/iter. Eval: 0.0008 s/iter. Total: 0.8811 s/iter. ETA=1:08:56
[02/04 20:22:30] d2.evaluation.evaluator INFO: Inference done 263/4952. Dataloading: 0.0007 s/iter. Inference: 0.8794 s/iter. Eval: 0.0008 s/iter. Total: 0.8810 s/iter. ETA=1:08:50
[02/04 20:22:35] d2.evaluation.evaluator INFO: Inference done 269/4952. Dataloading: 0.0007 s/iter. Inference: 0.8792 s/iter. Eval: 0.0008 s/iter. Total: 0.8807 s/iter. ETA=1:08:44
[02/04 20:22:40] d2.evaluation.evaluator INFO: Inference done 275/4952. Dataloading: 0.0007 s/iter. Inference: 0.8791 s/iter. Eval: 0.0008 s/iter. Total: 0.8806 s/iter. ETA=1:08:38
[02/04 20:22:45] d2.evaluation.evaluator INFO: Inference done 281/4952. Dataloading: 0.0007 s/iter. Inference: 0.8791 s/iter. Eval: 0.0008 s/iter. Total: 0.8806 s/iter. ETA=1:08:33
[02/04 20:22:51] d2.evaluation.evaluator INFO: Inference done 287/4952. Dataloading: 0.0007 s/iter. Inference: 0.8792 s/iter. Eval: 0.0008 s/iter. Total: 0.8807 s/iter. ETA=1:08:28
[02/04 20:22:56] d2.evaluation.evaluator INFO: Inference done 293/4952. Dataloading: 0.0007 s/iter. Inference: 0.8789 s/iter. Eval: 0.0008 s/iter. Total: 0.8804 s/iter. ETA=1:08:21
[02/04 20:23:01] d2.evaluation.evaluator INFO: Inference done 299/4952. Dataloading: 0.0007 s/iter. Inference: 0.8790 s/iter. Eval: 0.0008 s/iter. Total: 0.8805 s/iter. ETA=1:08:16
[02/04 20:23:07] d2.evaluation.evaluator INFO: Inference done 305/4952. Dataloading: 0.0007 s/iter. Inference: 0.8789 s/iter. Eval: 0.0008 s/iter. Total: 0.8804 s/iter. ETA=1:08:11
[02/04 20:23:12] d2.evaluation.evaluator INFO: Inference done 311/4952. Dataloading: 0.0007 s/iter. Inference: 0.8790 s/iter. Eval: 0.0008 s/iter. Total: 0.8806 s/iter. ETA=1:08:06
[02/04 20:23:17] d2.evaluation.evaluator INFO: Inference done 317/4952. Dataloading: 0.0007 s/iter. Inference: 0.8790 s/iter. Eval: 0.0008 s/iter. Total: 0.8805 s/iter. ETA=1:08:01
[02/04 20:23:22] d2.evaluation.evaluator INFO: Inference done 323/4952. Dataloading: 0.0007 s/iter. Inference: 0.8790 s/iter. Eval: 0.0008 s/iter. Total: 0.8805 s/iter. ETA=1:07:55
[02/04 20:23:28] d2.evaluation.evaluator INFO: Inference done 329/4952. Dataloading: 0.0007 s/iter. Inference: 0.8790 s/iter. Eval: 0.0008 s/iter. Total: 0.8805 s/iter. ETA=1:07:50
[02/04 20:23:33] d2.evaluation.evaluator INFO: Inference done 335/4952. Dataloading: 0.0007 s/iter. Inference: 0.8789 s/iter. Eval: 0.0008 s/iter. Total: 0.8804 s/iter. ETA=1:07:45
[02/04 20:23:38] d2.evaluation.evaluator INFO: Inference done 341/4952. Dataloading: 0.0007 s/iter. Inference: 0.8791 s/iter. Eval: 0.0008 s/iter. Total: 0.8806 s/iter. ETA=1:07:40
[02/04 20:23:44] d2.evaluation.evaluator INFO: Inference done 347/4952. Dataloading: 0.0007 s/iter. Inference: 0.8793 s/iter. Eval: 0.0008 s/iter. Total: 0.8808 s/iter. ETA=1:07:36
[02/04 20:23:49] d2.evaluation.evaluator INFO: Inference done 353/4952. Dataloading: 0.0007 s/iter. Inference: 0.8797 s/iter. Eval: 0.0008 s/iter. Total: 0.8812 s/iter. ETA=1:07:32
[02/04 20:23:54] d2.evaluation.evaluator INFO: Inference done 359/4952. Dataloading: 0.0007 s/iter. Inference: 0.8800 s/iter. Eval: 0.0008 s/iter. Total: 0.8815 s/iter. ETA=1:07:28
[02/04 20:24:00] d2.evaluation.evaluator INFO: Inference done 365/4952. Dataloading: 0.0007 s/iter. Inference: 0.8802 s/iter. Eval: 0.0008 s/iter. Total: 0.8818 s/iter. ETA=1:07:24
[02/04 20:24:05] d2.evaluation.evaluator INFO: Inference done 371/4952. Dataloading: 0.0007 s/iter. Inference: 0.8801 s/iter. Eval: 0.0008 s/iter. Total: 0.8817 s/iter. ETA=1:07:18
[02/04 20:24:10] d2.evaluation.evaluator INFO: Inference done 377/4952. Dataloading: 0.0007 s/iter. Inference: 0.8803 s/iter. Eval: 0.0008 s/iter. Total: 0.8818 s/iter. ETA=1:07:14
[02/04 20:24:16] d2.evaluation.evaluator INFO: Inference done 383/4952. Dataloading: 0.0007 s/iter. Inference: 0.8806 s/iter. Eval: 0.0008 s/iter. Total: 0.8822 s/iter. ETA=1:07:10
[02/04 20:24:21] d2.evaluation.evaluator INFO: Inference done 389/4952. Dataloading: 0.0007 s/iter. Inference: 0.8809 s/iter. Eval: 0.0008 s/iter. Total: 0.8825 s/iter. ETA=1:07:06
[02/04 20:24:27] d2.evaluation.evaluator INFO: Inference done 395/4952. Dataloading: 0.0007 s/iter. Inference: 0.8810 s/iter. Eval: 0.0008 s/iter. Total: 0.8825 s/iter. ETA=1:07:01
[02/04 20:24:32] d2.evaluation.evaluator INFO: Inference done 401/4952. Dataloading: 0.0007 s/iter. Inference: 0.8809 s/iter. Eval: 0.0008 s/iter. Total: 0.8825 s/iter. ETA=1:06:56
[02/04 20:24:37] d2.evaluation.evaluator INFO: Inference done 407/4952. Dataloading: 0.0007 s/iter. Inference: 0.8809 s/iter. Eval: 0.0008 s/iter. Total: 0.8825 s/iter. ETA=1:06:50
[02/04 20:24:43] d2.evaluation.evaluator INFO: Inference done 413/4952. Dataloading: 0.0007 s/iter. Inference: 0.8813 s/iter. Eval: 0.0008 s/iter. Total: 0.8828 s/iter. ETA=1:06:46
[02/04 20:24:48] d2.evaluation.evaluator INFO: Inference done 419/4952. Dataloading: 0.0007 s/iter. Inference: 0.8815 s/iter. Eval: 0.0008 s/iter. Total: 0.8830 s/iter. ETA=1:06:42
[02/04 20:24:53] d2.evaluation.evaluator INFO: Inference done 425/4952. Dataloading: 0.0007 s/iter. Inference: 0.8816 s/iter. Eval: 0.0008 s/iter. Total: 0.8831 s/iter. ETA=1:06:37
[02/04 20:24:59] d2.evaluation.evaluator INFO: Inference done 431/4952. Dataloading: 0.0007 s/iter. Inference: 0.8815 s/iter. Eval: 0.0008 s/iter. Total: 0.8830 s/iter. ETA=1:06:32
[02/04 20:25:04] d2.evaluation.evaluator INFO: Inference done 437/4952. Dataloading: 0.0007 s/iter. Inference: 0.8817 s/iter. Eval: 0.0008 s/iter. Total: 0.8832 s/iter. ETA=1:06:27
[02/04 20:25:09] d2.evaluation.evaluator INFO: Inference done 443/4952. Dataloading: 0.0007 s/iter. Inference: 0.8818 s/iter. Eval: 0.0008 s/iter. Total: 0.8834 s/iter. ETA=1:06:23
[02/04 20:25:15] d2.evaluation.evaluator INFO: Inference done 449/4952. Dataloading: 0.0007 s/iter. Inference: 0.8822 s/iter. Eval: 0.0008 s/iter. Total: 0.8837 s/iter. ETA=1:06:19
[02/04 20:25:20] d2.evaluation.evaluator INFO: Inference done 455/4952. Dataloading: 0.0007 s/iter. Inference: 0.8822 s/iter. Eval: 0.0008 s/iter. Total: 0.8837 s/iter. ETA=1:06:14
[02/04 20:25:25] d2.evaluation.evaluator INFO: Inference done 461/4952. Dataloading: 0.0007 s/iter. Inference: 0.8820 s/iter. Eval: 0.0008 s/iter. Total: 0.8836 s/iter. ETA=1:06:08
[02/04 20:25:31] d2.evaluation.evaluator INFO: Inference done 467/4952. Dataloading: 0.0007 s/iter. Inference: 0.8822 s/iter. Eval: 0.0008 s/iter. Total: 0.8837 s/iter. ETA=1:06:03
[02/04 20:25:36] d2.evaluation.evaluator INFO: Inference done 473/4952. Dataloading: 0.0007 s/iter. Inference: 0.8822 s/iter. Eval: 0.0008 s/iter. Total: 0.8837 s/iter. ETA=1:05:58
[02/04 20:25:41] d2.evaluation.evaluator INFO: Inference done 479/4952. Dataloading: 0.0007 s/iter. Inference: 0.8822 s/iter. Eval: 0.0008 s/iter. Total: 0.8837 s/iter. ETA=1:05:52
[02/04 20:25:47] d2.evaluation.evaluator INFO: Inference done 485/4952. Dataloading: 0.0007 s/iter. Inference: 0.8823 s/iter. Eval: 0.0008 s/iter. Total: 0.8839 s/iter. ETA=1:05:48
[02/04 20:25:52] d2.evaluation.evaluator INFO: Inference done 491/4952. Dataloading: 0.0007 s/iter. Inference: 0.8823 s/iter. Eval: 0.0008 s/iter. Total: 0.8838 s/iter. ETA=1:05:42
[02/04 20:25:57] d2.evaluation.evaluator INFO: Inference done 497/4952. Dataloading: 0.0007 s/iter. Inference: 0.8824 s/iter. Eval: 0.0008 s/iter. Total: 0.8839 s/iter. ETA=1:05:37
[02/04 20:26:03] d2.evaluation.evaluator INFO: Inference done 503/4952. Dataloading: 0.0007 s/iter. Inference: 0.8825 s/iter. Eval: 0.0008 s/iter. Total: 0.8841 s/iter. ETA=1:05:33
[02/04 20:26:08] d2.evaluation.evaluator INFO: Inference done 509/4952. Dataloading: 0.0007 s/iter. Inference: 0.8826 s/iter. Eval: 0.0008 s/iter. Total: 0.8842 s/iter. ETA=1:05:28
[02/04 20:26:13] d2.evaluation.evaluator INFO: Inference done 515/4952. Dataloading: 0.0007 s/iter. Inference: 0.8826 s/iter. Eval: 0.0008 s/iter. Total: 0.8841 s/iter. ETA=1:05:22
[02/04 20:26:19] d2.evaluation.evaluator INFO: Inference done 521/4952. Dataloading: 0.0007 s/iter. Inference: 0.8827 s/iter. Eval: 0.0008 s/iter. Total: 0.8842 s/iter. ETA=1:05:18
[02/04 20:26:24] d2.evaluation.evaluator INFO: Inference done 527/4952. Dataloading: 0.0007 s/iter. Inference: 0.8827 s/iter. Eval: 0.0008 s/iter. Total: 0.8843 s/iter. ETA=1:05:12
[02/04 20:26:29] d2.evaluation.evaluator INFO: Inference done 533/4952. Dataloading: 0.0007 s/iter. Inference: 0.8828 s/iter. Eval: 0.0008 s/iter. Total: 0.8843 s/iter. ETA=1:05:07
[02/04 20:26:35] d2.evaluation.evaluator INFO: Inference done 539/4952. Dataloading: 0.0007 s/iter. Inference: 0.8828 s/iter. Eval: 0.0008 s/iter. Total: 0.8844 s/iter. ETA=1:05:02
[02/04 20:26:40] d2.evaluation.evaluator INFO: Inference done 545/4952. Dataloading: 0.0007 s/iter. Inference: 0.8827 s/iter. Eval: 0.0008 s/iter. Total: 0.8843 s/iter. ETA=1:04:56
[02/04 20:26:45] d2.evaluation.evaluator INFO: Inference done 551/4952. Dataloading: 0.0007 s/iter. Inference: 0.8827 s/iter. Eval: 0.0008 s/iter. Total: 0.8842 s/iter. ETA=1:04:51
[02/04 20:26:51] d2.evaluation.evaluator INFO: Inference done 557/4952. Dataloading: 0.0007 s/iter. Inference: 0.8827 s/iter. Eval: 0.0008 s/iter. Total: 0.8842 s/iter. ETA=1:04:46
[02/04 20:26:56] d2.evaluation.evaluator INFO: Inference done 563/4952. Dataloading: 0.0007 s/iter. Inference: 0.8829 s/iter. Eval: 0.0008 s/iter. Total: 0.8844 s/iter. ETA=1:04:41
[02/04 20:27:01] d2.evaluation.evaluator INFO: Inference done 569/4952. Dataloading: 0.0007 s/iter. Inference: 0.8830 s/iter. Eval: 0.0008 s/iter. Total: 0.8845 s/iter. ETA=1:04:36
[02/04 20:27:07] d2.evaluation.evaluator INFO: Inference done 575/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=1:04:32
[02/04 20:27:12] d2.evaluation.evaluator INFO: Inference done 581/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=1:04:26
[02/04 20:27:17] d2.evaluation.evaluator INFO: Inference done 587/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=1:04:21
[02/04 20:27:23] d2.evaluation.evaluator INFO: Inference done 593/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:04:17
[02/04 20:27:28] d2.evaluation.evaluator INFO: Inference done 599/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:04:12
[02/04 20:27:33] d2.evaluation.evaluator INFO: Inference done 605/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:04:06
[02/04 20:27:39] d2.evaluation.evaluator INFO: Inference done 611/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:04:01
[02/04 20:27:44] d2.evaluation.evaluator INFO: Inference done 617/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:03:56
[02/04 20:27:49] d2.evaluation.evaluator INFO: Inference done 623/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:03:51
[02/04 20:27:55] d2.evaluation.evaluator INFO: Inference done 629/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:03:45
[02/04 20:28:00] d2.evaluation.evaluator INFO: Inference done 635/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:03:39
[02/04 20:28:05] d2.evaluation.evaluator INFO: Inference done 641/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=1:03:34
[02/04 20:28:11] d2.evaluation.evaluator INFO: Inference done 647/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:03:29
[02/04 20:28:16] d2.evaluation.evaluator INFO: Inference done 653/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=1:03:24
[02/04 20:28:21] d2.evaluation.evaluator INFO: Inference done 659/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:03:19
[02/04 20:28:27] d2.evaluation.evaluator INFO: Inference done 665/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:03:14
[02/04 20:28:32] d2.evaluation.evaluator INFO: Inference done 671/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=1:03:08
[02/04 20:28:37] d2.evaluation.evaluator INFO: Inference done 677/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:03:03
[02/04 20:28:42] d2.evaluation.evaluator INFO: Inference done 683/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:02:58
[02/04 20:28:48] d2.evaluation.evaluator INFO: Inference done 689/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=1:02:53
[02/04 20:28:53] d2.evaluation.evaluator INFO: Inference done 695/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=1:02:48
[02/04 20:28:59] d2.evaluation.evaluator INFO: Inference done 701/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=1:02:43
[02/04 20:29:04] d2.evaluation.evaluator INFO: Inference done 707/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=1:02:37
[02/04 20:29:09] d2.evaluation.evaluator INFO: Inference done 713/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:02:33
[02/04 20:29:15] d2.evaluation.evaluator INFO: Inference done 719/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:02:28
[02/04 20:29:20] d2.evaluation.evaluator INFO: Inference done 725/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:02:22
[02/04 20:29:25] d2.evaluation.evaluator INFO: Inference done 731/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:02:17
[02/04 20:29:31] d2.evaluation.evaluator INFO: Inference done 737/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=1:02:12
[02/04 20:29:36] d2.evaluation.evaluator INFO: Inference done 743/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:02:06
[02/04 20:29:41] d2.evaluation.evaluator INFO: Inference done 749/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=1:02:01
[02/04 20:29:46] d2.evaluation.evaluator INFO: Inference done 755/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:01:56
[02/04 20:29:52] d2.evaluation.evaluator INFO: Inference done 761/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:01:50
[02/04 20:29:57] d2.evaluation.evaluator INFO: Inference done 767/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:01:45
[02/04 20:30:02] d2.evaluation.evaluator INFO: Inference done 773/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:01:40
[02/04 20:30:08] d2.evaluation.evaluator INFO: Inference done 779/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:01:34
[02/04 20:30:13] d2.evaluation.evaluator INFO: Inference done 785/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=1:01:28
[02/04 20:30:18] d2.evaluation.evaluator INFO: Inference done 791/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=1:01:23
[02/04 20:30:23] d2.evaluation.evaluator INFO: Inference done 797/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=1:01:17
[02/04 20:30:29] d2.evaluation.evaluator INFO: Inference done 803/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=1:01:12
[02/04 20:30:34] d2.evaluation.evaluator INFO: Inference done 809/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:01:06
[02/04 20:30:39] d2.evaluation.evaluator INFO: Inference done 815/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=1:01:01
[02/04 20:30:45] d2.evaluation.evaluator INFO: Inference done 821/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=1:00:56
[02/04 20:30:50] d2.evaluation.evaluator INFO: Inference done 827/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=1:00:51
[02/04 20:30:55] d2.evaluation.evaluator INFO: Inference done 833/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=1:00:46
[02/04 20:31:01] d2.evaluation.evaluator INFO: Inference done 839/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=1:00:41
[02/04 20:31:06] d2.evaluation.evaluator INFO: Inference done 845/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=1:00:36
[02/04 20:31:11] d2.evaluation.evaluator INFO: Inference done 851/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=1:00:30
[02/04 20:31:17] d2.evaluation.evaluator INFO: Inference done 857/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=1:00:25
[02/04 20:31:22] d2.evaluation.evaluator INFO: Inference done 863/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=1:00:20
[02/04 20:31:27] d2.evaluation.evaluator INFO: Inference done 869/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=1:00:15
[02/04 20:31:33] d2.evaluation.evaluator INFO: Inference done 875/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=1:00:10
[02/04 20:31:38] d2.evaluation.evaluator INFO: Inference done 881/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=1:00:04
[02/04 20:31:43] d2.evaluation.evaluator INFO: Inference done 887/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:58
[02/04 20:31:49] d2.evaluation.evaluator INFO: Inference done 893/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:53
[02/04 20:31:54] d2.evaluation.evaluator INFO: Inference done 899/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:47
[02/04 20:31:59] d2.evaluation.evaluator INFO: Inference done 905/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:59:42
[02/04 20:32:04] d2.evaluation.evaluator INFO: Inference done 911/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:37
[02/04 20:32:10] d2.evaluation.evaluator INFO: Inference done 917/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:59:31
[02/04 20:32:15] d2.evaluation.evaluator INFO: Inference done 923/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:26
[02/04 20:32:20] d2.evaluation.evaluator INFO: Inference done 929/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:59:21
[02/04 20:32:26] d2.evaluation.evaluator INFO: Inference done 935/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:16
[02/04 20:32:31] d2.evaluation.evaluator INFO: Inference done 941/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:59:10
[02/04 20:32:36] d2.evaluation.evaluator INFO: Inference done 947/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:59:05
[02/04 20:32:42] d2.evaluation.evaluator INFO: Inference done 953/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:58:59
[02/04 20:32:47] d2.evaluation.evaluator INFO: Inference done 959/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:58:54
[02/04 20:32:52] d2.evaluation.evaluator INFO: Inference done 965/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:58:49
[02/04 20:32:58] d2.evaluation.evaluator INFO: Inference done 971/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:58:44
[02/04 20:33:03] d2.evaluation.evaluator INFO: Inference done 977/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:58:39
[02/04 20:33:08] d2.evaluation.evaluator INFO: Inference done 983/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:58:34
[02/04 20:33:14] d2.evaluation.evaluator INFO: Inference done 989/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:58:29
[02/04 20:33:19] d2.evaluation.evaluator INFO: Inference done 995/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:58:23
[02/04 20:33:24] d2.evaluation.evaluator INFO: Inference done 1001/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:58:18
[02/04 20:33:30] d2.evaluation.evaluator INFO: Inference done 1007/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:58:13
[02/04 20:33:35] d2.evaluation.evaluator INFO: Inference done 1013/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:58:07
[02/04 20:33:40] d2.evaluation.evaluator INFO: Inference done 1019/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:58:02
[02/04 20:33:46] d2.evaluation.evaluator INFO: Inference done 1025/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:57:57
[02/04 20:33:51] d2.evaluation.evaluator INFO: Inference done 1031/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:57:52
[02/04 20:33:56] d2.evaluation.evaluator INFO: Inference done 1037/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:57:47
[02/04 20:34:02] d2.evaluation.evaluator INFO: Inference done 1043/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:57:42
[02/04 20:34:07] d2.evaluation.evaluator INFO: Inference done 1049/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:57:36
[02/04 20:34:12] d2.evaluation.evaluator INFO: Inference done 1055/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:57:31
[02/04 20:34:18] d2.evaluation.evaluator INFO: Inference done 1061/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:57:26
[02/04 20:34:23] d2.evaluation.evaluator INFO: Inference done 1067/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8858 s/iter. ETA=0:57:21
[02/04 20:34:28] d2.evaluation.evaluator INFO: Inference done 1073/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8858 s/iter. ETA=0:57:16
[02/04 20:34:34] d2.evaluation.evaluator INFO: Inference done 1079/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:57:10
[02/04 20:34:39] d2.evaluation.evaluator INFO: Inference done 1085/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8858 s/iter. ETA=0:57:05
[02/04 20:34:44] d2.evaluation.evaluator INFO: Inference done 1091/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:57:00
[02/04 20:34:50] d2.evaluation.evaluator INFO: Inference done 1097/4952. Dataloading: 0.0007 s/iter. Inference: 0.8844 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:56:55
[02/04 20:34:55] d2.evaluation.evaluator INFO: Inference done 1103/4952. Dataloading: 0.0007 s/iter. Inference: 0.8844 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:56:50
[02/04 20:35:01] d2.evaluation.evaluator INFO: Inference done 1109/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:56:44
[02/04 20:35:06] d2.evaluation.evaluator INFO: Inference done 1115/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:56:39
[02/04 20:35:11] d2.evaluation.evaluator INFO: Inference done 1121/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:56:34
[02/04 20:35:17] d2.evaluation.evaluator INFO: Inference done 1127/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:56:29
[02/04 20:35:22] d2.evaluation.evaluator INFO: Inference done 1133/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:56:24
[02/04 20:35:27] d2.evaluation.evaluator INFO: Inference done 1139/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:56:19
[02/04 20:35:33] d2.evaluation.evaluator INFO: Inference done 1145/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:56:13
[02/04 20:35:38] d2.evaluation.evaluator INFO: Inference done 1151/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:56:08
[02/04 20:35:43] d2.evaluation.evaluator INFO: Inference done 1157/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:56:03
[02/04 20:35:49] d2.evaluation.evaluator INFO: Inference done 1163/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:55:58
[02/04 20:35:54] d2.evaluation.evaluator INFO: Inference done 1169/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:55:52
[02/04 20:35:59] d2.evaluation.evaluator INFO: Inference done 1175/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:55:47
[02/04 20:36:05] d2.evaluation.evaluator INFO: Inference done 1181/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:55:41
[02/04 20:36:10] d2.evaluation.evaluator INFO: Inference done 1187/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:55:36
[02/04 20:36:15] d2.evaluation.evaluator INFO: Inference done 1193/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:55:31
[02/04 20:36:21] d2.evaluation.evaluator INFO: Inference done 1199/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:55:26
[02/04 20:36:26] d2.evaluation.evaluator INFO: Inference done 1205/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:55:21
[02/04 20:36:31] d2.evaluation.evaluator INFO: Inference done 1211/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:55:15
[02/04 20:36:37] d2.evaluation.evaluator INFO: Inference done 1217/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:55:10
[02/04 20:36:42] d2.evaluation.evaluator INFO: Inference done 1223/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:55:04
[02/04 20:36:47] d2.evaluation.evaluator INFO: Inference done 1229/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:54:59
[02/04 20:36:52] d2.evaluation.evaluator INFO: Inference done 1235/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:54:54
[02/04 20:36:58] d2.evaluation.evaluator INFO: Inference done 1241/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:54:48
[02/04 20:37:03] d2.evaluation.evaluator INFO: Inference done 1247/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:54:43
[02/04 20:37:09] d2.evaluation.evaluator INFO: Inference done 1253/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:54:38
[02/04 20:37:14] d2.evaluation.evaluator INFO: Inference done 1259/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:54:33
[02/04 20:37:19] d2.evaluation.evaluator INFO: Inference done 1265/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:54:28
[02/04 20:37:25] d2.evaluation.evaluator INFO: Inference done 1271/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:54:23
[02/04 20:37:30] d2.evaluation.evaluator INFO: Inference done 1277/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:54:17
[02/04 20:37:35] d2.evaluation.evaluator INFO: Inference done 1283/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:54:12
[02/04 20:37:41] d2.evaluation.evaluator INFO: Inference done 1289/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:54:07
[02/04 20:37:46] d2.evaluation.evaluator INFO: Inference done 1295/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:54:01
[02/04 20:37:51] d2.evaluation.evaluator INFO: Inference done 1301/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:53:56
[02/04 20:37:57] d2.evaluation.evaluator INFO: Inference done 1307/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:51
[02/04 20:38:02] d2.evaluation.evaluator INFO: Inference done 1313/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:46
[02/04 20:38:07] d2.evaluation.evaluator INFO: Inference done 1319/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:40
[02/04 20:38:13] d2.evaluation.evaluator INFO: Inference done 1325/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:35
[02/04 20:38:18] d2.evaluation.evaluator INFO: Inference done 1331/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:30
[02/04 20:38:23] d2.evaluation.evaluator INFO: Inference done 1337/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:24
[02/04 20:38:29] d2.evaluation.evaluator INFO: Inference done 1343/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:19
[02/04 20:38:34] d2.evaluation.evaluator INFO: Inference done 1349/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:14
[02/04 20:38:39] d2.evaluation.evaluator INFO: Inference done 1355/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:08
[02/04 20:38:45] d2.evaluation.evaluator INFO: Inference done 1361/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:53:03
[02/04 20:38:50] d2.evaluation.evaluator INFO: Inference done 1367/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:58
[02/04 20:38:55] d2.evaluation.evaluator INFO: Inference done 1373/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:52
[02/04 20:39:01] d2.evaluation.evaluator INFO: Inference done 1379/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:47
[02/04 20:39:06] d2.evaluation.evaluator INFO: Inference done 1385/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:42
[02/04 20:39:11] d2.evaluation.evaluator INFO: Inference done 1391/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:52:37
[02/04 20:39:16] d2.evaluation.evaluator INFO: Inference done 1397/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:31
[02/04 20:39:22] d2.evaluation.evaluator INFO: Inference done 1403/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:26
[02/04 20:39:27] d2.evaluation.evaluator INFO: Inference done 1409/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:20
[02/04 20:39:32] d2.evaluation.evaluator INFO: Inference done 1415/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:15
[02/04 20:39:38] d2.evaluation.evaluator INFO: Inference done 1421/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:10
[02/04 20:39:43] d2.evaluation.evaluator INFO: Inference done 1427/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:52:04
[02/04 20:39:48] d2.evaluation.evaluator INFO: Inference done 1433/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:51:59
[02/04 20:39:53] d2.evaluation.evaluator INFO: Inference done 1439/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:51:53
[02/04 20:39:59] d2.evaluation.evaluator INFO: Inference done 1445/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:51:48
[02/04 20:40:04] d2.evaluation.evaluator INFO: Inference done 1451/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:51:43
[02/04 20:40:10] d2.evaluation.evaluator INFO: Inference done 1457/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:51:38
[02/04 20:40:15] d2.evaluation.evaluator INFO: Inference done 1463/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:51:33
[02/04 20:40:20] d2.evaluation.evaluator INFO: Inference done 1469/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:51:28
[02/04 20:40:26] d2.evaluation.evaluator INFO: Inference done 1475/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:51:22
[02/04 20:40:31] d2.evaluation.evaluator INFO: Inference done 1481/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:51:17
[02/04 20:40:36] d2.evaluation.evaluator INFO: Inference done 1487/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:51:12
[02/04 20:40:42] d2.evaluation.evaluator INFO: Inference done 1493/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:51:07
[02/04 20:40:47] d2.evaluation.evaluator INFO: Inference done 1499/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:51:01
[02/04 20:40:52] d2.evaluation.evaluator INFO: Inference done 1505/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:50:56
[02/04 20:40:58] d2.evaluation.evaluator INFO: Inference done 1511/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:50:51
[02/04 20:41:03] d2.evaluation.evaluator INFO: Inference done 1517/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:50:45
[02/04 20:41:09] d2.evaluation.evaluator INFO: Inference done 1523/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:50:40
[02/04 20:41:14] d2.evaluation.evaluator INFO: Inference done 1529/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:50:35
[02/04 20:41:19] d2.evaluation.evaluator INFO: Inference done 1535/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:50:29
[02/04 20:41:24] d2.evaluation.evaluator INFO: Inference done 1541/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:50:24
[02/04 20:41:30] d2.evaluation.evaluator INFO: Inference done 1547/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:50:19
[02/04 20:41:35] d2.evaluation.evaluator INFO: Inference done 1553/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:50:14
[02/04 20:41:40] d2.evaluation.evaluator INFO: Inference done 1559/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:50:08
[02/04 20:41:46] d2.evaluation.evaluator INFO: Inference done 1565/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:50:03
[02/04 20:41:51] d2.evaluation.evaluator INFO: Inference done 1571/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:49:58
[02/04 20:41:57] d2.evaluation.evaluator INFO: Inference done 1577/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:49:53
[02/04 20:42:02] d2.evaluation.evaluator INFO: Inference done 1583/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:49:47
[02/04 20:42:07] d2.evaluation.evaluator INFO: Inference done 1589/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:49:42
[02/04 20:42:13] d2.evaluation.evaluator INFO: Inference done 1595/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:37
[02/04 20:42:18] d2.evaluation.evaluator INFO: Inference done 1601/4952. Dataloading: 0.0007 s/iter. Inference: 0.8855 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:32
[02/04 20:42:23] d2.evaluation.evaluator INFO: Inference done 1607/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:27
[02/04 20:42:29] d2.evaluation.evaluator INFO: Inference done 1613/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:21
[02/04 20:42:34] d2.evaluation.evaluator INFO: Inference done 1619/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:16
[02/04 20:42:39] d2.evaluation.evaluator INFO: Inference done 1625/4952. Dataloading: 0.0007 s/iter. Inference: 0.8855 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:11
[02/04 20:42:45] d2.evaluation.evaluator INFO: Inference done 1631/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:05
[02/04 20:42:50] d2.evaluation.evaluator INFO: Inference done 1637/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:49:00
[02/04 20:42:55] d2.evaluation.evaluator INFO: Inference done 1643/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:48:55
[02/04 20:43:01] d2.evaluation.evaluator INFO: Inference done 1649/4952. Dataloading: 0.0007 s/iter. Inference: 0.8855 s/iter. Eval: 0.0008 s/iter. Total: 0.8870 s/iter. ETA=0:48:49
[02/04 20:43:06] d2.evaluation.evaluator INFO: Inference done 1655/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:44
[02/04 20:43:11] d2.evaluation.evaluator INFO: Inference done 1661/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:38
[02/04 20:43:16] d2.evaluation.evaluator INFO: Inference done 1667/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:33
[02/04 20:43:22] d2.evaluation.evaluator INFO: Inference done 1673/4952. Dataloading: 0.0007 s/iter. Inference: 0.8854 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:28
[02/04 20:43:27] d2.evaluation.evaluator INFO: Inference done 1679/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:22
[02/04 20:43:32] d2.evaluation.evaluator INFO: Inference done 1685/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:17
[02/04 20:43:38] d2.evaluation.evaluator INFO: Inference done 1691/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:12
[02/04 20:43:43] d2.evaluation.evaluator INFO: Inference done 1697/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:48:06
[02/04 20:43:48] d2.evaluation.evaluator INFO: Inference done 1703/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:48:01
[02/04 20:43:54] d2.evaluation.evaluator INFO: Inference done 1709/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:47:55
[02/04 20:43:59] d2.evaluation.evaluator INFO: Inference done 1715/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:47:50
[02/04 20:44:04] d2.evaluation.evaluator INFO: Inference done 1721/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:47:45
[02/04 20:44:10] d2.evaluation.evaluator INFO: Inference done 1727/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:47:40
[02/04 20:44:15] d2.evaluation.evaluator INFO: Inference done 1733/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8869 s/iter. ETA=0:47:34
[02/04 20:44:20] d2.evaluation.evaluator INFO: Inference done 1739/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:47:29
[02/04 20:44:25] d2.evaluation.evaluator INFO: Inference done 1745/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:47:23
[02/04 20:44:31] d2.evaluation.evaluator INFO: Inference done 1751/4952. Dataloading: 0.0007 s/iter. Inference: 0.8853 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:47:18
[02/04 20:44:36] d2.evaluation.evaluator INFO: Inference done 1757/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8868 s/iter. ETA=0:47:13
[02/04 20:44:41] d2.evaluation.evaluator INFO: Inference done 1763/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:47:07
[02/04 20:44:47] d2.evaluation.evaluator INFO: Inference done 1769/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:47:02
[02/04 20:44:52] d2.evaluation.evaluator INFO: Inference done 1775/4952. Dataloading: 0.0007 s/iter. Inference: 0.8852 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:46:57
[02/04 20:44:57] d2.evaluation.evaluator INFO: Inference done 1781/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8867 s/iter. ETA=0:46:51
[02/04 20:45:02] d2.evaluation.evaluator INFO: Inference done 1787/4952. Dataloading: 0.0007 s/iter. Inference: 0.8851 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:46:46
[02/04 20:45:08] d2.evaluation.evaluator INFO: Inference done 1793/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:46:40
[02/04 20:45:13] d2.evaluation.evaluator INFO: Inference done 1799/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:46:35
[02/04 20:45:18] d2.evaluation.evaluator INFO: Inference done 1805/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8866 s/iter. ETA=0:46:29
[02/04 20:45:23] d2.evaluation.evaluator INFO: Inference done 1811/4952. Dataloading: 0.0007 s/iter. Inference: 0.8850 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:46:24
[02/04 20:45:29] d2.evaluation.evaluator INFO: Inference done 1817/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8865 s/iter. ETA=0:46:19
[02/04 20:45:34] d2.evaluation.evaluator INFO: Inference done 1823/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:46:13
[02/04 20:45:39] d2.evaluation.evaluator INFO: Inference done 1829/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:46:08
[02/04 20:45:45] d2.evaluation.evaluator INFO: Inference done 1835/4952. Dataloading: 0.0007 s/iter. Inference: 0.8849 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:46:02
[02/04 20:45:50] d2.evaluation.evaluator INFO: Inference done 1841/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:45:57
[02/04 20:45:55] d2.evaluation.evaluator INFO: Inference done 1847/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8864 s/iter. ETA=0:45:52
[02/04 20:46:00] d2.evaluation.evaluator INFO: Inference done 1853/4952. Dataloading: 0.0007 s/iter. Inference: 0.8848 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:45:46
[02/04 20:46:06] d2.evaluation.evaluator INFO: Inference done 1859/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8863 s/iter. ETA=0:45:41
[02/04 20:46:11] d2.evaluation.evaluator INFO: Inference done 1865/4952. Dataloading: 0.0007 s/iter. Inference: 0.8847 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:45:35
[02/04 20:46:16] d2.evaluation.evaluator INFO: Inference done 1871/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8862 s/iter. ETA=0:45:30
[02/04 20:46:21] d2.evaluation.evaluator INFO: Inference done 1877/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:45:24
[02/04 20:46:27] d2.evaluation.evaluator INFO: Inference done 1883/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:45:19
[02/04 20:46:32] d2.evaluation.evaluator INFO: Inference done 1889/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:45:14
[02/04 20:46:37] d2.evaluation.evaluator INFO: Inference done 1895/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:45:08
[02/04 20:46:42] d2.evaluation.evaluator INFO: Inference done 1901/4952. Dataloading: 0.0007 s/iter. Inference: 0.8846 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:45:03
[02/04 20:46:48] d2.evaluation.evaluator INFO: Inference done 1907/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8861 s/iter. ETA=0:44:58
[02/04 20:46:53] d2.evaluation.evaluator INFO: Inference done 1913/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:52
[02/04 20:46:58] d2.evaluation.evaluator INFO: Inference done 1919/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:47
[02/04 20:47:04] d2.evaluation.evaluator INFO: Inference done 1925/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:41
[02/04 20:47:09] d2.evaluation.evaluator INFO: Inference done 1931/4952. Dataloading: 0.0007 s/iter. Inference: 0.8844 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:36
[02/04 20:47:14] d2.evaluation.evaluator INFO: Inference done 1937/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:31
[02/04 20:47:20] d2.evaluation.evaluator INFO: Inference done 1943/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:26
[02/04 20:47:25] d2.evaluation.evaluator INFO: Inference done 1949/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:20
[02/04 20:47:30] d2.evaluation.evaluator INFO: Inference done 1955/4952. Dataloading: 0.0007 s/iter. Inference: 0.8845 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:15
[02/04 20:47:35] d2.evaluation.evaluator INFO: Inference done 1961/4952. Dataloading: 0.0007 s/iter. Inference: 0.8844 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:09
[02/04 20:47:41] d2.evaluation.evaluator INFO: Inference done 1967/4952. Dataloading: 0.0007 s/iter. Inference: 0.8844 s/iter. Eval: 0.0008 s/iter. Total: 0.8860 s/iter. ETA=0:44:04
[02/04 20:47:46] d2.evaluation.evaluator INFO: Inference done 1973/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:43:59
[02/04 20:47:51] d2.evaluation.evaluator INFO: Inference done 1979/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:43:53
[02/04 20:47:56] d2.evaluation.evaluator INFO: Inference done 1985/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:43:48
[02/04 20:48:02] d2.evaluation.evaluator INFO: Inference done 1991/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8859 s/iter. ETA=0:43:43
[02/04 20:48:07] d2.evaluation.evaluator INFO: Inference done 1997/4952. Dataloading: 0.0007 s/iter. Inference: 0.8843 s/iter. Eval: 0.0008 s/iter. Total: 0.8858 s/iter. ETA=0:43:37
[02/04 20:48:12] d2.evaluation.evaluator INFO: Inference done 2003/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8858 s/iter. ETA=0:43:32
[02/04 20:48:17] d2.evaluation.evaluator INFO: Inference done 2009/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:43:26
[02/04 20:48:23] d2.evaluation.evaluator INFO: Inference done 2015/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:43:21
[02/04 20:48:28] d2.evaluation.evaluator INFO: Inference done 2021/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:43:15
[02/04 20:48:33] d2.evaluation.evaluator INFO: Inference done 2027/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:43:10
[02/04 20:48:39] d2.evaluation.evaluator INFO: Inference done 2033/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:43:05
[02/04 20:48:44] d2.evaluation.evaluator INFO: Inference done 2039/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:43:00
[02/04 20:48:49] d2.evaluation.evaluator INFO: Inference done 2045/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:54
[02/04 20:48:55] d2.evaluation.evaluator INFO: Inference done 2051/4952. Dataloading: 0.0007 s/iter. Inference: 0.8842 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:49
[02/04 20:49:00] d2.evaluation.evaluator INFO: Inference done 2057/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:44
[02/04 20:49:05] d2.evaluation.evaluator INFO: Inference done 2063/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:38
[02/04 20:49:10] d2.evaluation.evaluator INFO: Inference done 2069/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:33
[02/04 20:49:16] d2.evaluation.evaluator INFO: Inference done 2075/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:28
[02/04 20:49:21] d2.evaluation.evaluator INFO: Inference done 2081/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:22
[02/04 20:49:26] d2.evaluation.evaluator INFO: Inference done 2087/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:42:17
[02/04 20:49:32] d2.evaluation.evaluator INFO: Inference done 2093/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:12
[02/04 20:49:37] d2.evaluation.evaluator INFO: Inference done 2099/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:06
[02/04 20:49:42] d2.evaluation.evaluator INFO: Inference done 2105/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:42:01
[02/04 20:49:48] d2.evaluation.evaluator INFO: Inference done 2111/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:41:56
[02/04 20:49:53] d2.evaluation.evaluator INFO: Inference done 2117/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:41:50
[02/04 20:49:58] d2.evaluation.evaluator INFO: Inference done 2123/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:41:45
[02/04 20:50:04] d2.evaluation.evaluator INFO: Inference done 2129/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8857 s/iter. ETA=0:41:40
[02/04 20:50:09] d2.evaluation.evaluator INFO: Inference done 2135/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:41:34
[02/04 20:50:14] d2.evaluation.evaluator INFO: Inference done 2141/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:41:29
[02/04 20:50:19] d2.evaluation.evaluator INFO: Inference done 2147/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:41:23
[02/04 20:50:25] d2.evaluation.evaluator INFO: Inference done 2153/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:41:18
[02/04 20:50:30] d2.evaluation.evaluator INFO: Inference done 2159/4952. Dataloading: 0.0007 s/iter. Inference: 0.8841 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:41:13
[02/04 20:50:35] d2.evaluation.evaluator INFO: Inference done 2165/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:41:08
[02/04 20:50:40] d2.evaluation.evaluator INFO: Inference done 2171/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:41:02
[02/04 20:50:46] d2.evaluation.evaluator INFO: Inference done 2177/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:40:57
[02/04 20:50:51] d2.evaluation.evaluator INFO: Inference done 2183/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:52
[02/04 20:50:57] d2.evaluation.evaluator INFO: Inference done 2189/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:46
[02/04 20:51:02] d2.evaluation.evaluator INFO: Inference done 2195/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:41
[02/04 20:51:07] d2.evaluation.evaluator INFO: Inference done 2201/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:36
[02/04 20:51:12] d2.evaluation.evaluator INFO: Inference done 2207/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:30
[02/04 20:51:18] d2.evaluation.evaluator INFO: Inference done 2213/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:25
[02/04 20:51:23] d2.evaluation.evaluator INFO: Inference done 2219/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:40:20
[02/04 20:51:28] d2.evaluation.evaluator INFO: Inference done 2225/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8856 s/iter. ETA=0:40:14
[02/04 20:51:34] d2.evaluation.evaluator INFO: Inference done 2231/4952. Dataloading: 0.0007 s/iter. Inference: 0.8840 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:40:09
[02/04 20:51:39] d2.evaluation.evaluator INFO: Inference done 2237/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:40:04
[02/04 20:51:44] d2.evaluation.evaluator INFO: Inference done 2243/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:58
[02/04 20:51:49] d2.evaluation.evaluator INFO: Inference done 2249/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:53
[02/04 20:51:55] d2.evaluation.evaluator INFO: Inference done 2255/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:48
[02/04 20:52:00] d2.evaluation.evaluator INFO: Inference done 2261/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:42
[02/04 20:52:05] d2.evaluation.evaluator INFO: Inference done 2267/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:37
[02/04 20:52:11] d2.evaluation.evaluator INFO: Inference done 2273/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:32
[02/04 20:52:16] d2.evaluation.evaluator INFO: Inference done 2279/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:26
[02/04 20:52:21] d2.evaluation.evaluator INFO: Inference done 2285/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:21
[02/04 20:52:27] d2.evaluation.evaluator INFO: Inference done 2291/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:39:16
[02/04 20:52:32] d2.evaluation.evaluator INFO: Inference done 2297/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:10
[02/04 20:52:37] d2.evaluation.evaluator INFO: Inference done 2303/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:05
[02/04 20:52:43] d2.evaluation.evaluator INFO: Inference done 2309/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8855 s/iter. ETA=0:39:00
[02/04 20:52:48] d2.evaluation.evaluator INFO: Inference done 2315/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:38:54
[02/04 20:52:53] d2.evaluation.evaluator INFO: Inference done 2321/4952. Dataloading: 0.0007 s/iter. Inference: 0.8839 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:38:49
[02/04 20:52:58] d2.evaluation.evaluator INFO: Inference done 2327/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:38:44
[02/04 20:53:04] d2.evaluation.evaluator INFO: Inference done 2333/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:38:38
[02/04 20:53:09] d2.evaluation.evaluator INFO: Inference done 2339/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:38:33
[02/04 20:53:14] d2.evaluation.evaluator INFO: Inference done 2345/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:38:28
[02/04 20:53:19] d2.evaluation.evaluator INFO: Inference done 2351/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:38:22
[02/04 20:53:25] d2.evaluation.evaluator INFO: Inference done 2357/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:38:17
[02/04 20:53:30] d2.evaluation.evaluator INFO: Inference done 2363/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:38:11
[02/04 20:53:35] d2.evaluation.evaluator INFO: Inference done 2369/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:38:06
[02/04 20:53:40] d2.evaluation.evaluator INFO: Inference done 2375/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:38:01
[02/04 20:53:46] d2.evaluation.evaluator INFO: Inference done 2381/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:55
[02/04 20:53:51] d2.evaluation.evaluator INFO: Inference done 2387/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:50
[02/04 20:53:56] d2.evaluation.evaluator INFO: Inference done 2393/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:37:45
[02/04 20:54:02] d2.evaluation.evaluator INFO: Inference done 2399/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:40
[02/04 20:54:07] d2.evaluation.evaluator INFO: Inference done 2405/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:37:34
[02/04 20:54:12] d2.evaluation.evaluator INFO: Inference done 2411/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:29
[02/04 20:54:18] d2.evaluation.evaluator INFO: Inference done 2417/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:24
[02/04 20:54:23] d2.evaluation.evaluator INFO: Inference done 2423/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:18
[02/04 20:54:28] d2.evaluation.evaluator INFO: Inference done 2429/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:13
[02/04 20:54:34] d2.evaluation.evaluator INFO: Inference done 2435/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:08
[02/04 20:54:39] d2.evaluation.evaluator INFO: Inference done 2441/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:37:03
[02/04 20:54:44] d2.evaluation.evaluator INFO: Inference done 2447/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:36:57
[02/04 20:54:50] d2.evaluation.evaluator INFO: Inference done 2453/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:52
[02/04 20:54:55] d2.evaluation.evaluator INFO: Inference done 2459/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:47
[02/04 20:55:00] d2.evaluation.evaluator INFO: Inference done 2465/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:36:41
[02/04 20:55:06] d2.evaluation.evaluator INFO: Inference done 2471/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:36:36
[02/04 20:55:11] d2.evaluation.evaluator INFO: Inference done 2477/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:31
[02/04 20:55:16] d2.evaluation.evaluator INFO: Inference done 2483/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:25
[02/04 20:55:22] d2.evaluation.evaluator INFO: Inference done 2489/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:36:20
[02/04 20:55:27] d2.evaluation.evaluator INFO: Inference done 2495/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:15
[02/04 20:55:32] d2.evaluation.evaluator INFO: Inference done 2501/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:10
[02/04 20:55:38] d2.evaluation.evaluator INFO: Inference done 2507/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:36:04
[02/04 20:55:43] d2.evaluation.evaluator INFO: Inference done 2513/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:35:59
[02/04 20:55:48] d2.evaluation.evaluator INFO: Inference done 2519/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8854 s/iter. ETA=0:35:54
[02/04 20:55:53] d2.evaluation.evaluator INFO: Inference done 2525/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:48
[02/04 20:55:59] d2.evaluation.evaluator INFO: Inference done 2531/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:43
[02/04 20:56:04] d2.evaluation.evaluator INFO: Inference done 2537/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:38
[02/04 20:56:09] d2.evaluation.evaluator INFO: Inference done 2543/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:32
[02/04 20:56:15] d2.evaluation.evaluator INFO: Inference done 2549/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:27
[02/04 20:56:20] d2.evaluation.evaluator INFO: Inference done 2555/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:22
[02/04 20:56:25] d2.evaluation.evaluator INFO: Inference done 2561/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:16
[02/04 20:56:31] d2.evaluation.evaluator INFO: Inference done 2567/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:11
[02/04 20:56:36] d2.evaluation.evaluator INFO: Inference done 2573/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:06
[02/04 20:56:41] d2.evaluation.evaluator INFO: Inference done 2579/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:35:00
[02/04 20:56:46] d2.evaluation.evaluator INFO: Inference done 2585/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:34:55
[02/04 20:56:52] d2.evaluation.evaluator INFO: Inference done 2591/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:34:50
[02/04 20:56:57] d2.evaluation.evaluator INFO: Inference done 2597/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:44
[02/04 20:57:02] d2.evaluation.evaluator INFO: Inference done 2603/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:39
[02/04 20:57:07] d2.evaluation.evaluator INFO: Inference done 2609/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:33
[02/04 20:57:13] d2.evaluation.evaluator INFO: Inference done 2615/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:28
[02/04 20:57:18] d2.evaluation.evaluator INFO: Inference done 2621/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:23
[02/04 20:57:23] d2.evaluation.evaluator INFO: Inference done 2627/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:18
[02/04 20:57:29] d2.evaluation.evaluator INFO: Inference done 2633/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:12
[02/04 20:57:34] d2.evaluation.evaluator INFO: Inference done 2639/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:07
[02/04 20:57:39] d2.evaluation.evaluator INFO: Inference done 2645/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:34:02
[02/04 20:57:45] d2.evaluation.evaluator INFO: Inference done 2651/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:56
[02/04 20:57:50] d2.evaluation.evaluator INFO: Inference done 2657/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:51
[02/04 20:57:55] d2.evaluation.evaluator INFO: Inference done 2663/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:46
[02/04 20:58:01] d2.evaluation.evaluator INFO: Inference done 2669/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:40
[02/04 20:58:06] d2.evaluation.evaluator INFO: Inference done 2675/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:35
[02/04 20:58:11] d2.evaluation.evaluator INFO: Inference done 2681/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:30
[02/04 20:58:17] d2.evaluation.evaluator INFO: Inference done 2687/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:25
[02/04 20:58:22] d2.evaluation.evaluator INFO: Inference done 2693/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:19
[02/04 20:58:27] d2.evaluation.evaluator INFO: Inference done 2699/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:14
[02/04 20:58:32] d2.evaluation.evaluator INFO: Inference done 2705/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:08
[02/04 20:58:38] d2.evaluation.evaluator INFO: Inference done 2711/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:33:03
[02/04 20:58:43] d2.evaluation.evaluator INFO: Inference done 2717/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:58
[02/04 20:58:48] d2.evaluation.evaluator INFO: Inference done 2723/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:53
[02/04 20:58:54] d2.evaluation.evaluator INFO: Inference done 2729/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:47
[02/04 20:58:59] d2.evaluation.evaluator INFO: Inference done 2735/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:42
[02/04 20:59:04] d2.evaluation.evaluator INFO: Inference done 2741/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:37
[02/04 20:59:10] d2.evaluation.evaluator INFO: Inference done 2747/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:31
[02/04 20:59:15] d2.evaluation.evaluator INFO: Inference done 2753/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:32:26
[02/04 20:59:20] d2.evaluation.evaluator INFO: Inference done 2759/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:32:21
[02/04 20:59:26] d2.evaluation.evaluator INFO: Inference done 2765/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:32:16
[02/04 20:59:31] d2.evaluation.evaluator INFO: Inference done 2771/4952. Dataloading: 0.0007 s/iter. Inference: 0.8838 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:32:10
[02/04 20:59:36] d2.evaluation.evaluator INFO: Inference done 2777/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:32:05
[02/04 20:59:42] d2.evaluation.evaluator INFO: Inference done 2783/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:32:00
[02/04 20:59:47] d2.evaluation.evaluator INFO: Inference done 2789/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:54
[02/04 20:59:52] d2.evaluation.evaluator INFO: Inference done 2795/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:49
[02/04 20:59:57] d2.evaluation.evaluator INFO: Inference done 2801/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:31:44
[02/04 21:00:03] d2.evaluation.evaluator INFO: Inference done 2807/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:38
[02/04 21:00:08] d2.evaluation.evaluator INFO: Inference done 2813/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:33
[02/04 21:00:14] d2.evaluation.evaluator INFO: Inference done 2819/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:28
[02/04 21:00:19] d2.evaluation.evaluator INFO: Inference done 2825/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:23
[02/04 21:00:24] d2.evaluation.evaluator INFO: Inference done 2831/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:17
[02/04 21:00:29] d2.evaluation.evaluator INFO: Inference done 2837/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:12
[02/04 21:00:35] d2.evaluation.evaluator INFO: Inference done 2843/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:07
[02/04 21:00:40] d2.evaluation.evaluator INFO: Inference done 2849/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8853 s/iter. ETA=0:31:01
[02/04 21:00:45] d2.evaluation.evaluator INFO: Inference done 2855/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:30:56
[02/04 21:00:51] d2.evaluation.evaluator INFO: Inference done 2861/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:30:50
[02/04 21:00:56] d2.evaluation.evaluator INFO: Inference done 2867/4952. Dataloading: 0.0007 s/iter. Inference: 0.8837 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:30:45
[02/04 21:01:01] d2.evaluation.evaluator INFO: Inference done 2873/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:30:40
[02/04 21:01:06] d2.evaluation.evaluator INFO: Inference done 2879/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8852 s/iter. ETA=0:30:34
[02/04 21:01:12] d2.evaluation.evaluator INFO: Inference done 2885/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:30:29
[02/04 21:01:17] d2.evaluation.evaluator INFO: Inference done 2891/4952. Dataloading: 0.0007 s/iter. Inference: 0.8836 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:30:24
[02/04 21:01:22] d2.evaluation.evaluator INFO: Inference done 2897/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:30:18
[02/04 21:01:27] d2.evaluation.evaluator INFO: Inference done 2903/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:30:13
[02/04 21:01:33] d2.evaluation.evaluator INFO: Inference done 2909/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:30:08
[02/04 21:01:38] d2.evaluation.evaluator INFO: Inference done 2915/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:30:02
[02/04 21:01:43] d2.evaluation.evaluator INFO: Inference done 2921/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:57
[02/04 21:01:49] d2.evaluation.evaluator INFO: Inference done 2927/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:52
[02/04 21:01:54] d2.evaluation.evaluator INFO: Inference done 2933/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:29:46
[02/04 21:01:59] d2.evaluation.evaluator INFO: Inference done 2939/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:29:41
[02/04 21:02:04] d2.evaluation.evaluator INFO: Inference done 2945/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:29:36
[02/04 21:02:10] d2.evaluation.evaluator INFO: Inference done 2951/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:31
[02/04 21:02:15] d2.evaluation.evaluator INFO: Inference done 2957/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:25
[02/04 21:02:20] d2.evaluation.evaluator INFO: Inference done 2963/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:20
[02/04 21:02:26] d2.evaluation.evaluator INFO: Inference done 2969/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:15
[02/04 21:02:31] d2.evaluation.evaluator INFO: Inference done 2975/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:09
[02/04 21:02:36] d2.evaluation.evaluator INFO: Inference done 2981/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:29:04
[02/04 21:02:42] d2.evaluation.evaluator INFO: Inference done 2987/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:59
[02/04 21:02:47] d2.evaluation.evaluator INFO: Inference done 2993/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:53
[02/04 21:02:52] d2.evaluation.evaluator INFO: Inference done 2999/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:48
[02/04 21:02:58] d2.evaluation.evaluator INFO: Inference done 3005/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:43
[02/04 21:03:03] d2.evaluation.evaluator INFO: Inference done 3011/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:37
[02/04 21:03:08] d2.evaluation.evaluator INFO: Inference done 3017/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:32
[02/04 21:03:13] d2.evaluation.evaluator INFO: Inference done 3023/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8851 s/iter. ETA=0:28:27
[02/04 21:03:19] d2.evaluation.evaluator INFO: Inference done 3029/4952. Dataloading: 0.0007 s/iter. Inference: 0.8835 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:28:21
[02/04 21:03:24] d2.evaluation.evaluator INFO: Inference done 3035/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:28:16
[02/04 21:03:29] d2.evaluation.evaluator INFO: Inference done 3041/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:28:11
[02/04 21:03:35] d2.evaluation.evaluator INFO: Inference done 3047/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:28:05
[02/04 21:03:40] d2.evaluation.evaluator INFO: Inference done 3053/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:28:00
[02/04 21:03:45] d2.evaluation.evaluator INFO: Inference done 3059/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:55
[02/04 21:03:50] d2.evaluation.evaluator INFO: Inference done 3065/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:49
[02/04 21:03:56] d2.evaluation.evaluator INFO: Inference done 3071/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:44
[02/04 21:04:01] d2.evaluation.evaluator INFO: Inference done 3077/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:39
[02/04 21:04:06] d2.evaluation.evaluator INFO: Inference done 3083/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:34
[02/04 21:04:12] d2.evaluation.evaluator INFO: Inference done 3089/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:28
[02/04 21:04:17] d2.evaluation.evaluator INFO: Inference done 3095/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:23
[02/04 21:04:22] d2.evaluation.evaluator INFO: Inference done 3101/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:18
[02/04 21:04:28] d2.evaluation.evaluator INFO: Inference done 3107/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:12
[02/04 21:04:33] d2.evaluation.evaluator INFO: Inference done 3113/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:07
[02/04 21:04:38] d2.evaluation.evaluator INFO: Inference done 3119/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:27:02
[02/04 21:04:44] d2.evaluation.evaluator INFO: Inference done 3125/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:56
[02/04 21:04:49] d2.evaluation.evaluator INFO: Inference done 3131/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:51
[02/04 21:04:54] d2.evaluation.evaluator INFO: Inference done 3137/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:26:46
[02/04 21:04:59] d2.evaluation.evaluator INFO: Inference done 3143/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:40
[02/04 21:05:05] d2.evaluation.evaluator INFO: Inference done 3149/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:35
[02/04 21:05:10] d2.evaluation.evaluator INFO: Inference done 3155/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:30
[02/04 21:05:15] d2.evaluation.evaluator INFO: Inference done 3161/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:24
[02/04 21:05:21] d2.evaluation.evaluator INFO: Inference done 3167/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:26:19
[02/04 21:05:26] d2.evaluation.evaluator INFO: Inference done 3173/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:26:14
[02/04 21:05:31] d2.evaluation.evaluator INFO: Inference done 3179/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:09
[02/04 21:05:37] d2.evaluation.evaluator INFO: Inference done 3185/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:26:03
[02/04 21:05:42] d2.evaluation.evaluator INFO: Inference done 3191/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:25:58
[02/04 21:05:47] d2.evaluation.evaluator INFO: Inference done 3197/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:25:53
[02/04 21:05:52] d2.evaluation.evaluator INFO: Inference done 3203/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:47
[02/04 21:05:58] d2.evaluation.evaluator INFO: Inference done 3209/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:42
[02/04 21:06:03] d2.evaluation.evaluator INFO: Inference done 3215/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:37
[02/04 21:06:08] d2.evaluation.evaluator INFO: Inference done 3221/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:31
[02/04 21:06:14] d2.evaluation.evaluator INFO: Inference done 3227/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:26
[02/04 21:06:19] d2.evaluation.evaluator INFO: Inference done 3233/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:21
[02/04 21:06:24] d2.evaluation.evaluator INFO: Inference done 3239/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:15
[02/04 21:06:30] d2.evaluation.evaluator INFO: Inference done 3245/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:10
[02/04 21:06:35] d2.evaluation.evaluator INFO: Inference done 3251/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:25:05
[02/04 21:06:40] d2.evaluation.evaluator INFO: Inference done 3257/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:59
[02/04 21:06:45] d2.evaluation.evaluator INFO: Inference done 3263/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:54
[02/04 21:06:51] d2.evaluation.evaluator INFO: Inference done 3269/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:49
[02/04 21:06:56] d2.evaluation.evaluator INFO: Inference done 3275/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:43
[02/04 21:07:01] d2.evaluation.evaluator INFO: Inference done 3281/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:38
[02/04 21:07:07] d2.evaluation.evaluator INFO: Inference done 3287/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:33
[02/04 21:07:12] d2.evaluation.evaluator INFO: Inference done 3293/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:28
[02/04 21:07:17] d2.evaluation.evaluator INFO: Inference done 3299/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:22
[02/04 21:07:23] d2.evaluation.evaluator INFO: Inference done 3305/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:17
[02/04 21:07:28] d2.evaluation.evaluator INFO: Inference done 3311/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:12
[02/04 21:07:33] d2.evaluation.evaluator INFO: Inference done 3317/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:06
[02/04 21:07:39] d2.evaluation.evaluator INFO: Inference done 3323/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:24:01
[02/04 21:07:44] d2.evaluation.evaluator INFO: Inference done 3329/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:56
[02/04 21:07:49] d2.evaluation.evaluator INFO: Inference done 3335/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:50
[02/04 21:07:54] d2.evaluation.evaluator INFO: Inference done 3341/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:45
[02/04 21:08:00] d2.evaluation.evaluator INFO: Inference done 3347/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:40
[02/04 21:08:05] d2.evaluation.evaluator INFO: Inference done 3353/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:34
[02/04 21:08:10] d2.evaluation.evaluator INFO: Inference done 3359/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:29
[02/04 21:08:16] d2.evaluation.evaluator INFO: Inference done 3365/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:24
[02/04 21:08:21] d2.evaluation.evaluator INFO: Inference done 3371/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:19
[02/04 21:08:26] d2.evaluation.evaluator INFO: Inference done 3377/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:13
[02/04 21:08:32] d2.evaluation.evaluator INFO: Inference done 3383/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:08
[02/04 21:08:37] d2.evaluation.evaluator INFO: Inference done 3389/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:23:03
[02/04 21:08:42] d2.evaluation.evaluator INFO: Inference done 3395/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:57
[02/04 21:08:48] d2.evaluation.evaluator INFO: Inference done 3401/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:22:52
[02/04 21:08:53] d2.evaluation.evaluator INFO: Inference done 3407/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:47
[02/04 21:08:58] d2.evaluation.evaluator INFO: Inference done 3413/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:22:41
[02/04 21:09:04] d2.evaluation.evaluator INFO: Inference done 3419/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:36
[02/04 21:09:09] d2.evaluation.evaluator INFO: Inference done 3425/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:31
[02/04 21:09:14] d2.evaluation.evaluator INFO: Inference done 3431/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:25
[02/04 21:09:19] d2.evaluation.evaluator INFO: Inference done 3437/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:20
[02/04 21:09:25] d2.evaluation.evaluator INFO: Inference done 3443/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:15
[02/04 21:09:30] d2.evaluation.evaluator INFO: Inference done 3449/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:09
[02/04 21:09:35] d2.evaluation.evaluator INFO: Inference done 3455/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:22:04
[02/04 21:09:41] d2.evaluation.evaluator INFO: Inference done 3461/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:59
[02/04 21:09:46] d2.evaluation.evaluator INFO: Inference done 3467/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:54
[02/04 21:09:51] d2.evaluation.evaluator INFO: Inference done 3473/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:48
[02/04 21:09:56] d2.evaluation.evaluator INFO: Inference done 3479/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:43
[02/04 21:10:02] d2.evaluation.evaluator INFO: Inference done 3485/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:38
[02/04 21:10:07] d2.evaluation.evaluator INFO: Inference done 3491/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:32
[02/04 21:10:12] d2.evaluation.evaluator INFO: Inference done 3497/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:27
[02/04 21:10:18] d2.evaluation.evaluator INFO: Inference done 3503/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:22
[02/04 21:10:23] d2.evaluation.evaluator INFO: Inference done 3509/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:16
[02/04 21:10:28] d2.evaluation.evaluator INFO: Inference done 3515/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:11
[02/04 21:10:34] d2.evaluation.evaluator INFO: Inference done 3521/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:06
[02/04 21:10:39] d2.evaluation.evaluator INFO: Inference done 3527/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:21:01
[02/04 21:10:44] d2.evaluation.evaluator INFO: Inference done 3533/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:55
[02/04 21:10:50] d2.evaluation.evaluator INFO: Inference done 3539/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:50
[02/04 21:10:55] d2.evaluation.evaluator INFO: Inference done 3545/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:45
[02/04 21:11:00] d2.evaluation.evaluator INFO: Inference done 3551/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:39
[02/04 21:11:06] d2.evaluation.evaluator INFO: Inference done 3557/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:34
[02/04 21:11:11] d2.evaluation.evaluator INFO: Inference done 3563/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:29
[02/04 21:11:16] d2.evaluation.evaluator INFO: Inference done 3569/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:23
[02/04 21:11:22] d2.evaluation.evaluator INFO: Inference done 3575/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:18
[02/04 21:11:27] d2.evaluation.evaluator INFO: Inference done 3581/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:13
[02/04 21:11:32] d2.evaluation.evaluator INFO: Inference done 3587/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:07
[02/04 21:11:37] d2.evaluation.evaluator INFO: Inference done 3593/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:20:02
[02/04 21:11:43] d2.evaluation.evaluator INFO: Inference done 3599/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:57
[02/04 21:11:48] d2.evaluation.evaluator INFO: Inference done 3605/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:51
[02/04 21:11:53] d2.evaluation.evaluator INFO: Inference done 3611/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:46
[02/04 21:11:59] d2.evaluation.evaluator INFO: Inference done 3617/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:41
[02/04 21:12:04] d2.evaluation.evaluator INFO: Inference done 3623/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:36
[02/04 21:12:09] d2.evaluation.evaluator INFO: Inference done 3629/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:30
[02/04 21:12:15] d2.evaluation.evaluator INFO: Inference done 3635/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:25
[02/04 21:12:20] d2.evaluation.evaluator INFO: Inference done 3641/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:20
[02/04 21:12:25] d2.evaluation.evaluator INFO: Inference done 3647/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:19:14
[02/04 21:12:30] d2.evaluation.evaluator INFO: Inference done 3653/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:19:09
[02/04 21:12:36] d2.evaluation.evaluator INFO: Inference done 3659/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:19:04
[02/04 21:12:41] d2.evaluation.evaluator INFO: Inference done 3665/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:58
[02/04 21:12:46] d2.evaluation.evaluator INFO: Inference done 3671/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:53
[02/04 21:12:51] d2.evaluation.evaluator INFO: Inference done 3677/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:48
[02/04 21:12:57] d2.evaluation.evaluator INFO: Inference done 3683/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:42
[02/04 21:13:02] d2.evaluation.evaluator INFO: Inference done 3689/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:37
[02/04 21:13:07] d2.evaluation.evaluator INFO: Inference done 3695/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:32
[02/04 21:13:13] d2.evaluation.evaluator INFO: Inference done 3701/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:26
[02/04 21:13:18] d2.evaluation.evaluator INFO: Inference done 3707/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:21
[02/04 21:13:23] d2.evaluation.evaluator INFO: Inference done 3713/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:16
[02/04 21:13:29] d2.evaluation.evaluator INFO: Inference done 3719/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:10
[02/04 21:13:34] d2.evaluation.evaluator INFO: Inference done 3725/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:05
[02/04 21:13:39] d2.evaluation.evaluator INFO: Inference done 3731/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:18:00
[02/04 21:13:45] d2.evaluation.evaluator INFO: Inference done 3737/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:17:55
[02/04 21:13:50] d2.evaluation.evaluator INFO: Inference done 3743/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:17:49
[02/04 21:13:55] d2.evaluation.evaluator INFO: Inference done 3749/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:17:44
[02/04 21:14:01] d2.evaluation.evaluator INFO: Inference done 3755/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:17:39
[02/04 21:14:06] d2.evaluation.evaluator INFO: Inference done 3761/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:17:33
[02/04 21:14:11] d2.evaluation.evaluator INFO: Inference done 3767/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:17:28
[02/04 21:14:17] d2.evaluation.evaluator INFO: Inference done 3773/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:17:23
[02/04 21:14:22] d2.evaluation.evaluator INFO: Inference done 3779/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:17:17
[02/04 21:14:27] d2.evaluation.evaluator INFO: Inference done 3785/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:17:12
[02/04 21:14:32] d2.evaluation.evaluator INFO: Inference done 3791/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:17:07
[02/04 21:14:38] d2.evaluation.evaluator INFO: Inference done 3797/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:17:01
[02/04 21:14:43] d2.evaluation.evaluator INFO: Inference done 3803/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:16:56
[02/04 21:14:48] d2.evaluation.evaluator INFO: Inference done 3809/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:51
[02/04 21:14:54] d2.evaluation.evaluator INFO: Inference done 3815/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:46
[02/04 21:14:59] d2.evaluation.evaluator INFO: Inference done 3821/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:40
[02/04 21:15:04] d2.evaluation.evaluator INFO: Inference done 3827/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:35
[02/04 21:15:10] d2.evaluation.evaluator INFO: Inference done 3833/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:30
[02/04 21:15:15] d2.evaluation.evaluator INFO: Inference done 3839/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:24
[02/04 21:15:20] d2.evaluation.evaluator INFO: Inference done 3845/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:16:19
[02/04 21:15:26] d2.evaluation.evaluator INFO: Inference done 3851/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:16:14
[02/04 21:15:31] d2.evaluation.evaluator INFO: Inference done 3857/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:16:08
[02/04 21:15:36] d2.evaluation.evaluator INFO: Inference done 3863/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:16:03
[02/04 21:15:41] d2.evaluation.evaluator INFO: Inference done 3869/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:15:58
[02/04 21:15:47] d2.evaluation.evaluator INFO: Inference done 3875/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:15:52
[02/04 21:15:52] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:15:47
[02/04 21:15:57] d2.evaluation.evaluator INFO: Inference done 3887/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:15:42
[02/04 21:16:03] d2.evaluation.evaluator INFO: Inference done 3893/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:37
[02/04 21:16:08] d2.evaluation.evaluator INFO: Inference done 3899/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:31
[02/04 21:16:13] d2.evaluation.evaluator INFO: Inference done 3905/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:26
[02/04 21:16:19] d2.evaluation.evaluator INFO: Inference done 3911/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:21
[02/04 21:16:24] d2.evaluation.evaluator INFO: Inference done 3917/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:15
[02/04 21:16:29] d2.evaluation.evaluator INFO: Inference done 3923/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:10
[02/04 21:16:35] d2.evaluation.evaluator INFO: Inference done 3929/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:15:05
[02/04 21:16:40] d2.evaluation.evaluator INFO: Inference done 3935/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:59
[02/04 21:16:45] d2.evaluation.evaluator INFO: Inference done 3941/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:54
[02/04 21:16:50] d2.evaluation.evaluator INFO: Inference done 3947/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:49
[02/04 21:16:56] d2.evaluation.evaluator INFO: Inference done 3953/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:43
[02/04 21:17:01] d2.evaluation.evaluator INFO: Inference done 3959/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:38
[02/04 21:17:06] d2.evaluation.evaluator INFO: Inference done 3965/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:33
[02/04 21:17:12] d2.evaluation.evaluator INFO: Inference done 3971/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:28
[02/04 21:17:17] d2.evaluation.evaluator INFO: Inference done 3977/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:22
[02/04 21:17:22] d2.evaluation.evaluator INFO: Inference done 3983/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:17
[02/04 21:17:28] d2.evaluation.evaluator INFO: Inference done 3989/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:12
[02/04 21:17:33] d2.evaluation.evaluator INFO: Inference done 3995/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:06
[02/04 21:17:38] d2.evaluation.evaluator INFO: Inference done 4001/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:14:01
[02/04 21:17:43] d2.evaluation.evaluator INFO: Inference done 4007/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:56
[02/04 21:17:49] d2.evaluation.evaluator INFO: Inference done 4013/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:50
[02/04 21:17:54] d2.evaluation.evaluator INFO: Inference done 4019/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:45
[02/04 21:17:59] d2.evaluation.evaluator INFO: Inference done 4025/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:40
[02/04 21:18:05] d2.evaluation.evaluator INFO: Inference done 4031/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:34
[02/04 21:18:10] d2.evaluation.evaluator INFO: Inference done 4037/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:29
[02/04 21:18:15] d2.evaluation.evaluator INFO: Inference done 4043/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:24
[02/04 21:18:21] d2.evaluation.evaluator INFO: Inference done 4049/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:18
[02/04 21:18:26] d2.evaluation.evaluator INFO: Inference done 4055/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:13
[02/04 21:18:31] d2.evaluation.evaluator INFO: Inference done 4061/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:08
[02/04 21:18:37] d2.evaluation.evaluator INFO: Inference done 4067/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:13:03
[02/04 21:18:42] d2.evaluation.evaluator INFO: Inference done 4073/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:57
[02/04 21:18:47] d2.evaluation.evaluator INFO: Inference done 4079/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:52
[02/04 21:18:52] d2.evaluation.evaluator INFO: Inference done 4085/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:47
[02/04 21:18:58] d2.evaluation.evaluator INFO: Inference done 4091/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:41
[02/04 21:19:03] d2.evaluation.evaluator INFO: Inference done 4097/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:36
[02/04 21:19:08] d2.evaluation.evaluator INFO: Inference done 4103/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:31
[02/04 21:19:14] d2.evaluation.evaluator INFO: Inference done 4109/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:25
[02/04 21:19:19] d2.evaluation.evaluator INFO: Inference done 4115/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:20
[02/04 21:19:24] d2.evaluation.evaluator INFO: Inference done 4121/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:15
[02/04 21:19:29] d2.evaluation.evaluator INFO: Inference done 4127/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:09
[02/04 21:19:35] d2.evaluation.evaluator INFO: Inference done 4133/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:12:04
[02/04 21:19:40] d2.evaluation.evaluator INFO: Inference done 4139/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:59
[02/04 21:19:45] d2.evaluation.evaluator INFO: Inference done 4145/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:54
[02/04 21:19:51] d2.evaluation.evaluator INFO: Inference done 4151/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:48
[02/04 21:19:56] d2.evaluation.evaluator INFO: Inference done 4157/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:43
[02/04 21:20:02] d2.evaluation.evaluator INFO: Inference done 4163/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:38
[02/04 21:20:07] d2.evaluation.evaluator INFO: Inference done 4169/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:32
[02/04 21:20:12] d2.evaluation.evaluator INFO: Inference done 4175/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:27
[02/04 21:20:17] d2.evaluation.evaluator INFO: Inference done 4181/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:22
[02/04 21:20:23] d2.evaluation.evaluator INFO: Inference done 4187/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:16
[02/04 21:20:28] d2.evaluation.evaluator INFO: Inference done 4193/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:11
[02/04 21:20:33] d2.evaluation.evaluator INFO: Inference done 4199/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:06
[02/04 21:20:39] d2.evaluation.evaluator INFO: Inference done 4205/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:11:00
[02/04 21:20:44] d2.evaluation.evaluator INFO: Inference done 4211/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:55
[02/04 21:20:49] d2.evaluation.evaluator INFO: Inference done 4217/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:50
[02/04 21:20:55] d2.evaluation.evaluator INFO: Inference done 4223/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:45
[02/04 21:21:00] d2.evaluation.evaluator INFO: Inference done 4229/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:39
[02/04 21:21:05] d2.evaluation.evaluator INFO: Inference done 4235/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:34
[02/04 21:21:10] d2.evaluation.evaluator INFO: Inference done 4241/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:29
[02/04 21:21:16] d2.evaluation.evaluator INFO: Inference done 4247/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:23
[02/04 21:21:21] d2.evaluation.evaluator INFO: Inference done 4253/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:18
[02/04 21:21:26] d2.evaluation.evaluator INFO: Inference done 4259/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:13
[02/04 21:21:32] d2.evaluation.evaluator INFO: Inference done 4265/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:07
[02/04 21:21:37] d2.evaluation.evaluator INFO: Inference done 4271/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:10:02
[02/04 21:21:42] d2.evaluation.evaluator INFO: Inference done 4277/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:09:57
[02/04 21:21:48] d2.evaluation.evaluator INFO: Inference done 4283/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:09:51
[02/04 21:21:53] d2.evaluation.evaluator INFO: Inference done 4289/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:09:46
[02/04 21:21:58] d2.evaluation.evaluator INFO: Inference done 4295/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:09:41
[02/04 21:22:04] d2.evaluation.evaluator INFO: Inference done 4301/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:09:36
[02/04 21:22:09] d2.evaluation.evaluator INFO: Inference done 4307/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:09:30
[02/04 21:22:14] d2.evaluation.evaluator INFO: Inference done 4313/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:09:25
[02/04 21:22:20] d2.evaluation.evaluator INFO: Inference done 4319/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:09:20
[02/04 21:22:25] d2.evaluation.evaluator INFO: Inference done 4325/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:09:14
[02/04 21:22:30] d2.evaluation.evaluator INFO: Inference done 4331/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:09:09
[02/04 21:22:36] d2.evaluation.evaluator INFO: Inference done 4337/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:09:04
[02/04 21:22:41] d2.evaluation.evaluator INFO: Inference done 4343/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:58
[02/04 21:22:46] d2.evaluation.evaluator INFO: Inference done 4349/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:53
[02/04 21:22:52] d2.evaluation.evaluator INFO: Inference done 4355/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:48
[02/04 21:22:57] d2.evaluation.evaluator INFO: Inference done 4361/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:42
[02/04 21:23:02] d2.evaluation.evaluator INFO: Inference done 4367/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:37
[02/04 21:23:07] d2.evaluation.evaluator INFO: Inference done 4373/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:08:32
[02/04 21:23:13] d2.evaluation.evaluator INFO: Inference done 4379/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:27
[02/04 21:23:18] d2.evaluation.evaluator INFO: Inference done 4385/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:21
[02/04 21:23:23] d2.evaluation.evaluator INFO: Inference done 4391/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:16
[02/04 21:23:29] d2.evaluation.evaluator INFO: Inference done 4397/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:08:11
[02/04 21:23:34] d2.evaluation.evaluator INFO: Inference done 4403/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:05
[02/04 21:23:39] d2.evaluation.evaluator INFO: Inference done 4409/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:08:00
[02/04 21:23:45] d2.evaluation.evaluator INFO: Inference done 4415/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:07:55
[02/04 21:23:50] d2.evaluation.evaluator INFO: Inference done 4421/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:49
[02/04 21:23:55] d2.evaluation.evaluator INFO: Inference done 4427/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:44
[02/04 21:24:01] d2.evaluation.evaluator INFO: Inference done 4433/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:39
[02/04 21:24:06] d2.evaluation.evaluator INFO: Inference done 4439/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:33
[02/04 21:24:11] d2.evaluation.evaluator INFO: Inference done 4445/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:28
[02/04 21:24:16] d2.evaluation.evaluator INFO: Inference done 4451/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:23
[02/04 21:24:22] d2.evaluation.evaluator INFO: Inference done 4457/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:18
[02/04 21:24:27] d2.evaluation.evaluator INFO: Inference done 4463/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:12
[02/04 21:24:32] d2.evaluation.evaluator INFO: Inference done 4469/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:07
[02/04 21:24:38] d2.evaluation.evaluator INFO: Inference done 4475/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:07:02
[02/04 21:24:43] d2.evaluation.evaluator INFO: Inference done 4481/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:56
[02/04 21:24:48] d2.evaluation.evaluator INFO: Inference done 4487/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:51
[02/04 21:24:54] d2.evaluation.evaluator INFO: Inference done 4493/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:46
[02/04 21:24:59] d2.evaluation.evaluator INFO: Inference done 4499/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:40
[02/04 21:25:05] d2.evaluation.evaluator INFO: Inference done 4505/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:35
[02/04 21:25:10] d2.evaluation.evaluator INFO: Inference done 4511/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:30
[02/04 21:25:15] d2.evaluation.evaluator INFO: Inference done 4517/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:06:24
[02/04 21:25:21] d2.evaluation.evaluator INFO: Inference done 4523/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:19
[02/04 21:25:26] d2.evaluation.evaluator INFO: Inference done 4529/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:14
[02/04 21:25:31] d2.evaluation.evaluator INFO: Inference done 4535/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8850 s/iter. ETA=0:06:09
[02/04 21:25:37] d2.evaluation.evaluator INFO: Inference done 4541/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:06:03
[02/04 21:25:42] d2.evaluation.evaluator INFO: Inference done 4547/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:58
[02/04 21:25:47] d2.evaluation.evaluator INFO: Inference done 4553/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:53
[02/04 21:25:52] d2.evaluation.evaluator INFO: Inference done 4559/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:47
[02/04 21:25:58] d2.evaluation.evaluator INFO: Inference done 4565/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:42
[02/04 21:26:03] d2.evaluation.evaluator INFO: Inference done 4571/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:37
[02/04 21:26:08] d2.evaluation.evaluator INFO: Inference done 4577/4952. Dataloading: 0.0007 s/iter. Inference: 0.8834 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:31
[02/04 21:26:13] d2.evaluation.evaluator INFO: Inference done 4583/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:26
[02/04 21:26:19] d2.evaluation.evaluator INFO: Inference done 4589/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:21
[02/04 21:26:24] d2.evaluation.evaluator INFO: Inference done 4595/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:15
[02/04 21:26:29] d2.evaluation.evaluator INFO: Inference done 4601/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:10
[02/04 21:26:35] d2.evaluation.evaluator INFO: Inference done 4607/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:05:05
[02/04 21:26:40] d2.evaluation.evaluator INFO: Inference done 4613/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:04:59
[02/04 21:26:45] d2.evaluation.evaluator INFO: Inference done 4619/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:04:54
[02/04 21:26:50] d2.evaluation.evaluator INFO: Inference done 4625/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:49
[02/04 21:26:56] d2.evaluation.evaluator INFO: Inference done 4631/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8849 s/iter. ETA=0:04:44
[02/04 21:27:01] d2.evaluation.evaluator INFO: Inference done 4637/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:38
[02/04 21:27:06] d2.evaluation.evaluator INFO: Inference done 4643/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:33
[02/04 21:27:12] d2.evaluation.evaluator INFO: Inference done 4649/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:28
[02/04 21:27:17] d2.evaluation.evaluator INFO: Inference done 4655/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:22
[02/04 21:27:22] d2.evaluation.evaluator INFO: Inference done 4661/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:17
[02/04 21:27:27] d2.evaluation.evaluator INFO: Inference done 4667/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:12
[02/04 21:27:33] d2.evaluation.evaluator INFO: Inference done 4673/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:06
[02/04 21:27:38] d2.evaluation.evaluator INFO: Inference done 4679/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:04:01
[02/04 21:27:43] d2.evaluation.evaluator INFO: Inference done 4685/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:56
[02/04 21:27:49] d2.evaluation.evaluator INFO: Inference done 4691/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:50
[02/04 21:27:54] d2.evaluation.evaluator INFO: Inference done 4697/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:45
[02/04 21:27:59] d2.evaluation.evaluator INFO: Inference done 4703/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:40
[02/04 21:28:05] d2.evaluation.evaluator INFO: Inference done 4709/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:35
[02/04 21:28:10] d2.evaluation.evaluator INFO: Inference done 4715/4952. Dataloading: 0.0007 s/iter. Inference: 0.8833 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:29
[02/04 21:28:15] d2.evaluation.evaluator INFO: Inference done 4721/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:24
[02/04 21:28:20] d2.evaluation.evaluator INFO: Inference done 4727/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:19
[02/04 21:28:26] d2.evaluation.evaluator INFO: Inference done 4733/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:13
[02/04 21:28:31] d2.evaluation.evaluator INFO: Inference done 4739/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:08
[02/04 21:28:36] d2.evaluation.evaluator INFO: Inference done 4745/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:03:03
[02/04 21:28:41] d2.evaluation.evaluator INFO: Inference done 4751/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8848 s/iter. ETA=0:02:57
[02/04 21:28:47] d2.evaluation.evaluator INFO: Inference done 4757/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:52
[02/04 21:28:52] d2.evaluation.evaluator INFO: Inference done 4763/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:47
[02/04 21:28:57] d2.evaluation.evaluator INFO: Inference done 4769/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:41
[02/04 21:29:03] d2.evaluation.evaluator INFO: Inference done 4775/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:36
[02/04 21:29:08] d2.evaluation.evaluator INFO: Inference done 4781/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:31
[02/04 21:29:13] d2.evaluation.evaluator INFO: Inference done 4787/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:25
[02/04 21:29:19] d2.evaluation.evaluator INFO: Inference done 4793/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:20
[02/04 21:29:24] d2.evaluation.evaluator INFO: Inference done 4799/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:15
[02/04 21:29:29] d2.evaluation.evaluator INFO: Inference done 4805/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:10
[02/04 21:29:34] d2.evaluation.evaluator INFO: Inference done 4811/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:02:04
[02/04 21:29:40] d2.evaluation.evaluator INFO: Inference done 4817/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:59
[02/04 21:29:45] d2.evaluation.evaluator INFO: Inference done 4823/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:54
[02/04 21:29:50] d2.evaluation.evaluator INFO: Inference done 4829/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:48
[02/04 21:29:56] d2.evaluation.evaluator INFO: Inference done 4835/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:43
[02/04 21:30:01] d2.evaluation.evaluator INFO: Inference done 4841/4952. Dataloading: 0.0007 s/iter. Inference: 0.8832 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:38
[02/04 21:30:06] d2.evaluation.evaluator INFO: Inference done 4847/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:32
[02/04 21:30:11] d2.evaluation.evaluator INFO: Inference done 4853/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:27
[02/04 21:30:17] d2.evaluation.evaluator INFO: Inference done 4859/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:22
[02/04 21:30:22] d2.evaluation.evaluator INFO: Inference done 4865/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:16
[02/04 21:30:27] d2.evaluation.evaluator INFO: Inference done 4871/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:01:11
[02/04 21:30:32] d2.evaluation.evaluator INFO: Inference done 4877/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8847 s/iter. ETA=0:01:06
[02/04 21:30:38] d2.evaluation.evaluator INFO: Inference done 4883/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:01:01
[02/04 21:30:43] d2.evaluation.evaluator INFO: Inference done 4889/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:55
[02/04 21:30:48] d2.evaluation.evaluator INFO: Inference done 4895/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:50
[02/04 21:30:54] d2.evaluation.evaluator INFO: Inference done 4901/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:45
[02/04 21:30:59] d2.evaluation.evaluator INFO: Inference done 4907/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:39
[02/04 21:31:04] d2.evaluation.evaluator INFO: Inference done 4913/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:34
[02/04 21:31:10] d2.evaluation.evaluator INFO: Inference done 4919/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:29
[02/04 21:31:15] d2.evaluation.evaluator INFO: Inference done 4925/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:23
[02/04 21:31:20] d2.evaluation.evaluator INFO: Inference done 4931/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:18
[02/04 21:31:25] d2.evaluation.evaluator INFO: Inference done 4937/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:13
[02/04 21:31:31] d2.evaluation.evaluator INFO: Inference done 4943/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:07
[02/04 21:31:36] d2.evaluation.evaluator INFO: Inference done 4949/4952. Dataloading: 0.0007 s/iter. Inference: 0.8831 s/iter. Eval: 0.0008 s/iter. Total: 0.8846 s/iter. ETA=0:00:02
[02/04 21:31:39] d2.evaluation.evaluator INFO: Total inference time: 1:12:56.290997 (0.884635 s / iter per device, on 1 devices)
[02/04 21:31:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 1:12:48 (0.883055 s / iter per device, on 1 devices)
[02/04 21:31:39] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[02/04 21:32:26] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car   |  cat   |  chair  |  diningtable  |  dog  |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow   |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:------:|:------:|:-------:|:-------------:|:-----:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:------:|:-----------:|:------:|
|   20.725    |  20.311   | 18.019 |  17.716  | 10.252 | 11.409 | 13.850  |     0.003     | 2.715 | 10.088  |  27.880  |    15.061     | 29.679  |  6.136  |    1.326    | 2.880  | 0.021 | 26.398 |    0.536    | 0.009  |
[02/04 21:32:26] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|  AP   |  AP50  |  AP75  |  bAP  |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:-----:|:------:|:------:|:-----:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 6.626 | 11.751 | 6.432  | 7.549 | 13.678  |  7.210  | 3.856 |  5.969  |  4.097  |
[02/04 21:32:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/04 21:32:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[02/04 21:32:26] d2.evaluation.testing INFO: copypaste: 6.6261,11.7507,6.4319,7.5494,13.6780,7.2101,3.8561,5.9688,4.0973
[02/04 21:32:26] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[02/04 21:32:37] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0007 s/iter. Inference: 0.9391 s/iter. Eval: 0.0008 s/iter. Total: 0.9406 s/iter. ETA=1:17:27
[02/04 21:32:43] d2.evaluation.evaluator INFO: Inference done 17/4952. Dataloading: 0.0005 s/iter. Inference: 0.9343 s/iter. Eval: 0.0008 s/iter. Total: 0.9356 s/iter. ETA=1:16:57
[02/04 21:32:48] d2.evaluation.evaluator INFO: Inference done 23/4952. Dataloading: 0.0006 s/iter. Inference: 0.9383 s/iter. Eval: 0.0008 s/iter. Total: 0.9397 s/iter. ETA=1:17:11
[02/04 21:32:54] d2.evaluation.evaluator INFO: Inference done 29/4952. Dataloading: 0.0006 s/iter. Inference: 0.9394 s/iter. Eval: 0.0008 s/iter. Total: 0.9408 s/iter. ETA=1:17:11
[02/04 21:33:00] d2.evaluation.evaluator INFO: Inference done 35/4952. Dataloading: 0.0006 s/iter. Inference: 0.9399 s/iter. Eval: 0.0008 s/iter. Total: 0.9414 s/iter. ETA=1:17:08
[02/04 21:33:05] d2.evaluation.evaluator INFO: Inference done 41/4952. Dataloading: 0.0006 s/iter. Inference: 0.9396 s/iter. Eval: 0.0008 s/iter. Total: 0.9411 s/iter. ETA=1:17:01
[02/04 21:33:11] d2.evaluation.evaluator INFO: Inference done 47/4952. Dataloading: 0.0006 s/iter. Inference: 0.9417 s/iter. Eval: 0.0008 s/iter. Total: 0.9431 s/iter. ETA=1:17:06
[02/04 21:33:17] d2.evaluation.evaluator INFO: Inference done 53/4952. Dataloading: 0.0007 s/iter. Inference: 0.9425 s/iter. Eval: 0.0008 s/iter. Total: 0.9440 s/iter. ETA=1:17:04
[02/04 21:33:22] d2.evaluation.evaluator INFO: Inference done 59/4952. Dataloading: 0.0007 s/iter. Inference: 0.9435 s/iter. Eval: 0.0008 s/iter. Total: 0.9450 s/iter. ETA=1:17:04
[02/04 21:33:28] d2.evaluation.evaluator INFO: Inference done 65/4952. Dataloading: 0.0007 s/iter. Inference: 0.9428 s/iter. Eval: 0.0008 s/iter. Total: 0.9443 s/iter. ETA=1:16:55
[02/04 21:33:34] d2.evaluation.evaluator INFO: Inference done 71/4952. Dataloading: 0.0007 s/iter. Inference: 0.9427 s/iter. Eval: 0.0008 s/iter. Total: 0.9443 s/iter. ETA=1:16:48
[02/04 21:33:39] d2.evaluation.evaluator INFO: Inference done 77/4952. Dataloading: 0.0007 s/iter. Inference: 0.9429 s/iter. Eval: 0.0008 s/iter. Total: 0.9444 s/iter. ETA=1:16:43
[02/04 21:33:45] d2.evaluation.evaluator INFO: Inference done 83/4952. Dataloading: 0.0007 s/iter. Inference: 0.9429 s/iter. Eval: 0.0008 s/iter. Total: 0.9444 s/iter. ETA=1:16:38
[02/04 21:33:51] d2.evaluation.evaluator INFO: Inference done 89/4952. Dataloading: 0.0007 s/iter. Inference: 0.9432 s/iter. Eval: 0.0008 s/iter. Total: 0.9447 s/iter. ETA=1:16:34
[02/04 21:33:56] d2.evaluation.evaluator INFO: Inference done 95/4952. Dataloading: 0.0007 s/iter. Inference: 0.9421 s/iter. Eval: 0.0008 s/iter. Total: 0.9436 s/iter. ETA=1:16:22
[02/04 21:34:02] d2.evaluation.evaluator INFO: Inference done 101/4952. Dataloading: 0.0007 s/iter. Inference: 0.9424 s/iter. Eval: 0.0008 s/iter. Total: 0.9439 s/iter. ETA=1:16:19
[02/04 21:34:08] d2.evaluation.evaluator INFO: Inference done 107/4952. Dataloading: 0.0007 s/iter. Inference: 0.9422 s/iter. Eval: 0.0008 s/iter. Total: 0.9437 s/iter. ETA=1:16:12
[02/04 21:34:13] d2.evaluation.evaluator INFO: Inference done 113/4952. Dataloading: 0.0007 s/iter. Inference: 0.9424 s/iter. Eval: 0.0008 s/iter. Total: 0.9439 s/iter. ETA=1:16:07
[02/04 21:34:19] d2.evaluation.evaluator INFO: Inference done 119/4952. Dataloading: 0.0007 s/iter. Inference: 0.9422 s/iter. Eval: 0.0008 s/iter. Total: 0.9437 s/iter. ETA=1:16:01
[02/04 21:34:25] d2.evaluation.evaluator INFO: Inference done 125/4952. Dataloading: 0.0007 s/iter. Inference: 0.9430 s/iter. Eval: 0.0008 s/iter. Total: 0.9445 s/iter. ETA=1:15:59
[02/04 21:34:30] d2.evaluation.evaluator INFO: Inference done 131/4952. Dataloading: 0.0007 s/iter. Inference: 0.9436 s/iter. Eval: 0.0008 s/iter. Total: 0.9451 s/iter. ETA=1:15:56
[02/04 21:34:36] d2.evaluation.evaluator INFO: Inference done 137/4952. Dataloading: 0.0007 s/iter. Inference: 0.9440 s/iter. Eval: 0.0008 s/iter. Total: 0.9455 s/iter. ETA=1:15:52
[02/04 21:34:42] d2.evaluation.evaluator INFO: Inference done 143/4952. Dataloading: 0.0007 s/iter. Inference: 0.9437 s/iter. Eval: 0.0008 s/iter. Total: 0.9452 s/iter. ETA=1:15:45
[02/04 21:34:47] d2.evaluation.evaluator INFO: Inference done 149/4952. Dataloading: 0.0007 s/iter. Inference: 0.9436 s/iter. Eval: 0.0008 s/iter. Total: 0.9452 s/iter. ETA=1:15:39
[02/04 21:34:53] d2.evaluation.evaluator INFO: Inference done 155/4952. Dataloading: 0.0007 s/iter. Inference: 0.9430 s/iter. Eval: 0.0008 s/iter. Total: 0.9445 s/iter. ETA=1:15:30
[02/04 21:34:59] d2.evaluation.evaluator INFO: Inference done 161/4952. Dataloading: 0.0007 s/iter. Inference: 0.9433 s/iter. Eval: 0.0008 s/iter. Total: 0.9449 s/iter. ETA=1:15:26
[02/04 21:35:04] d2.evaluation.evaluator INFO: Inference done 167/4952. Dataloading: 0.0007 s/iter. Inference: 0.9436 s/iter. Eval: 0.0008 s/iter. Total: 0.9451 s/iter. ETA=1:15:22
[02/04 21:35:10] d2.evaluation.evaluator INFO: Inference done 173/4952. Dataloading: 0.0007 s/iter. Inference: 0.9441 s/iter. Eval: 0.0008 s/iter. Total: 0.9456 s/iter. ETA=1:15:19
[02/04 21:35:16] d2.evaluation.evaluator INFO: Inference done 179/4952. Dataloading: 0.0007 s/iter. Inference: 0.9444 s/iter. Eval: 0.0008 s/iter. Total: 0.9459 s/iter. ETA=1:15:14
[02/04 21:35:22] d2.evaluation.evaluator INFO: Inference done 185/4952. Dataloading: 0.0007 s/iter. Inference: 0.9445 s/iter. Eval: 0.0008 s/iter. Total: 0.9461 s/iter. ETA=1:15:09
[02/04 21:35:27] d2.evaluation.evaluator INFO: Inference done 191/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=1:15:06
[02/04 21:35:33] d2.evaluation.evaluator INFO: Inference done 197/4952. Dataloading: 0.0007 s/iter. Inference: 0.9449 s/iter. Eval: 0.0008 s/iter. Total: 0.9465 s/iter. ETA=1:15:00
[02/04 21:35:39] d2.evaluation.evaluator INFO: Inference done 203/4952. Dataloading: 0.0007 s/iter. Inference: 0.9448 s/iter. Eval: 0.0008 s/iter. Total: 0.9463 s/iter. ETA=1:14:54
[02/04 21:35:44] d2.evaluation.evaluator INFO: Inference done 209/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=1:14:50
[02/04 21:35:50] d2.evaluation.evaluator INFO: Inference done 215/4952. Dataloading: 0.0007 s/iter. Inference: 0.9446 s/iter. Eval: 0.0008 s/iter. Total: 0.9462 s/iter. ETA=1:14:42
[02/04 21:35:56] d2.evaluation.evaluator INFO: Inference done 221/4952. Dataloading: 0.0007 s/iter. Inference: 0.9446 s/iter. Eval: 0.0008 s/iter. Total: 0.9461 s/iter. ETA=1:14:36
[02/04 21:36:01] d2.evaluation.evaluator INFO: Inference done 227/4952. Dataloading: 0.0007 s/iter. Inference: 0.9448 s/iter. Eval: 0.0008 s/iter. Total: 0.9463 s/iter. ETA=1:14:31
[02/04 21:36:07] d2.evaluation.evaluator INFO: Inference done 233/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=1:14:26
[02/04 21:36:13] d2.evaluation.evaluator INFO: Inference done 239/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9465 s/iter. ETA=1:14:20
[02/04 21:36:18] d2.evaluation.evaluator INFO: Inference done 245/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9465 s/iter. ETA=1:14:15
[02/04 21:36:24] d2.evaluation.evaluator INFO: Inference done 251/4952. Dataloading: 0.0007 s/iter. Inference: 0.9449 s/iter. Eval: 0.0008 s/iter. Total: 0.9464 s/iter. ETA=1:14:09
[02/04 21:36:30] d2.evaluation.evaluator INFO: Inference done 257/4952. Dataloading: 0.0007 s/iter. Inference: 0.9446 s/iter. Eval: 0.0008 s/iter. Total: 0.9462 s/iter. ETA=1:14:02
[02/04 21:36:35] d2.evaluation.evaluator INFO: Inference done 263/4952. Dataloading: 0.0007 s/iter. Inference: 0.9445 s/iter. Eval: 0.0008 s/iter. Total: 0.9460 s/iter. ETA=1:13:55
[02/04 21:36:41] d2.evaluation.evaluator INFO: Inference done 269/4952. Dataloading: 0.0007 s/iter. Inference: 0.9442 s/iter. Eval: 0.0008 s/iter. Total: 0.9457 s/iter. ETA=1:13:48
[02/04 21:36:47] d2.evaluation.evaluator INFO: Inference done 275/4952. Dataloading: 0.0007 s/iter. Inference: 0.9442 s/iter. Eval: 0.0008 s/iter. Total: 0.9458 s/iter. ETA=1:13:43
[02/04 21:36:52] d2.evaluation.evaluator INFO: Inference done 281/4952. Dataloading: 0.0007 s/iter. Inference: 0.9444 s/iter. Eval: 0.0008 s/iter. Total: 0.9460 s/iter. ETA=1:13:38
[02/04 21:36:58] d2.evaluation.evaluator INFO: Inference done 287/4952. Dataloading: 0.0007 s/iter. Inference: 0.9446 s/iter. Eval: 0.0008 s/iter. Total: 0.9462 s/iter. ETA=1:13:33
[02/04 21:37:04] d2.evaluation.evaluator INFO: Inference done 293/4952. Dataloading: 0.0007 s/iter. Inference: 0.9446 s/iter. Eval: 0.0008 s/iter. Total: 0.9461 s/iter. ETA=1:13:27
[02/04 21:37:09] d2.evaluation.evaluator INFO: Inference done 299/4952. Dataloading: 0.0007 s/iter. Inference: 0.9448 s/iter. Eval: 0.0008 s/iter. Total: 0.9463 s/iter. ETA=1:13:23
[02/04 21:37:15] d2.evaluation.evaluator INFO: Inference done 305/4952. Dataloading: 0.0007 s/iter. Inference: 0.9448 s/iter. Eval: 0.0008 s/iter. Total: 0.9463 s/iter. ETA=1:13:17
[02/04 21:37:21] d2.evaluation.evaluator INFO: Inference done 311/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=1:13:13
[02/04 21:37:27] d2.evaluation.evaluator INFO: Inference done 317/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=1:13:07
[02/04 21:37:32] d2.evaluation.evaluator INFO: Inference done 323/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=1:13:02
[02/04 21:37:38] d2.evaluation.evaluator INFO: Inference done 329/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=1:12:56
[02/04 21:37:44] d2.evaluation.evaluator INFO: Inference done 335/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=1:12:50
[02/04 21:37:49] d2.evaluation.evaluator INFO: Inference done 341/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=1:12:44
[02/04 21:37:55] d2.evaluation.evaluator INFO: Inference done 347/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=1:12:39
[02/04 21:38:01] d2.evaluation.evaluator INFO: Inference done 353/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=1:12:35
[02/04 21:38:07] d2.evaluation.evaluator INFO: Inference done 359/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=1:12:31
[02/04 21:38:12] d2.evaluation.evaluator INFO: Inference done 365/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:12:26
[02/04 21:38:18] d2.evaluation.evaluator INFO: Inference done 371/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=1:12:20
[02/04 21:38:24] d2.evaluation.evaluator INFO: Inference done 377/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:12:15
[02/04 21:38:30] d2.evaluation.evaluator INFO: Inference done 383/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:12:11
[02/04 21:38:35] d2.evaluation.evaluator INFO: Inference done 389/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:12:06
[02/04 21:38:41] d2.evaluation.evaluator INFO: Inference done 395/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:12:00
[02/04 21:38:47] d2.evaluation.evaluator INFO: Inference done 401/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:11:53
[02/04 21:38:52] d2.evaluation.evaluator INFO: Inference done 407/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:11:47
[02/04 21:38:58] d2.evaluation.evaluator INFO: Inference done 413/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:11:43
[02/04 21:39:04] d2.evaluation.evaluator INFO: Inference done 419/4952. Dataloading: 0.0007 s/iter. Inference: 0.9467 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:11:38
[02/04 21:39:10] d2.evaluation.evaluator INFO: Inference done 425/4952. Dataloading: 0.0007 s/iter. Inference: 0.9469 s/iter. Eval: 0.0008 s/iter. Total: 0.9484 s/iter. ETA=1:11:33
[02/04 21:39:15] d2.evaluation.evaluator INFO: Inference done 431/4952. Dataloading: 0.0007 s/iter. Inference: 0.9468 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:11:27
[02/04 21:39:21] d2.evaluation.evaluator INFO: Inference done 437/4952. Dataloading: 0.0007 s/iter. Inference: 0.9468 s/iter. Eval: 0.0008 s/iter. Total: 0.9484 s/iter. ETA=1:11:21
[02/04 21:39:27] d2.evaluation.evaluator INFO: Inference done 443/4952. Dataloading: 0.0007 s/iter. Inference: 0.9469 s/iter. Eval: 0.0008 s/iter. Total: 0.9484 s/iter. ETA=1:11:16
[02/04 21:39:32] d2.evaluation.evaluator INFO: Inference done 449/4952. Dataloading: 0.0007 s/iter. Inference: 0.9471 s/iter. Eval: 0.0008 s/iter. Total: 0.9486 s/iter. ETA=1:11:11
[02/04 21:39:38] d2.evaluation.evaluator INFO: Inference done 455/4952. Dataloading: 0.0007 s/iter. Inference: 0.9470 s/iter. Eval: 0.0008 s/iter. Total: 0.9486 s/iter. ETA=1:11:05
[02/04 21:39:44] d2.evaluation.evaluator INFO: Inference done 461/4952. Dataloading: 0.0007 s/iter. Inference: 0.9468 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:10:58
[02/04 21:39:49] d2.evaluation.evaluator INFO: Inference done 467/4952. Dataloading: 0.0007 s/iter. Inference: 0.9468 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:10:53
[02/04 21:39:55] d2.evaluation.evaluator INFO: Inference done 473/4952. Dataloading: 0.0007 s/iter. Inference: 0.9467 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:10:47
[02/04 21:40:01] d2.evaluation.evaluator INFO: Inference done 479/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:10:41
[02/04 21:40:06] d2.evaluation.evaluator INFO: Inference done 485/4952. Dataloading: 0.0007 s/iter. Inference: 0.9467 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:10:35
[02/04 21:40:12] d2.evaluation.evaluator INFO: Inference done 491/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:10:28
[02/04 21:40:18] d2.evaluation.evaluator INFO: Inference done 497/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:10:23
[02/04 21:40:23] d2.evaluation.evaluator INFO: Inference done 503/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:10:17
[02/04 21:40:29] d2.evaluation.evaluator INFO: Inference done 509/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:10:12
[02/04 21:40:35] d2.evaluation.evaluator INFO: Inference done 515/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:10:06
[02/04 21:40:40] d2.evaluation.evaluator INFO: Inference done 521/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:10:01
[02/04 21:40:46] d2.evaluation.evaluator INFO: Inference done 527/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:09:55
[02/04 21:40:52] d2.evaluation.evaluator INFO: Inference done 533/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:09:49
[02/04 21:40:57] d2.evaluation.evaluator INFO: Inference done 539/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:09:43
[02/04 21:41:03] d2.evaluation.evaluator INFO: Inference done 545/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:09:37
[02/04 21:41:09] d2.evaluation.evaluator INFO: Inference done 551/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:09:31
[02/04 21:41:14] d2.evaluation.evaluator INFO: Inference done 557/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:09:25
[02/04 21:41:20] d2.evaluation.evaluator INFO: Inference done 563/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:09:20
[02/04 21:41:26] d2.evaluation.evaluator INFO: Inference done 569/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:09:15
[02/04 21:41:32] d2.evaluation.evaluator INFO: Inference done 575/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:09:10
[02/04 21:41:37] d2.evaluation.evaluator INFO: Inference done 581/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:09:04
[02/04 21:41:43] d2.evaluation.evaluator INFO: Inference done 587/4952. Dataloading: 0.0007 s/iter. Inference: 0.9467 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:08:58
[02/04 21:41:49] d2.evaluation.evaluator INFO: Inference done 593/4952. Dataloading: 0.0007 s/iter. Inference: 0.9468 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:08:53
[02/04 21:41:55] d2.evaluation.evaluator INFO: Inference done 599/4952. Dataloading: 0.0007 s/iter. Inference: 0.9467 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:08:47
[02/04 21:42:00] d2.evaluation.evaluator INFO: Inference done 605/4952. Dataloading: 0.0007 s/iter. Inference: 0.9467 s/iter. Eval: 0.0008 s/iter. Total: 0.9483 s/iter. ETA=1:08:42
[02/04 21:42:06] d2.evaluation.evaluator INFO: Inference done 611/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:08:35
[02/04 21:42:12] d2.evaluation.evaluator INFO: Inference done 617/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9481 s/iter. ETA=1:08:29
[02/04 21:42:17] d2.evaluation.evaluator INFO: Inference done 623/4952. Dataloading: 0.0007 s/iter. Inference: 0.9466 s/iter. Eval: 0.0008 s/iter. Total: 0.9482 s/iter. ETA=1:08:24
[02/04 21:42:23] d2.evaluation.evaluator INFO: Inference done 629/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:08:18
[02/04 21:42:28] d2.evaluation.evaluator INFO: Inference done 635/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:08:11
[02/04 21:42:34] d2.evaluation.evaluator INFO: Inference done 641/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:08:05
[02/04 21:42:40] d2.evaluation.evaluator INFO: Inference done 647/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:08:00
[02/04 21:42:45] d2.evaluation.evaluator INFO: Inference done 653/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:54
[02/04 21:42:51] d2.evaluation.evaluator INFO: Inference done 659/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:48
[02/04 21:42:57] d2.evaluation.evaluator INFO: Inference done 665/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:42
[02/04 21:43:02] d2.evaluation.evaluator INFO: Inference done 671/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:07:37
[02/04 21:43:08] d2.evaluation.evaluator INFO: Inference done 677/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:31
[02/04 21:43:14] d2.evaluation.evaluator INFO: Inference done 683/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:25
[02/04 21:43:19] d2.evaluation.evaluator INFO: Inference done 689/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:19
[02/04 21:43:25] d2.evaluation.evaluator INFO: Inference done 695/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:07:14
[02/04 21:43:31] d2.evaluation.evaluator INFO: Inference done 701/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:07:09
[02/04 21:43:37] d2.evaluation.evaluator INFO: Inference done 707/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:07:03
[02/04 21:43:42] d2.evaluation.evaluator INFO: Inference done 713/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:06:58
[02/04 21:43:48] d2.evaluation.evaluator INFO: Inference done 719/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:06:52
[02/04 21:43:54] d2.evaluation.evaluator INFO: Inference done 725/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:06:46
[02/04 21:43:59] d2.evaluation.evaluator INFO: Inference done 731/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:06:40
[02/04 21:44:05] d2.evaluation.evaluator INFO: Inference done 737/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:06:35
[02/04 21:44:11] d2.evaluation.evaluator INFO: Inference done 743/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:06:29
[02/04 21:44:17] d2.evaluation.evaluator INFO: Inference done 749/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:06:24
[02/04 21:44:22] d2.evaluation.evaluator INFO: Inference done 755/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:06:18
[02/04 21:44:28] d2.evaluation.evaluator INFO: Inference done 761/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:06:13
[02/04 21:44:34] d2.evaluation.evaluator INFO: Inference done 767/4952. Dataloading: 0.0007 s/iter. Inference: 0.9465 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:06:07
[02/04 21:44:39] d2.evaluation.evaluator INFO: Inference done 773/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:06:01
[02/04 21:44:45] d2.evaluation.evaluator INFO: Inference done 779/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9480 s/iter. ETA=1:05:55
[02/04 21:44:51] d2.evaluation.evaluator INFO: Inference done 785/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:05:49
[02/04 21:44:56] d2.evaluation.evaluator INFO: Inference done 791/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:05:43
[02/04 21:45:02] d2.evaluation.evaluator INFO: Inference done 797/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:05:37
[02/04 21:45:08] d2.evaluation.evaluator INFO: Inference done 803/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:05:31
[02/04 21:45:13] d2.evaluation.evaluator INFO: Inference done 809/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:05:25
[02/04 21:45:19] d2.evaluation.evaluator INFO: Inference done 815/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:05:20
[02/04 21:45:25] d2.evaluation.evaluator INFO: Inference done 821/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:05:14
[02/04 21:45:30] d2.evaluation.evaluator INFO: Inference done 827/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:05:09
[02/04 21:45:36] d2.evaluation.evaluator INFO: Inference done 833/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:05:03
[02/04 21:45:42] d2.evaluation.evaluator INFO: Inference done 839/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:57
[02/04 21:45:47] d2.evaluation.evaluator INFO: Inference done 845/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:52
[02/04 21:45:53] d2.evaluation.evaluator INFO: Inference done 851/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:46
[02/04 21:45:59] d2.evaluation.evaluator INFO: Inference done 857/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:40
[02/04 21:46:04] d2.evaluation.evaluator INFO: Inference done 863/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:04:35
[02/04 21:46:10] d2.evaluation.evaluator INFO: Inference done 869/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:29
[02/04 21:46:16] d2.evaluation.evaluator INFO: Inference done 875/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:23
[02/04 21:46:21] d2.evaluation.evaluator INFO: Inference done 881/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:04:17
[02/04 21:46:27] d2.evaluation.evaluator INFO: Inference done 887/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:04:11
[02/04 21:46:33] d2.evaluation.evaluator INFO: Inference done 893/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:04:06
[02/04 21:46:38] d2.evaluation.evaluator INFO: Inference done 899/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:04:00
[02/04 21:46:44] d2.evaluation.evaluator INFO: Inference done 905/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:03:54
[02/04 21:46:50] d2.evaluation.evaluator INFO: Inference done 911/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:03:49
[02/04 21:46:55] d2.evaluation.evaluator INFO: Inference done 917/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=1:03:43
[02/04 21:47:01] d2.evaluation.evaluator INFO: Inference done 923/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:03:38
[02/04 21:47:07] d2.evaluation.evaluator INFO: Inference done 929/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:03:32
[02/04 21:47:13] d2.evaluation.evaluator INFO: Inference done 935/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:03:27
[02/04 21:47:18] d2.evaluation.evaluator INFO: Inference done 941/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:03:21
[02/04 21:47:24] d2.evaluation.evaluator INFO: Inference done 947/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:03:15
[02/04 21:47:30] d2.evaluation.evaluator INFO: Inference done 953/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:03:10
[02/04 21:47:35] d2.evaluation.evaluator INFO: Inference done 959/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:03:04
[02/04 21:47:41] d2.evaluation.evaluator INFO: Inference done 965/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:02:58
[02/04 21:47:47] d2.evaluation.evaluator INFO: Inference done 971/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:02:53
[02/04 21:47:53] d2.evaluation.evaluator INFO: Inference done 977/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:02:47
[02/04 21:47:58] d2.evaluation.evaluator INFO: Inference done 983/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:42
[02/04 21:48:04] d2.evaluation.evaluator INFO: Inference done 989/4952. Dataloading: 0.0007 s/iter. Inference: 0.9464 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:36
[02/04 21:48:10] d2.evaluation.evaluator INFO: Inference done 995/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:30
[02/04 21:48:15] d2.evaluation.evaluator INFO: Inference done 1001/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:25
[02/04 21:48:21] d2.evaluation.evaluator INFO: Inference done 1007/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:19
[02/04 21:48:27] d2.evaluation.evaluator INFO: Inference done 1013/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:13
[02/04 21:48:32] d2.evaluation.evaluator INFO: Inference done 1019/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:02:07
[02/04 21:48:38] d2.evaluation.evaluator INFO: Inference done 1025/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:02:01
[02/04 21:48:44] d2.evaluation.evaluator INFO: Inference done 1031/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:01:56
[02/04 21:48:49] d2.evaluation.evaluator INFO: Inference done 1037/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:01:50
[02/04 21:48:55] d2.evaluation.evaluator INFO: Inference done 1043/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:01:45
[02/04 21:49:01] d2.evaluation.evaluator INFO: Inference done 1049/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:01:39
[02/04 21:49:06] d2.evaluation.evaluator INFO: Inference done 1055/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:01:33
[02/04 21:49:12] d2.evaluation.evaluator INFO: Inference done 1061/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:01:28
[02/04 21:49:18] d2.evaluation.evaluator INFO: Inference done 1067/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:01:22
[02/04 21:49:24] d2.evaluation.evaluator INFO: Inference done 1073/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:01:16
[02/04 21:49:29] d2.evaluation.evaluator INFO: Inference done 1079/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=1:01:11
[02/04 21:49:35] d2.evaluation.evaluator INFO: Inference done 1085/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:01:05
[02/04 21:49:41] d2.evaluation.evaluator INFO: Inference done 1091/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:00:59
[02/04 21:49:46] d2.evaluation.evaluator INFO: Inference done 1097/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:00:53
[02/04 21:49:52] d2.evaluation.evaluator INFO: Inference done 1103/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:00:47
[02/04 21:49:58] d2.evaluation.evaluator INFO: Inference done 1109/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:00:42
[02/04 21:50:03] d2.evaluation.evaluator INFO: Inference done 1115/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:00:36
[02/04 21:50:09] d2.evaluation.evaluator INFO: Inference done 1121/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:00:30
[02/04 21:50:15] d2.evaluation.evaluator INFO: Inference done 1127/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=1:00:25
[02/04 21:50:20] d2.evaluation.evaluator INFO: Inference done 1133/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:00:19
[02/04 21:50:26] d2.evaluation.evaluator INFO: Inference done 1139/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:00:13
[02/04 21:50:32] d2.evaluation.evaluator INFO: Inference done 1145/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:00:08
[02/04 21:50:37] d2.evaluation.evaluator INFO: Inference done 1151/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=1:00:02
[02/04 21:50:43] d2.evaluation.evaluator INFO: Inference done 1157/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:59:56
[02/04 21:50:49] d2.evaluation.evaluator INFO: Inference done 1163/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:59:51
[02/04 21:50:54] d2.evaluation.evaluator INFO: Inference done 1169/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:59:45
[02/04 21:51:00] d2.evaluation.evaluator INFO: Inference done 1175/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:59:39
[02/04 21:51:06] d2.evaluation.evaluator INFO: Inference done 1181/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:59:33
[02/04 21:51:11] d2.evaluation.evaluator INFO: Inference done 1187/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:59:27
[02/04 21:51:17] d2.evaluation.evaluator INFO: Inference done 1193/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:59:22
[02/04 21:51:23] d2.evaluation.evaluator INFO: Inference done 1199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:59:16
[02/04 21:51:29] d2.evaluation.evaluator INFO: Inference done 1205/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:59:11
[02/04 21:51:34] d2.evaluation.evaluator INFO: Inference done 1211/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:59:05
[02/04 21:51:40] d2.evaluation.evaluator INFO: Inference done 1217/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:58:59
[02/04 21:51:45] d2.evaluation.evaluator INFO: Inference done 1223/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:58:53
[02/04 21:51:51] d2.evaluation.evaluator INFO: Inference done 1229/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:58:47
[02/04 21:51:57] d2.evaluation.evaluator INFO: Inference done 1235/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:58:42
[02/04 21:52:02] d2.evaluation.evaluator INFO: Inference done 1241/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:58:36
[02/04 21:52:08] d2.evaluation.evaluator INFO: Inference done 1247/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:58:31
[02/04 21:52:14] d2.evaluation.evaluator INFO: Inference done 1253/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:58:25
[02/04 21:52:20] d2.evaluation.evaluator INFO: Inference done 1259/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:58:20
[02/04 21:52:26] d2.evaluation.evaluator INFO: Inference done 1265/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:58:14
[02/04 21:52:31] d2.evaluation.evaluator INFO: Inference done 1271/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9479 s/iter. ETA=0:58:09
[02/04 21:52:37] d2.evaluation.evaluator INFO: Inference done 1277/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:58:03
[02/04 21:52:43] d2.evaluation.evaluator INFO: Inference done 1283/4952. Dataloading: 0.0007 s/iter. Inference: 0.9463 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:57:57
[02/04 21:52:48] d2.evaluation.evaluator INFO: Inference done 1289/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:57:51
[02/04 21:52:54] d2.evaluation.evaluator INFO: Inference done 1295/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:57:45
[02/04 21:53:00] d2.evaluation.evaluator INFO: Inference done 1301/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:57:40
[02/04 21:53:05] d2.evaluation.evaluator INFO: Inference done 1307/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9478 s/iter. ETA=0:57:34
[02/04 21:53:11] d2.evaluation.evaluator INFO: Inference done 1313/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:57:28
[02/04 21:53:17] d2.evaluation.evaluator INFO: Inference done 1319/4952. Dataloading: 0.0007 s/iter. Inference: 0.9462 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:57:23
[02/04 21:53:22] d2.evaluation.evaluator INFO: Inference done 1325/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:57:17
[02/04 21:53:28] d2.evaluation.evaluator INFO: Inference done 1331/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9477 s/iter. ETA=0:57:11
[02/04 21:53:34] d2.evaluation.evaluator INFO: Inference done 1337/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:57:05
[02/04 21:53:39] d2.evaluation.evaluator INFO: Inference done 1343/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:56:59
[02/04 21:53:45] d2.evaluation.evaluator INFO: Inference done 1349/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:56:54
[02/04 21:53:50] d2.evaluation.evaluator INFO: Inference done 1355/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:56:48
[02/04 21:53:56] d2.evaluation.evaluator INFO: Inference done 1361/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:56:42
[02/04 21:54:02] d2.evaluation.evaluator INFO: Inference done 1367/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:56:36
[02/04 21:54:07] d2.evaluation.evaluator INFO: Inference done 1373/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:56:30
[02/04 21:54:13] d2.evaluation.evaluator INFO: Inference done 1379/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:56:25
[02/04 21:54:19] d2.evaluation.evaluator INFO: Inference done 1385/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:56:19
[02/04 21:54:24] d2.evaluation.evaluator INFO: Inference done 1391/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:56:13
[02/04 21:54:30] d2.evaluation.evaluator INFO: Inference done 1397/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:56:08
[02/04 21:54:36] d2.evaluation.evaluator INFO: Inference done 1403/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:56:02
[02/04 21:54:41] d2.evaluation.evaluator INFO: Inference done 1409/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:55:56
[02/04 21:54:47] d2.evaluation.evaluator INFO: Inference done 1415/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:55:51
[02/04 21:54:53] d2.evaluation.evaluator INFO: Inference done 1421/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:55:45
[02/04 21:54:59] d2.evaluation.evaluator INFO: Inference done 1427/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:55:39
[02/04 21:55:04] d2.evaluation.evaluator INFO: Inference done 1433/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:55:34
[02/04 21:55:10] d2.evaluation.evaluator INFO: Inference done 1439/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:55:28
[02/04 21:55:16] d2.evaluation.evaluator INFO: Inference done 1445/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:55:22
[02/04 21:55:21] d2.evaluation.evaluator INFO: Inference done 1451/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:55:16
[02/04 21:55:27] d2.evaluation.evaluator INFO: Inference done 1457/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:55:11
[02/04 21:55:33] d2.evaluation.evaluator INFO: Inference done 1463/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:55:06
[02/04 21:55:39] d2.evaluation.evaluator INFO: Inference done 1469/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:55:00
[02/04 21:55:44] d2.evaluation.evaluator INFO: Inference done 1475/4952. Dataloading: 0.0007 s/iter. Inference: 0.9461 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:54:54
[02/04 21:55:50] d2.evaluation.evaluator INFO: Inference done 1481/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9476 s/iter. ETA=0:54:49
[02/04 21:55:56] d2.evaluation.evaluator INFO: Inference done 1487/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:43
[02/04 21:56:01] d2.evaluation.evaluator INFO: Inference done 1493/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:37
[02/04 21:56:07] d2.evaluation.evaluator INFO: Inference done 1499/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:31
[02/04 21:56:13] d2.evaluation.evaluator INFO: Inference done 1505/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:26
[02/04 21:56:18] d2.evaluation.evaluator INFO: Inference done 1511/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:20
[02/04 21:56:24] d2.evaluation.evaluator INFO: Inference done 1517/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:14
[02/04 21:56:30] d2.evaluation.evaluator INFO: Inference done 1523/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:09
[02/04 21:56:35] d2.evaluation.evaluator INFO: Inference done 1529/4952. Dataloading: 0.0007 s/iter. Inference: 0.9460 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:54:03
[02/04 21:56:41] d2.evaluation.evaluator INFO: Inference done 1535/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:57
[02/04 21:56:47] d2.evaluation.evaluator INFO: Inference done 1541/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:53:51
[02/04 21:56:52] d2.evaluation.evaluator INFO: Inference done 1547/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:53:46
[02/04 21:56:58] d2.evaluation.evaluator INFO: Inference done 1553/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:40
[02/04 21:57:04] d2.evaluation.evaluator INFO: Inference done 1559/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:34
[02/04 21:57:09] d2.evaluation.evaluator INFO: Inference done 1565/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:28
[02/04 21:57:15] d2.evaluation.evaluator INFO: Inference done 1571/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:23
[02/04 21:57:21] d2.evaluation.evaluator INFO: Inference done 1577/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:17
[02/04 21:57:26] d2.evaluation.evaluator INFO: Inference done 1583/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:53:11
[02/04 21:57:32] d2.evaluation.evaluator INFO: Inference done 1589/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:53:06
[02/04 21:57:38] d2.evaluation.evaluator INFO: Inference done 1595/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:53:00
[02/04 21:57:43] d2.evaluation.evaluator INFO: Inference done 1601/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:52:55
[02/04 21:57:49] d2.evaluation.evaluator INFO: Inference done 1607/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:52:49
[02/04 21:57:55] d2.evaluation.evaluator INFO: Inference done 1613/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:52:43
[02/04 21:58:00] d2.evaluation.evaluator INFO: Inference done 1619/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:52:37
[02/04 21:58:06] d2.evaluation.evaluator INFO: Inference done 1625/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9475 s/iter. ETA=0:52:32
[02/04 21:58:12] d2.evaluation.evaluator INFO: Inference done 1631/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:52:26
[02/04 21:58:17] d2.evaluation.evaluator INFO: Inference done 1637/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:52:20
[02/04 21:58:23] d2.evaluation.evaluator INFO: Inference done 1643/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:52:14
[02/04 21:58:29] d2.evaluation.evaluator INFO: Inference done 1649/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:52:09
[02/04 21:58:34] d2.evaluation.evaluator INFO: Inference done 1655/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:52:03
[02/04 21:58:40] d2.evaluation.evaluator INFO: Inference done 1661/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:51:57
[02/04 21:58:46] d2.evaluation.evaluator INFO: Inference done 1667/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:51:51
[02/04 21:58:51] d2.evaluation.evaluator INFO: Inference done 1673/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:51:46
[02/04 21:58:57] d2.evaluation.evaluator INFO: Inference done 1679/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:40
[02/04 21:59:03] d2.evaluation.evaluator INFO: Inference done 1685/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:34
[02/04 21:59:08] d2.evaluation.evaluator INFO: Inference done 1691/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:28
[02/04 21:59:14] d2.evaluation.evaluator INFO: Inference done 1697/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:23
[02/04 21:59:20] d2.evaluation.evaluator INFO: Inference done 1703/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:17
[02/04 21:59:25] d2.evaluation.evaluator INFO: Inference done 1709/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:11
[02/04 21:59:31] d2.evaluation.evaluator INFO: Inference done 1715/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:51:05
[02/04 21:59:37] d2.evaluation.evaluator INFO: Inference done 1721/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:51:00
[02/04 21:59:42] d2.evaluation.evaluator INFO: Inference done 1727/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:54
[02/04 21:59:48] d2.evaluation.evaluator INFO: Inference done 1733/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:49
[02/04 21:59:54] d2.evaluation.evaluator INFO: Inference done 1739/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:43
[02/04 21:59:59] d2.evaluation.evaluator INFO: Inference done 1745/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:37
[02/04 22:00:05] d2.evaluation.evaluator INFO: Inference done 1751/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:32
[02/04 22:00:11] d2.evaluation.evaluator INFO: Inference done 1757/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:26
[02/04 22:00:17] d2.evaluation.evaluator INFO: Inference done 1763/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:20
[02/04 22:00:22] d2.evaluation.evaluator INFO: Inference done 1769/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:15
[02/04 22:00:28] d2.evaluation.evaluator INFO: Inference done 1775/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:09
[02/04 22:00:34] d2.evaluation.evaluator INFO: Inference done 1781/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:50:03
[02/04 22:00:39] d2.evaluation.evaluator INFO: Inference done 1787/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:57
[02/04 22:00:45] d2.evaluation.evaluator INFO: Inference done 1793/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:49:52
[02/04 22:00:50] d2.evaluation.evaluator INFO: Inference done 1799/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:49:46
[02/04 22:00:56] d2.evaluation.evaluator INFO: Inference done 1805/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:40
[02/04 22:01:02] d2.evaluation.evaluator INFO: Inference done 1811/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:35
[02/04 22:01:08] d2.evaluation.evaluator INFO: Inference done 1817/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:29
[02/04 22:01:13] d2.evaluation.evaluator INFO: Inference done 1823/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:49:23
[02/04 22:01:19] d2.evaluation.evaluator INFO: Inference done 1829/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:18
[02/04 22:01:25] d2.evaluation.evaluator INFO: Inference done 1835/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:12
[02/04 22:01:30] d2.evaluation.evaluator INFO: Inference done 1841/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:06
[02/04 22:01:36] d2.evaluation.evaluator INFO: Inference done 1847/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:49:01
[02/04 22:01:42] d2.evaluation.evaluator INFO: Inference done 1853/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:48:55
[02/04 22:01:47] d2.evaluation.evaluator INFO: Inference done 1859/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:48:49
[02/04 22:01:53] d2.evaluation.evaluator INFO: Inference done 1865/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:43
[02/04 22:01:59] d2.evaluation.evaluator INFO: Inference done 1871/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:38
[02/04 22:02:04] d2.evaluation.evaluator INFO: Inference done 1877/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:32
[02/04 22:02:10] d2.evaluation.evaluator INFO: Inference done 1883/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:26
[02/04 22:02:16] d2.evaluation.evaluator INFO: Inference done 1889/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:20
[02/04 22:02:21] d2.evaluation.evaluator INFO: Inference done 1895/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:15
[02/04 22:02:27] d2.evaluation.evaluator INFO: Inference done 1901/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:48:09
[02/04 22:02:33] d2.evaluation.evaluator INFO: Inference done 1907/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:48:03
[02/04 22:02:38] d2.evaluation.evaluator INFO: Inference done 1913/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:57
[02/04 22:02:44] d2.evaluation.evaluator INFO: Inference done 1919/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:52
[02/04 22:02:50] d2.evaluation.evaluator INFO: Inference done 1925/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:46
[02/04 22:02:55] d2.evaluation.evaluator INFO: Inference done 1931/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:40
[02/04 22:03:01] d2.evaluation.evaluator INFO: Inference done 1937/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:35
[02/04 22:03:07] d2.evaluation.evaluator INFO: Inference done 1943/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:29
[02/04 22:03:12] d2.evaluation.evaluator INFO: Inference done 1949/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:23
[02/04 22:03:18] d2.evaluation.evaluator INFO: Inference done 1955/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:18
[02/04 22:03:24] d2.evaluation.evaluator INFO: Inference done 1961/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:12
[02/04 22:03:29] d2.evaluation.evaluator INFO: Inference done 1967/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:47:06
[02/04 22:03:35] d2.evaluation.evaluator INFO: Inference done 1973/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:47:00
[02/04 22:03:41] d2.evaluation.evaluator INFO: Inference done 1979/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:46:55
[02/04 22:03:46] d2.evaluation.evaluator INFO: Inference done 1985/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:46:49
[02/04 22:03:52] d2.evaluation.evaluator INFO: Inference done 1991/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:46:43
[02/04 22:03:58] d2.evaluation.evaluator INFO: Inference done 1997/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:46:38
[02/04 22:04:03] d2.evaluation.evaluator INFO: Inference done 2003/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:46:32
[02/04 22:04:09] d2.evaluation.evaluator INFO: Inference done 2009/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:46:26
[02/04 22:04:14] d2.evaluation.evaluator INFO: Inference done 2015/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:46:20
[02/04 22:04:20] d2.evaluation.evaluator INFO: Inference done 2021/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:46:15
[02/04 22:04:26] d2.evaluation.evaluator INFO: Inference done 2027/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:46:09
[02/04 22:04:31] d2.evaluation.evaluator INFO: Inference done 2033/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:46:03
[02/04 22:04:37] d2.evaluation.evaluator INFO: Inference done 2039/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:58
[02/04 22:04:43] d2.evaluation.evaluator INFO: Inference done 2045/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:52
[02/04 22:04:49] d2.evaluation.evaluator INFO: Inference done 2051/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:46
[02/04 22:04:54] d2.evaluation.evaluator INFO: Inference done 2057/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:41
[02/04 22:05:00] d2.evaluation.evaluator INFO: Inference done 2063/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:35
[02/04 22:05:06] d2.evaluation.evaluator INFO: Inference done 2069/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:29
[02/04 22:05:11] d2.evaluation.evaluator INFO: Inference done 2075/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:24
[02/04 22:05:17] d2.evaluation.evaluator INFO: Inference done 2081/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:18
[02/04 22:05:23] d2.evaluation.evaluator INFO: Inference done 2087/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:12
[02/04 22:05:28] d2.evaluation.evaluator INFO: Inference done 2093/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:06
[02/04 22:05:34] d2.evaluation.evaluator INFO: Inference done 2099/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:45:01
[02/04 22:05:40] d2.evaluation.evaluator INFO: Inference done 2105/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:55
[02/04 22:05:45] d2.evaluation.evaluator INFO: Inference done 2111/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:49
[02/04 22:05:51] d2.evaluation.evaluator INFO: Inference done 2117/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:44
[02/04 22:05:57] d2.evaluation.evaluator INFO: Inference done 2123/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:38
[02/04 22:06:02] d2.evaluation.evaluator INFO: Inference done 2129/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:32
[02/04 22:06:08] d2.evaluation.evaluator INFO: Inference done 2135/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:27
[02/04 22:06:14] d2.evaluation.evaluator INFO: Inference done 2141/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:44:21
[02/04 22:06:19] d2.evaluation.evaluator INFO: Inference done 2147/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:44:15
[02/04 22:06:25] d2.evaluation.evaluator INFO: Inference done 2153/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:09
[02/04 22:06:31] d2.evaluation.evaluator INFO: Inference done 2159/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:44:04
[02/04 22:06:36] d2.evaluation.evaluator INFO: Inference done 2165/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:43:58
[02/04 22:06:42] d2.evaluation.evaluator INFO: Inference done 2171/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:43:52
[02/04 22:06:48] d2.evaluation.evaluator INFO: Inference done 2177/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:43:47
[02/04 22:06:53] d2.evaluation.evaluator INFO: Inference done 2183/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:41
[02/04 22:06:59] d2.evaluation.evaluator INFO: Inference done 2189/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:35
[02/04 22:07:05] d2.evaluation.evaluator INFO: Inference done 2195/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:30
[02/04 22:07:10] d2.evaluation.evaluator INFO: Inference done 2201/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:24
[02/04 22:07:16] d2.evaluation.evaluator INFO: Inference done 2207/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:19
[02/04 22:07:22] d2.evaluation.evaluator INFO: Inference done 2213/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:13
[02/04 22:07:27] d2.evaluation.evaluator INFO: Inference done 2219/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:07
[02/04 22:07:33] d2.evaluation.evaluator INFO: Inference done 2225/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:43:01
[02/04 22:07:39] d2.evaluation.evaluator INFO: Inference done 2231/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:56
[02/04 22:07:44] d2.evaluation.evaluator INFO: Inference done 2237/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:50
[02/04 22:07:50] d2.evaluation.evaluator INFO: Inference done 2243/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:44
[02/04 22:07:56] d2.evaluation.evaluator INFO: Inference done 2249/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:38
[02/04 22:08:01] d2.evaluation.evaluator INFO: Inference done 2255/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:33
[02/04 22:08:07] d2.evaluation.evaluator INFO: Inference done 2261/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:27
[02/04 22:08:13] d2.evaluation.evaluator INFO: Inference done 2267/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:21
[02/04 22:08:18] d2.evaluation.evaluator INFO: Inference done 2273/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:16
[02/04 22:08:24] d2.evaluation.evaluator INFO: Inference done 2279/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:10
[02/04 22:08:30] d2.evaluation.evaluator INFO: Inference done 2285/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:42:04
[02/04 22:08:35] d2.evaluation.evaluator INFO: Inference done 2291/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:59
[02/04 22:08:41] d2.evaluation.evaluator INFO: Inference done 2297/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:53
[02/04 22:08:47] d2.evaluation.evaluator INFO: Inference done 2303/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:47
[02/04 22:08:53] d2.evaluation.evaluator INFO: Inference done 2309/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:42
[02/04 22:08:58] d2.evaluation.evaluator INFO: Inference done 2315/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:36
[02/04 22:09:04] d2.evaluation.evaluator INFO: Inference done 2321/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:30
[02/04 22:09:09] d2.evaluation.evaluator INFO: Inference done 2327/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:41:24
[02/04 22:09:15] d2.evaluation.evaluator INFO: Inference done 2333/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:41:19
[02/04 22:09:21] d2.evaluation.evaluator INFO: Inference done 2339/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:41:13
[02/04 22:09:26] d2.evaluation.evaluator INFO: Inference done 2345/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:41:07
[02/04 22:09:32] d2.evaluation.evaluator INFO: Inference done 2351/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:41:02
[02/04 22:09:38] d2.evaluation.evaluator INFO: Inference done 2357/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:56
[02/04 22:09:43] d2.evaluation.evaluator INFO: Inference done 2363/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:50
[02/04 22:09:49] d2.evaluation.evaluator INFO: Inference done 2369/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:45
[02/04 22:09:55] d2.evaluation.evaluator INFO: Inference done 2375/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:39
[02/04 22:10:00] d2.evaluation.evaluator INFO: Inference done 2381/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:33
[02/04 22:10:06] d2.evaluation.evaluator INFO: Inference done 2387/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:28
[02/04 22:10:12] d2.evaluation.evaluator INFO: Inference done 2393/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:40:22
[02/04 22:10:18] d2.evaluation.evaluator INFO: Inference done 2399/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:40:16
[02/04 22:10:23] d2.evaluation.evaluator INFO: Inference done 2405/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:40:11
[02/04 22:10:29] d2.evaluation.evaluator INFO: Inference done 2411/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:40:05
[02/04 22:10:35] d2.evaluation.evaluator INFO: Inference done 2417/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:59
[02/04 22:10:40] d2.evaluation.evaluator INFO: Inference done 2423/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:54
[02/04 22:10:46] d2.evaluation.evaluator INFO: Inference done 2429/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:48
[02/04 22:10:52] d2.evaluation.evaluator INFO: Inference done 2435/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:42
[02/04 22:10:57] d2.evaluation.evaluator INFO: Inference done 2441/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:37
[02/04 22:11:03] d2.evaluation.evaluator INFO: Inference done 2447/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:31
[02/04 22:11:09] d2.evaluation.evaluator INFO: Inference done 2453/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:25
[02/04 22:11:14] d2.evaluation.evaluator INFO: Inference done 2459/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:20
[02/04 22:11:20] d2.evaluation.evaluator INFO: Inference done 2465/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:14
[02/04 22:11:26] d2.evaluation.evaluator INFO: Inference done 2471/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:08
[02/04 22:11:32] d2.evaluation.evaluator INFO: Inference done 2477/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:39:03
[02/04 22:11:37] d2.evaluation.evaluator INFO: Inference done 2483/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:57
[02/04 22:11:43] d2.evaluation.evaluator INFO: Inference done 2489/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:51
[02/04 22:11:49] d2.evaluation.evaluator INFO: Inference done 2495/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:46
[02/04 22:11:54] d2.evaluation.evaluator INFO: Inference done 2501/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:40
[02/04 22:12:00] d2.evaluation.evaluator INFO: Inference done 2507/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:34
[02/04 22:12:06] d2.evaluation.evaluator INFO: Inference done 2513/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:29
[02/04 22:12:11] d2.evaluation.evaluator INFO: Inference done 2519/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:23
[02/04 22:12:17] d2.evaluation.evaluator INFO: Inference done 2525/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:17
[02/04 22:12:23] d2.evaluation.evaluator INFO: Inference done 2531/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:11
[02/04 22:12:28] d2.evaluation.evaluator INFO: Inference done 2537/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:38:06
[02/04 22:12:34] d2.evaluation.evaluator INFO: Inference done 2543/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:38:00
[02/04 22:12:40] d2.evaluation.evaluator INFO: Inference done 2549/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:55
[02/04 22:12:46] d2.evaluation.evaluator INFO: Inference done 2555/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:49
[02/04 22:12:51] d2.evaluation.evaluator INFO: Inference done 2561/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:43
[02/04 22:12:57] d2.evaluation.evaluator INFO: Inference done 2567/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:38
[02/04 22:13:03] d2.evaluation.evaluator INFO: Inference done 2573/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:32
[02/04 22:13:08] d2.evaluation.evaluator INFO: Inference done 2579/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:26
[02/04 22:13:14] d2.evaluation.evaluator INFO: Inference done 2585/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:21
[02/04 22:13:20] d2.evaluation.evaluator INFO: Inference done 2591/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:37:15
[02/04 22:13:25] d2.evaluation.evaluator INFO: Inference done 2597/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:37:09
[02/04 22:13:31] d2.evaluation.evaluator INFO: Inference done 2603/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:37:03
[02/04 22:13:36] d2.evaluation.evaluator INFO: Inference done 2609/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:36:58
[02/04 22:13:42] d2.evaluation.evaluator INFO: Inference done 2615/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:36:52
[02/04 22:13:48] d2.evaluation.evaluator INFO: Inference done 2621/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:36:46
[02/04 22:13:54] d2.evaluation.evaluator INFO: Inference done 2627/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:36:41
[02/04 22:13:59] d2.evaluation.evaluator INFO: Inference done 2633/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:36:35
[02/04 22:14:05] d2.evaluation.evaluator INFO: Inference done 2639/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:36:29
[02/04 22:14:11] d2.evaluation.evaluator INFO: Inference done 2645/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:36:24
[02/04 22:14:16] d2.evaluation.evaluator INFO: Inference done 2651/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:36:18
[02/04 22:14:22] d2.evaluation.evaluator INFO: Inference done 2657/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:36:12
[02/04 22:14:28] d2.evaluation.evaluator INFO: Inference done 2663/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:36:07
[02/04 22:14:34] d2.evaluation.evaluator INFO: Inference done 2669/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:36:01
[02/04 22:14:39] d2.evaluation.evaluator INFO: Inference done 2675/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:55
[02/04 22:14:45] d2.evaluation.evaluator INFO: Inference done 2681/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:50
[02/04 22:14:51] d2.evaluation.evaluator INFO: Inference done 2687/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:44
[02/04 22:14:56] d2.evaluation.evaluator INFO: Inference done 2693/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:38
[02/04 22:15:02] d2.evaluation.evaluator INFO: Inference done 2699/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:33
[02/04 22:15:08] d2.evaluation.evaluator INFO: Inference done 2705/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:27
[02/04 22:15:13] d2.evaluation.evaluator INFO: Inference done 2711/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:21
[02/04 22:15:19] d2.evaluation.evaluator INFO: Inference done 2717/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:35:16
[02/04 22:15:25] d2.evaluation.evaluator INFO: Inference done 2723/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:35:10
[02/04 22:15:30] d2.evaluation.evaluator INFO: Inference done 2729/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:35:04
[02/04 22:15:36] d2.evaluation.evaluator INFO: Inference done 2735/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:59
[02/04 22:15:42] d2.evaluation.evaluator INFO: Inference done 2741/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:53
[02/04 22:15:47] d2.evaluation.evaluator INFO: Inference done 2747/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:47
[02/04 22:15:53] d2.evaluation.evaluator INFO: Inference done 2753/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:42
[02/04 22:15:59] d2.evaluation.evaluator INFO: Inference done 2759/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:36
[02/04 22:16:05] d2.evaluation.evaluator INFO: Inference done 2765/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:30
[02/04 22:16:10] d2.evaluation.evaluator INFO: Inference done 2771/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:25
[02/04 22:16:16] d2.evaluation.evaluator INFO: Inference done 2777/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:19
[02/04 22:16:21] d2.evaluation.evaluator INFO: Inference done 2783/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:13
[02/04 22:16:27] d2.evaluation.evaluator INFO: Inference done 2789/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:07
[02/04 22:16:33] d2.evaluation.evaluator INFO: Inference done 2795/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:34:02
[02/04 22:16:38] d2.evaluation.evaluator INFO: Inference done 2801/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:33:56
[02/04 22:16:44] d2.evaluation.evaluator INFO: Inference done 2807/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:33:50
[02/04 22:16:50] d2.evaluation.evaluator INFO: Inference done 2813/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:33:45
[02/04 22:16:55] d2.evaluation.evaluator INFO: Inference done 2819/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:33:39
[02/04 22:17:01] d2.evaluation.evaluator INFO: Inference done 2825/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:33:33
[02/04 22:17:07] d2.evaluation.evaluator INFO: Inference done 2831/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:33:28
[02/04 22:17:12] d2.evaluation.evaluator INFO: Inference done 2837/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:33:22
[02/04 22:17:18] d2.evaluation.evaluator INFO: Inference done 2843/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:33:16
[02/04 22:17:24] d2.evaluation.evaluator INFO: Inference done 2849/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:33:11
[02/04 22:17:30] d2.evaluation.evaluator INFO: Inference done 2855/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:33:05
[02/04 22:17:35] d2.evaluation.evaluator INFO: Inference done 2861/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:32:59
[02/04 22:17:41] d2.evaluation.evaluator INFO: Inference done 2867/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:32:54
[02/04 22:17:47] d2.evaluation.evaluator INFO: Inference done 2873/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:32:48
[02/04 22:17:52] d2.evaluation.evaluator INFO: Inference done 2879/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:42
[02/04 22:17:58] d2.evaluation.evaluator INFO: Inference done 2885/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:36
[02/04 22:18:04] d2.evaluation.evaluator INFO: Inference done 2891/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:31
[02/04 22:18:09] d2.evaluation.evaluator INFO: Inference done 2897/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:25
[02/04 22:18:15] d2.evaluation.evaluator INFO: Inference done 2903/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:19
[02/04 22:18:20] d2.evaluation.evaluator INFO: Inference done 2909/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:14
[02/04 22:18:26] d2.evaluation.evaluator INFO: Inference done 2915/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:08
[02/04 22:18:32] d2.evaluation.evaluator INFO: Inference done 2921/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:32:02
[02/04 22:18:37] d2.evaluation.evaluator INFO: Inference done 2927/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:31:56
[02/04 22:18:43] d2.evaluation.evaluator INFO: Inference done 2933/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:31:51
[02/04 22:18:49] d2.evaluation.evaluator INFO: Inference done 2939/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:31:45
[02/04 22:18:54] d2.evaluation.evaluator INFO: Inference done 2945/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:31:39
[02/04 22:19:00] d2.evaluation.evaluator INFO: Inference done 2951/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:31:34
[02/04 22:19:06] d2.evaluation.evaluator INFO: Inference done 2957/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:31:28
[02/04 22:19:11] d2.evaluation.evaluator INFO: Inference done 2963/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:31:22
[02/04 22:19:17] d2.evaluation.evaluator INFO: Inference done 2969/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:31:17
[02/04 22:19:23] d2.evaluation.evaluator INFO: Inference done 2975/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:31:11
[02/04 22:19:29] d2.evaluation.evaluator INFO: Inference done 2981/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:31:05
[02/04 22:19:34] d2.evaluation.evaluator INFO: Inference done 2987/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:31:00
[02/04 22:19:40] d2.evaluation.evaluator INFO: Inference done 2993/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:30:54
[02/04 22:19:46] d2.evaluation.evaluator INFO: Inference done 2999/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:48
[02/04 22:19:51] d2.evaluation.evaluator INFO: Inference done 3005/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:43
[02/04 22:19:57] d2.evaluation.evaluator INFO: Inference done 3011/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:37
[02/04 22:20:03] d2.evaluation.evaluator INFO: Inference done 3017/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:31
[02/04 22:20:08] d2.evaluation.evaluator INFO: Inference done 3023/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:26
[02/04 22:20:14] d2.evaluation.evaluator INFO: Inference done 3029/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:20
[02/04 22:20:19] d2.evaluation.evaluator INFO: Inference done 3035/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:30:14
[02/04 22:20:25] d2.evaluation.evaluator INFO: Inference done 3041/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9465 s/iter. ETA=0:30:08
[02/04 22:20:31] d2.evaluation.evaluator INFO: Inference done 3047/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9465 s/iter. ETA=0:30:03
[02/04 22:20:36] d2.evaluation.evaluator INFO: Inference done 3053/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:57
[02/04 22:20:42] d2.evaluation.evaluator INFO: Inference done 3059/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:51
[02/04 22:20:48] d2.evaluation.evaluator INFO: Inference done 3065/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:46
[02/04 22:20:54] d2.evaluation.evaluator INFO: Inference done 3071/4952. Dataloading: 0.0007 s/iter. Inference: 0.9450 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:40
[02/04 22:20:59] d2.evaluation.evaluator INFO: Inference done 3077/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:34
[02/04 22:21:05] d2.evaluation.evaluator INFO: Inference done 3083/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:29
[02/04 22:21:11] d2.evaluation.evaluator INFO: Inference done 3089/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9466 s/iter. ETA=0:29:23
[02/04 22:21:16] d2.evaluation.evaluator INFO: Inference done 3095/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:29:17
[02/04 22:21:22] d2.evaluation.evaluator INFO: Inference done 3101/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:29:12
[02/04 22:21:28] d2.evaluation.evaluator INFO: Inference done 3107/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:29:06
[02/04 22:21:34] d2.evaluation.evaluator INFO: Inference done 3113/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:29:00
[02/04 22:21:39] d2.evaluation.evaluator INFO: Inference done 3119/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:28:55
[02/04 22:21:45] d2.evaluation.evaluator INFO: Inference done 3125/4952. Dataloading: 0.0007 s/iter. Inference: 0.9451 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:28:49
[02/04 22:21:51] d2.evaluation.evaluator INFO: Inference done 3131/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:28:43
[02/04 22:21:56] d2.evaluation.evaluator INFO: Inference done 3137/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:28:38
[02/04 22:22:02] d2.evaluation.evaluator INFO: Inference done 3143/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:28:32
[02/04 22:22:08] d2.evaluation.evaluator INFO: Inference done 3149/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:28:27
[02/04 22:22:14] d2.evaluation.evaluator INFO: Inference done 3155/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:28:21
[02/04 22:22:19] d2.evaluation.evaluator INFO: Inference done 3161/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:28:15
[02/04 22:22:25] d2.evaluation.evaluator INFO: Inference done 3167/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:28:09
[02/04 22:22:31] d2.evaluation.evaluator INFO: Inference done 3173/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:28:04
[02/04 22:22:36] d2.evaluation.evaluator INFO: Inference done 3179/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:58
[02/04 22:22:42] d2.evaluation.evaluator INFO: Inference done 3185/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:53
[02/04 22:22:48] d2.evaluation.evaluator INFO: Inference done 3191/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:47
[02/04 22:22:54] d2.evaluation.evaluator INFO: Inference done 3197/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:41
[02/04 22:22:59] d2.evaluation.evaluator INFO: Inference done 3203/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:36
[02/04 22:23:05] d2.evaluation.evaluator INFO: Inference done 3209/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:30
[02/04 22:23:11] d2.evaluation.evaluator INFO: Inference done 3215/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:24
[02/04 22:23:16] d2.evaluation.evaluator INFO: Inference done 3221/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:18
[02/04 22:23:22] d2.evaluation.evaluator INFO: Inference done 3227/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:27:13
[02/04 22:23:28] d2.evaluation.evaluator INFO: Inference done 3233/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:27:07
[02/04 22:23:33] d2.evaluation.evaluator INFO: Inference done 3239/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:27:01
[02/04 22:23:39] d2.evaluation.evaluator INFO: Inference done 3245/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:26:56
[02/04 22:23:45] d2.evaluation.evaluator INFO: Inference done 3251/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:50
[02/04 22:23:50] d2.evaluation.evaluator INFO: Inference done 3257/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:26:44
[02/04 22:23:56] d2.evaluation.evaluator INFO: Inference done 3263/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:39
[02/04 22:24:02] d2.evaluation.evaluator INFO: Inference done 3269/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:33
[02/04 22:24:07] d2.evaluation.evaluator INFO: Inference done 3275/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:27
[02/04 22:24:13] d2.evaluation.evaluator INFO: Inference done 3281/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:22
[02/04 22:24:19] d2.evaluation.evaluator INFO: Inference done 3287/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:16
[02/04 22:24:24] d2.evaluation.evaluator INFO: Inference done 3293/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:10
[02/04 22:24:30] d2.evaluation.evaluator INFO: Inference done 3299/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:26:05
[02/04 22:24:36] d2.evaluation.evaluator INFO: Inference done 3305/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:59
[02/04 22:24:41] d2.evaluation.evaluator INFO: Inference done 3311/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:53
[02/04 22:24:47] d2.evaluation.evaluator INFO: Inference done 3317/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:48
[02/04 22:24:53] d2.evaluation.evaluator INFO: Inference done 3323/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:42
[02/04 22:24:58] d2.evaluation.evaluator INFO: Inference done 3329/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:36
[02/04 22:25:04] d2.evaluation.evaluator INFO: Inference done 3335/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:31
[02/04 22:25:10] d2.evaluation.evaluator INFO: Inference done 3341/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:25
[02/04 22:25:15] d2.evaluation.evaluator INFO: Inference done 3347/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:19
[02/04 22:25:21] d2.evaluation.evaluator INFO: Inference done 3353/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:13
[02/04 22:25:27] d2.evaluation.evaluator INFO: Inference done 3359/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:08
[02/04 22:25:33] d2.evaluation.evaluator INFO: Inference done 3365/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:25:02
[02/04 22:25:38] d2.evaluation.evaluator INFO: Inference done 3371/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:56
[02/04 22:25:44] d2.evaluation.evaluator INFO: Inference done 3377/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:51
[02/04 22:25:50] d2.evaluation.evaluator INFO: Inference done 3383/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:45
[02/04 22:25:55] d2.evaluation.evaluator INFO: Inference done 3389/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:39
[02/04 22:26:01] d2.evaluation.evaluator INFO: Inference done 3395/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:34
[02/04 22:26:07] d2.evaluation.evaluator INFO: Inference done 3401/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:28
[02/04 22:26:12] d2.evaluation.evaluator INFO: Inference done 3407/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:22
[02/04 22:26:18] d2.evaluation.evaluator INFO: Inference done 3413/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:24:17
[02/04 22:26:23] d2.evaluation.evaluator INFO: Inference done 3419/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:24:11
[02/04 22:26:29] d2.evaluation.evaluator INFO: Inference done 3425/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:24:05
[02/04 22:26:35] d2.evaluation.evaluator INFO: Inference done 3431/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:23:59
[02/04 22:26:40] d2.evaluation.evaluator INFO: Inference done 3437/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:23:54
[02/04 22:26:46] d2.evaluation.evaluator INFO: Inference done 3443/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:23:48
[02/04 22:26:52] d2.evaluation.evaluator INFO: Inference done 3449/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9467 s/iter. ETA=0:23:42
[02/04 22:26:58] d2.evaluation.evaluator INFO: Inference done 3455/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:37
[02/04 22:27:03] d2.evaluation.evaluator INFO: Inference done 3461/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:31
[02/04 22:27:09] d2.evaluation.evaluator INFO: Inference done 3467/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:25
[02/04 22:27:15] d2.evaluation.evaluator INFO: Inference done 3473/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:20
[02/04 22:27:20] d2.evaluation.evaluator INFO: Inference done 3479/4952. Dataloading: 0.0007 s/iter. Inference: 0.9452 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:14
[02/04 22:27:26] d2.evaluation.evaluator INFO: Inference done 3485/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:08
[02/04 22:27:32] d2.evaluation.evaluator INFO: Inference done 3491/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:23:03
[02/04 22:27:38] d2.evaluation.evaluator INFO: Inference done 3497/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:22:57
[02/04 22:27:43] d2.evaluation.evaluator INFO: Inference done 3503/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9468 s/iter. ETA=0:22:51
[02/04 22:27:49] d2.evaluation.evaluator INFO: Inference done 3509/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:46
[02/04 22:27:55] d2.evaluation.evaluator INFO: Inference done 3515/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:40
[02/04 22:28:01] d2.evaluation.evaluator INFO: Inference done 3521/4952. Dataloading: 0.0007 s/iter. Inference: 0.9453 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:34
[02/04 22:28:06] d2.evaluation.evaluator INFO: Inference done 3527/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:29
[02/04 22:28:12] d2.evaluation.evaluator INFO: Inference done 3533/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:23
[02/04 22:28:18] d2.evaluation.evaluator INFO: Inference done 3539/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:17
[02/04 22:28:23] d2.evaluation.evaluator INFO: Inference done 3545/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:12
[02/04 22:28:29] d2.evaluation.evaluator INFO: Inference done 3551/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:06
[02/04 22:28:35] d2.evaluation.evaluator INFO: Inference done 3557/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9469 s/iter. ETA=0:22:00
[02/04 22:28:41] d2.evaluation.evaluator INFO: Inference done 3563/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:55
[02/04 22:28:46] d2.evaluation.evaluator INFO: Inference done 3569/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:49
[02/04 22:28:52] d2.evaluation.evaluator INFO: Inference done 3575/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:43
[02/04 22:28:58] d2.evaluation.evaluator INFO: Inference done 3581/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:38
[02/04 22:29:03] d2.evaluation.evaluator INFO: Inference done 3587/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:32
[02/04 22:29:09] d2.evaluation.evaluator INFO: Inference done 3593/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:26
[02/04 22:29:15] d2.evaluation.evaluator INFO: Inference done 3599/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:21
[02/04 22:29:21] d2.evaluation.evaluator INFO: Inference done 3605/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:15
[02/04 22:29:26] d2.evaluation.evaluator INFO: Inference done 3611/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:09
[02/04 22:29:32] d2.evaluation.evaluator INFO: Inference done 3617/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:21:04
[02/04 22:29:38] d2.evaluation.evaluator INFO: Inference done 3623/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:58
[02/04 22:29:43] d2.evaluation.evaluator INFO: Inference done 3629/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:52
[02/04 22:29:49] d2.evaluation.evaluator INFO: Inference done 3635/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:47
[02/04 22:29:55] d2.evaluation.evaluator INFO: Inference done 3641/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:41
[02/04 22:30:00] d2.evaluation.evaluator INFO: Inference done 3647/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:35
[02/04 22:30:06] d2.evaluation.evaluator INFO: Inference done 3653/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:30
[02/04 22:30:12] d2.evaluation.evaluator INFO: Inference done 3659/4952. Dataloading: 0.0007 s/iter. Inference: 0.9454 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:24
[02/04 22:30:17] d2.evaluation.evaluator INFO: Inference done 3665/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:18
[02/04 22:30:23] d2.evaluation.evaluator INFO: Inference done 3671/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:13
[02/04 22:30:29] d2.evaluation.evaluator INFO: Inference done 3677/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:20:07
[02/04 22:30:35] d2.evaluation.evaluator INFO: Inference done 3683/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:20:01
[02/04 22:30:40] d2.evaluation.evaluator INFO: Inference done 3689/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:19:56
[02/04 22:30:46] d2.evaluation.evaluator INFO: Inference done 3695/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:19:50
[02/04 22:30:52] d2.evaluation.evaluator INFO: Inference done 3701/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:19:44
[02/04 22:30:57] d2.evaluation.evaluator INFO: Inference done 3707/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:19:39
[02/04 22:31:03] d2.evaluation.evaluator INFO: Inference done 3713/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:19:33
[02/04 22:31:09] d2.evaluation.evaluator INFO: Inference done 3719/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:19:27
[02/04 22:31:14] d2.evaluation.evaluator INFO: Inference done 3725/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:19:22
[02/04 22:31:20] d2.evaluation.evaluator INFO: Inference done 3731/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:19:16
[02/04 22:31:26] d2.evaluation.evaluator INFO: Inference done 3737/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:19:10
[02/04 22:31:31] d2.evaluation.evaluator INFO: Inference done 3743/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9470 s/iter. ETA=0:19:04
[02/04 22:31:37] d2.evaluation.evaluator INFO: Inference done 3749/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:59
[02/04 22:31:43] d2.evaluation.evaluator INFO: Inference done 3755/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:53
[02/04 22:31:48] d2.evaluation.evaluator INFO: Inference done 3761/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:47
[02/04 22:31:54] d2.evaluation.evaluator INFO: Inference done 3767/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:42
[02/04 22:32:00] d2.evaluation.evaluator INFO: Inference done 3773/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:36
[02/04 22:32:06] d2.evaluation.evaluator INFO: Inference done 3779/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:30
[02/04 22:32:11] d2.evaluation.evaluator INFO: Inference done 3785/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:25
[02/04 22:32:17] d2.evaluation.evaluator INFO: Inference done 3791/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:19
[02/04 22:32:23] d2.evaluation.evaluator INFO: Inference done 3797/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:13
[02/04 22:32:28] d2.evaluation.evaluator INFO: Inference done 3803/4952. Dataloading: 0.0007 s/iter. Inference: 0.9455 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:08
[02/04 22:32:34] d2.evaluation.evaluator INFO: Inference done 3809/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:18:02
[02/04 22:32:40] d2.evaluation.evaluator INFO: Inference done 3815/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:17:56
[02/04 22:32:46] d2.evaluation.evaluator INFO: Inference done 3821/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:17:51
[02/04 22:32:51] d2.evaluation.evaluator INFO: Inference done 3827/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:17:45
[02/04 22:32:57] d2.evaluation.evaluator INFO: Inference done 3833/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:17:39
[02/04 22:33:03] d2.evaluation.evaluator INFO: Inference done 3839/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:17:34
[02/04 22:33:08] d2.evaluation.evaluator INFO: Inference done 3845/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:17:28
[02/04 22:33:14] d2.evaluation.evaluator INFO: Inference done 3851/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:17:22
[02/04 22:33:20] d2.evaluation.evaluator INFO: Inference done 3857/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9471 s/iter. ETA=0:17:17
[02/04 22:33:25] d2.evaluation.evaluator INFO: Inference done 3863/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:17:11
[02/04 22:33:31] d2.evaluation.evaluator INFO: Inference done 3869/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:17:05
[02/04 22:33:37] d2.evaluation.evaluator INFO: Inference done 3875/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:17:00
[02/04 22:33:42] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:16:54
[02/04 22:33:48] d2.evaluation.evaluator INFO: Inference done 3887/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:16:48
[02/04 22:33:54] d2.evaluation.evaluator INFO: Inference done 3893/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:16:43
[02/04 22:34:00] d2.evaluation.evaluator INFO: Inference done 3899/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:16:37
[02/04 22:34:06] d2.evaluation.evaluator INFO: Inference done 3905/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:16:31
[02/04 22:34:11] d2.evaluation.evaluator INFO: Inference done 3911/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:16:26
[02/04 22:34:17] d2.evaluation.evaluator INFO: Inference done 3917/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:16:20
[02/04 22:34:23] d2.evaluation.evaluator INFO: Inference done 3923/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:16:14
[02/04 22:34:28] d2.evaluation.evaluator INFO: Inference done 3929/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:16:09
[02/04 22:34:34] d2.evaluation.evaluator INFO: Inference done 3935/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:16:03
[02/04 22:34:40] d2.evaluation.evaluator INFO: Inference done 3941/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:57
[02/04 22:34:45] d2.evaluation.evaluator INFO: Inference done 3947/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:52
[02/04 22:34:51] d2.evaluation.evaluator INFO: Inference done 3953/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:46
[02/04 22:34:57] d2.evaluation.evaluator INFO: Inference done 3959/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:40
[02/04 22:35:02] d2.evaluation.evaluator INFO: Inference done 3965/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:34
[02/04 22:35:08] d2.evaluation.evaluator INFO: Inference done 3971/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:29
[02/04 22:35:14] d2.evaluation.evaluator INFO: Inference done 3977/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:23
[02/04 22:35:20] d2.evaluation.evaluator INFO: Inference done 3983/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:17
[02/04 22:35:25] d2.evaluation.evaluator INFO: Inference done 3989/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:12
[02/04 22:35:31] d2.evaluation.evaluator INFO: Inference done 3995/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:06
[02/04 22:35:37] d2.evaluation.evaluator INFO: Inference done 4001/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:15:00
[02/04 22:35:42] d2.evaluation.evaluator INFO: Inference done 4007/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:14:55
[02/04 22:35:48] d2.evaluation.evaluator INFO: Inference done 4013/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:14:49
[02/04 22:35:54] d2.evaluation.evaluator INFO: Inference done 4019/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:14:43
[02/04 22:36:00] d2.evaluation.evaluator INFO: Inference done 4025/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:14:38
[02/04 22:36:05] d2.evaluation.evaluator INFO: Inference done 4031/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:14:32
[02/04 22:36:11] d2.evaluation.evaluator INFO: Inference done 4037/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:14:26
[02/04 22:36:17] d2.evaluation.evaluator INFO: Inference done 4043/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:14:21
[02/04 22:36:22] d2.evaluation.evaluator INFO: Inference done 4049/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:14:15
[02/04 22:36:28] d2.evaluation.evaluator INFO: Inference done 4055/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:14:09
[02/04 22:36:34] d2.evaluation.evaluator INFO: Inference done 4061/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:14:04
[02/04 22:36:39] d2.evaluation.evaluator INFO: Inference done 4067/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:58
[02/04 22:36:45] d2.evaluation.evaluator INFO: Inference done 4073/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:52
[02/04 22:36:51] d2.evaluation.evaluator INFO: Inference done 4079/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:47
[02/04 22:36:56] d2.evaluation.evaluator INFO: Inference done 4085/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:41
[02/04 22:37:02] d2.evaluation.evaluator INFO: Inference done 4091/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:35
[02/04 22:37:08] d2.evaluation.evaluator INFO: Inference done 4097/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:29
[02/04 22:37:13] d2.evaluation.evaluator INFO: Inference done 4103/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:24
[02/04 22:37:19] d2.evaluation.evaluator INFO: Inference done 4109/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:18
[02/04 22:37:25] d2.evaluation.evaluator INFO: Inference done 4115/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:13:12
[02/04 22:37:30] d2.evaluation.evaluator INFO: Inference done 4121/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:13:07
[02/04 22:37:36] d2.evaluation.evaluator INFO: Inference done 4127/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:13:01
[02/04 22:37:41] d2.evaluation.evaluator INFO: Inference done 4133/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:55
[02/04 22:37:47] d2.evaluation.evaluator INFO: Inference done 4139/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:50
[02/04 22:37:53] d2.evaluation.evaluator INFO: Inference done 4145/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:44
[02/04 22:37:59] d2.evaluation.evaluator INFO: Inference done 4151/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:12:38
[02/04 22:38:04] d2.evaluation.evaluator INFO: Inference done 4157/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:33
[02/04 22:38:10] d2.evaluation.evaluator INFO: Inference done 4163/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:12:27
[02/04 22:38:16] d2.evaluation.evaluator INFO: Inference done 4169/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:21
[02/04 22:38:21] d2.evaluation.evaluator INFO: Inference done 4175/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:15
[02/04 22:38:27] d2.evaluation.evaluator INFO: Inference done 4181/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:10
[02/04 22:38:32] d2.evaluation.evaluator INFO: Inference done 4187/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:12:04
[02/04 22:38:38] d2.evaluation.evaluator INFO: Inference done 4193/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:58
[02/04 22:38:44] d2.evaluation.evaluator INFO: Inference done 4199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:53
[02/04 22:38:49] d2.evaluation.evaluator INFO: Inference done 4205/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:47
[02/04 22:38:55] d2.evaluation.evaluator INFO: Inference done 4211/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:41
[02/04 22:39:01] d2.evaluation.evaluator INFO: Inference done 4217/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:36
[02/04 22:39:07] d2.evaluation.evaluator INFO: Inference done 4223/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:30
[02/04 22:39:12] d2.evaluation.evaluator INFO: Inference done 4229/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:24
[02/04 22:39:18] d2.evaluation.evaluator INFO: Inference done 4235/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:19
[02/04 22:39:24] d2.evaluation.evaluator INFO: Inference done 4241/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:13
[02/04 22:39:29] d2.evaluation.evaluator INFO: Inference done 4247/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:07
[02/04 22:39:35] d2.evaluation.evaluator INFO: Inference done 4253/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:11:02
[02/04 22:39:41] d2.evaluation.evaluator INFO: Inference done 4259/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:56
[02/04 22:39:46] d2.evaluation.evaluator INFO: Inference done 4265/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:50
[02/04 22:39:52] d2.evaluation.evaluator INFO: Inference done 4271/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:45
[02/04 22:39:58] d2.evaluation.evaluator INFO: Inference done 4277/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:39
[02/04 22:40:03] d2.evaluation.evaluator INFO: Inference done 4283/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:33
[02/04 22:40:09] d2.evaluation.evaluator INFO: Inference done 4289/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:27
[02/04 22:40:15] d2.evaluation.evaluator INFO: Inference done 4295/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:22
[02/04 22:40:21] d2.evaluation.evaluator INFO: Inference done 4301/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:16
[02/04 22:40:26] d2.evaluation.evaluator INFO: Inference done 4307/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:10
[02/04 22:40:32] d2.evaluation.evaluator INFO: Inference done 4313/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:10:05
[02/04 22:40:38] d2.evaluation.evaluator INFO: Inference done 4319/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:09:59
[02/04 22:40:43] d2.evaluation.evaluator INFO: Inference done 4325/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:09:53
[02/04 22:40:49] d2.evaluation.evaluator INFO: Inference done 4331/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:09:48
[02/04 22:40:55] d2.evaluation.evaluator INFO: Inference done 4337/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:09:42
[02/04 22:41:00] d2.evaluation.evaluator INFO: Inference done 4343/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:09:36
[02/04 22:41:06] d2.evaluation.evaluator INFO: Inference done 4349/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:09:31
[02/04 22:41:12] d2.evaluation.evaluator INFO: Inference done 4355/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:09:25
[02/04 22:41:18] d2.evaluation.evaluator INFO: Inference done 4361/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:09:19
[02/04 22:41:23] d2.evaluation.evaluator INFO: Inference done 4367/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:09:14
[02/04 22:41:29] d2.evaluation.evaluator INFO: Inference done 4373/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:09:08
[02/04 22:41:35] d2.evaluation.evaluator INFO: Inference done 4379/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:09:02
[02/04 22:41:40] d2.evaluation.evaluator INFO: Inference done 4385/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:08:57
[02/04 22:41:46] d2.evaluation.evaluator INFO: Inference done 4391/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:08:51
[02/04 22:41:52] d2.evaluation.evaluator INFO: Inference done 4397/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:08:45
[02/04 22:41:57] d2.evaluation.evaluator INFO: Inference done 4403/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:08:40
[02/04 22:42:03] d2.evaluation.evaluator INFO: Inference done 4409/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:08:34
[02/04 22:42:09] d2.evaluation.evaluator INFO: Inference done 4415/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:08:28
[02/04 22:42:14] d2.evaluation.evaluator INFO: Inference done 4421/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:08:22
[02/04 22:42:20] d2.evaluation.evaluator INFO: Inference done 4427/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:08:17
[02/04 22:42:26] d2.evaluation.evaluator INFO: Inference done 4433/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:08:11
[02/04 22:42:32] d2.evaluation.evaluator INFO: Inference done 4439/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:08:05
[02/04 22:42:37] d2.evaluation.evaluator INFO: Inference done 4445/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:08:00
[02/04 22:42:43] d2.evaluation.evaluator INFO: Inference done 4451/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:54
[02/04 22:42:49] d2.evaluation.evaluator INFO: Inference done 4457/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:48
[02/04 22:42:54] d2.evaluation.evaluator INFO: Inference done 4463/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:43
[02/04 22:43:00] d2.evaluation.evaluator INFO: Inference done 4469/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:37
[02/04 22:43:06] d2.evaluation.evaluator INFO: Inference done 4475/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:31
[02/04 22:43:11] d2.evaluation.evaluator INFO: Inference done 4481/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:26
[02/04 22:43:17] d2.evaluation.evaluator INFO: Inference done 4487/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:20
[02/04 22:43:23] d2.evaluation.evaluator INFO: Inference done 4493/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:14
[02/04 22:43:29] d2.evaluation.evaluator INFO: Inference done 4499/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:07:09
[02/04 22:43:34] d2.evaluation.evaluator INFO: Inference done 4505/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:07:03
[02/04 22:43:40] d2.evaluation.evaluator INFO: Inference done 4511/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:57
[02/04 22:43:46] d2.evaluation.evaluator INFO: Inference done 4517/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:52
[02/04 22:43:52] d2.evaluation.evaluator INFO: Inference done 4523/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:46
[02/04 22:43:57] d2.evaluation.evaluator INFO: Inference done 4529/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:40
[02/04 22:44:03] d2.evaluation.evaluator INFO: Inference done 4535/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:35
[02/04 22:44:09] d2.evaluation.evaluator INFO: Inference done 4541/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:29
[02/04 22:44:14] d2.evaluation.evaluator INFO: Inference done 4547/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:23
[02/04 22:44:20] d2.evaluation.evaluator INFO: Inference done 4553/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:18
[02/04 22:44:26] d2.evaluation.evaluator INFO: Inference done 4559/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:12
[02/04 22:44:32] d2.evaluation.evaluator INFO: Inference done 4565/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:06
[02/04 22:44:37] d2.evaluation.evaluator INFO: Inference done 4571/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:06:00
[02/04 22:44:43] d2.evaluation.evaluator INFO: Inference done 4577/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:55
[02/04 22:44:48] d2.evaluation.evaluator INFO: Inference done 4583/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:49
[02/04 22:44:54] d2.evaluation.evaluator INFO: Inference done 4589/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:43
[02/04 22:45:00] d2.evaluation.evaluator INFO: Inference done 4595/4952. Dataloading: 0.0007 s/iter. Inference: 0.9459 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:38
[02/04 22:45:06] d2.evaluation.evaluator INFO: Inference done 4601/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:32
[02/04 22:45:11] d2.evaluation.evaluator INFO: Inference done 4607/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:26
[02/04 22:45:17] d2.evaluation.evaluator INFO: Inference done 4613/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:21
[02/04 22:45:22] d2.evaluation.evaluator INFO: Inference done 4619/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:15
[02/04 22:45:28] d2.evaluation.evaluator INFO: Inference done 4625/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:09
[02/04 22:45:34] d2.evaluation.evaluator INFO: Inference done 4631/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:05:04
[02/04 22:45:39] d2.evaluation.evaluator INFO: Inference done 4637/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9474 s/iter. ETA=0:04:58
[02/04 22:45:45] d2.evaluation.evaluator INFO: Inference done 4643/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:52
[02/04 22:45:51] d2.evaluation.evaluator INFO: Inference done 4649/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:47
[02/04 22:45:56] d2.evaluation.evaluator INFO: Inference done 4655/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:41
[02/04 22:46:02] d2.evaluation.evaluator INFO: Inference done 4661/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:35
[02/04 22:46:08] d2.evaluation.evaluator INFO: Inference done 4667/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:29
[02/04 22:46:13] d2.evaluation.evaluator INFO: Inference done 4673/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:24
[02/04 22:46:19] d2.evaluation.evaluator INFO: Inference done 4679/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:18
[02/04 22:46:25] d2.evaluation.evaluator INFO: Inference done 4685/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:12
[02/04 22:46:31] d2.evaluation.evaluator INFO: Inference done 4691/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:07
[02/04 22:46:36] d2.evaluation.evaluator INFO: Inference done 4697/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:04:01
[02/04 22:46:42] d2.evaluation.evaluator INFO: Inference done 4703/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:55
[02/04 22:46:48] d2.evaluation.evaluator INFO: Inference done 4709/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:50
[02/04 22:46:53] d2.evaluation.evaluator INFO: Inference done 4715/4952. Dataloading: 0.0007 s/iter. Inference: 0.9458 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:44
[02/04 22:46:59] d2.evaluation.evaluator INFO: Inference done 4721/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:38
[02/04 22:47:04] d2.evaluation.evaluator INFO: Inference done 4727/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:33
[02/04 22:47:10] d2.evaluation.evaluator INFO: Inference done 4733/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:27
[02/04 22:47:16] d2.evaluation.evaluator INFO: Inference done 4739/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:21
[02/04 22:47:21] d2.evaluation.evaluator INFO: Inference done 4745/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9473 s/iter. ETA=0:03:16
[02/04 22:47:27] d2.evaluation.evaluator INFO: Inference done 4751/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:03:10
[02/04 22:47:33] d2.evaluation.evaluator INFO: Inference done 4757/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:03:04
[02/04 22:47:38] d2.evaluation.evaluator INFO: Inference done 4763/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:59
[02/04 22:47:44] d2.evaluation.evaluator INFO: Inference done 4769/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:53
[02/04 22:47:50] d2.evaluation.evaluator INFO: Inference done 4775/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:47
[02/04 22:47:55] d2.evaluation.evaluator INFO: Inference done 4781/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:41
[02/04 22:48:01] d2.evaluation.evaluator INFO: Inference done 4787/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:36
[02/04 22:48:07] d2.evaluation.evaluator INFO: Inference done 4793/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:30
[02/04 22:48:12] d2.evaluation.evaluator INFO: Inference done 4799/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:24
[02/04 22:48:18] d2.evaluation.evaluator INFO: Inference done 4805/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:19
[02/04 22:48:24] d2.evaluation.evaluator INFO: Inference done 4811/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:13
[02/04 22:48:29] d2.evaluation.evaluator INFO: Inference done 4817/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:07
[02/04 22:48:35] d2.evaluation.evaluator INFO: Inference done 4823/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:02:02
[02/04 22:48:41] d2.evaluation.evaluator INFO: Inference done 4829/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:56
[02/04 22:48:46] d2.evaluation.evaluator INFO: Inference done 4835/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:50
[02/04 22:48:52] d2.evaluation.evaluator INFO: Inference done 4841/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:45
[02/04 22:48:58] d2.evaluation.evaluator INFO: Inference done 4847/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:39
[02/04 22:49:03] d2.evaluation.evaluator INFO: Inference done 4853/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:33
[02/04 22:49:09] d2.evaluation.evaluator INFO: Inference done 4859/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:28
[02/04 22:49:15] d2.evaluation.evaluator INFO: Inference done 4865/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:22
[02/04 22:49:20] d2.evaluation.evaluator INFO: Inference done 4871/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:16
[02/04 22:49:26] d2.evaluation.evaluator INFO: Inference done 4877/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:11
[02/04 22:49:32] d2.evaluation.evaluator INFO: Inference done 4883/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:01:05
[02/04 22:49:37] d2.evaluation.evaluator INFO: Inference done 4889/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:59
[02/04 22:49:43] d2.evaluation.evaluator INFO: Inference done 4895/4952. Dataloading: 0.0007 s/iter. Inference: 0.9456 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:53
[02/04 22:49:49] d2.evaluation.evaluator INFO: Inference done 4901/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:48
[02/04 22:49:55] d2.evaluation.evaluator INFO: Inference done 4907/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:42
[02/04 22:50:00] d2.evaluation.evaluator INFO: Inference done 4913/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:36
[02/04 22:50:06] d2.evaluation.evaluator INFO: Inference done 4919/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:31
[02/04 22:50:12] d2.evaluation.evaluator INFO: Inference done 4925/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:25
[02/04 22:50:17] d2.evaluation.evaluator INFO: Inference done 4931/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:19
[02/04 22:50:23] d2.evaluation.evaluator INFO: Inference done 4937/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:14
[02/04 22:50:29] d2.evaluation.evaluator INFO: Inference done 4943/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:08
[02/04 22:50:34] d2.evaluation.evaluator INFO: Inference done 4949/4952. Dataloading: 0.0007 s/iter. Inference: 0.9457 s/iter. Eval: 0.0008 s/iter. Total: 0.9472 s/iter. ETA=0:00:02
[02/04 22:50:37] d2.evaluation.evaluator INFO: Total inference time: 1:18:06.112565 (0.947264 s / iter per device, on 1 devices)
[02/04 22:50:37] d2.evaluation.evaluator INFO: Total inference pure compute time: 1:17:58 (0.945681 s / iter per device, on 1 devices)
[02/04 22:50:37] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[02/04 22:51:26] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car   |  cat   |  chair  |  diningtable  |  dog  |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow   |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:------:|:------:|:-------:|:-------------:|:-----:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:------:|:-----------:|:------:|
|   21.665    |  23.024   | 18.125 |  16.179  | 33.916 | 11.589 | 15.449  |     0.010     | 5.693 | 10.395  |  27.112  |    16.566     | 32.634  |  4.545  |   15.438    | 9.753  | 0.275 | 17.129 |    0.144    | 0.021  |
[02/04 22:51:26] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|  AP   |  AP50  |  AP75  |  bAP  |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:-----:|:------:|:------:|:-----:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 8.066 | 13.983 | 8.117  | 9.547 | 16.823  |  9.491  | 3.623 |  5.465  |  3.995  |
[02/04 22:51:26] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/04 22:51:26] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[02/04 22:51:26] d2.evaluation.testing INFO: copypaste: 8.0659,13.9831,8.1168,9.5470,16.8226,9.4908,3.6229,5.4646,3.9947
[02/04 22:51:26] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[02/04 22:51:37] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0006 s/iter. Inference: 0.9781 s/iter. Eval: 0.0008 s/iter. Total: 0.9795 s/iter. ETA=1:20:39
[02/04 22:51:43] d2.evaluation.evaluator INFO: Inference done 17/4952. Dataloading: 0.0005 s/iter. Inference: 0.9787 s/iter. Eval: 0.0008 s/iter. Total: 0.9800 s/iter. ETA=1:20:36
[02/04 22:51:49] d2.evaluation.evaluator INFO: Inference done 23/4952. Dataloading: 0.0006 s/iter. Inference: 0.9835 s/iter. Eval: 0.0008 s/iter. Total: 0.9850 s/iter. ETA=1:20:54
[02/04 22:51:54] d2.evaluation.evaluator INFO: Inference done 28/4952. Dataloading: 0.0006 s/iter. Inference: 0.9868 s/iter. Eval: 0.0008 s/iter. Total: 0.9883 s/iter. ETA=1:21:06
[02/04 22:51:59] d2.evaluation.evaluator INFO: Inference done 33/4952. Dataloading: 0.0006 s/iter. Inference: 0.9890 s/iter. Eval: 0.0008 s/iter. Total: 0.9905 s/iter. ETA=1:21:12
[02/04 22:52:05] d2.evaluation.evaluator INFO: Inference done 39/4952. Dataloading: 0.0006 s/iter. Inference: 0.9885 s/iter. Eval: 0.0008 s/iter. Total: 0.9900 s/iter. ETA=1:21:03
[02/04 22:52:11] d2.evaluation.evaluator INFO: Inference done 45/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:21:02
[02/04 22:52:16] d2.evaluation.evaluator INFO: Inference done 50/4952. Dataloading: 0.0007 s/iter. Inference: 0.9910 s/iter. Eval: 0.0008 s/iter. Total: 0.9925 s/iter. ETA=1:21:05
[02/04 22:52:21] d2.evaluation.evaluator INFO: Inference done 55/4952. Dataloading: 0.0007 s/iter. Inference: 0.9926 s/iter. Eval: 0.0008 s/iter. Total: 0.9941 s/iter. ETA=1:21:08
[02/04 22:52:27] d2.evaluation.evaluator INFO: Inference done 61/4952. Dataloading: 0.0007 s/iter. Inference: 0.9927 s/iter. Eval: 0.0008 s/iter. Total: 0.9942 s/iter. ETA=1:21:02
[02/04 22:52:33] d2.evaluation.evaluator INFO: Inference done 67/4952. Dataloading: 0.0007 s/iter. Inference: 0.9916 s/iter. Eval: 0.0008 s/iter. Total: 0.9932 s/iter. ETA=1:20:51
[02/04 22:52:38] d2.evaluation.evaluator INFO: Inference done 72/4952. Dataloading: 0.0007 s/iter. Inference: 0.9923 s/iter. Eval: 0.0008 s/iter. Total: 0.9938 s/iter. ETA=1:20:49
[02/04 22:52:44] d2.evaluation.evaluator INFO: Inference done 78/4952. Dataloading: 0.0007 s/iter. Inference: 0.9926 s/iter. Eval: 0.0008 s/iter. Total: 0.9942 s/iter. ETA=1:20:45
[02/04 22:52:50] d2.evaluation.evaluator INFO: Inference done 84/4952. Dataloading: 0.0007 s/iter. Inference: 0.9930 s/iter. Eval: 0.0008 s/iter. Total: 0.9946 s/iter. ETA=1:20:41
[02/04 22:52:56] d2.evaluation.evaluator INFO: Inference done 90/4952. Dataloading: 0.0007 s/iter. Inference: 0.9929 s/iter. Eval: 0.0008 s/iter. Total: 0.9945 s/iter. ETA=1:20:35
[02/04 22:53:02] d2.evaluation.evaluator INFO: Inference done 96/4952. Dataloading: 0.0007 s/iter. Inference: 0.9925 s/iter. Eval: 0.0008 s/iter. Total: 0.9941 s/iter. ETA=1:20:27
[02/04 22:53:07] d2.evaluation.evaluator INFO: Inference done 101/4952. Dataloading: 0.0007 s/iter. Inference: 0.9929 s/iter. Eval: 0.0008 s/iter. Total: 0.9945 s/iter. ETA=1:20:24
[02/04 22:53:12] d2.evaluation.evaluator INFO: Inference done 107/4952. Dataloading: 0.0007 s/iter. Inference: 0.9925 s/iter. Eval: 0.0008 s/iter. Total: 0.9940 s/iter. ETA=1:20:16
[02/04 22:53:18] d2.evaluation.evaluator INFO: Inference done 112/4952. Dataloading: 0.0007 s/iter. Inference: 0.9929 s/iter. Eval: 0.0008 s/iter. Total: 0.9945 s/iter. ETA=1:20:13
[02/04 22:53:23] d2.evaluation.evaluator INFO: Inference done 118/4952. Dataloading: 0.0007 s/iter. Inference: 0.9928 s/iter. Eval: 0.0008 s/iter. Total: 0.9944 s/iter. ETA=1:20:06
[02/04 22:53:28] d2.evaluation.evaluator INFO: Inference done 123/4952. Dataloading: 0.0007 s/iter. Inference: 0.9933 s/iter. Eval: 0.0008 s/iter. Total: 0.9949 s/iter. ETA=1:20:04
[02/04 22:53:34] d2.evaluation.evaluator INFO: Inference done 128/4952. Dataloading: 0.0007 s/iter. Inference: 0.9940 s/iter. Eval: 0.0008 s/iter. Total: 0.9956 s/iter. ETA=1:20:02
[02/04 22:53:39] d2.evaluation.evaluator INFO: Inference done 133/4952. Dataloading: 0.0007 s/iter. Inference: 0.9947 s/iter. Eval: 0.0008 s/iter. Total: 0.9963 s/iter. ETA=1:20:01
[02/04 22:53:45] d2.evaluation.evaluator INFO: Inference done 139/4952. Dataloading: 0.0007 s/iter. Inference: 0.9944 s/iter. Eval: 0.0008 s/iter. Total: 0.9960 s/iter. ETA=1:19:53
[02/04 22:53:51] d2.evaluation.evaluator INFO: Inference done 145/4952. Dataloading: 0.0007 s/iter. Inference: 0.9944 s/iter. Eval: 0.0008 s/iter. Total: 0.9960 s/iter. ETA=1:19:47
[02/04 22:53:56] d2.evaluation.evaluator INFO: Inference done 151/4952. Dataloading: 0.0007 s/iter. Inference: 0.9939 s/iter. Eval: 0.0008 s/iter. Total: 0.9955 s/iter. ETA=1:19:39
[02/04 22:54:02] d2.evaluation.evaluator INFO: Inference done 157/4952. Dataloading: 0.0007 s/iter. Inference: 0.9936 s/iter. Eval: 0.0008 s/iter. Total: 0.9952 s/iter. ETA=1:19:32
[02/04 22:54:08] d2.evaluation.evaluator INFO: Inference done 163/4952. Dataloading: 0.0007 s/iter. Inference: 0.9933 s/iter. Eval: 0.0008 s/iter. Total: 0.9949 s/iter. ETA=1:19:24
[02/04 22:54:14] d2.evaluation.evaluator INFO: Inference done 169/4952. Dataloading: 0.0007 s/iter. Inference: 0.9932 s/iter. Eval: 0.0008 s/iter. Total: 0.9948 s/iter. ETA=1:19:17
[02/04 22:54:19] d2.evaluation.evaluator INFO: Inference done 174/4952. Dataloading: 0.0007 s/iter. Inference: 0.9933 s/iter. Eval: 0.0008 s/iter. Total: 0.9949 s/iter. ETA=1:19:13
[02/04 22:54:25] d2.evaluation.evaluator INFO: Inference done 180/4952. Dataloading: 0.0007 s/iter. Inference: 0.9934 s/iter. Eval: 0.0008 s/iter. Total: 0.9950 s/iter. ETA=1:19:08
[02/04 22:54:31] d2.evaluation.evaluator INFO: Inference done 186/4952. Dataloading: 0.0007 s/iter. Inference: 0.9934 s/iter. Eval: 0.0008 s/iter. Total: 0.9950 s/iter. ETA=1:19:02
[02/04 22:54:36] d2.evaluation.evaluator INFO: Inference done 191/4952. Dataloading: 0.0007 s/iter. Inference: 0.9938 s/iter. Eval: 0.0008 s/iter. Total: 0.9954 s/iter. ETA=1:18:59
[02/04 22:54:42] d2.evaluation.evaluator INFO: Inference done 197/4952. Dataloading: 0.0007 s/iter. Inference: 0.9936 s/iter. Eval: 0.0008 s/iter. Total: 0.9952 s/iter. ETA=1:18:52
[02/04 22:54:48] d2.evaluation.evaluator INFO: Inference done 203/4952. Dataloading: 0.0007 s/iter. Inference: 0.9934 s/iter. Eval: 0.0008 s/iter. Total: 0.9949 s/iter. ETA=1:18:45
[02/04 22:54:53] d2.evaluation.evaluator INFO: Inference done 208/4952. Dataloading: 0.0007 s/iter. Inference: 0.9935 s/iter. Eval: 0.0008 s/iter. Total: 0.9951 s/iter. ETA=1:18:40
[02/04 22:54:59] d2.evaluation.evaluator INFO: Inference done 214/4952. Dataloading: 0.0007 s/iter. Inference: 0.9932 s/iter. Eval: 0.0008 s/iter. Total: 0.9948 s/iter. ETA=1:18:33
[02/04 22:55:05] d2.evaluation.evaluator INFO: Inference done 220/4952. Dataloading: 0.0007 s/iter. Inference: 0.9931 s/iter. Eval: 0.0008 s/iter. Total: 0.9946 s/iter. ETA=1:18:26
[02/04 22:55:10] d2.evaluation.evaluator INFO: Inference done 225/4952. Dataloading: 0.0007 s/iter. Inference: 0.9932 s/iter. Eval: 0.0008 s/iter. Total: 0.9948 s/iter. ETA=1:18:22
[02/04 22:55:15] d2.evaluation.evaluator INFO: Inference done 230/4952. Dataloading: 0.0007 s/iter. Inference: 0.9936 s/iter. Eval: 0.0008 s/iter. Total: 0.9951 s/iter. ETA=1:18:19
[02/04 22:55:20] d2.evaluation.evaluator INFO: Inference done 235/4952. Dataloading: 0.0007 s/iter. Inference: 0.9938 s/iter. Eval: 0.0008 s/iter. Total: 0.9953 s/iter. ETA=1:18:15
[02/04 22:55:26] d2.evaluation.evaluator INFO: Inference done 241/4952. Dataloading: 0.0007 s/iter. Inference: 0.9938 s/iter. Eval: 0.0008 s/iter. Total: 0.9954 s/iter. ETA=1:18:09
[02/04 22:55:32] d2.evaluation.evaluator INFO: Inference done 247/4952. Dataloading: 0.0007 s/iter. Inference: 0.9938 s/iter. Eval: 0.0008 s/iter. Total: 0.9953 s/iter. ETA=1:18:03
[02/04 22:55:38] d2.evaluation.evaluator INFO: Inference done 253/4952. Dataloading: 0.0007 s/iter. Inference: 0.9938 s/iter. Eval: 0.0008 s/iter. Total: 0.9953 s/iter. ETA=1:17:57
[02/04 22:55:44] d2.evaluation.evaluator INFO: Inference done 259/4952. Dataloading: 0.0007 s/iter. Inference: 0.9932 s/iter. Eval: 0.0008 s/iter. Total: 0.9948 s/iter. ETA=1:17:48
[02/04 22:55:50] d2.evaluation.evaluator INFO: Inference done 265/4952. Dataloading: 0.0007 s/iter. Inference: 0.9931 s/iter. Eval: 0.0008 s/iter. Total: 0.9947 s/iter. ETA=1:17:42
[02/04 22:55:56] d2.evaluation.evaluator INFO: Inference done 271/4952. Dataloading: 0.0007 s/iter. Inference: 0.9925 s/iter. Eval: 0.0008 s/iter. Total: 0.9941 s/iter. ETA=1:17:33
[02/04 22:56:01] d2.evaluation.evaluator INFO: Inference done 277/4952. Dataloading: 0.0007 s/iter. Inference: 0.9923 s/iter. Eval: 0.0008 s/iter. Total: 0.9938 s/iter. ETA=1:17:26
[02/04 22:56:07] d2.evaluation.evaluator INFO: Inference done 283/4952. Dataloading: 0.0007 s/iter. Inference: 0.9922 s/iter. Eval: 0.0008 s/iter. Total: 0.9938 s/iter. ETA=1:17:20
[02/04 22:56:13] d2.evaluation.evaluator INFO: Inference done 289/4952. Dataloading: 0.0007 s/iter. Inference: 0.9922 s/iter. Eval: 0.0008 s/iter. Total: 0.9938 s/iter. ETA=1:17:14
[02/04 22:56:19] d2.evaluation.evaluator INFO: Inference done 295/4952. Dataloading: 0.0007 s/iter. Inference: 0.9920 s/iter. Eval: 0.0008 s/iter. Total: 0.9936 s/iter. ETA=1:17:07
[02/04 22:56:25] d2.evaluation.evaluator INFO: Inference done 301/4952. Dataloading: 0.0007 s/iter. Inference: 0.9919 s/iter. Eval: 0.0008 s/iter. Total: 0.9934 s/iter. ETA=1:17:00
[02/04 22:56:31] d2.evaluation.evaluator INFO: Inference done 307/4952. Dataloading: 0.0007 s/iter. Inference: 0.9919 s/iter. Eval: 0.0008 s/iter. Total: 0.9935 s/iter. ETA=1:16:54
[02/04 22:56:37] d2.evaluation.evaluator INFO: Inference done 313/4952. Dataloading: 0.0007 s/iter. Inference: 0.9919 s/iter. Eval: 0.0008 s/iter. Total: 0.9935 s/iter. ETA=1:16:48
[02/04 22:56:43] d2.evaluation.evaluator INFO: Inference done 319/4952. Dataloading: 0.0007 s/iter. Inference: 0.9918 s/iter. Eval: 0.0008 s/iter. Total: 0.9933 s/iter. ETA=1:16:42
[02/04 22:56:49] d2.evaluation.evaluator INFO: Inference done 325/4952. Dataloading: 0.0007 s/iter. Inference: 0.9916 s/iter. Eval: 0.0008 s/iter. Total: 0.9932 s/iter. ETA=1:16:35
[02/04 22:56:55] d2.evaluation.evaluator INFO: Inference done 331/4952. Dataloading: 0.0007 s/iter. Inference: 0.9915 s/iter. Eval: 0.0008 s/iter. Total: 0.9931 s/iter. ETA=1:16:28
[02/04 22:57:01] d2.evaluation.evaluator INFO: Inference done 337/4952. Dataloading: 0.0007 s/iter. Inference: 0.9913 s/iter. Eval: 0.0008 s/iter. Total: 0.9929 s/iter. ETA=1:16:22
[02/04 22:57:07] d2.evaluation.evaluator INFO: Inference done 343/4952. Dataloading: 0.0007 s/iter. Inference: 0.9910 s/iter. Eval: 0.0008 s/iter. Total: 0.9926 s/iter. ETA=1:16:14
[02/04 22:57:13] d2.evaluation.evaluator INFO: Inference done 349/4952. Dataloading: 0.0007 s/iter. Inference: 0.9910 s/iter. Eval: 0.0008 s/iter. Total: 0.9926 s/iter. ETA=1:16:08
[02/04 22:57:18] d2.evaluation.evaluator INFO: Inference done 354/4952. Dataloading: 0.0007 s/iter. Inference: 0.9913 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:16:05
[02/04 22:57:23] d2.evaluation.evaluator INFO: Inference done 359/4952. Dataloading: 0.0007 s/iter. Inference: 0.9914 s/iter. Eval: 0.0008 s/iter. Total: 0.9930 s/iter. ETA=1:16:00
[02/04 22:57:28] d2.evaluation.evaluator INFO: Inference done 364/4952. Dataloading: 0.0007 s/iter. Inference: 0.9915 s/iter. Eval: 0.0008 s/iter. Total: 0.9931 s/iter. ETA=1:15:56
[02/04 22:57:34] d2.evaluation.evaluator INFO: Inference done 370/4952. Dataloading: 0.0007 s/iter. Inference: 0.9914 s/iter. Eval: 0.0008 s/iter. Total: 0.9930 s/iter. ETA=1:15:49
[02/04 22:57:39] d2.evaluation.evaluator INFO: Inference done 376/4952. Dataloading: 0.0007 s/iter. Inference: 0.9913 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:15:43
[02/04 22:57:45] d2.evaluation.evaluator INFO: Inference done 381/4952. Dataloading: 0.0007 s/iter. Inference: 0.9916 s/iter. Eval: 0.0008 s/iter. Total: 0.9931 s/iter. ETA=1:15:39
[02/04 22:57:50] d2.evaluation.evaluator INFO: Inference done 387/4952. Dataloading: 0.0007 s/iter. Inference: 0.9916 s/iter. Eval: 0.0008 s/iter. Total: 0.9931 s/iter. ETA=1:15:33
[02/04 22:57:56] d2.evaluation.evaluator INFO: Inference done 393/4952. Dataloading: 0.0007 s/iter. Inference: 0.9915 s/iter. Eval: 0.0008 s/iter. Total: 0.9930 s/iter. ETA=1:15:27
[02/04 22:58:02] d2.evaluation.evaluator INFO: Inference done 399/4952. Dataloading: 0.0007 s/iter. Inference: 0.9914 s/iter. Eval: 0.0008 s/iter. Total: 0.9930 s/iter. ETA=1:15:20
[02/04 22:58:08] d2.evaluation.evaluator INFO: Inference done 405/4952. Dataloading: 0.0007 s/iter. Inference: 0.9910 s/iter. Eval: 0.0008 s/iter. Total: 0.9926 s/iter. ETA=1:15:13
[02/04 22:58:13] d2.evaluation.evaluator INFO: Inference done 410/4952. Dataloading: 0.0007 s/iter. Inference: 0.9912 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:15:09
[02/04 22:58:19] d2.evaluation.evaluator INFO: Inference done 416/4952. Dataloading: 0.0007 s/iter. Inference: 0.9912 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:15:03
[02/04 22:58:25] d2.evaluation.evaluator INFO: Inference done 422/4952. Dataloading: 0.0007 s/iter. Inference: 0.9913 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:14:57
[02/04 22:58:31] d2.evaluation.evaluator INFO: Inference done 428/4952. Dataloading: 0.0007 s/iter. Inference: 0.9912 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:14:51
[02/04 22:58:37] d2.evaluation.evaluator INFO: Inference done 434/4952. Dataloading: 0.0007 s/iter. Inference: 0.9912 s/iter. Eval: 0.0008 s/iter. Total: 0.9927 s/iter. ETA=1:14:45
[02/04 22:58:43] d2.evaluation.evaluator INFO: Inference done 440/4952. Dataloading: 0.0007 s/iter. Inference: 0.9911 s/iter. Eval: 0.0008 s/iter. Total: 0.9927 s/iter. ETA=1:14:38
[02/04 22:58:48] d2.evaluation.evaluator INFO: Inference done 445/4952. Dataloading: 0.0007 s/iter. Inference: 0.9912 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:14:34
[02/04 22:58:54] d2.evaluation.evaluator INFO: Inference done 451/4952. Dataloading: 0.0007 s/iter. Inference: 0.9912 s/iter. Eval: 0.0008 s/iter. Total: 0.9928 s/iter. ETA=1:14:28
[02/04 22:59:00] d2.evaluation.evaluator INFO: Inference done 457/4952. Dataloading: 0.0007 s/iter. Inference: 0.9910 s/iter. Eval: 0.0008 s/iter. Total: 0.9926 s/iter. ETA=1:14:21
[02/04 22:59:06] d2.evaluation.evaluator INFO: Inference done 463/4952. Dataloading: 0.0007 s/iter. Inference: 0.9909 s/iter. Eval: 0.0008 s/iter. Total: 0.9925 s/iter. ETA=1:14:15
[02/04 22:59:12] d2.evaluation.evaluator INFO: Inference done 469/4952. Dataloading: 0.0007 s/iter. Inference: 0.9908 s/iter. Eval: 0.0008 s/iter. Total: 0.9923 s/iter. ETA=1:14:08
[02/04 22:59:17] d2.evaluation.evaluator INFO: Inference done 475/4952. Dataloading: 0.0007 s/iter. Inference: 0.9907 s/iter. Eval: 0.0008 s/iter. Total: 0.9922 s/iter. ETA=1:14:02
[02/04 22:59:23] d2.evaluation.evaluator INFO: Inference done 481/4952. Dataloading: 0.0007 s/iter. Inference: 0.9906 s/iter. Eval: 0.0008 s/iter. Total: 0.9921 s/iter. ETA=1:13:55
[02/04 22:59:29] d2.evaluation.evaluator INFO: Inference done 487/4952. Dataloading: 0.0007 s/iter. Inference: 0.9906 s/iter. Eval: 0.0008 s/iter. Total: 0.9921 s/iter. ETA=1:13:49
[02/04 22:59:35] d2.evaluation.evaluator INFO: Inference done 493/4952. Dataloading: 0.0007 s/iter. Inference: 0.9903 s/iter. Eval: 0.0008 s/iter. Total: 0.9918 s/iter. ETA=1:13:42
[02/04 22:59:41] d2.evaluation.evaluator INFO: Inference done 499/4952. Dataloading: 0.0007 s/iter. Inference: 0.9903 s/iter. Eval: 0.0008 s/iter. Total: 0.9919 s/iter. ETA=1:13:36
[02/04 22:59:47] d2.evaluation.evaluator INFO: Inference done 505/4952. Dataloading: 0.0007 s/iter. Inference: 0.9903 s/iter. Eval: 0.0008 s/iter. Total: 0.9919 s/iter. ETA=1:13:30
[02/04 22:59:53] d2.evaluation.evaluator INFO: Inference done 511/4952. Dataloading: 0.0007 s/iter. Inference: 0.9903 s/iter. Eval: 0.0008 s/iter. Total: 0.9918 s/iter. ETA=1:13:24
[02/04 22:59:59] d2.evaluation.evaluator INFO: Inference done 517/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9918 s/iter. ETA=1:13:18
[02/04 23:00:05] d2.evaluation.evaluator INFO: Inference done 523/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9918 s/iter. ETA=1:13:12
[02/04 23:00:11] d2.evaluation.evaluator INFO: Inference done 529/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=1:13:06
[02/04 23:00:17] d2.evaluation.evaluator INFO: Inference done 535/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=1:13:00
[02/04 23:00:23] d2.evaluation.evaluator INFO: Inference done 541/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=1:12:53
[02/04 23:00:28] d2.evaluation.evaluator INFO: Inference done 547/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=1:12:46
[02/04 23:00:34] d2.evaluation.evaluator INFO: Inference done 553/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:12:40
[02/04 23:00:40] d2.evaluation.evaluator INFO: Inference done 559/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:12:34
[02/04 23:00:46] d2.evaluation.evaluator INFO: Inference done 565/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:12:28
[02/04 23:00:51] d2.evaluation.evaluator INFO: Inference done 570/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=1:12:24
[02/04 23:00:57] d2.evaluation.evaluator INFO: Inference done 576/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=1:12:18
[02/04 23:01:03] d2.evaluation.evaluator INFO: Inference done 582/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:12:12
[02/04 23:01:09] d2.evaluation.evaluator INFO: Inference done 588/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:12:06
[02/04 23:01:15] d2.evaluation.evaluator INFO: Inference done 594/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:12:00
[02/04 23:01:21] d2.evaluation.evaluator INFO: Inference done 600/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:11:54
[02/04 23:01:27] d2.evaluation.evaluator INFO: Inference done 606/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:11:48
[02/04 23:01:33] d2.evaluation.evaluator INFO: Inference done 612/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:11:41
[02/04 23:01:39] d2.evaluation.evaluator INFO: Inference done 618/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:11:35
[02/04 23:01:44] d2.evaluation.evaluator INFO: Inference done 623/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:11:31
[02/04 23:01:50] d2.evaluation.evaluator INFO: Inference done 629/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:11:24
[02/04 23:01:55] d2.evaluation.evaluator INFO: Inference done 635/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:11:18
[02/04 23:02:01] d2.evaluation.evaluator INFO: Inference done 641/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:11:12
[02/04 23:02:06] d2.evaluation.evaluator INFO: Inference done 646/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:11:07
[02/04 23:02:12] d2.evaluation.evaluator INFO: Inference done 652/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:11:01
[02/04 23:02:17] d2.evaluation.evaluator INFO: Inference done 657/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:10:57
[02/04 23:02:23] d2.evaluation.evaluator INFO: Inference done 663/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:10:51
[02/04 23:02:29] d2.evaluation.evaluator INFO: Inference done 669/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:10:45
[02/04 23:02:35] d2.evaluation.evaluator INFO: Inference done 675/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:10:39
[02/04 23:02:41] d2.evaluation.evaluator INFO: Inference done 681/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:10:33
[02/04 23:02:47] d2.evaluation.evaluator INFO: Inference done 687/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:10:27
[02/04 23:02:53] d2.evaluation.evaluator INFO: Inference done 693/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:10:21
[02/04 23:02:59] d2.evaluation.evaluator INFO: Inference done 699/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:10:15
[02/04 23:03:05] d2.evaluation.evaluator INFO: Inference done 705/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:10:09
[02/04 23:03:10] d2.evaluation.evaluator INFO: Inference done 710/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:10:04
[02/04 23:03:15] d2.evaluation.evaluator INFO: Inference done 715/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:10:00
[02/04 23:03:21] d2.evaluation.evaluator INFO: Inference done 721/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:09:54
[02/04 23:03:27] d2.evaluation.evaluator INFO: Inference done 727/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:09:47
[02/04 23:03:32] d2.evaluation.evaluator INFO: Inference done 732/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:09:43
[02/04 23:03:38] d2.evaluation.evaluator INFO: Inference done 738/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:09:37
[02/04 23:03:44] d2.evaluation.evaluator INFO: Inference done 744/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:09:30
[02/04 23:03:50] d2.evaluation.evaluator INFO: Inference done 750/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:09:25
[02/04 23:03:55] d2.evaluation.evaluator INFO: Inference done 756/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:09:18
[02/04 23:04:01] d2.evaluation.evaluator INFO: Inference done 762/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:09:12
[02/04 23:04:07] d2.evaluation.evaluator INFO: Inference done 768/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:09:07
[02/04 23:04:13] d2.evaluation.evaluator INFO: Inference done 774/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:09:01
[02/04 23:04:19] d2.evaluation.evaluator INFO: Inference done 780/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:08:54
[02/04 23:04:25] d2.evaluation.evaluator INFO: Inference done 786/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:08:48
[02/04 23:04:31] d2.evaluation.evaluator INFO: Inference done 792/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:08:42
[02/04 23:04:37] d2.evaluation.evaluator INFO: Inference done 798/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:08:35
[02/04 23:04:43] d2.evaluation.evaluator INFO: Inference done 804/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:08:29
[02/04 23:04:49] d2.evaluation.evaluator INFO: Inference done 810/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:08:23
[02/04 23:04:55] d2.evaluation.evaluator INFO: Inference done 816/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:08:17
[02/04 23:05:00] d2.evaluation.evaluator INFO: Inference done 821/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:08:13
[02/04 23:05:06] d2.evaluation.evaluator INFO: Inference done 827/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:08:07
[02/04 23:05:12] d2.evaluation.evaluator INFO: Inference done 833/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:08:01
[02/04 23:05:17] d2.evaluation.evaluator INFO: Inference done 839/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:07:55
[02/04 23:05:23] d2.evaluation.evaluator INFO: Inference done 845/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:07:49
[02/04 23:05:29] d2.evaluation.evaluator INFO: Inference done 851/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:07:43
[02/04 23:05:34] d2.evaluation.evaluator INFO: Inference done 856/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:07:38
[02/04 23:05:40] d2.evaluation.evaluator INFO: Inference done 862/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:07:32
[02/04 23:05:46] d2.evaluation.evaluator INFO: Inference done 868/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:07:26
[02/04 23:05:52] d2.evaluation.evaluator INFO: Inference done 874/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:07:20
[02/04 23:05:58] d2.evaluation.evaluator INFO: Inference done 880/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:07:14
[02/04 23:06:04] d2.evaluation.evaluator INFO: Inference done 886/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9908 s/iter. ETA=1:07:08
[02/04 23:06:10] d2.evaluation.evaluator INFO: Inference done 892/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:07:02
[02/04 23:06:16] d2.evaluation.evaluator INFO: Inference done 898/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:56
[02/04 23:06:22] d2.evaluation.evaluator INFO: Inference done 904/4952. Dataloading: 0.0007 s/iter. Inference: 0.9891 s/iter. Eval: 0.0008 s/iter. Total: 0.9906 s/iter. ETA=1:06:50
[02/04 23:06:27] d2.evaluation.evaluator INFO: Inference done 909/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:45
[02/04 23:06:33] d2.evaluation.evaluator INFO: Inference done 915/4952. Dataloading: 0.0007 s/iter. Inference: 0.9891 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:39
[02/04 23:06:39] d2.evaluation.evaluator INFO: Inference done 921/4952. Dataloading: 0.0007 s/iter. Inference: 0.9891 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:33
[02/04 23:06:44] d2.evaluation.evaluator INFO: Inference done 927/4952. Dataloading: 0.0007 s/iter. Inference: 0.9891 s/iter. Eval: 0.0008 s/iter. Total: 0.9906 s/iter. ETA=1:06:27
[02/04 23:06:49] d2.evaluation.evaluator INFO: Inference done 932/4952. Dataloading: 0.0007 s/iter. Inference: 0.9891 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:22
[02/04 23:06:55] d2.evaluation.evaluator INFO: Inference done 938/4952. Dataloading: 0.0007 s/iter. Inference: 0.9891 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:16
[02/04 23:07:01] d2.evaluation.evaluator INFO: Inference done 944/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:10
[02/04 23:07:07] d2.evaluation.evaluator INFO: Inference done 950/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:06:04
[02/04 23:07:13] d2.evaluation.evaluator INFO: Inference done 956/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:05:58
[02/04 23:07:19] d2.evaluation.evaluator INFO: Inference done 962/4952. Dataloading: 0.0007 s/iter. Inference: 0.9892 s/iter. Eval: 0.0008 s/iter. Total: 0.9907 s/iter. ETA=1:05:52
[02/04 23:07:24] d2.evaluation.evaluator INFO: Inference done 967/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:05:48
[02/04 23:07:30] d2.evaluation.evaluator INFO: Inference done 973/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:05:43
[02/04 23:07:36] d2.evaluation.evaluator INFO: Inference done 979/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:05:37
[02/04 23:07:42] d2.evaluation.evaluator INFO: Inference done 985/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:05:31
[02/04 23:07:48] d2.evaluation.evaluator INFO: Inference done 991/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:05:25
[02/04 23:07:54] d2.evaluation.evaluator INFO: Inference done 997/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:05:19
[02/04 23:08:00] d2.evaluation.evaluator INFO: Inference done 1003/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:05:13
[02/04 23:08:06] d2.evaluation.evaluator INFO: Inference done 1009/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:05:07
[02/04 23:08:12] d2.evaluation.evaluator INFO: Inference done 1015/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:05:01
[02/04 23:08:18] d2.evaluation.evaluator INFO: Inference done 1021/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:04:56
[02/04 23:08:24] d2.evaluation.evaluator INFO: Inference done 1027/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:49
[02/04 23:08:30] d2.evaluation.evaluator INFO: Inference done 1033/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:43
[02/04 23:08:36] d2.evaluation.evaluator INFO: Inference done 1039/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:37
[02/04 23:08:42] d2.evaluation.evaluator INFO: Inference done 1045/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:31
[02/04 23:08:48] d2.evaluation.evaluator INFO: Inference done 1051/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:25
[02/04 23:08:54] d2.evaluation.evaluator INFO: Inference done 1057/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:19
[02/04 23:09:00] d2.evaluation.evaluator INFO: Inference done 1063/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:13
[02/04 23:09:05] d2.evaluation.evaluator INFO: Inference done 1069/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:07
[02/04 23:09:11] d2.evaluation.evaluator INFO: Inference done 1074/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:04:03
[02/04 23:09:16] d2.evaluation.evaluator INFO: Inference done 1080/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:03:57
[02/04 23:09:22] d2.evaluation.evaluator INFO: Inference done 1086/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:03:51
[02/04 23:09:28] d2.evaluation.evaluator INFO: Inference done 1092/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:03:45
[02/04 23:09:34] d2.evaluation.evaluator INFO: Inference done 1098/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:03:39
[02/04 23:09:40] d2.evaluation.evaluator INFO: Inference done 1104/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:03:33
[02/04 23:09:46] d2.evaluation.evaluator INFO: Inference done 1110/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:03:27
[02/04 23:09:52] d2.evaluation.evaluator INFO: Inference done 1116/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:03:20
[02/04 23:09:58] d2.evaluation.evaluator INFO: Inference done 1122/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:03:15
[02/04 23:10:03] d2.evaluation.evaluator INFO: Inference done 1127/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=1:03:10
[02/04 23:10:08] d2.evaluation.evaluator INFO: Inference done 1132/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:03:05
[02/04 23:10:14] d2.evaluation.evaluator INFO: Inference done 1138/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:02:59
[02/04 23:10:19] d2.evaluation.evaluator INFO: Inference done 1143/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:02:54
[02/04 23:10:25] d2.evaluation.evaluator INFO: Inference done 1149/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:02:49
[02/04 23:10:31] d2.evaluation.evaluator INFO: Inference done 1155/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:02:43
[02/04 23:10:37] d2.evaluation.evaluator INFO: Inference done 1161/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:02:37
[02/04 23:10:43] d2.evaluation.evaluator INFO: Inference done 1167/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:02:30
[02/04 23:10:48] d2.evaluation.evaluator INFO: Inference done 1172/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:02:26
[02/04 23:10:54] d2.evaluation.evaluator INFO: Inference done 1178/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:02:19
[02/04 23:10:59] d2.evaluation.evaluator INFO: Inference done 1184/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:02:14
[02/04 23:11:04] d2.evaluation.evaluator INFO: Inference done 1189/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=1:02:09
[02/04 23:11:10] d2.evaluation.evaluator INFO: Inference done 1194/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=1:02:04
[02/04 23:11:15] d2.evaluation.evaluator INFO: Inference done 1199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:01:59
[02/04 23:11:20] d2.evaluation.evaluator INFO: Inference done 1204/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:01:55
[02/04 23:11:26] d2.evaluation.evaluator INFO: Inference done 1210/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:01:49
[02/04 23:11:31] d2.evaluation.evaluator INFO: Inference done 1215/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:01:44
[02/04 23:11:37] d2.evaluation.evaluator INFO: Inference done 1221/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:01:38
[02/04 23:11:42] d2.evaluation.evaluator INFO: Inference done 1227/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:01:32
[02/04 23:11:48] d2.evaluation.evaluator INFO: Inference done 1233/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:01:26
[02/04 23:11:54] d2.evaluation.evaluator INFO: Inference done 1239/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=1:01:20
[02/04 23:11:59] d2.evaluation.evaluator INFO: Inference done 1244/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=1:01:15
[02/04 23:12:04] d2.evaluation.evaluator INFO: Inference done 1249/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=1:01:10
[02/04 23:12:10] d2.evaluation.evaluator INFO: Inference done 1255/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=1:01:05
[02/04 23:12:15] d2.evaluation.evaluator INFO: Inference done 1260/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=1:01:00
[02/04 23:12:20] d2.evaluation.evaluator INFO: Inference done 1265/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=1:00:55
[02/04 23:12:25] d2.evaluation.evaluator INFO: Inference done 1270/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=1:00:50
[02/04 23:12:31] d2.evaluation.evaluator INFO: Inference done 1276/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:44
[02/04 23:12:36] d2.evaluation.evaluator INFO: Inference done 1281/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:40
[02/04 23:12:42] d2.evaluation.evaluator INFO: Inference done 1287/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:34
[02/04 23:12:48] d2.evaluation.evaluator INFO: Inference done 1293/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:28
[02/04 23:12:54] d2.evaluation.evaluator INFO: Inference done 1299/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:22
[02/04 23:13:00] d2.evaluation.evaluator INFO: Inference done 1305/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:16
[02/04 23:13:06] d2.evaluation.evaluator INFO: Inference done 1311/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:10
[02/04 23:13:12] d2.evaluation.evaluator INFO: Inference done 1317/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=1:00:04
[02/04 23:13:18] d2.evaluation.evaluator INFO: Inference done 1323/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:59:58
[02/04 23:13:24] d2.evaluation.evaluator INFO: Inference done 1329/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:59:52
[02/04 23:13:30] d2.evaluation.evaluator INFO: Inference done 1335/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:59:46
[02/04 23:13:36] d2.evaluation.evaluator INFO: Inference done 1341/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:59:40
[02/04 23:13:41] d2.evaluation.evaluator INFO: Inference done 1346/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:59:35
[02/04 23:13:47] d2.evaluation.evaluator INFO: Inference done 1352/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:59:29
[02/04 23:13:53] d2.evaluation.evaluator INFO: Inference done 1358/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:59:23
[02/04 23:13:59] d2.evaluation.evaluator INFO: Inference done 1364/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:59:17
[02/04 23:14:04] d2.evaluation.evaluator INFO: Inference done 1370/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:59:11
[02/04 23:14:10] d2.evaluation.evaluator INFO: Inference done 1376/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:59:05
[02/04 23:14:15] d2.evaluation.evaluator INFO: Inference done 1381/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:59:00
[02/04 23:14:21] d2.evaluation.evaluator INFO: Inference done 1387/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:58:54
[02/04 23:14:27] d2.evaluation.evaluator INFO: Inference done 1393/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:58:48
[02/04 23:14:33] d2.evaluation.evaluator INFO: Inference done 1399/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:58:42
[02/04 23:14:39] d2.evaluation.evaluator INFO: Inference done 1405/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:58:36
[02/04 23:14:45] d2.evaluation.evaluator INFO: Inference done 1411/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:58:30
[02/04 23:14:50] d2.evaluation.evaluator INFO: Inference done 1416/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:58:26
[02/04 23:14:56] d2.evaluation.evaluator INFO: Inference done 1422/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:58:20
[02/04 23:15:01] d2.evaluation.evaluator INFO: Inference done 1427/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:58:15
[02/04 23:15:07] d2.evaluation.evaluator INFO: Inference done 1433/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:58:09
[02/04 23:15:13] d2.evaluation.evaluator INFO: Inference done 1439/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:58:03
[02/04 23:15:19] d2.evaluation.evaluator INFO: Inference done 1445/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:57
[02/04 23:15:25] d2.evaluation.evaluator INFO: Inference done 1451/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:57:51
[02/04 23:15:30] d2.evaluation.evaluator INFO: Inference done 1456/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:46
[02/04 23:15:35] d2.evaluation.evaluator INFO: Inference done 1461/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:41
[02/04 23:15:40] d2.evaluation.evaluator INFO: Inference done 1466/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:57:36
[02/04 23:15:46] d2.evaluation.evaluator INFO: Inference done 1472/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:57:30
[02/04 23:15:52] d2.evaluation.evaluator INFO: Inference done 1478/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:57:25
[02/04 23:15:58] d2.evaluation.evaluator INFO: Inference done 1484/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:18
[02/04 23:16:04] d2.evaluation.evaluator INFO: Inference done 1490/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:12
[02/04 23:16:10] d2.evaluation.evaluator INFO: Inference done 1496/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:07
[02/04 23:16:16] d2.evaluation.evaluator INFO: Inference done 1502/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:57:01
[02/04 23:16:21] d2.evaluation.evaluator INFO: Inference done 1508/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:55
[02/04 23:16:27] d2.evaluation.evaluator INFO: Inference done 1514/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:49
[02/04 23:16:33] d2.evaluation.evaluator INFO: Inference done 1520/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:43
[02/04 23:16:38] d2.evaluation.evaluator INFO: Inference done 1525/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:56:38
[02/04 23:16:44] d2.evaluation.evaluator INFO: Inference done 1531/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:32
[02/04 23:16:50] d2.evaluation.evaluator INFO: Inference done 1537/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:26
[02/04 23:16:56] d2.evaluation.evaluator INFO: Inference done 1543/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:20
[02/04 23:17:02] d2.evaluation.evaluator INFO: Inference done 1549/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:14
[02/04 23:17:08] d2.evaluation.evaluator INFO: Inference done 1555/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:08
[02/04 23:17:14] d2.evaluation.evaluator INFO: Inference done 1561/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:56:02
[02/04 23:17:19] d2.evaluation.evaluator INFO: Inference done 1566/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:57
[02/04 23:17:25] d2.evaluation.evaluator INFO: Inference done 1572/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:55:51
[02/04 23:17:31] d2.evaluation.evaluator INFO: Inference done 1578/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:55:45
[02/04 23:17:36] d2.evaluation.evaluator INFO: Inference done 1583/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:40
[02/04 23:17:41] d2.evaluation.evaluator INFO: Inference done 1588/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:36
[02/04 23:17:47] d2.evaluation.evaluator INFO: Inference done 1594/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:30
[02/04 23:17:53] d2.evaluation.evaluator INFO: Inference done 1600/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:24
[02/04 23:17:59] d2.evaluation.evaluator INFO: Inference done 1606/4952. Dataloading: 0.0007 s/iter. Inference: 0.9902 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:18
[02/04 23:18:05] d2.evaluation.evaluator INFO: Inference done 1612/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:12
[02/04 23:18:11] d2.evaluation.evaluator INFO: Inference done 1618/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:06
[02/04 23:18:17] d2.evaluation.evaluator INFO: Inference done 1624/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9917 s/iter. ETA=0:55:00
[02/04 23:18:22] d2.evaluation.evaluator INFO: Inference done 1630/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:54:54
[02/04 23:18:28] d2.evaluation.evaluator INFO: Inference done 1636/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:54:48
[02/04 23:18:34] d2.evaluation.evaluator INFO: Inference done 1642/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:54:42
[02/04 23:18:40] d2.evaluation.evaluator INFO: Inference done 1648/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:54:36
[02/04 23:18:46] d2.evaluation.evaluator INFO: Inference done 1654/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:54:30
[02/04 23:18:52] d2.evaluation.evaluator INFO: Inference done 1660/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:54:24
[02/04 23:18:58] d2.evaluation.evaluator INFO: Inference done 1666/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:54:17
[02/04 23:19:04] d2.evaluation.evaluator INFO: Inference done 1672/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:54:12
[02/04 23:19:10] d2.evaluation.evaluator INFO: Inference done 1678/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:54:05
[02/04 23:19:16] d2.evaluation.evaluator INFO: Inference done 1684/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:54:00
[02/04 23:19:22] d2.evaluation.evaluator INFO: Inference done 1690/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:53:54
[02/04 23:19:28] d2.evaluation.evaluator INFO: Inference done 1696/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:53:48
[02/04 23:19:34] d2.evaluation.evaluator INFO: Inference done 1702/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:53:42
[02/04 23:19:39] d2.evaluation.evaluator INFO: Inference done 1707/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:53:37
[02/04 23:19:45] d2.evaluation.evaluator INFO: Inference done 1713/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:53:31
[02/04 23:19:50] d2.evaluation.evaluator INFO: Inference done 1718/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:53:26
[02/04 23:19:55] d2.evaluation.evaluator INFO: Inference done 1723/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:53:21
[02/04 23:20:01] d2.evaluation.evaluator INFO: Inference done 1729/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:53:15
[02/04 23:20:06] d2.evaluation.evaluator INFO: Inference done 1734/4952. Dataloading: 0.0007 s/iter. Inference: 0.9901 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:53:10
[02/04 23:20:12] d2.evaluation.evaluator INFO: Inference done 1740/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:53:05
[02/04 23:20:17] d2.evaluation.evaluator INFO: Inference done 1746/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:52:59
[02/04 23:20:23] d2.evaluation.evaluator INFO: Inference done 1752/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9916 s/iter. ETA=0:52:53
[02/04 23:20:29] d2.evaluation.evaluator INFO: Inference done 1758/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:52:46
[02/04 23:20:35] d2.evaluation.evaluator INFO: Inference done 1764/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:52:41
[02/04 23:20:41] d2.evaluation.evaluator INFO: Inference done 1770/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:52:35
[02/04 23:20:47] d2.evaluation.evaluator INFO: Inference done 1776/4952. Dataloading: 0.0007 s/iter. Inference: 0.9900 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:52:29
[02/04 23:20:53] d2.evaluation.evaluator INFO: Inference done 1782/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:52:23
[02/04 23:20:59] d2.evaluation.evaluator INFO: Inference done 1788/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9915 s/iter. ETA=0:52:16
[02/04 23:21:05] d2.evaluation.evaluator INFO: Inference done 1794/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:52:10
[02/04 23:21:11] d2.evaluation.evaluator INFO: Inference done 1800/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:52:04
[02/04 23:21:16] d2.evaluation.evaluator INFO: Inference done 1805/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:52:00
[02/04 23:21:22] d2.evaluation.evaluator INFO: Inference done 1811/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:51:54
[02/04 23:21:28] d2.evaluation.evaluator INFO: Inference done 1817/4952. Dataloading: 0.0007 s/iter. Inference: 0.9899 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:51:48
[02/04 23:21:33] d2.evaluation.evaluator INFO: Inference done 1823/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:51:41
[02/04 23:21:39] d2.evaluation.evaluator INFO: Inference done 1829/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9914 s/iter. ETA=0:51:36
[02/04 23:21:45] d2.evaluation.evaluator INFO: Inference done 1835/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:51:29
[02/04 23:21:51] d2.evaluation.evaluator INFO: Inference done 1841/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:51:24
[02/04 23:21:57] d2.evaluation.evaluator INFO: Inference done 1847/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:51:18
[02/04 23:22:03] d2.evaluation.evaluator INFO: Inference done 1853/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:51:12
[02/04 23:22:09] d2.evaluation.evaluator INFO: Inference done 1859/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:51:05
[02/04 23:22:15] d2.evaluation.evaluator INFO: Inference done 1865/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:50:59
[02/04 23:22:21] d2.evaluation.evaluator INFO: Inference done 1871/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:50:53
[02/04 23:22:26] d2.evaluation.evaluator INFO: Inference done 1877/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:47
[02/04 23:22:32] d2.evaluation.evaluator INFO: Inference done 1883/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:41
[02/04 23:22:38] d2.evaluation.evaluator INFO: Inference done 1889/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:35
[02/04 23:22:44] d2.evaluation.evaluator INFO: Inference done 1895/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:29
[02/04 23:22:50] d2.evaluation.evaluator INFO: Inference done 1901/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:23
[02/04 23:22:56] d2.evaluation.evaluator INFO: Inference done 1907/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:17
[02/04 23:23:02] d2.evaluation.evaluator INFO: Inference done 1913/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:50:11
[02/04 23:23:08] d2.evaluation.evaluator INFO: Inference done 1919/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:50:05
[02/04 23:23:13] d2.evaluation.evaluator INFO: Inference done 1924/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:50:01
[02/04 23:23:19] d2.evaluation.evaluator INFO: Inference done 1930/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:49:54
[02/04 23:23:25] d2.evaluation.evaluator INFO: Inference done 1936/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:49:49
[02/04 23:23:30] d2.evaluation.evaluator INFO: Inference done 1941/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:49:44
[02/04 23:23:36] d2.evaluation.evaluator INFO: Inference done 1947/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:49:38
[02/04 23:23:41] d2.evaluation.evaluator INFO: Inference done 1952/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:49:33
[02/04 23:23:47] d2.evaluation.evaluator INFO: Inference done 1958/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:49:27
[02/04 23:23:53] d2.evaluation.evaluator INFO: Inference done 1964/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:49:21
[02/04 23:23:59] d2.evaluation.evaluator INFO: Inference done 1970/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:49:15
[02/04 23:24:05] d2.evaluation.evaluator INFO: Inference done 1976/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:49:09
[02/04 23:24:11] d2.evaluation.evaluator INFO: Inference done 1982/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:49:03
[02/04 23:24:16] d2.evaluation.evaluator INFO: Inference done 1987/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:48:58
[02/04 23:24:21] d2.evaluation.evaluator INFO: Inference done 1993/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:52
[02/04 23:24:27] d2.evaluation.evaluator INFO: Inference done 1999/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:46
[02/04 23:24:33] d2.evaluation.evaluator INFO: Inference done 2005/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:40
[02/04 23:24:39] d2.evaluation.evaluator INFO: Inference done 2011/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:34
[02/04 23:24:45] d2.evaluation.evaluator INFO: Inference done 2017/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:28
[02/04 23:24:51] d2.evaluation.evaluator INFO: Inference done 2023/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:22
[02/04 23:24:56] d2.evaluation.evaluator INFO: Inference done 2028/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:18
[02/04 23:25:01] d2.evaluation.evaluator INFO: Inference done 2033/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:48:13
[02/04 23:25:07] d2.evaluation.evaluator INFO: Inference done 2039/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:48:07
[02/04 23:25:13] d2.evaluation.evaluator INFO: Inference done 2045/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:48:01
[02/04 23:25:19] d2.evaluation.evaluator INFO: Inference done 2051/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:47:55
[02/04 23:25:25] d2.evaluation.evaluator INFO: Inference done 2057/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:47:49
[02/04 23:25:31] d2.evaluation.evaluator INFO: Inference done 2063/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:47:43
[02/04 23:25:37] d2.evaluation.evaluator INFO: Inference done 2069/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:47:37
[02/04 23:25:42] d2.evaluation.evaluator INFO: Inference done 2074/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:47:32
[02/04 23:25:48] d2.evaluation.evaluator INFO: Inference done 2080/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:47:26
[02/04 23:25:54] d2.evaluation.evaluator INFO: Inference done 2086/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:47:20
[02/04 23:26:00] d2.evaluation.evaluator INFO: Inference done 2092/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:47:14
[02/04 23:26:06] d2.evaluation.evaluator INFO: Inference done 2098/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:47:08
[02/04 23:26:12] d2.evaluation.evaluator INFO: Inference done 2104/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:47:02
[02/04 23:26:18] d2.evaluation.evaluator INFO: Inference done 2110/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:46:56
[02/04 23:26:23] d2.evaluation.evaluator INFO: Inference done 2115/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:46:52
[02/04 23:26:28] d2.evaluation.evaluator INFO: Inference done 2120/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:46:47
[02/04 23:26:34] d2.evaluation.evaluator INFO: Inference done 2126/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:46:41
[02/04 23:26:39] d2.evaluation.evaluator INFO: Inference done 2132/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:46:35
[02/04 23:26:45] d2.evaluation.evaluator INFO: Inference done 2138/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:46:29
[02/04 23:26:51] d2.evaluation.evaluator INFO: Inference done 2144/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:46:22
[02/04 23:26:56] d2.evaluation.evaluator INFO: Inference done 2149/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:46:18
[02/04 23:27:02] d2.evaluation.evaluator INFO: Inference done 2155/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:46:12
[02/04 23:27:08] d2.evaluation.evaluator INFO: Inference done 2161/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:46:06
[02/04 23:27:14] d2.evaluation.evaluator INFO: Inference done 2167/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:46:00
[02/04 23:27:20] d2.evaluation.evaluator INFO: Inference done 2173/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:45:54
[02/04 23:27:25] d2.evaluation.evaluator INFO: Inference done 2178/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:45:49
[02/04 23:27:30] d2.evaluation.evaluator INFO: Inference done 2183/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:45:44
[02/04 23:27:35] d2.evaluation.evaluator INFO: Inference done 2188/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:45:39
[02/04 23:27:41] d2.evaluation.evaluator INFO: Inference done 2194/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:45:33
[02/04 23:27:46] d2.evaluation.evaluator INFO: Inference done 2199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:45:28
[02/04 23:27:52] d2.evaluation.evaluator INFO: Inference done 2205/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:45:22
[02/04 23:27:58] d2.evaluation.evaluator INFO: Inference done 2211/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:45:16
[02/04 23:28:04] d2.evaluation.evaluator INFO: Inference done 2217/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:45:10
[02/04 23:28:10] d2.evaluation.evaluator INFO: Inference done 2223/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:45:04
[02/04 23:28:15] d2.evaluation.evaluator INFO: Inference done 2229/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:44:58
[02/04 23:28:21] d2.evaluation.evaluator INFO: Inference done 2235/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:52
[02/04 23:28:27] d2.evaluation.evaluator INFO: Inference done 2241/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:46
[02/04 23:28:33] d2.evaluation.evaluator INFO: Inference done 2247/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:40
[02/04 23:28:39] d2.evaluation.evaluator INFO: Inference done 2253/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:35
[02/04 23:28:45] d2.evaluation.evaluator INFO: Inference done 2259/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:29
[02/04 23:28:51] d2.evaluation.evaluator INFO: Inference done 2265/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:23
[02/04 23:28:57] d2.evaluation.evaluator INFO: Inference done 2271/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:44:17
[02/04 23:29:03] d2.evaluation.evaluator INFO: Inference done 2277/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:11
[02/04 23:29:09] d2.evaluation.evaluator INFO: Inference done 2283/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:44:05
[02/04 23:29:15] d2.evaluation.evaluator INFO: Inference done 2289/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:43:59
[02/04 23:29:21] d2.evaluation.evaluator INFO: Inference done 2295/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:43:53
[02/04 23:29:27] d2.evaluation.evaluator INFO: Inference done 2301/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:43:47
[02/04 23:29:32] d2.evaluation.evaluator INFO: Inference done 2306/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:42
[02/04 23:29:38] d2.evaluation.evaluator INFO: Inference done 2312/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:36
[02/04 23:29:43] d2.evaluation.evaluator INFO: Inference done 2317/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:31
[02/04 23:29:49] d2.evaluation.evaluator INFO: Inference done 2323/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:25
[02/04 23:29:55] d2.evaluation.evaluator INFO: Inference done 2329/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:19
[02/04 23:30:01] d2.evaluation.evaluator INFO: Inference done 2335/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:13
[02/04 23:30:06] d2.evaluation.evaluator INFO: Inference done 2341/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:43:07
[02/04 23:30:12] d2.evaluation.evaluator INFO: Inference done 2347/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:43:01
[02/04 23:30:18] d2.evaluation.evaluator INFO: Inference done 2353/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:55
[02/04 23:30:24] d2.evaluation.evaluator INFO: Inference done 2359/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:49
[02/04 23:30:30] d2.evaluation.evaluator INFO: Inference done 2365/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:43
[02/04 23:30:36] d2.evaluation.evaluator INFO: Inference done 2371/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:37
[02/04 23:30:42] d2.evaluation.evaluator INFO: Inference done 2377/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:32
[02/04 23:30:48] d2.evaluation.evaluator INFO: Inference done 2383/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:26
[02/04 23:30:53] d2.evaluation.evaluator INFO: Inference done 2388/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:21
[02/04 23:30:59] d2.evaluation.evaluator INFO: Inference done 2394/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:15
[02/04 23:31:05] d2.evaluation.evaluator INFO: Inference done 2400/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:09
[02/04 23:31:11] d2.evaluation.evaluator INFO: Inference done 2406/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:42:03
[02/04 23:31:16] d2.evaluation.evaluator INFO: Inference done 2411/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:58
[02/04 23:31:22] d2.evaluation.evaluator INFO: Inference done 2417/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:41:52
[02/04 23:31:28] d2.evaluation.evaluator INFO: Inference done 2423/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:46
[02/04 23:31:34] d2.evaluation.evaluator INFO: Inference done 2429/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:40
[02/04 23:31:40] d2.evaluation.evaluator INFO: Inference done 2435/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:34
[02/04 23:31:45] d2.evaluation.evaluator INFO: Inference done 2441/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:28
[02/04 23:31:51] d2.evaluation.evaluator INFO: Inference done 2447/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:22
[02/04 23:31:57] d2.evaluation.evaluator INFO: Inference done 2453/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:16
[02/04 23:32:03] d2.evaluation.evaluator INFO: Inference done 2459/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:10
[02/04 23:32:09] d2.evaluation.evaluator INFO: Inference done 2465/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:41:04
[02/04 23:32:14] d2.evaluation.evaluator INFO: Inference done 2470/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:40:59
[02/04 23:32:20] d2.evaluation.evaluator INFO: Inference done 2476/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:40:53
[02/04 23:32:25] d2.evaluation.evaluator INFO: Inference done 2481/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:40:49
[02/04 23:32:31] d2.evaluation.evaluator INFO: Inference done 2487/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:40:43
[02/04 23:32:36] d2.evaluation.evaluator INFO: Inference done 2492/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:40:38
[02/04 23:32:41] d2.evaluation.evaluator INFO: Inference done 2497/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:40:33
[02/04 23:32:47] d2.evaluation.evaluator INFO: Inference done 2503/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:40:27
[02/04 23:32:52] d2.evaluation.evaluator INFO: Inference done 2508/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:40:22
[02/04 23:32:58] d2.evaluation.evaluator INFO: Inference done 2514/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:40:16
[02/04 23:33:04] d2.evaluation.evaluator INFO: Inference done 2520/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:40:10
[02/04 23:33:10] d2.evaluation.evaluator INFO: Inference done 2526/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:40:04
[02/04 23:33:15] d2.evaluation.evaluator INFO: Inference done 2531/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:59
[02/04 23:33:21] d2.evaluation.evaluator INFO: Inference done 2537/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:53
[02/04 23:33:27] d2.evaluation.evaluator INFO: Inference done 2543/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:47
[02/04 23:33:33] d2.evaluation.evaluator INFO: Inference done 2549/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:41
[02/04 23:33:39] d2.evaluation.evaluator INFO: Inference done 2555/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:35
[02/04 23:33:44] d2.evaluation.evaluator INFO: Inference done 2560/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:39:31
[02/04 23:33:50] d2.evaluation.evaluator INFO: Inference done 2566/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:25
[02/04 23:33:56] d2.evaluation.evaluator INFO: Inference done 2572/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:19
[02/04 23:34:02] d2.evaluation.evaluator INFO: Inference done 2578/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:39:13
[02/04 23:34:08] d2.evaluation.evaluator INFO: Inference done 2584/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:07
[02/04 23:34:13] d2.evaluation.evaluator INFO: Inference done 2590/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:39:01
[02/04 23:34:19] d2.evaluation.evaluator INFO: Inference done 2596/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:55
[02/04 23:34:25] d2.evaluation.evaluator INFO: Inference done 2602/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:49
[02/04 23:34:31] d2.evaluation.evaluator INFO: Inference done 2608/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:43
[02/04 23:34:37] d2.evaluation.evaluator INFO: Inference done 2614/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:37
[02/04 23:34:42] d2.evaluation.evaluator INFO: Inference done 2619/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:32
[02/04 23:34:48] d2.evaluation.evaluator INFO: Inference done 2625/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:26
[02/04 23:34:54] d2.evaluation.evaluator INFO: Inference done 2631/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:20
[02/04 23:35:00] d2.evaluation.evaluator INFO: Inference done 2637/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:14
[02/04 23:35:06] d2.evaluation.evaluator INFO: Inference done 2643/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:38:08
[02/04 23:35:12] d2.evaluation.evaluator INFO: Inference done 2649/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:38:02
[02/04 23:35:17] d2.evaluation.evaluator INFO: Inference done 2654/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:57
[02/04 23:35:23] d2.evaluation.evaluator INFO: Inference done 2660/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:52
[02/04 23:35:29] d2.evaluation.evaluator INFO: Inference done 2666/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:46
[02/04 23:35:34] d2.evaluation.evaluator INFO: Inference done 2671/4952. Dataloading: 0.0007 s/iter. Inference: 0.9898 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:41
[02/04 23:35:40] d2.evaluation.evaluator INFO: Inference done 2677/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:35
[02/04 23:35:46] d2.evaluation.evaluator INFO: Inference done 2683/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:29
[02/04 23:35:52] d2.evaluation.evaluator INFO: Inference done 2689/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:23
[02/04 23:35:58] d2.evaluation.evaluator INFO: Inference done 2695/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:17
[02/04 23:36:04] d2.evaluation.evaluator INFO: Inference done 2701/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:37:11
[02/04 23:36:09] d2.evaluation.evaluator INFO: Inference done 2707/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:37:05
[02/04 23:36:15] d2.evaluation.evaluator INFO: Inference done 2713/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:36:59
[02/04 23:36:20] d2.evaluation.evaluator INFO: Inference done 2718/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:36:54
[02/04 23:36:26] d2.evaluation.evaluator INFO: Inference done 2724/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9913 s/iter. ETA=0:36:48
[02/04 23:36:32] d2.evaluation.evaluator INFO: Inference done 2730/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:42
[02/04 23:36:38] d2.evaluation.evaluator INFO: Inference done 2736/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:36
[02/04 23:36:44] d2.evaluation.evaluator INFO: Inference done 2742/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:30
[02/04 23:36:49] d2.evaluation.evaluator INFO: Inference done 2747/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:25
[02/04 23:36:55] d2.evaluation.evaluator INFO: Inference done 2753/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:19
[02/04 23:37:00] d2.evaluation.evaluator INFO: Inference done 2758/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:14
[02/04 23:37:05] d2.evaluation.evaluator INFO: Inference done 2763/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:09
[02/04 23:37:11] d2.evaluation.evaluator INFO: Inference done 2769/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:36:03
[02/04 23:37:17] d2.evaluation.evaluator INFO: Inference done 2775/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:35:57
[02/04 23:37:23] d2.evaluation.evaluator INFO: Inference done 2781/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:35:51
[02/04 23:37:29] d2.evaluation.evaluator INFO: Inference done 2787/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:35:45
[02/04 23:37:34] d2.evaluation.evaluator INFO: Inference done 2793/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:35:39
[02/04 23:37:40] d2.evaluation.evaluator INFO: Inference done 2799/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:35:33
[02/04 23:37:46] d2.evaluation.evaluator INFO: Inference done 2805/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:35:27
[02/04 23:37:52] d2.evaluation.evaluator INFO: Inference done 2811/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:35:21
[02/04 23:37:58] d2.evaluation.evaluator INFO: Inference done 2817/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:35:15
[02/04 23:38:03] d2.evaluation.evaluator INFO: Inference done 2822/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:35:11
[02/04 23:38:09] d2.evaluation.evaluator INFO: Inference done 2828/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:35:05
[02/04 23:38:15] d2.evaluation.evaluator INFO: Inference done 2834/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:59
[02/04 23:38:21] d2.evaluation.evaluator INFO: Inference done 2840/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:53
[02/04 23:38:27] d2.evaluation.evaluator INFO: Inference done 2846/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:47
[02/04 23:38:33] d2.evaluation.evaluator INFO: Inference done 2852/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:41
[02/04 23:38:39] d2.evaluation.evaluator INFO: Inference done 2858/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:35
[02/04 23:38:45] d2.evaluation.evaluator INFO: Inference done 2864/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:29
[02/04 23:38:51] d2.evaluation.evaluator INFO: Inference done 2870/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:23
[02/04 23:38:56] d2.evaluation.evaluator INFO: Inference done 2876/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:34:17
[02/04 23:39:02] d2.evaluation.evaluator INFO: Inference done 2882/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:34:11
[02/04 23:39:08] d2.evaluation.evaluator INFO: Inference done 2888/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:34:05
[02/04 23:39:14] d2.evaluation.evaluator INFO: Inference done 2894/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:59
[02/04 23:39:20] d2.evaluation.evaluator INFO: Inference done 2900/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:53
[02/04 23:39:26] d2.evaluation.evaluator INFO: Inference done 2906/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:47
[02/04 23:39:32] d2.evaluation.evaluator INFO: Inference done 2912/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:41
[02/04 23:39:37] d2.evaluation.evaluator INFO: Inference done 2917/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:36
[02/04 23:39:43] d2.evaluation.evaluator INFO: Inference done 2923/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:30
[02/04 23:39:49] d2.evaluation.evaluator INFO: Inference done 2929/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:24
[02/04 23:39:55] d2.evaluation.evaluator INFO: Inference done 2935/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:18
[02/04 23:40:01] d2.evaluation.evaluator INFO: Inference done 2941/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:33:12
[02/04 23:40:06] d2.evaluation.evaluator INFO: Inference done 2946/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:33:08
[02/04 23:40:11] d2.evaluation.evaluator INFO: Inference done 2951/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:33:03
[02/04 23:40:17] d2.evaluation.evaluator INFO: Inference done 2957/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:57
[02/04 23:40:23] d2.evaluation.evaluator INFO: Inference done 2963/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:51
[02/04 23:40:28] d2.evaluation.evaluator INFO: Inference done 2968/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:46
[02/04 23:40:34] d2.evaluation.evaluator INFO: Inference done 2974/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:40
[02/04 23:40:39] d2.evaluation.evaluator INFO: Inference done 2979/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:35
[02/04 23:40:44] d2.evaluation.evaluator INFO: Inference done 2984/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:30
[02/04 23:40:50] d2.evaluation.evaluator INFO: Inference done 2990/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:24
[02/04 23:40:56] d2.evaluation.evaluator INFO: Inference done 2996/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:18
[02/04 23:41:02] d2.evaluation.evaluator INFO: Inference done 3002/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:12
[02/04 23:41:07] d2.evaluation.evaluator INFO: Inference done 3008/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:32:06
[02/04 23:41:13] d2.evaluation.evaluator INFO: Inference done 3014/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:32:00
[02/04 23:41:19] d2.evaluation.evaluator INFO: Inference done 3020/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:54
[02/04 23:41:25] d2.evaluation.evaluator INFO: Inference done 3026/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:48
[02/04 23:41:31] d2.evaluation.evaluator INFO: Inference done 3032/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:42
[02/04 23:41:37] d2.evaluation.evaluator INFO: Inference done 3038/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:36
[02/04 23:41:43] d2.evaluation.evaluator INFO: Inference done 3044/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:30
[02/04 23:41:49] d2.evaluation.evaluator INFO: Inference done 3050/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:25
[02/04 23:41:55] d2.evaluation.evaluator INFO: Inference done 3056/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:19
[02/04 23:42:01] d2.evaluation.evaluator INFO: Inference done 3062/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:13
[02/04 23:42:07] d2.evaluation.evaluator INFO: Inference done 3068/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:07
[02/04 23:42:12] d2.evaluation.evaluator INFO: Inference done 3073/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:31:02
[02/04 23:42:17] d2.evaluation.evaluator INFO: Inference done 3078/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:57
[02/04 23:42:23] d2.evaluation.evaluator INFO: Inference done 3084/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:51
[02/04 23:42:28] d2.evaluation.evaluator INFO: Inference done 3089/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:46
[02/04 23:42:34] d2.evaluation.evaluator INFO: Inference done 3095/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:40
[02/04 23:42:39] d2.evaluation.evaluator INFO: Inference done 3100/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:35
[02/04 23:42:45] d2.evaluation.evaluator INFO: Inference done 3106/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:29
[02/04 23:42:51] d2.evaluation.evaluator INFO: Inference done 3112/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:23
[02/04 23:42:56] d2.evaluation.evaluator INFO: Inference done 3118/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:17
[02/04 23:43:01] d2.evaluation.evaluator INFO: Inference done 3123/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:12
[02/04 23:43:07] d2.evaluation.evaluator INFO: Inference done 3129/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:06
[02/04 23:43:13] d2.evaluation.evaluator INFO: Inference done 3135/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:30:00
[02/04 23:43:19] d2.evaluation.evaluator INFO: Inference done 3141/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:54
[02/04 23:43:25] d2.evaluation.evaluator INFO: Inference done 3147/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:48
[02/04 23:43:31] d2.evaluation.evaluator INFO: Inference done 3153/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:43
[02/04 23:43:36] d2.evaluation.evaluator INFO: Inference done 3158/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:38
[02/04 23:43:42] d2.evaluation.evaluator INFO: Inference done 3164/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:32
[02/04 23:43:48] d2.evaluation.evaluator INFO: Inference done 3170/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:26
[02/04 23:43:53] d2.evaluation.evaluator INFO: Inference done 3175/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:21
[02/04 23:43:59] d2.evaluation.evaluator INFO: Inference done 3181/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:15
[02/04 23:44:05] d2.evaluation.evaluator INFO: Inference done 3187/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:09
[02/04 23:44:11] d2.evaluation.evaluator INFO: Inference done 3193/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:29:03
[02/04 23:44:17] d2.evaluation.evaluator INFO: Inference done 3199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:57
[02/04 23:44:23] d2.evaluation.evaluator INFO: Inference done 3205/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:51
[02/04 23:44:29] d2.evaluation.evaluator INFO: Inference done 3211/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:45
[02/04 23:44:34] d2.evaluation.evaluator INFO: Inference done 3216/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:40
[02/04 23:44:39] d2.evaluation.evaluator INFO: Inference done 3222/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:34
[02/04 23:44:45] d2.evaluation.evaluator INFO: Inference done 3228/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:28
[02/04 23:44:51] d2.evaluation.evaluator INFO: Inference done 3234/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:22
[02/04 23:44:57] d2.evaluation.evaluator INFO: Inference done 3240/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:16
[02/04 23:45:03] d2.evaluation.evaluator INFO: Inference done 3246/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:10
[02/04 23:45:09] d2.evaluation.evaluator INFO: Inference done 3252/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:28:04
[02/04 23:45:15] d2.evaluation.evaluator INFO: Inference done 3258/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:58
[02/04 23:45:21] d2.evaluation.evaluator INFO: Inference done 3264/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:52
[02/04 23:45:27] d2.evaluation.evaluator INFO: Inference done 3270/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:47
[02/04 23:45:32] d2.evaluation.evaluator INFO: Inference done 3275/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:42
[02/04 23:45:38] d2.evaluation.evaluator INFO: Inference done 3281/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:36
[02/04 23:45:44] d2.evaluation.evaluator INFO: Inference done 3287/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:30
[02/04 23:45:50] d2.evaluation.evaluator INFO: Inference done 3293/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:24
[02/04 23:45:56] d2.evaluation.evaluator INFO: Inference done 3299/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:27:18
[02/04 23:46:01] d2.evaluation.evaluator INFO: Inference done 3304/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:27:13
[02/04 23:46:07] d2.evaluation.evaluator INFO: Inference done 3310/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:27:07
[02/04 23:46:13] d2.evaluation.evaluator INFO: Inference done 3316/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:27:01
[02/04 23:46:19] d2.evaluation.evaluator INFO: Inference done 3322/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:26:55
[02/04 23:46:25] d2.evaluation.evaluator INFO: Inference done 3328/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:26:49
[02/04 23:46:31] d2.evaluation.evaluator INFO: Inference done 3334/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:26:43
[02/04 23:46:37] d2.evaluation.evaluator INFO: Inference done 3340/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:37
[02/04 23:46:43] d2.evaluation.evaluator INFO: Inference done 3346/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:31
[02/04 23:46:49] d2.evaluation.evaluator INFO: Inference done 3352/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:25
[02/04 23:46:54] d2.evaluation.evaluator INFO: Inference done 3358/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:19
[02/04 23:47:00] d2.evaluation.evaluator INFO: Inference done 3364/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:13
[02/04 23:47:06] d2.evaluation.evaluator INFO: Inference done 3370/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:08
[02/04 23:47:12] d2.evaluation.evaluator INFO: Inference done 3376/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:26:02
[02/04 23:47:18] d2.evaluation.evaluator INFO: Inference done 3382/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:25:56
[02/04 23:47:24] d2.evaluation.evaluator INFO: Inference done 3388/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:25:50
[02/04 23:47:30] d2.evaluation.evaluator INFO: Inference done 3394/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:25:44
[02/04 23:47:36] d2.evaluation.evaluator INFO: Inference done 3400/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:25:38
[02/04 23:47:42] d2.evaluation.evaluator INFO: Inference done 3406/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:25:32
[02/04 23:47:48] d2.evaluation.evaluator INFO: Inference done 3412/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:25:26
[02/04 23:47:54] d2.evaluation.evaluator INFO: Inference done 3418/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:25:20
[02/04 23:48:00] d2.evaluation.evaluator INFO: Inference done 3424/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:25:14
[02/04 23:48:06] d2.evaluation.evaluator INFO: Inference done 3430/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:25:08
[02/04 23:48:11] d2.evaluation.evaluator INFO: Inference done 3436/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:25:02
[02/04 23:48:17] d2.evaluation.evaluator INFO: Inference done 3442/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:24:56
[02/04 23:48:23] d2.evaluation.evaluator INFO: Inference done 3448/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:24:50
[02/04 23:48:29] d2.evaluation.evaluator INFO: Inference done 3454/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:24:44
[02/04 23:48:35] d2.evaluation.evaluator INFO: Inference done 3460/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:24:38
[02/04 23:48:41] d2.evaluation.evaluator INFO: Inference done 3466/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:24:32
[02/04 23:48:47] d2.evaluation.evaluator INFO: Inference done 3472/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:24:26
[02/04 23:48:53] d2.evaluation.evaluator INFO: Inference done 3478/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:24:20
[02/04 23:48:59] d2.evaluation.evaluator INFO: Inference done 3484/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:24:14
[02/04 23:49:05] d2.evaluation.evaluator INFO: Inference done 3490/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:24:08
[02/04 23:49:11] d2.evaluation.evaluator INFO: Inference done 3496/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:24:02
[02/04 23:49:17] d2.evaluation.evaluator INFO: Inference done 3502/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:57
[02/04 23:49:23] d2.evaluation.evaluator INFO: Inference done 3508/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:51
[02/04 23:49:29] d2.evaluation.evaluator INFO: Inference done 3514/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:45
[02/04 23:49:35] d2.evaluation.evaluator INFO: Inference done 3520/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:39
[02/04 23:49:41] d2.evaluation.evaluator INFO: Inference done 3526/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:33
[02/04 23:49:47] d2.evaluation.evaluator INFO: Inference done 3532/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:27
[02/04 23:49:53] d2.evaluation.evaluator INFO: Inference done 3538/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:21
[02/04 23:49:59] d2.evaluation.evaluator INFO: Inference done 3544/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:15
[02/04 23:50:04] d2.evaluation.evaluator INFO: Inference done 3550/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:09
[02/04 23:50:10] d2.evaluation.evaluator INFO: Inference done 3556/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:23:03
[02/04 23:50:16] d2.evaluation.evaluator INFO: Inference done 3562/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:57
[02/04 23:50:22] d2.evaluation.evaluator INFO: Inference done 3568/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:51
[02/04 23:50:28] d2.evaluation.evaluator INFO: Inference done 3574/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:45
[02/04 23:50:34] d2.evaluation.evaluator INFO: Inference done 3580/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:39
[02/04 23:50:40] d2.evaluation.evaluator INFO: Inference done 3586/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:33
[02/04 23:50:46] d2.evaluation.evaluator INFO: Inference done 3592/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:27
[02/04 23:50:51] d2.evaluation.evaluator INFO: Inference done 3597/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:22
[02/04 23:50:57] d2.evaluation.evaluator INFO: Inference done 3603/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:16
[02/04 23:51:03] d2.evaluation.evaluator INFO: Inference done 3609/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:11
[02/04 23:51:09] d2.evaluation.evaluator INFO: Inference done 3615/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:22:05
[02/04 23:51:15] d2.evaluation.evaluator INFO: Inference done 3621/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:59
[02/04 23:51:21] d2.evaluation.evaluator INFO: Inference done 3627/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:53
[02/04 23:51:27] d2.evaluation.evaluator INFO: Inference done 3633/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:47
[02/04 23:51:33] d2.evaluation.evaluator INFO: Inference done 3639/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:41
[02/04 23:51:39] d2.evaluation.evaluator INFO: Inference done 3645/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:35
[02/04 23:51:45] d2.evaluation.evaluator INFO: Inference done 3651/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:29
[02/04 23:51:50] d2.evaluation.evaluator INFO: Inference done 3657/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:23
[02/04 23:51:56] d2.evaluation.evaluator INFO: Inference done 3663/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:17
[02/04 23:52:02] d2.evaluation.evaluator INFO: Inference done 3669/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:11
[02/04 23:52:08] d2.evaluation.evaluator INFO: Inference done 3675/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:21:05
[02/04 23:52:14] d2.evaluation.evaluator INFO: Inference done 3681/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:20:59
[02/04 23:52:20] d2.evaluation.evaluator INFO: Inference done 3687/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:20:53
[02/04 23:52:26] d2.evaluation.evaluator INFO: Inference done 3693/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:20:47
[02/04 23:52:32] d2.evaluation.evaluator INFO: Inference done 3699/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:20:41
[02/04 23:52:38] d2.evaluation.evaluator INFO: Inference done 3705/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:35
[02/04 23:52:44] d2.evaluation.evaluator INFO: Inference done 3711/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:29
[02/04 23:52:50] d2.evaluation.evaluator INFO: Inference done 3717/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:23
[02/04 23:52:56] d2.evaluation.evaluator INFO: Inference done 3723/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:17
[02/04 23:53:02] d2.evaluation.evaluator INFO: Inference done 3729/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:12
[02/04 23:53:08] d2.evaluation.evaluator INFO: Inference done 3735/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:06
[02/04 23:53:13] d2.evaluation.evaluator INFO: Inference done 3741/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:20:00
[02/04 23:53:19] d2.evaluation.evaluator INFO: Inference done 3747/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:54
[02/04 23:53:25] d2.evaluation.evaluator INFO: Inference done 3753/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:48
[02/04 23:53:31] d2.evaluation.evaluator INFO: Inference done 3759/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:42
[02/04 23:53:37] d2.evaluation.evaluator INFO: Inference done 3765/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:36
[02/04 23:53:43] d2.evaluation.evaluator INFO: Inference done 3771/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:30
[02/04 23:53:49] d2.evaluation.evaluator INFO: Inference done 3777/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:24
[02/04 23:53:55] d2.evaluation.evaluator INFO: Inference done 3783/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:19:18
[02/04 23:54:01] d2.evaluation.evaluator INFO: Inference done 3789/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:19:12
[02/04 23:54:07] d2.evaluation.evaluator INFO: Inference done 3795/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:19:06
[02/04 23:54:13] d2.evaluation.evaluator INFO: Inference done 3801/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:19:00
[02/04 23:54:18] d2.evaluation.evaluator INFO: Inference done 3806/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:55
[02/04 23:54:23] d2.evaluation.evaluator INFO: Inference done 3811/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:50
[02/04 23:54:28] d2.evaluation.evaluator INFO: Inference done 3816/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:45
[02/04 23:54:34] d2.evaluation.evaluator INFO: Inference done 3822/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:39
[02/04 23:54:40] d2.evaluation.evaluator INFO: Inference done 3828/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:33
[02/04 23:54:45] d2.evaluation.evaluator INFO: Inference done 3833/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:28
[02/04 23:54:51] d2.evaluation.evaluator INFO: Inference done 3839/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:23
[02/04 23:54:57] d2.evaluation.evaluator INFO: Inference done 3845/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:17
[02/04 23:55:03] d2.evaluation.evaluator INFO: Inference done 3851/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:11
[02/04 23:55:09] d2.evaluation.evaluator INFO: Inference done 3857/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:18:05
[02/04 23:55:14] d2.evaluation.evaluator INFO: Inference done 3863/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:17:59
[02/04 23:55:20] d2.evaluation.evaluator INFO: Inference done 3869/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:17:53
[02/04 23:55:26] d2.evaluation.evaluator INFO: Inference done 3875/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:17:47
[02/04 23:55:32] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:17:41
[02/04 23:55:37] d2.evaluation.evaluator INFO: Inference done 3886/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:17:36
[02/04 23:55:42] d2.evaluation.evaluator INFO: Inference done 3891/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:17:31
[02/04 23:55:47] d2.evaluation.evaluator INFO: Inference done 3896/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:17:26
[02/04 23:55:53] d2.evaluation.evaluator INFO: Inference done 3902/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:17:20
[02/04 23:55:59] d2.evaluation.evaluator INFO: Inference done 3908/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:17:14
[02/04 23:56:04] d2.evaluation.evaluator INFO: Inference done 3913/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:17:09
[02/04 23:56:11] d2.evaluation.evaluator INFO: Inference done 3919/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:17:03
[02/04 23:56:16] d2.evaluation.evaluator INFO: Inference done 3924/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:58
[02/04 23:56:21] d2.evaluation.evaluator INFO: Inference done 3930/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:52
[02/04 23:56:27] d2.evaluation.evaluator INFO: Inference done 3936/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:16:47
[02/04 23:56:33] d2.evaluation.evaluator INFO: Inference done 3942/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:16:41
[02/04 23:56:38] d2.evaluation.evaluator INFO: Inference done 3947/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:36
[02/04 23:56:44] d2.evaluation.evaluator INFO: Inference done 3953/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:30
[02/04 23:56:49] d2.evaluation.evaluator INFO: Inference done 3958/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:25
[02/04 23:56:55] d2.evaluation.evaluator INFO: Inference done 3964/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:19
[02/04 23:57:00] d2.evaluation.evaluator INFO: Inference done 3969/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:14
[02/04 23:57:06] d2.evaluation.evaluator INFO: Inference done 3975/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:08
[02/04 23:57:11] d2.evaluation.evaluator INFO: Inference done 3980/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:16:03
[02/04 23:57:17] d2.evaluation.evaluator INFO: Inference done 3986/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:57
[02/04 23:57:23] d2.evaluation.evaluator INFO: Inference done 3992/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:51
[02/04 23:57:29] d2.evaluation.evaluator INFO: Inference done 3998/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:45
[02/04 23:57:35] d2.evaluation.evaluator INFO: Inference done 4004/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:39
[02/04 23:57:41] d2.evaluation.evaluator INFO: Inference done 4010/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:33
[02/04 23:57:47] d2.evaluation.evaluator INFO: Inference done 4016/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:27
[02/04 23:57:52] d2.evaluation.evaluator INFO: Inference done 4021/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:22
[02/04 23:57:58] d2.evaluation.evaluator INFO: Inference done 4027/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:16
[02/04 23:58:04] d2.evaluation.evaluator INFO: Inference done 4033/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:10
[02/04 23:58:10] d2.evaluation.evaluator INFO: Inference done 4039/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:15:04
[02/04 23:58:16] d2.evaluation.evaluator INFO: Inference done 4045/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:14:59
[02/04 23:58:22] d2.evaluation.evaluator INFO: Inference done 4051/4952. Dataloading: 0.0007 s/iter. Inference: 0.9897 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:14:53
[02/04 23:58:27] d2.evaluation.evaluator INFO: Inference done 4057/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:14:47
[02/04 23:58:33] d2.evaluation.evaluator INFO: Inference done 4063/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:14:41
[02/04 23:58:39] d2.evaluation.evaluator INFO: Inference done 4069/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:14:35
[02/04 23:58:45] d2.evaluation.evaluator INFO: Inference done 4075/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:14:29
[02/04 23:58:51] d2.evaluation.evaluator INFO: Inference done 4081/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:14:23
[02/04 23:58:57] d2.evaluation.evaluator INFO: Inference done 4087/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:14:17
[02/04 23:59:03] d2.evaluation.evaluator INFO: Inference done 4093/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:14:11
[02/04 23:59:09] d2.evaluation.evaluator INFO: Inference done 4099/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:14:05
[02/04 23:59:15] d2.evaluation.evaluator INFO: Inference done 4105/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:59
[02/04 23:59:21] d2.evaluation.evaluator INFO: Inference done 4111/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:53
[02/04 23:59:27] d2.evaluation.evaluator INFO: Inference done 4117/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:47
[02/04 23:59:33] d2.evaluation.evaluator INFO: Inference done 4123/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:41
[02/04 23:59:38] d2.evaluation.evaluator INFO: Inference done 4129/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:35
[02/04 23:59:44] d2.evaluation.evaluator INFO: Inference done 4135/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:29
[02/04 23:59:50] d2.evaluation.evaluator INFO: Inference done 4141/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:23
[02/04 23:59:55] d2.evaluation.evaluator INFO: Inference done 4146/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:13:18
[02/05 00:00:00] d2.evaluation.evaluator INFO: Inference done 4151/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:13:13
[02/05 00:00:06] d2.evaluation.evaluator INFO: Inference done 4157/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:13:07
[02/05 00:00:12] d2.evaluation.evaluator INFO: Inference done 4163/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:13:02
[02/05 00:00:18] d2.evaluation.evaluator INFO: Inference done 4169/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:56
[02/05 00:00:24] d2.evaluation.evaluator INFO: Inference done 4175/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:50
[02/05 00:00:30] d2.evaluation.evaluator INFO: Inference done 4181/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:44
[02/05 00:00:36] d2.evaluation.evaluator INFO: Inference done 4187/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:38
[02/05 00:00:42] d2.evaluation.evaluator INFO: Inference done 4193/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:32
[02/05 00:00:48] d2.evaluation.evaluator INFO: Inference done 4199/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:26
[02/05 00:00:54] d2.evaluation.evaluator INFO: Inference done 4205/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:20
[02/05 00:01:00] d2.evaluation.evaluator INFO: Inference done 4211/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:14
[02/05 00:01:05] d2.evaluation.evaluator INFO: Inference done 4217/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:08
[02/05 00:01:11] d2.evaluation.evaluator INFO: Inference done 4223/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:12:02
[02/05 00:01:16] d2.evaluation.evaluator INFO: Inference done 4228/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:57
[02/05 00:01:22] d2.evaluation.evaluator INFO: Inference done 4234/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:51
[02/05 00:01:28] d2.evaluation.evaluator INFO: Inference done 4240/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:45
[02/05 00:01:34] d2.evaluation.evaluator INFO: Inference done 4246/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:39
[02/05 00:01:40] d2.evaluation.evaluator INFO: Inference done 4252/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:11:33
[02/05 00:01:46] d2.evaluation.evaluator INFO: Inference done 4258/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:11:27
[02/05 00:01:52] d2.evaluation.evaluator INFO: Inference done 4264/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:11:21
[02/05 00:01:58] d2.evaluation.evaluator INFO: Inference done 4270/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:15
[02/05 00:02:04] d2.evaluation.evaluator INFO: Inference done 4276/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:09
[02/05 00:02:09] d2.evaluation.evaluator INFO: Inference done 4281/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:05
[02/05 00:02:14] d2.evaluation.evaluator INFO: Inference done 4286/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:11:00
[02/05 00:02:20] d2.evaluation.evaluator INFO: Inference done 4292/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:54
[02/05 00:02:25] d2.evaluation.evaluator INFO: Inference done 4297/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:49
[02/05 00:02:31] d2.evaluation.evaluator INFO: Inference done 4303/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:43
[02/05 00:02:37] d2.evaluation.evaluator INFO: Inference done 4309/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:37
[02/05 00:02:42] d2.evaluation.evaluator INFO: Inference done 4314/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:32
[02/05 00:02:47] d2.evaluation.evaluator INFO: Inference done 4319/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:27
[02/05 00:02:53] d2.evaluation.evaluator INFO: Inference done 4325/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:10:21
[02/05 00:02:58] d2.evaluation.evaluator INFO: Inference done 4330/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:10:16
[02/05 00:03:03] d2.evaluation.evaluator INFO: Inference done 4335/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:10:11
[02/05 00:03:09] d2.evaluation.evaluator INFO: Inference done 4341/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:10:05
[02/05 00:03:15] d2.evaluation.evaluator INFO: Inference done 4347/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:59
[02/05 00:03:21] d2.evaluation.evaluator INFO: Inference done 4353/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:53
[02/05 00:03:26] d2.evaluation.evaluator INFO: Inference done 4358/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:48
[02/05 00:03:32] d2.evaluation.evaluator INFO: Inference done 4364/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:42
[02/05 00:03:38] d2.evaluation.evaluator INFO: Inference done 4370/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:36
[02/05 00:03:44] d2.evaluation.evaluator INFO: Inference done 4376/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:30
[02/05 00:03:50] d2.evaluation.evaluator INFO: Inference done 4382/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:24
[02/05 00:03:56] d2.evaluation.evaluator INFO: Inference done 4388/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:19
[02/05 00:04:01] d2.evaluation.evaluator INFO: Inference done 4394/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:13
[02/05 00:04:07] d2.evaluation.evaluator INFO: Inference done 4400/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:07
[02/05 00:04:13] d2.evaluation.evaluator INFO: Inference done 4406/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:09:01
[02/05 00:04:19] d2.evaluation.evaluator INFO: Inference done 4412/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:55
[02/05 00:04:25] d2.evaluation.evaluator INFO: Inference done 4418/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:49
[02/05 00:04:31] d2.evaluation.evaluator INFO: Inference done 4424/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:43
[02/05 00:04:37] d2.evaluation.evaluator INFO: Inference done 4430/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:37
[02/05 00:04:43] d2.evaluation.evaluator INFO: Inference done 4436/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:31
[02/05 00:04:49] d2.evaluation.evaluator INFO: Inference done 4442/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:25
[02/05 00:04:55] d2.evaluation.evaluator INFO: Inference done 4448/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:19
[02/05 00:05:01] d2.evaluation.evaluator INFO: Inference done 4454/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:13
[02/05 00:05:07] d2.evaluation.evaluator INFO: Inference done 4460/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:07
[02/05 00:05:13] d2.evaluation.evaluator INFO: Inference done 4466/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9912 s/iter. ETA=0:08:01
[02/05 00:05:19] d2.evaluation.evaluator INFO: Inference done 4472/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:55
[02/05 00:05:24] d2.evaluation.evaluator INFO: Inference done 4477/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:50
[02/05 00:05:29] d2.evaluation.evaluator INFO: Inference done 4483/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:44
[02/05 00:05:35] d2.evaluation.evaluator INFO: Inference done 4489/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:38
[02/05 00:05:41] d2.evaluation.evaluator INFO: Inference done 4495/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:32
[02/05 00:05:47] d2.evaluation.evaluator INFO: Inference done 4501/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:26
[02/05 00:05:52] d2.evaluation.evaluator INFO: Inference done 4506/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:22
[02/05 00:05:58] d2.evaluation.evaluator INFO: Inference done 4512/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:16
[02/05 00:06:04] d2.evaluation.evaluator INFO: Inference done 4518/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:10
[02/05 00:06:10] d2.evaluation.evaluator INFO: Inference done 4524/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:07:04
[02/05 00:06:16] d2.evaluation.evaluator INFO: Inference done 4530/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:58
[02/05 00:06:21] d2.evaluation.evaluator INFO: Inference done 4535/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:53
[02/05 00:06:27] d2.evaluation.evaluator INFO: Inference done 4541/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:47
[02/05 00:06:33] d2.evaluation.evaluator INFO: Inference done 4547/4952. Dataloading: 0.0007 s/iter. Inference: 0.9896 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:41
[02/05 00:06:39] d2.evaluation.evaluator INFO: Inference done 4553/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:35
[02/05 00:06:45] d2.evaluation.evaluator INFO: Inference done 4559/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:29
[02/05 00:06:51] d2.evaluation.evaluator INFO: Inference done 4565/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:23
[02/05 00:06:56] d2.evaluation.evaluator INFO: Inference done 4571/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:17
[02/05 00:07:02] d2.evaluation.evaluator INFO: Inference done 4577/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:11
[02/05 00:07:08] d2.evaluation.evaluator INFO: Inference done 4583/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:06:05
[02/05 00:07:14] d2.evaluation.evaluator INFO: Inference done 4589/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:05:59
[02/05 00:07:20] d2.evaluation.evaluator INFO: Inference done 4595/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:05:53
[02/05 00:07:26] d2.evaluation.evaluator INFO: Inference done 4601/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9911 s/iter. ETA=0:05:47
[02/05 00:07:32] d2.evaluation.evaluator INFO: Inference done 4607/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:41
[02/05 00:07:38] d2.evaluation.evaluator INFO: Inference done 4613/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:35
[02/05 00:07:44] d2.evaluation.evaluator INFO: Inference done 4619/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:30
[02/05 00:07:50] d2.evaluation.evaluator INFO: Inference done 4625/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:24
[02/05 00:07:55] d2.evaluation.evaluator INFO: Inference done 4630/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:19
[02/05 00:08:00] d2.evaluation.evaluator INFO: Inference done 4636/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:13
[02/05 00:08:06] d2.evaluation.evaluator INFO: Inference done 4642/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:07
[02/05 00:08:12] d2.evaluation.evaluator INFO: Inference done 4648/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:05:01
[02/05 00:08:18] d2.evaluation.evaluator INFO: Inference done 4654/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:55
[02/05 00:08:24] d2.evaluation.evaluator INFO: Inference done 4660/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:49
[02/05 00:08:30] d2.evaluation.evaluator INFO: Inference done 4666/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:43
[02/05 00:08:35] d2.evaluation.evaluator INFO: Inference done 4671/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:38
[02/05 00:08:41] d2.evaluation.evaluator INFO: Inference done 4677/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:32
[02/05 00:08:46] d2.evaluation.evaluator INFO: Inference done 4682/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:27
[02/05 00:08:51] d2.evaluation.evaluator INFO: Inference done 4687/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:22
[02/05 00:08:57] d2.evaluation.evaluator INFO: Inference done 4693/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:16
[02/05 00:09:03] d2.evaluation.evaluator INFO: Inference done 4699/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:10
[02/05 00:09:09] d2.evaluation.evaluator INFO: Inference done 4705/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:04:04
[02/05 00:09:15] d2.evaluation.evaluator INFO: Inference done 4711/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:58
[02/05 00:09:21] d2.evaluation.evaluator INFO: Inference done 4717/4952. Dataloading: 0.0007 s/iter. Inference: 0.9895 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:52
[02/05 00:09:27] d2.evaluation.evaluator INFO: Inference done 4723/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:46
[02/05 00:09:33] d2.evaluation.evaluator INFO: Inference done 4729/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:40
[02/05 00:09:38] d2.evaluation.evaluator INFO: Inference done 4735/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:35
[02/05 00:09:44] d2.evaluation.evaluator INFO: Inference done 4741/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:29
[02/05 00:09:50] d2.evaluation.evaluator INFO: Inference done 4747/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:23
[02/05 00:09:56] d2.evaluation.evaluator INFO: Inference done 4753/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:17
[02/05 00:10:02] d2.evaluation.evaluator INFO: Inference done 4759/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:11
[02/05 00:10:08] d2.evaluation.evaluator INFO: Inference done 4765/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:03:05
[02/05 00:10:14] d2.evaluation.evaluator INFO: Inference done 4771/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:59
[02/05 00:10:20] d2.evaluation.evaluator INFO: Inference done 4777/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:53
[02/05 00:10:26] d2.evaluation.evaluator INFO: Inference done 4783/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:47
[02/05 00:10:32] d2.evaluation.evaluator INFO: Inference done 4789/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:41
[02/05 00:10:38] d2.evaluation.evaluator INFO: Inference done 4795/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:35
[02/05 00:10:44] d2.evaluation.evaluator INFO: Inference done 4801/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:29
[02/05 00:10:50] d2.evaluation.evaluator INFO: Inference done 4807/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:23
[02/05 00:10:55] d2.evaluation.evaluator INFO: Inference done 4812/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:18
[02/05 00:11:01] d2.evaluation.evaluator INFO: Inference done 4818/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:12
[02/05 00:11:07] d2.evaluation.evaluator INFO: Inference done 4824/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:06
[02/05 00:11:13] d2.evaluation.evaluator INFO: Inference done 4830/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:02:00
[02/05 00:11:18] d2.evaluation.evaluator INFO: Inference done 4836/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:01:54
[02/05 00:11:24] d2.evaluation.evaluator INFO: Inference done 4842/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:01:49
[02/05 00:11:30] d2.evaluation.evaluator INFO: Inference done 4848/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:43
[02/05 00:11:36] d2.evaluation.evaluator INFO: Inference done 4854/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:37
[02/05 00:11:42] d2.evaluation.evaluator INFO: Inference done 4860/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:31
[02/05 00:11:48] d2.evaluation.evaluator INFO: Inference done 4866/4952. Dataloading: 0.0007 s/iter. Inference: 0.9893 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:25
[02/05 00:11:54] d2.evaluation.evaluator INFO: Inference done 4872/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:19
[02/05 00:12:00] d2.evaluation.evaluator INFO: Inference done 4878/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:13
[02/05 00:12:06] d2.evaluation.evaluator INFO: Inference done 4884/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:07
[02/05 00:12:12] d2.evaluation.evaluator INFO: Inference done 4890/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:01:01
[02/05 00:12:18] d2.evaluation.evaluator INFO: Inference done 4896/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:00:55
[02/05 00:12:23] d2.evaluation.evaluator INFO: Inference done 4901/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:00:50
[02/05 00:12:29] d2.evaluation.evaluator INFO: Inference done 4907/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:00:44
[02/05 00:12:35] d2.evaluation.evaluator INFO: Inference done 4913/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:00:38
[02/05 00:12:40] d2.evaluation.evaluator INFO: Inference done 4918/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9909 s/iter. ETA=0:00:33
[02/05 00:12:46] d2.evaluation.evaluator INFO: Inference done 4924/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:00:27
[02/05 00:12:52] d2.evaluation.evaluator INFO: Inference done 4930/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:00:21
[02/05 00:12:57] d2.evaluation.evaluator INFO: Inference done 4936/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:00:15
[02/05 00:13:03] d2.evaluation.evaluator INFO: Inference done 4941/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:00:10
[02/05 00:13:08] d2.evaluation.evaluator INFO: Inference done 4946/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:00:05
[02/05 00:13:13] d2.evaluation.evaluator INFO: Inference done 4952/4952. Dataloading: 0.0007 s/iter. Inference: 0.9894 s/iter. Eval: 0.0008 s/iter. Total: 0.9910 s/iter. ETA=0:00:00
[02/05 00:13:14] d2.evaluation.evaluator INFO: Total inference time: 1:21:42.428179 (0.990990 s / iter per device, on 1 devices)
[02/05 00:13:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 1:21:34 (0.989407 s / iter per device, on 1 devices)
[02/05 00:13:14] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[02/05 00:14:03] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car   |  cat   |  chair  |  diningtable  |  dog  |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow   |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:------:|:------:|:-------:|:-------------:|:-----:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:------:|:-----------:|:------:|
|   24.814    |  22.886   | 18.436 |  23.190  | 32.752 | 11.239 | 15.625  |     6.061     | 4.302 | 10.472  |  25.437  |    13.558     | 32.357  |  5.295  |   19.865    | 1.835  | 0.220 | 22.552 |    0.144    | 0.026  |
[02/05 00:14:03] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|  AP   |  AP50  |  AP75  |  bAP   |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:-----:|:------:|:------:|:------:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 8.344 | 14.553 | 8.170  | 10.020 | 17.753  |  9.732  | 3.315 |  4.955  |  3.484  |
[02/05 00:14:03] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/05 00:14:03] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[02/05 00:14:03] d2.evaluation.testing INFO: copypaste: 8.3436,14.5532,8.1702,10.0199,17.7525,9.7324,3.3147,4.9553,3.4836
[02/05 00:14:03] d2.evaluation.evaluator INFO: Start inference on 4952 batches
[02/05 00:14:15] d2.evaluation.evaluator INFO: Inference done 11/4952. Dataloading: 0.0005 s/iter. Inference: 1.0860 s/iter. Eval: 0.0008 s/iter. Total: 1.0873 s/iter. ETA=1:29:32
[02/05 00:14:21] d2.evaluation.evaluator INFO: Inference done 16/4952. Dataloading: 0.0004 s/iter. Inference: 1.0764 s/iter. Eval: 0.0008 s/iter. Total: 1.0777 s/iter. ETA=1:28:39
[02/05 00:14:26] d2.evaluation.evaluator INFO: Inference done 21/4952. Dataloading: 0.0005 s/iter. Inference: 1.0812 s/iter. Eval: 0.0008 s/iter. Total: 1.0825 s/iter. ETA=1:28:57
[02/05 00:14:32] d2.evaluation.evaluator INFO: Inference done 26/4952. Dataloading: 0.0005 s/iter. Inference: 1.0804 s/iter. Eval: 0.0008 s/iter. Total: 1.0818 s/iter. ETA=1:28:49
[02/05 00:14:37] d2.evaluation.evaluator INFO: Inference done 31/4952. Dataloading: 0.0006 s/iter. Inference: 1.0815 s/iter. Eval: 0.0008 s/iter. Total: 1.0829 s/iter. ETA=1:28:49
[02/05 00:14:42] d2.evaluation.evaluator INFO: Inference done 36/4952. Dataloading: 0.0006 s/iter. Inference: 1.0832 s/iter. Eval: 0.0008 s/iter. Total: 1.0846 s/iter. ETA=1:28:51
[02/05 00:14:48] d2.evaluation.evaluator INFO: Inference done 41/4952. Dataloading: 0.0006 s/iter. Inference: 1.0828 s/iter. Eval: 0.0008 s/iter. Total: 1.0843 s/iter. ETA=1:28:44
[02/05 00:14:53] d2.evaluation.evaluator INFO: Inference done 46/4952. Dataloading: 0.0006 s/iter. Inference: 1.0848 s/iter. Eval: 0.0008 s/iter. Total: 1.0862 s/iter. ETA=1:28:49
[02/05 00:14:59] d2.evaluation.evaluator INFO: Inference done 51/4952. Dataloading: 0.0006 s/iter. Inference: 1.0861 s/iter. Eval: 0.0008 s/iter. Total: 1.0876 s/iter. ETA=1:28:50
[02/05 00:15:04] d2.evaluation.evaluator INFO: Inference done 56/4952. Dataloading: 0.0006 s/iter. Inference: 1.0870 s/iter. Eval: 0.0008 s/iter. Total: 1.0885 s/iter. ETA=1:28:49
[02/05 00:15:10] d2.evaluation.evaluator INFO: Inference done 61/4952. Dataloading: 0.0006 s/iter. Inference: 1.0873 s/iter. Eval: 0.0008 s/iter. Total: 1.0888 s/iter. ETA=1:28:45
[02/05 00:15:15] d2.evaluation.evaluator INFO: Inference done 66/4952. Dataloading: 0.0007 s/iter. Inference: 1.0858 s/iter. Eval: 0.0008 s/iter. Total: 1.0873 s/iter. ETA=1:28:32
[02/05 00:15:21] d2.evaluation.evaluator INFO: Inference done 71/4952. Dataloading: 0.0007 s/iter. Inference: 1.0856 s/iter. Eval: 0.0008 s/iter. Total: 1.0871 s/iter. ETA=1:28:26
[02/05 00:15:26] d2.evaluation.evaluator INFO: Inference done 76/4952. Dataloading: 0.0007 s/iter. Inference: 1.0864 s/iter. Eval: 0.0008 s/iter. Total: 1.0879 s/iter. ETA=1:28:24
[02/05 00:15:32] d2.evaluation.evaluator INFO: Inference done 81/4952. Dataloading: 0.0007 s/iter. Inference: 1.0869 s/iter. Eval: 0.0008 s/iter. Total: 1.0884 s/iter. ETA=1:28:21
[02/05 00:15:37] d2.evaluation.evaluator INFO: Inference done 86/4952. Dataloading: 0.0007 s/iter. Inference: 1.0872 s/iter. Eval: 0.0008 s/iter. Total: 1.0888 s/iter. ETA=1:28:17
[02/05 00:15:42] d2.evaluation.evaluator INFO: Inference done 91/4952. Dataloading: 0.0007 s/iter. Inference: 1.0869 s/iter. Eval: 0.0008 s/iter. Total: 1.0884 s/iter. ETA=1:28:10
[02/05 00:15:48] d2.evaluation.evaluator INFO: Inference done 96/4952. Dataloading: 0.0007 s/iter. Inference: 1.0866 s/iter. Eval: 0.0008 s/iter. Total: 1.0881 s/iter. ETA=1:28:03
[02/05 00:15:53] d2.evaluation.evaluator INFO: Inference done 101/4952. Dataloading: 0.0007 s/iter. Inference: 1.0869 s/iter. Eval: 0.0008 s/iter. Total: 1.0884 s/iter. ETA=1:28:00
[02/05 00:15:59] d2.evaluation.evaluator INFO: Inference done 106/4952. Dataloading: 0.0007 s/iter. Inference: 1.0867 s/iter. Eval: 0.0008 s/iter. Total: 1.0883 s/iter. ETA=1:27:53
[02/05 00:16:04] d2.evaluation.evaluator INFO: Inference done 111/4952. Dataloading: 0.0007 s/iter. Inference: 1.0872 s/iter. Eval: 0.0008 s/iter. Total: 1.0887 s/iter. ETA=1:27:50
[02/05 00:16:10] d2.evaluation.evaluator INFO: Inference done 116/4952. Dataloading: 0.0007 s/iter. Inference: 1.0869 s/iter. Eval: 0.0008 s/iter. Total: 1.0884 s/iter. ETA=1:27:43
[02/05 00:16:15] d2.evaluation.evaluator INFO: Inference done 121/4952. Dataloading: 0.0007 s/iter. Inference: 1.0873 s/iter. Eval: 0.0008 s/iter. Total: 1.0888 s/iter. ETA=1:27:39
[02/05 00:16:21] d2.evaluation.evaluator INFO: Inference done 126/4952. Dataloading: 0.0007 s/iter. Inference: 1.0885 s/iter. Eval: 0.0008 s/iter. Total: 1.0900 s/iter. ETA=1:27:40
[02/05 00:16:26] d2.evaluation.evaluator INFO: Inference done 131/4952. Dataloading: 0.0007 s/iter. Inference: 1.0889 s/iter. Eval: 0.0008 s/iter. Total: 1.0904 s/iter. ETA=1:27:37
[02/05 00:16:32] d2.evaluation.evaluator INFO: Inference done 136/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:27:34
[02/05 00:16:37] d2.evaluation.evaluator INFO: Inference done 141/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:27:26
[02/05 00:16:43] d2.evaluation.evaluator INFO: Inference done 146/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:27:21
[02/05 00:16:48] d2.evaluation.evaluator INFO: Inference done 151/4952. Dataloading: 0.0007 s/iter. Inference: 1.0886 s/iter. Eval: 0.0008 s/iter. Total: 1.0902 s/iter. ETA=1:27:13
[02/05 00:16:53] d2.evaluation.evaluator INFO: Inference done 156/4952. Dataloading: 0.0007 s/iter. Inference: 1.0883 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:27:06
[02/05 00:16:59] d2.evaluation.evaluator INFO: Inference done 161/4952. Dataloading: 0.0007 s/iter. Inference: 1.0884 s/iter. Eval: 0.0008 s/iter. Total: 1.0900 s/iter. ETA=1:27:02
[02/05 00:17:04] d2.evaluation.evaluator INFO: Inference done 166/4952. Dataloading: 0.0007 s/iter. Inference: 1.0884 s/iter. Eval: 0.0008 s/iter. Total: 1.0900 s/iter. ETA=1:26:56
[02/05 00:17:10] d2.evaluation.evaluator INFO: Inference done 171/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0897 s/iter. ETA=1:26:50
[02/05 00:17:15] d2.evaluation.evaluator INFO: Inference done 176/4952. Dataloading: 0.0007 s/iter. Inference: 1.0888 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:26:47
[02/05 00:17:21] d2.evaluation.evaluator INFO: Inference done 181/4952. Dataloading: 0.0007 s/iter. Inference: 1.0887 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:26:41
[02/05 00:17:26] d2.evaluation.evaluator INFO: Inference done 186/4952. Dataloading: 0.0007 s/iter. Inference: 1.0885 s/iter. Eval: 0.0008 s/iter. Total: 1.0901 s/iter. ETA=1:26:35
[02/05 00:17:32] d2.evaluation.evaluator INFO: Inference done 191/4952. Dataloading: 0.0007 s/iter. Inference: 1.0889 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:26:31
[02/05 00:17:37] d2.evaluation.evaluator INFO: Inference done 196/4952. Dataloading: 0.0007 s/iter. Inference: 1.0889 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:26:26
[02/05 00:17:43] d2.evaluation.evaluator INFO: Inference done 201/4952. Dataloading: 0.0007 s/iter. Inference: 1.0889 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:26:20
[02/05 00:17:48] d2.evaluation.evaluator INFO: Inference done 206/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:26:15
[02/05 00:17:53] d2.evaluation.evaluator INFO: Inference done 211/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:26:11
[02/05 00:17:59] d2.evaluation.evaluator INFO: Inference done 216/4952. Dataloading: 0.0007 s/iter. Inference: 1.0887 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:26:03
[02/05 00:18:04] d2.evaluation.evaluator INFO: Inference done 221/4952. Dataloading: 0.0007 s/iter. Inference: 1.0886 s/iter. Eval: 0.0008 s/iter. Total: 1.0902 s/iter. ETA=1:25:57
[02/05 00:18:10] d2.evaluation.evaluator INFO: Inference done 226/4952. Dataloading: 0.0007 s/iter. Inference: 1.0888 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:25:52
[02/05 00:18:15] d2.evaluation.evaluator INFO: Inference done 231/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:25:49
[02/05 00:18:21] d2.evaluation.evaluator INFO: Inference done 236/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:25:45
[02/05 00:18:26] d2.evaluation.evaluator INFO: Inference done 241/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:25:38
[02/05 00:18:32] d2.evaluation.evaluator INFO: Inference done 246/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:25:33
[02/05 00:18:37] d2.evaluation.evaluator INFO: Inference done 251/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:25:28
[02/05 00:18:43] d2.evaluation.evaluator INFO: Inference done 256/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:25:21
[02/05 00:18:48] d2.evaluation.evaluator INFO: Inference done 261/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:25:15
[02/05 00:18:53] d2.evaluation.evaluator INFO: Inference done 266/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:25:10
[02/05 00:18:59] d2.evaluation.evaluator INFO: Inference done 271/4952. Dataloading: 0.0007 s/iter. Inference: 1.0885 s/iter. Eval: 0.0008 s/iter. Total: 1.0900 s/iter. ETA=1:25:02
[02/05 00:19:04] d2.evaluation.evaluator INFO: Inference done 276/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:24:55
[02/05 00:19:10] d2.evaluation.evaluator INFO: Inference done 281/4952. Dataloading: 0.0007 s/iter. Inference: 1.0883 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:24:50
[02/05 00:19:15] d2.evaluation.evaluator INFO: Inference done 286/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:24:44
[02/05 00:19:20] d2.evaluation.evaluator INFO: Inference done 291/4952. Dataloading: 0.0007 s/iter. Inference: 1.0881 s/iter. Eval: 0.0008 s/iter. Total: 1.0896 s/iter. ETA=1:24:38
[02/05 00:19:26] d2.evaluation.evaluator INFO: Inference done 296/4952. Dataloading: 0.0007 s/iter. Inference: 1.0881 s/iter. Eval: 0.0008 s/iter. Total: 1.0896 s/iter. ETA=1:24:33
[02/05 00:19:31] d2.evaluation.evaluator INFO: Inference done 301/4952. Dataloading: 0.0007 s/iter. Inference: 1.0881 s/iter. Eval: 0.0008 s/iter. Total: 1.0896 s/iter. ETA=1:24:27
[02/05 00:19:37] d2.evaluation.evaluator INFO: Inference done 306/4952. Dataloading: 0.0007 s/iter. Inference: 1.0881 s/iter. Eval: 0.0008 s/iter. Total: 1.0897 s/iter. ETA=1:24:22
[02/05 00:19:42] d2.evaluation.evaluator INFO: Inference done 311/4952. Dataloading: 0.0007 s/iter. Inference: 1.0883 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:24:17
[02/05 00:19:48] d2.evaluation.evaluator INFO: Inference done 316/4952. Dataloading: 0.0007 s/iter. Inference: 1.0880 s/iter. Eval: 0.0008 s/iter. Total: 1.0896 s/iter. ETA=1:24:11
[02/05 00:19:53] d2.evaluation.evaluator INFO: Inference done 321/4952. Dataloading: 0.0007 s/iter. Inference: 1.0883 s/iter. Eval: 0.0008 s/iter. Total: 1.0899 s/iter. ETA=1:24:07
[02/05 00:19:59] d2.evaluation.evaluator INFO: Inference done 326/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:24:01
[02/05 00:20:04] d2.evaluation.evaluator INFO: Inference done 331/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0897 s/iter. ETA=1:23:55
[02/05 00:20:09] d2.evaluation.evaluator INFO: Inference done 336/4952. Dataloading: 0.0007 s/iter. Inference: 1.0880 s/iter. Eval: 0.0008 s/iter. Total: 1.0895 s/iter. ETA=1:23:49
[02/05 00:20:15] d2.evaluation.evaluator INFO: Inference done 341/4952. Dataloading: 0.0007 s/iter. Inference: 1.0878 s/iter. Eval: 0.0008 s/iter. Total: 1.0893 s/iter. ETA=1:23:42
[02/05 00:20:20] d2.evaluation.evaluator INFO: Inference done 346/4952. Dataloading: 0.0007 s/iter. Inference: 1.0878 s/iter. Eval: 0.0008 s/iter. Total: 1.0894 s/iter. ETA=1:23:37
[02/05 00:20:26] d2.evaluation.evaluator INFO: Inference done 351/4952. Dataloading: 0.0007 s/iter. Inference: 1.0878 s/iter. Eval: 0.0008 s/iter. Total: 1.0894 s/iter. ETA=1:23:32
[02/05 00:20:31] d2.evaluation.evaluator INFO: Inference done 356/4952. Dataloading: 0.0007 s/iter. Inference: 1.0881 s/iter. Eval: 0.0008 s/iter. Total: 1.0897 s/iter. ETA=1:23:28
[02/05 00:20:37] d2.evaluation.evaluator INFO: Inference done 361/4952. Dataloading: 0.0007 s/iter. Inference: 1.0883 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:23:23
[02/05 00:20:42] d2.evaluation.evaluator INFO: Inference done 366/4952. Dataloading: 0.0007 s/iter. Inference: 1.0883 s/iter. Eval: 0.0008 s/iter. Total: 1.0899 s/iter. ETA=1:23:18
[02/05 00:20:48] d2.evaluation.evaluator INFO: Inference done 371/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0897 s/iter. ETA=1:23:12
[02/05 00:20:53] d2.evaluation.evaluator INFO: Inference done 376/4952. Dataloading: 0.0007 s/iter. Inference: 1.0882 s/iter. Eval: 0.0008 s/iter. Total: 1.0898 s/iter. ETA=1:23:06
[02/05 00:20:59] d2.evaluation.evaluator INFO: Inference done 381/4952. Dataloading: 0.0007 s/iter. Inference: 1.0888 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:23:03
[02/05 00:21:04] d2.evaluation.evaluator INFO: Inference done 386/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:22:59
[02/05 00:21:10] d2.evaluation.evaluator INFO: Inference done 391/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:22:54
[02/05 00:21:15] d2.evaluation.evaluator INFO: Inference done 396/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:22:48
[02/05 00:21:21] d2.evaluation.evaluator INFO: Inference done 401/4952. Dataloading: 0.0007 s/iter. Inference: 1.0888 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:22:42
[02/05 00:21:26] d2.evaluation.evaluator INFO: Inference done 406/4952. Dataloading: 0.0007 s/iter. Inference: 1.0888 s/iter. Eval: 0.0008 s/iter. Total: 1.0903 s/iter. ETA=1:22:36
[02/05 00:21:32] d2.evaluation.evaluator INFO: Inference done 411/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0905 s/iter. ETA=1:22:32
[02/05 00:21:37] d2.evaluation.evaluator INFO: Inference done 416/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:22:26
[02/05 00:21:43] d2.evaluation.evaluator INFO: Inference done 421/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:22:21
[02/05 00:21:48] d2.evaluation.evaluator INFO: Inference done 426/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:22:17
[02/05 00:21:53] d2.evaluation.evaluator INFO: Inference done 431/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:22:11
[02/05 00:21:59] d2.evaluation.evaluator INFO: Inference done 436/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:22:06
[02/05 00:22:04] d2.evaluation.evaluator INFO: Inference done 441/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:22:01
[02/05 00:22:10] d2.evaluation.evaluator INFO: Inference done 446/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:21:56
[02/05 00:22:15] d2.evaluation.evaluator INFO: Inference done 451/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:21:51
[02/05 00:22:21] d2.evaluation.evaluator INFO: Inference done 456/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:21:45
[02/05 00:22:26] d2.evaluation.evaluator INFO: Inference done 461/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:21:39
[02/05 00:22:32] d2.evaluation.evaluator INFO: Inference done 466/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:21:34
[02/05 00:22:37] d2.evaluation.evaluator INFO: Inference done 471/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:21:28
[02/05 00:22:43] d2.evaluation.evaluator INFO: Inference done 476/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:21:22
[02/05 00:22:48] d2.evaluation.evaluator INFO: Inference done 481/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:21:17
[02/05 00:22:53] d2.evaluation.evaluator INFO: Inference done 486/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:21:11
[02/05 00:22:59] d2.evaluation.evaluator INFO: Inference done 491/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:21:05
[02/05 00:23:04] d2.evaluation.evaluator INFO: Inference done 496/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:21:00
[02/05 00:23:10] d2.evaluation.evaluator INFO: Inference done 501/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:20:54
[02/05 00:23:15] d2.evaluation.evaluator INFO: Inference done 506/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:20:49
[02/05 00:23:21] d2.evaluation.evaluator INFO: Inference done 511/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:20:44
[02/05 00:23:26] d2.evaluation.evaluator INFO: Inference done 516/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:20:38
[02/05 00:23:32] d2.evaluation.evaluator INFO: Inference done 521/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:20:33
[02/05 00:23:37] d2.evaluation.evaluator INFO: Inference done 526/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:20:27
[02/05 00:23:43] d2.evaluation.evaluator INFO: Inference done 531/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:20:22
[02/05 00:23:48] d2.evaluation.evaluator INFO: Inference done 536/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:20:17
[02/05 00:23:53] d2.evaluation.evaluator INFO: Inference done 541/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:20:11
[02/05 00:23:59] d2.evaluation.evaluator INFO: Inference done 546/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:20:05
[02/05 00:24:04] d2.evaluation.evaluator INFO: Inference done 551/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:19:59
[02/05 00:24:10] d2.evaluation.evaluator INFO: Inference done 556/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:19:54
[02/05 00:24:15] d2.evaluation.evaluator INFO: Inference done 561/4952. Dataloading: 0.0007 s/iter. Inference: 1.0890 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:19:48
[02/05 00:24:21] d2.evaluation.evaluator INFO: Inference done 566/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:19:43
[02/05 00:24:26] d2.evaluation.evaluator INFO: Inference done 571/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:19:39
[02/05 00:24:32] d2.evaluation.evaluator INFO: Inference done 576/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:19:34
[02/05 00:24:37] d2.evaluation.evaluator INFO: Inference done 581/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:19:27
[02/05 00:24:43] d2.evaluation.evaluator INFO: Inference done 586/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:19:22
[02/05 00:24:48] d2.evaluation.evaluator INFO: Inference done 591/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:19:17
[02/05 00:24:54] d2.evaluation.evaluator INFO: Inference done 596/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:19:12
[02/05 00:24:59] d2.evaluation.evaluator INFO: Inference done 601/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:19:06
[02/05 00:25:04] d2.evaluation.evaluator INFO: Inference done 606/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:19:01
[02/05 00:25:10] d2.evaluation.evaluator INFO: Inference done 611/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:18:55
[02/05 00:25:15] d2.evaluation.evaluator INFO: Inference done 616/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:18:49
[02/05 00:25:21] d2.evaluation.evaluator INFO: Inference done 621/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:18:44
[02/05 00:25:26] d2.evaluation.evaluator INFO: Inference done 626/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:18:39
[02/05 00:25:32] d2.evaluation.evaluator INFO: Inference done 631/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:18:33
[02/05 00:25:37] d2.evaluation.evaluator INFO: Inference done 636/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:18:27
[02/05 00:25:42] d2.evaluation.evaluator INFO: Inference done 641/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:18:21
[02/05 00:25:48] d2.evaluation.evaluator INFO: Inference done 646/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:18:16
[02/05 00:25:53] d2.evaluation.evaluator INFO: Inference done 651/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:18:10
[02/05 00:25:59] d2.evaluation.evaluator INFO: Inference done 656/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:18:05
[02/05 00:26:04] d2.evaluation.evaluator INFO: Inference done 661/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0906 s/iter. ETA=1:17:59
[02/05 00:26:10] d2.evaluation.evaluator INFO: Inference done 666/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:17:54
[02/05 00:26:15] d2.evaluation.evaluator INFO: Inference done 671/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:17:49
[02/05 00:26:21] d2.evaluation.evaluator INFO: Inference done 676/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:17:43
[02/05 00:26:26] d2.evaluation.evaluator INFO: Inference done 681/4952. Dataloading: 0.0007 s/iter. Inference: 1.0891 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:17:38
[02/05 00:26:32] d2.evaluation.evaluator INFO: Inference done 686/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0907 s/iter. ETA=1:17:32
[02/05 00:26:37] d2.evaluation.evaluator INFO: Inference done 691/4952. Dataloading: 0.0007 s/iter. Inference: 1.0892 s/iter. Eval: 0.0008 s/iter. Total: 1.0908 s/iter. ETA=1:17:27
[02/05 00:26:43] d2.evaluation.evaluator INFO: Inference done 696/4952. Dataloading: 0.0007 s/iter. Inference: 1.0893 s/iter. Eval: 0.0008 s/iter. Total: 1.0909 s/iter. ETA=1:17:22
[02/05 00:26:48] d2.evaluation.evaluator INFO: Inference done 701/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:17:17
[02/05 00:26:54] d2.evaluation.evaluator INFO: Inference done 706/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:17:12
[02/05 00:26:59] d2.evaluation.evaluator INFO: Inference done 711/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:17:07
[02/05 00:27:05] d2.evaluation.evaluator INFO: Inference done 716/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:17:02
[02/05 00:27:10] d2.evaluation.evaluator INFO: Inference done 721/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:57
[02/05 00:27:16] d2.evaluation.evaluator INFO: Inference done 726/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:51
[02/05 00:27:21] d2.evaluation.evaluator INFO: Inference done 731/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:46
[02/05 00:27:27] d2.evaluation.evaluator INFO: Inference done 736/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:16:41
[02/05 00:27:32] d2.evaluation.evaluator INFO: Inference done 741/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:35
[02/05 00:27:37] d2.evaluation.evaluator INFO: Inference done 746/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:30
[02/05 00:27:43] d2.evaluation.evaluator INFO: Inference done 751/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:24
[02/05 00:27:48] d2.evaluation.evaluator INFO: Inference done 756/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:19
[02/05 00:27:54] d2.evaluation.evaluator INFO: Inference done 761/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:16:13
[02/05 00:27:59] d2.evaluation.evaluator INFO: Inference done 766/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:16:08
[02/05 00:28:05] d2.evaluation.evaluator INFO: Inference done 771/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:16:03
[02/05 00:28:10] d2.evaluation.evaluator INFO: Inference done 776/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:15:57
[02/05 00:28:16] d2.evaluation.evaluator INFO: Inference done 781/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:15:51
[02/05 00:28:21] d2.evaluation.evaluator INFO: Inference done 786/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:15:46
[02/05 00:28:26] d2.evaluation.evaluator INFO: Inference done 791/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:15:40
[02/05 00:28:32] d2.evaluation.evaluator INFO: Inference done 796/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:15:34
[02/05 00:28:37] d2.evaluation.evaluator INFO: Inference done 801/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:15:29
[02/05 00:28:43] d2.evaluation.evaluator INFO: Inference done 806/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:15:23
[02/05 00:28:48] d2.evaluation.evaluator INFO: Inference done 811/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:15:17
[02/05 00:28:54] d2.evaluation.evaluator INFO: Inference done 816/4952. Dataloading: 0.0007 s/iter. Inference: 1.0894 s/iter. Eval: 0.0008 s/iter. Total: 1.0910 s/iter. ETA=1:15:12
[02/05 00:28:59] d2.evaluation.evaluator INFO: Inference done 821/4952. Dataloading: 0.0007 s/iter. Inference: 1.0895 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:15:07
[02/05 00:29:05] d2.evaluation.evaluator INFO: Inference done 826/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:15:02
[02/05 00:29:10] d2.evaluation.evaluator INFO: Inference done 831/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:14:56
[02/05 00:29:16] d2.evaluation.evaluator INFO: Inference done 836/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:14:51
[02/05 00:29:21] d2.evaluation.evaluator INFO: Inference done 841/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:14:45
[02/05 00:29:26] d2.evaluation.evaluator INFO: Inference done 846/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:14:40
[02/05 00:29:32] d2.evaluation.evaluator INFO: Inference done 851/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:14:34
[02/05 00:29:37] d2.evaluation.evaluator INFO: Inference done 856/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:14:29
[02/05 00:29:43] d2.evaluation.evaluator INFO: Inference done 861/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:14:24
[02/05 00:29:48] d2.evaluation.evaluator INFO: Inference done 866/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:14:19
[02/05 00:29:54] d2.evaluation.evaluator INFO: Inference done 871/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:14:13
[02/05 00:29:59] d2.evaluation.evaluator INFO: Inference done 876/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0914 s/iter. ETA=1:14:08
[02/05 00:30:05] d2.evaluation.evaluator INFO: Inference done 881/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:14:02
[02/05 00:30:10] d2.evaluation.evaluator INFO: Inference done 886/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:13:57
[02/05 00:30:16] d2.evaluation.evaluator INFO: Inference done 891/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:13:51
[02/05 00:30:21] d2.evaluation.evaluator INFO: Inference done 896/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:13:46
[02/05 00:30:27] d2.evaluation.evaluator INFO: Inference done 901/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:13:40
[02/05 00:30:32] d2.evaluation.evaluator INFO: Inference done 906/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0911 s/iter. ETA=1:13:34
[02/05 00:30:37] d2.evaluation.evaluator INFO: Inference done 911/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:13:29
[02/05 00:30:43] d2.evaluation.evaluator INFO: Inference done 916/4952. Dataloading: 0.0007 s/iter. Inference: 1.0896 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:13:24
[02/05 00:30:48] d2.evaluation.evaluator INFO: Inference done 921/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0912 s/iter. ETA=1:13:18
[02/05 00:30:54] d2.evaluation.evaluator INFO: Inference done 926/4952. Dataloading: 0.0007 s/iter. Inference: 1.0897 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:13:13
[02/05 00:30:59] d2.evaluation.evaluator INFO: Inference done 931/4952. Dataloading: 0.0007 s/iter. Inference: 1.0898 s/iter. Eval: 0.0008 s/iter. Total: 1.0913 s/iter. ETA=1:13:08
[02/05 00:31:05] d2.evaluation.evaluator INFO: Inference done 936/4952. Dataloading: 0.0007 s/iter. Inference: 1.0899 s/iter. Eval: 0.0008 s/iter. Total: 1.0915 s/iter. ETA=1:13:03
[02/05 00:31:10] d2.evaluation.evaluator INFO: Inference done 941/4952. Dataloading: 0.0007 s/iter. Inference: 1.0899 s/iter. Eval: 0.0008 s/iter. Total: 1.0915 s/iter. ETA=1:12:57
[02/05 00:31:16] d2.evaluation.evaluator INFO: Inference done 946/4952. Dataloading: 0.0007 s/iter. Inference: 1.0900 s/iter. Eval: 0.0008 s/iter. Total: 1.0915 s/iter. ETA=1:12:52
[02/05 00:31:21] d2.evaluation.evaluator INFO: Inference done 951/4952. Dataloading: 0.0007 s/iter. Inference: 1.0900 s/iter. Eval: 0.0008 s/iter. Total: 1.0915 s/iter. ETA=1:12:47
[02/05 00:31:27] d2.evaluation.evaluator INFO: Inference done 956/4952. Dataloading: 0.0007 s/iter. Inference: 1.0900 s/iter. Eval: 0.0008 s/iter. Total: 1.0915 s/iter. ETA=1:12:41
[02/05 00:31:32] d2.evaluation.evaluator INFO: Inference done 961/4952. Dataloading: 0.0007 s/iter. Inference: 1.0899 s/iter. Eval: 0.0008 s/iter. Total: 1.0915 s/iter. ETA=1:12:36
[02/05 00:31:38] d2.evaluation.evaluator INFO: Inference done 966/4952. Dataloading: 0.0007 s/iter. Inference: 1.0901 s/iter. Eval: 0.0008 s/iter. Total: 1.0917 s/iter. ETA=1:12:31
[02/05 00:31:43] d2.evaluation.evaluator INFO: Inference done 971/4952. Dataloading: 0.0007 s/iter. Inference: 1.0902 s/iter. Eval: 0.0008 s/iter. Total: 1.0918 s/iter. ETA=1:12:26
[02/05 00:31:49] d2.evaluation.evaluator INFO: Inference done 976/4952. Dataloading: 0.0007 s/iter. Inference: 1.0903 s/iter. Eval: 0.0008 s/iter. Total: 1.0918 s/iter. ETA=1:12:21
[02/05 00:31:55] d2.evaluation.evaluator INFO: Inference done 981/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:12:16
[02/05 00:32:00] d2.evaluation.evaluator INFO: Inference done 986/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:12:10
[02/05 00:32:05] d2.evaluation.evaluator INFO: Inference done 991/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:12:05
[02/05 00:32:11] d2.evaluation.evaluator INFO: Inference done 996/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:11:59
[02/05 00:32:16] d2.evaluation.evaluator INFO: Inference done 1001/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:11:54
[02/05 00:32:22] d2.evaluation.evaluator INFO: Inference done 1006/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:11:48
[02/05 00:32:27] d2.evaluation.evaluator INFO: Inference done 1011/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:11:43
[02/05 00:32:33] d2.evaluation.evaluator INFO: Inference done 1016/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:11:37
[02/05 00:32:38] d2.evaluation.evaluator INFO: Inference done 1021/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:11:32
[02/05 00:32:44] d2.evaluation.evaluator INFO: Inference done 1026/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:11:26
[02/05 00:32:49] d2.evaluation.evaluator INFO: Inference done 1031/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:11:21
[02/05 00:32:55] d2.evaluation.evaluator INFO: Inference done 1036/4952. Dataloading: 0.0007 s/iter. Inference: 1.0903 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:11:15
[02/05 00:33:00] d2.evaluation.evaluator INFO: Inference done 1041/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:11:10
[02/05 00:33:05] d2.evaluation.evaluator INFO: Inference done 1046/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:11:05
[02/05 00:33:11] d2.evaluation.evaluator INFO: Inference done 1051/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:10:59
[02/05 00:33:16] d2.evaluation.evaluator INFO: Inference done 1056/4952. Dataloading: 0.0007 s/iter. Inference: 1.0903 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:10:54
[02/05 00:33:22] d2.evaluation.evaluator INFO: Inference done 1061/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:10:48
[02/05 00:33:27] d2.evaluation.evaluator INFO: Inference done 1066/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:10:43
[02/05 00:33:33] d2.evaluation.evaluator INFO: Inference done 1071/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:10:38
[02/05 00:33:38] d2.evaluation.evaluator INFO: Inference done 1076/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:10:32
[02/05 00:33:44] d2.evaluation.evaluator INFO: Inference done 1081/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:10:27
[02/05 00:33:49] d2.evaluation.evaluator INFO: Inference done 1086/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:10:21
[02/05 00:33:55] d2.evaluation.evaluator INFO: Inference done 1091/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:10:16
[02/05 00:34:00] d2.evaluation.evaluator INFO: Inference done 1096/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:10:11
[02/05 00:34:06] d2.evaluation.evaluator INFO: Inference done 1101/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:10:05
[02/05 00:34:11] d2.evaluation.evaluator INFO: Inference done 1106/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:10:00
[02/05 00:34:17] d2.evaluation.evaluator INFO: Inference done 1111/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:09:54
[02/05 00:34:22] d2.evaluation.evaluator INFO: Inference done 1116/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:09:48
[02/05 00:34:27] d2.evaluation.evaluator INFO: Inference done 1121/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:09:43
[02/05 00:34:33] d2.evaluation.evaluator INFO: Inference done 1126/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:09:38
[02/05 00:34:39] d2.evaluation.evaluator INFO: Inference done 1131/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:09:33
[02/05 00:34:44] d2.evaluation.evaluator INFO: Inference done 1136/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:09:27
[02/05 00:34:50] d2.evaluation.evaluator INFO: Inference done 1141/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:09:22
[02/05 00:34:55] d2.evaluation.evaluator INFO: Inference done 1146/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:09:16
[02/05 00:35:00] d2.evaluation.evaluator INFO: Inference done 1151/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:09:11
[02/05 00:35:06] d2.evaluation.evaluator INFO: Inference done 1156/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:09:06
[02/05 00:35:11] d2.evaluation.evaluator INFO: Inference done 1161/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:09:00
[02/05 00:35:17] d2.evaluation.evaluator INFO: Inference done 1166/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:08:54
[02/05 00:35:22] d2.evaluation.evaluator INFO: Inference done 1171/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:08:49
[02/05 00:35:28] d2.evaluation.evaluator INFO: Inference done 1176/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:08:43
[02/05 00:35:33] d2.evaluation.evaluator INFO: Inference done 1181/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:08:38
[02/05 00:35:39] d2.evaluation.evaluator INFO: Inference done 1186/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:08:32
[02/05 00:35:44] d2.evaluation.evaluator INFO: Inference done 1191/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:08:27
[02/05 00:35:50] d2.evaluation.evaluator INFO: Inference done 1196/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:08:22
[02/05 00:35:55] d2.evaluation.evaluator INFO: Inference done 1201/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:08:16
[02/05 00:36:01] d2.evaluation.evaluator INFO: Inference done 1206/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:08:11
[02/05 00:36:06] d2.evaluation.evaluator INFO: Inference done 1211/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:08:06
[02/05 00:36:12] d2.evaluation.evaluator INFO: Inference done 1216/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:08:00
[02/05 00:36:17] d2.evaluation.evaluator INFO: Inference done 1221/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:07:55
[02/05 00:36:22] d2.evaluation.evaluator INFO: Inference done 1226/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:07:49
[02/05 00:36:28] d2.evaluation.evaluator INFO: Inference done 1231/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:07:44
[02/05 00:36:33] d2.evaluation.evaluator INFO: Inference done 1236/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:07:38
[02/05 00:36:39] d2.evaluation.evaluator INFO: Inference done 1241/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:07:33
[02/05 00:36:44] d2.evaluation.evaluator INFO: Inference done 1246/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:07:27
[02/05 00:36:50] d2.evaluation.evaluator INFO: Inference done 1251/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:07:22
[02/05 00:36:55] d2.evaluation.evaluator INFO: Inference done 1256/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:07:17
[02/05 00:37:01] d2.evaluation.evaluator INFO: Inference done 1261/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:07:11
[02/05 00:37:06] d2.evaluation.evaluator INFO: Inference done 1266/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:07:06
[02/05 00:37:12] d2.evaluation.evaluator INFO: Inference done 1271/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:07:01
[02/05 00:37:17] d2.evaluation.evaluator INFO: Inference done 1276/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:06:55
[02/05 00:37:23] d2.evaluation.evaluator INFO: Inference done 1281/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:06:50
[02/05 00:37:28] d2.evaluation.evaluator INFO: Inference done 1286/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:06:44
[02/05 00:37:33] d2.evaluation.evaluator INFO: Inference done 1291/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:06:38
[02/05 00:37:39] d2.evaluation.evaluator INFO: Inference done 1296/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:06:33
[02/05 00:37:44] d2.evaluation.evaluator INFO: Inference done 1301/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:06:27
[02/05 00:37:50] d2.evaluation.evaluator INFO: Inference done 1306/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:06:22
[02/05 00:37:55] d2.evaluation.evaluator INFO: Inference done 1311/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:06:16
[02/05 00:38:01] d2.evaluation.evaluator INFO: Inference done 1316/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:06:11
[02/05 00:38:06] d2.evaluation.evaluator INFO: Inference done 1321/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:06:05
[02/05 00:38:12] d2.evaluation.evaluator INFO: Inference done 1326/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:06:00
[02/05 00:38:17] d2.evaluation.evaluator INFO: Inference done 1331/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:05:54
[02/05 00:38:22] d2.evaluation.evaluator INFO: Inference done 1336/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:05:49
[02/05 00:38:28] d2.evaluation.evaluator INFO: Inference done 1341/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:05:43
[02/05 00:38:33] d2.evaluation.evaluator INFO: Inference done 1346/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:05:38
[02/05 00:38:39] d2.evaluation.evaluator INFO: Inference done 1351/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:05:32
[02/05 00:38:44] d2.evaluation.evaluator INFO: Inference done 1356/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:05:26
[02/05 00:38:50] d2.evaluation.evaluator INFO: Inference done 1361/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:05:21
[02/05 00:38:55] d2.evaluation.evaluator INFO: Inference done 1366/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:05:16
[02/05 00:39:00] d2.evaluation.evaluator INFO: Inference done 1371/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0919 s/iter. ETA=1:05:10
[02/05 00:39:06] d2.evaluation.evaluator INFO: Inference done 1376/4952. Dataloading: 0.0007 s/iter. Inference: 1.0904 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:05:04
[02/05 00:39:11] d2.evaluation.evaluator INFO: Inference done 1381/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:04:59
[02/05 00:39:17] d2.evaluation.evaluator INFO: Inference done 1386/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0920 s/iter. ETA=1:04:54
[02/05 00:39:22] d2.evaluation.evaluator INFO: Inference done 1391/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:04:48
[02/05 00:39:28] d2.evaluation.evaluator INFO: Inference done 1396/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:04:43
[02/05 00:39:33] d2.evaluation.evaluator INFO: Inference done 1401/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:04:38
[02/05 00:39:39] d2.evaluation.evaluator INFO: Inference done 1406/4952. Dataloading: 0.0007 s/iter. Inference: 1.0905 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:04:32
[02/05 00:39:44] d2.evaluation.evaluator INFO: Inference done 1411/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:04:27
[02/05 00:39:50] d2.evaluation.evaluator INFO: Inference done 1416/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:04:21
[02/05 00:39:55] d2.evaluation.evaluator INFO: Inference done 1421/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:04:16
[02/05 00:40:01] d2.evaluation.evaluator INFO: Inference done 1426/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:04:11
[02/05 00:40:06] d2.evaluation.evaluator INFO: Inference done 1431/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:04:05
[02/05 00:40:12] d2.evaluation.evaluator INFO: Inference done 1436/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:04:00
[02/05 00:40:17] d2.evaluation.evaluator INFO: Inference done 1441/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:03:54
[02/05 00:40:23] d2.evaluation.evaluator INFO: Inference done 1446/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:03:49
[02/05 00:40:28] d2.evaluation.evaluator INFO: Inference done 1451/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0921 s/iter. ETA=1:03:43
[02/05 00:40:34] d2.evaluation.evaluator INFO: Inference done 1456/4952. Dataloading: 0.0007 s/iter. Inference: 1.0906 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:03:38
[02/05 00:40:39] d2.evaluation.evaluator INFO: Inference done 1461/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:03:32
[02/05 00:40:45] d2.evaluation.evaluator INFO: Inference done 1466/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:03:27
[02/05 00:40:50] d2.evaluation.evaluator INFO: Inference done 1471/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:03:22
[02/05 00:40:56] d2.evaluation.evaluator INFO: Inference done 1476/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:03:16
[02/05 00:41:01] d2.evaluation.evaluator INFO: Inference done 1481/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:03:11
[02/05 00:41:06] d2.evaluation.evaluator INFO: Inference done 1486/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:03:05
[02/05 00:41:12] d2.evaluation.evaluator INFO: Inference done 1491/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:03:00
[02/05 00:41:17] d2.evaluation.evaluator INFO: Inference done 1496/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:54
[02/05 00:41:23] d2.evaluation.evaluator INFO: Inference done 1501/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:49
[02/05 00:41:28] d2.evaluation.evaluator INFO: Inference done 1506/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:02:43
[02/05 00:41:34] d2.evaluation.evaluator INFO: Inference done 1511/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:02:38
[02/05 00:41:39] d2.evaluation.evaluator INFO: Inference done 1516/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=1:02:32
[02/05 00:41:45] d2.evaluation.evaluator INFO: Inference done 1521/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:27
[02/05 00:41:50] d2.evaluation.evaluator INFO: Inference done 1526/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:22
[02/05 00:41:56] d2.evaluation.evaluator INFO: Inference done 1531/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:16
[02/05 00:42:01] d2.evaluation.evaluator INFO: Inference done 1536/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:11
[02/05 00:42:07] d2.evaluation.evaluator INFO: Inference done 1541/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:05
[02/05 00:42:12] d2.evaluation.evaluator INFO: Inference done 1546/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:02:00
[02/05 00:42:17] d2.evaluation.evaluator INFO: Inference done 1551/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:01:54
[02/05 00:42:23] d2.evaluation.evaluator INFO: Inference done 1556/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:01:49
[02/05 00:42:28] d2.evaluation.evaluator INFO: Inference done 1561/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:01:43
[02/05 00:42:34] d2.evaluation.evaluator INFO: Inference done 1566/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=1:01:38
[02/05 00:42:39] d2.evaluation.evaluator INFO: Inference done 1571/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:01:33
[02/05 00:42:45] d2.evaluation.evaluator INFO: Inference done 1576/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:01:27
[02/05 00:42:50] d2.evaluation.evaluator INFO: Inference done 1581/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=1:01:22
[02/05 00:42:56] d2.evaluation.evaluator INFO: Inference done 1586/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=1:01:17
[02/05 00:43:02] d2.evaluation.evaluator INFO: Inference done 1591/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:01:12
[02/05 00:43:07] d2.evaluation.evaluator INFO: Inference done 1596/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:01:06
[02/05 00:43:13] d2.evaluation.evaluator INFO: Inference done 1601/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:01:01
[02/05 00:43:18] d2.evaluation.evaluator INFO: Inference done 1606/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=1:00:56
[02/05 00:43:24] d2.evaluation.evaluator INFO: Inference done 1611/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:00:50
[02/05 00:43:29] d2.evaluation.evaluator INFO: Inference done 1616/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:00:45
[02/05 00:43:35] d2.evaluation.evaluator INFO: Inference done 1621/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=1:00:39
[02/05 00:43:40] d2.evaluation.evaluator INFO: Inference done 1626/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=1:00:34
[02/05 00:43:45] d2.evaluation.evaluator INFO: Inference done 1631/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:00:28
[02/05 00:43:51] d2.evaluation.evaluator INFO: Inference done 1636/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:00:23
[02/05 00:43:56] d2.evaluation.evaluator INFO: Inference done 1641/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=1:00:17
[02/05 00:44:02] d2.evaluation.evaluator INFO: Inference done 1646/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=1:00:12
[02/05 00:44:07] d2.evaluation.evaluator INFO: Inference done 1651/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=1:00:06
[02/05 00:44:13] d2.evaluation.evaluator INFO: Inference done 1656/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=1:00:01
[02/05 00:44:18] d2.evaluation.evaluator INFO: Inference done 1661/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:59:55
[02/05 00:44:24] d2.evaluation.evaluator INFO: Inference done 1666/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:50
[02/05 00:44:29] d2.evaluation.evaluator INFO: Inference done 1671/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:45
[02/05 00:44:35] d2.evaluation.evaluator INFO: Inference done 1676/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:39
[02/05 00:44:40] d2.evaluation.evaluator INFO: Inference done 1681/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:34
[02/05 00:44:46] d2.evaluation.evaluator INFO: Inference done 1686/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:28
[02/05 00:44:51] d2.evaluation.evaluator INFO: Inference done 1691/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:23
[02/05 00:44:56] d2.evaluation.evaluator INFO: Inference done 1696/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:17
[02/05 00:45:02] d2.evaluation.evaluator INFO: Inference done 1701/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:59:12
[02/05 00:45:07] d2.evaluation.evaluator INFO: Inference done 1706/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:59:06
[02/05 00:45:13] d2.evaluation.evaluator INFO: Inference done 1711/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:59:01
[02/05 00:45:18] d2.evaluation.evaluator INFO: Inference done 1716/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:58:55
[02/05 00:45:24] d2.evaluation.evaluator INFO: Inference done 1721/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:58:50
[02/05 00:45:29] d2.evaluation.evaluator INFO: Inference done 1726/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:58:44
[02/05 00:45:35] d2.evaluation.evaluator INFO: Inference done 1731/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:58:39
[02/05 00:45:40] d2.evaluation.evaluator INFO: Inference done 1736/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:58:34
[02/05 00:45:46] d2.evaluation.evaluator INFO: Inference done 1741/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:58:28
[02/05 00:45:51] d2.evaluation.evaluator INFO: Inference done 1746/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:58:23
[02/05 00:45:57] d2.evaluation.evaluator INFO: Inference done 1751/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:58:17
[02/05 00:46:02] d2.evaluation.evaluator INFO: Inference done 1756/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:58:12
[02/05 00:46:07] d2.evaluation.evaluator INFO: Inference done 1761/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:58:06
[02/05 00:46:13] d2.evaluation.evaluator INFO: Inference done 1766/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:58:01
[02/05 00:46:18] d2.evaluation.evaluator INFO: Inference done 1771/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:57:55
[02/05 00:46:24] d2.evaluation.evaluator INFO: Inference done 1776/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:50
[02/05 00:46:29] d2.evaluation.evaluator INFO: Inference done 1781/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:44
[02/05 00:46:35] d2.evaluation.evaluator INFO: Inference done 1786/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:39
[02/05 00:46:40] d2.evaluation.evaluator INFO: Inference done 1791/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:33
[02/05 00:46:46] d2.evaluation.evaluator INFO: Inference done 1796/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:28
[02/05 00:46:51] d2.evaluation.evaluator INFO: Inference done 1801/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:57:22
[02/05 00:46:57] d2.evaluation.evaluator INFO: Inference done 1806/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:17
[02/05 00:47:02] d2.evaluation.evaluator INFO: Inference done 1811/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:57:11
[02/05 00:47:07] d2.evaluation.evaluator INFO: Inference done 1816/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:57:06
[02/05 00:47:13] d2.evaluation.evaluator INFO: Inference done 1821/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:57:00
[02/05 00:47:18] d2.evaluation.evaluator INFO: Inference done 1826/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:56:55
[02/05 00:47:24] d2.evaluation.evaluator INFO: Inference done 1831/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:56:49
[02/05 00:47:29] d2.evaluation.evaluator INFO: Inference done 1836/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:56:44
[02/05 00:47:35] d2.evaluation.evaluator INFO: Inference done 1841/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:56:38
[02/05 00:47:40] d2.evaluation.evaluator INFO: Inference done 1846/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:56:33
[02/05 00:47:45] d2.evaluation.evaluator INFO: Inference done 1851/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:56:27
[02/05 00:47:51] d2.evaluation.evaluator INFO: Inference done 1856/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:56:22
[02/05 00:47:56] d2.evaluation.evaluator INFO: Inference done 1861/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:56:16
[02/05 00:48:02] d2.evaluation.evaluator INFO: Inference done 1866/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:56:10
[02/05 00:48:07] d2.evaluation.evaluator INFO: Inference done 1871/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:56:05
[02/05 00:48:12] d2.evaluation.evaluator INFO: Inference done 1876/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:59
[02/05 00:48:18] d2.evaluation.evaluator INFO: Inference done 1881/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:54
[02/05 00:48:23] d2.evaluation.evaluator INFO: Inference done 1886/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:48
[02/05 00:48:29] d2.evaluation.evaluator INFO: Inference done 1891/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:43
[02/05 00:48:34] d2.evaluation.evaluator INFO: Inference done 1896/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:38
[02/05 00:48:40] d2.evaluation.evaluator INFO: Inference done 1901/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:32
[02/05 00:48:45] d2.evaluation.evaluator INFO: Inference done 1906/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:27
[02/05 00:48:51] d2.evaluation.evaluator INFO: Inference done 1911/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=0:55:21
[02/05 00:48:56] d2.evaluation.evaluator INFO: Inference done 1916/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=0:55:15
[02/05 00:49:02] d2.evaluation.evaluator INFO: Inference done 1921/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0922 s/iter. ETA=0:55:10
[02/05 00:49:07] d2.evaluation.evaluator INFO: Inference done 1926/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:55:05
[02/05 00:49:12] d2.evaluation.evaluator INFO: Inference done 1931/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:54:59
[02/05 00:49:18] d2.evaluation.evaluator INFO: Inference done 1936/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:54:54
[02/05 00:49:24] d2.evaluation.evaluator INFO: Inference done 1941/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:49
[02/05 00:49:29] d2.evaluation.evaluator INFO: Inference done 1946/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:43
[02/05 00:49:35] d2.evaluation.evaluator INFO: Inference done 1951/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:38
[02/05 00:49:40] d2.evaluation.evaluator INFO: Inference done 1956/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:32
[02/05 00:49:46] d2.evaluation.evaluator INFO: Inference done 1961/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:27
[02/05 00:49:51] d2.evaluation.evaluator INFO: Inference done 1966/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:21
[02/05 00:49:56] d2.evaluation.evaluator INFO: Inference done 1971/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:16
[02/05 00:50:02] d2.evaluation.evaluator INFO: Inference done 1976/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:10
[02/05 00:50:07] d2.evaluation.evaluator INFO: Inference done 1981/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:05
[02/05 00:50:13] d2.evaluation.evaluator INFO: Inference done 1986/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:54:00
[02/05 00:50:18] d2.evaluation.evaluator INFO: Inference done 1991/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:53:54
[02/05 00:50:24] d2.evaluation.evaluator INFO: Inference done 1996/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:53:49
[02/05 00:50:29] d2.evaluation.evaluator INFO: Inference done 2001/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:53:43
[02/05 00:50:35] d2.evaluation.evaluator INFO: Inference done 2006/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:53:37
[02/05 00:50:40] d2.evaluation.evaluator INFO: Inference done 2011/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:53:32
[02/05 00:50:45] d2.evaluation.evaluator INFO: Inference done 2016/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:53:27
[02/05 00:50:51] d2.evaluation.evaluator INFO: Inference done 2021/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:53:21
[02/05 00:50:56] d2.evaluation.evaluator INFO: Inference done 2026/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:53:16
[02/05 00:51:02] d2.evaluation.evaluator INFO: Inference done 2031/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:53:10
[02/05 00:51:07] d2.evaluation.evaluator INFO: Inference done 2036/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:53:05
[02/05 00:51:13] d2.evaluation.evaluator INFO: Inference done 2041/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:52:59
[02/05 00:51:18] d2.evaluation.evaluator INFO: Inference done 2046/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:54
[02/05 00:51:24] d2.evaluation.evaluator INFO: Inference done 2051/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:48
[02/05 00:51:29] d2.evaluation.evaluator INFO: Inference done 2056/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:43
[02/05 00:51:35] d2.evaluation.evaluator INFO: Inference done 2061/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:52:37
[02/05 00:51:40] d2.evaluation.evaluator INFO: Inference done 2066/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:32
[02/05 00:51:46] d2.evaluation.evaluator INFO: Inference done 2071/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:27
[02/05 00:51:51] d2.evaluation.evaluator INFO: Inference done 2076/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:21
[02/05 00:51:57] d2.evaluation.evaluator INFO: Inference done 2081/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:16
[02/05 00:52:02] d2.evaluation.evaluator INFO: Inference done 2086/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:10
[02/05 00:52:08] d2.evaluation.evaluator INFO: Inference done 2091/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:52:05
[02/05 00:52:13] d2.evaluation.evaluator INFO: Inference done 2096/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:59
[02/05 00:52:18] d2.evaluation.evaluator INFO: Inference done 2101/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:54
[02/05 00:52:24] d2.evaluation.evaluator INFO: Inference done 2106/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:48
[02/05 00:52:29] d2.evaluation.evaluator INFO: Inference done 2111/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:43
[02/05 00:52:35] d2.evaluation.evaluator INFO: Inference done 2116/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:38
[02/05 00:52:40] d2.evaluation.evaluator INFO: Inference done 2121/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:32
[02/05 00:52:46] d2.evaluation.evaluator INFO: Inference done 2126/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:27
[02/05 00:52:51] d2.evaluation.evaluator INFO: Inference done 2131/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:21
[02/05 00:52:57] d2.evaluation.evaluator INFO: Inference done 2136/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:51:16
[02/05 00:53:02] d2.evaluation.evaluator INFO: Inference done 2141/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:51:10
[02/05 00:53:07] d2.evaluation.evaluator INFO: Inference done 2146/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:51:04
[02/05 00:53:13] d2.evaluation.evaluator INFO: Inference done 2151/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:50:59
[02/05 00:53:18] d2.evaluation.evaluator INFO: Inference done 2156/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:50:54
[02/05 00:53:24] d2.evaluation.evaluator INFO: Inference done 2161/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:50:48
[02/05 00:53:29] d2.evaluation.evaluator INFO: Inference done 2166/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:50:43
[02/05 00:53:35] d2.evaluation.evaluator INFO: Inference done 2171/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:50:37
[02/05 00:53:40] d2.evaluation.evaluator INFO: Inference done 2176/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:50:32
[02/05 00:53:46] d2.evaluation.evaluator INFO: Inference done 2181/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:50:27
[02/05 00:53:51] d2.evaluation.evaluator INFO: Inference done 2186/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:50:21
[02/05 00:53:57] d2.evaluation.evaluator INFO: Inference done 2191/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:50:16
[02/05 00:54:02] d2.evaluation.evaluator INFO: Inference done 2196/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:50:10
[02/05 00:54:08] d2.evaluation.evaluator INFO: Inference done 2201/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:50:05
[02/05 00:54:13] d2.evaluation.evaluator INFO: Inference done 2206/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:49:59
[02/05 00:54:19] d2.evaluation.evaluator INFO: Inference done 2211/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:49:54
[02/05 00:54:24] d2.evaluation.evaluator INFO: Inference done 2216/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:49:48
[02/05 00:54:30] d2.evaluation.evaluator INFO: Inference done 2221/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:43
[02/05 00:54:35] d2.evaluation.evaluator INFO: Inference done 2226/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:37
[02/05 00:54:40] d2.evaluation.evaluator INFO: Inference done 2231/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:32
[02/05 00:54:46] d2.evaluation.evaluator INFO: Inference done 2236/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:26
[02/05 00:54:51] d2.evaluation.evaluator INFO: Inference done 2241/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:49:21
[02/05 00:54:57] d2.evaluation.evaluator INFO: Inference done 2246/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:16
[02/05 00:55:02] d2.evaluation.evaluator INFO: Inference done 2251/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:10
[02/05 00:55:08] d2.evaluation.evaluator INFO: Inference done 2256/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:49:05
[02/05 00:55:13] d2.evaluation.evaluator INFO: Inference done 2261/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:59
[02/05 00:55:19] d2.evaluation.evaluator INFO: Inference done 2266/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:54
[02/05 00:55:24] d2.evaluation.evaluator INFO: Inference done 2271/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:48
[02/05 00:55:30] d2.evaluation.evaluator INFO: Inference done 2276/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:43
[02/05 00:55:35] d2.evaluation.evaluator INFO: Inference done 2281/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:48:37
[02/05 00:55:41] d2.evaluation.evaluator INFO: Inference done 2286/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:32
[02/05 00:55:46] d2.evaluation.evaluator INFO: Inference done 2291/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:26
[02/05 00:55:52] d2.evaluation.evaluator INFO: Inference done 2296/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:21
[02/05 00:55:57] d2.evaluation.evaluator INFO: Inference done 2301/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:16
[02/05 00:56:03] d2.evaluation.evaluator INFO: Inference done 2306/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:48:10
[02/05 00:56:08] d2.evaluation.evaluator INFO: Inference done 2311/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:48:05
[02/05 00:56:13] d2.evaluation.evaluator INFO: Inference done 2316/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:59
[02/05 00:56:19] d2.evaluation.evaluator INFO: Inference done 2321/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:54
[02/05 00:56:24] d2.evaluation.evaluator INFO: Inference done 2326/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:48
[02/05 00:56:30] d2.evaluation.evaluator INFO: Inference done 2331/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:43
[02/05 00:56:35] d2.evaluation.evaluator INFO: Inference done 2336/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:37
[02/05 00:56:41] d2.evaluation.evaluator INFO: Inference done 2341/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:32
[02/05 00:56:46] d2.evaluation.evaluator INFO: Inference done 2346/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:26
[02/05 00:56:52] d2.evaluation.evaluator INFO: Inference done 2351/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:21
[02/05 00:56:57] d2.evaluation.evaluator INFO: Inference done 2356/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:15
[02/05 00:57:03] d2.evaluation.evaluator INFO: Inference done 2361/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:10
[02/05 00:57:08] d2.evaluation.evaluator INFO: Inference done 2366/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:47:04
[02/05 00:57:14] d2.evaluation.evaluator INFO: Inference done 2371/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:46:59
[02/05 00:57:19] d2.evaluation.evaluator INFO: Inference done 2376/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:54
[02/05 00:57:25] d2.evaluation.evaluator INFO: Inference done 2381/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:48
[02/05 00:57:30] d2.evaluation.evaluator INFO: Inference done 2386/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:43
[02/05 00:57:36] d2.evaluation.evaluator INFO: Inference done 2391/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:37
[02/05 00:57:41] d2.evaluation.evaluator INFO: Inference done 2396/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:32
[02/05 00:57:47] d2.evaluation.evaluator INFO: Inference done 2401/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:27
[02/05 00:57:52] d2.evaluation.evaluator INFO: Inference done 2406/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:21
[02/05 00:57:57] d2.evaluation.evaluator INFO: Inference done 2411/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:16
[02/05 00:58:03] d2.evaluation.evaluator INFO: Inference done 2416/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:46:10
[02/05 00:58:08] d2.evaluation.evaluator INFO: Inference done 2421/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:46:05
[02/05 00:58:14] d2.evaluation.evaluator INFO: Inference done 2426/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:59
[02/05 00:58:19] d2.evaluation.evaluator INFO: Inference done 2431/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:54
[02/05 00:58:25] d2.evaluation.evaluator INFO: Inference done 2436/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:48
[02/05 00:58:30] d2.evaluation.evaluator INFO: Inference done 2441/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:43
[02/05 00:58:36] d2.evaluation.evaluator INFO: Inference done 2446/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:45:37
[02/05 00:58:41] d2.evaluation.evaluator INFO: Inference done 2451/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:32
[02/05 00:58:47] d2.evaluation.evaluator INFO: Inference done 2456/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:26
[02/05 00:58:52] d2.evaluation.evaluator INFO: Inference done 2461/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:21
[02/05 00:58:58] d2.evaluation.evaluator INFO: Inference done 2466/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:16
[02/05 00:59:03] d2.evaluation.evaluator INFO: Inference done 2471/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:45:10
[02/05 00:59:09] d2.evaluation.evaluator INFO: Inference done 2476/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:45:05
[02/05 00:59:14] d2.evaluation.evaluator INFO: Inference done 2481/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:59
[02/05 00:59:20] d2.evaluation.evaluator INFO: Inference done 2486/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:54
[02/05 00:59:25] d2.evaluation.evaluator INFO: Inference done 2491/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:48
[02/05 00:59:30] d2.evaluation.evaluator INFO: Inference done 2496/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:43
[02/05 00:59:36] d2.evaluation.evaluator INFO: Inference done 2501/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:38
[02/05 00:59:41] d2.evaluation.evaluator INFO: Inference done 2506/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:32
[02/05 00:59:47] d2.evaluation.evaluator INFO: Inference done 2511/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:27
[02/05 00:59:52] d2.evaluation.evaluator INFO: Inference done 2516/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:21
[02/05 00:59:58] d2.evaluation.evaluator INFO: Inference done 2521/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:16
[02/05 01:00:03] d2.evaluation.evaluator INFO: Inference done 2526/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:10
[02/05 01:00:09] d2.evaluation.evaluator INFO: Inference done 2531/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:44:05
[02/05 01:00:14] d2.evaluation.evaluator INFO: Inference done 2536/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:59
[02/05 01:00:20] d2.evaluation.evaluator INFO: Inference done 2541/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:54
[02/05 01:00:25] d2.evaluation.evaluator INFO: Inference done 2546/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:48
[02/05 01:00:31] d2.evaluation.evaluator INFO: Inference done 2551/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:43
[02/05 01:00:36] d2.evaluation.evaluator INFO: Inference done 2556/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:37
[02/05 01:00:42] d2.evaluation.evaluator INFO: Inference done 2561/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:32
[02/05 01:00:47] d2.evaluation.evaluator INFO: Inference done 2566/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:27
[02/05 01:00:52] d2.evaluation.evaluator INFO: Inference done 2571/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:21
[02/05 01:00:58] d2.evaluation.evaluator INFO: Inference done 2576/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:16
[02/05 01:01:03] d2.evaluation.evaluator INFO: Inference done 2581/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:10
[02/05 01:01:09] d2.evaluation.evaluator INFO: Inference done 2586/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:43:05
[02/05 01:01:14] d2.evaluation.evaluator INFO: Inference done 2591/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:59
[02/05 01:01:20] d2.evaluation.evaluator INFO: Inference done 2596/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:54
[02/05 01:01:25] d2.evaluation.evaluator INFO: Inference done 2601/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:48
[02/05 01:01:31] d2.evaluation.evaluator INFO: Inference done 2606/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:43
[02/05 01:01:36] d2.evaluation.evaluator INFO: Inference done 2611/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:42:37
[02/05 01:01:41] d2.evaluation.evaluator INFO: Inference done 2616/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:32
[02/05 01:01:47] d2.evaluation.evaluator INFO: Inference done 2621/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:26
[02/05 01:01:52] d2.evaluation.evaluator INFO: Inference done 2626/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:21
[02/05 01:01:58] d2.evaluation.evaluator INFO: Inference done 2631/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:15
[02/05 01:02:03] d2.evaluation.evaluator INFO: Inference done 2636/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:10
[02/05 01:02:09] d2.evaluation.evaluator INFO: Inference done 2641/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:42:04
[02/05 01:02:14] d2.evaluation.evaluator INFO: Inference done 2646/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:59
[02/05 01:02:20] d2.evaluation.evaluator INFO: Inference done 2651/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:54
[02/05 01:02:25] d2.evaluation.evaluator INFO: Inference done 2656/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:48
[02/05 01:02:31] d2.evaluation.evaluator INFO: Inference done 2661/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:43
[02/05 01:02:36] d2.evaluation.evaluator INFO: Inference done 2666/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:37
[02/05 01:02:42] d2.evaluation.evaluator INFO: Inference done 2671/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:32
[02/05 01:02:47] d2.evaluation.evaluator INFO: Inference done 2676/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:26
[02/05 01:02:53] d2.evaluation.evaluator INFO: Inference done 2681/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:21
[02/05 01:02:58] d2.evaluation.evaluator INFO: Inference done 2686/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:15
[02/05 01:03:04] d2.evaluation.evaluator INFO: Inference done 2691/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:10
[02/05 01:03:09] d2.evaluation.evaluator INFO: Inference done 2696/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:41:04
[02/05 01:03:15] d2.evaluation.evaluator INFO: Inference done 2701/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:59
[02/05 01:03:20] d2.evaluation.evaluator INFO: Inference done 2706/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:53
[02/05 01:03:25] d2.evaluation.evaluator INFO: Inference done 2711/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:48
[02/05 01:03:31] d2.evaluation.evaluator INFO: Inference done 2716/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:43
[02/05 01:03:36] d2.evaluation.evaluator INFO: Inference done 2721/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:37
[02/05 01:03:42] d2.evaluation.evaluator INFO: Inference done 2726/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:32
[02/05 01:03:47] d2.evaluation.evaluator INFO: Inference done 2731/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:26
[02/05 01:03:53] d2.evaluation.evaluator INFO: Inference done 2736/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:40:21
[02/05 01:03:58] d2.evaluation.evaluator INFO: Inference done 2741/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:40:15
[02/05 01:04:04] d2.evaluation.evaluator INFO: Inference done 2746/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:40:10
[02/05 01:04:09] d2.evaluation.evaluator INFO: Inference done 2751/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:40:04
[02/05 01:04:15] d2.evaluation.evaluator INFO: Inference done 2756/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:39:59
[02/05 01:04:20] d2.evaluation.evaluator INFO: Inference done 2761/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:39:54
[02/05 01:04:26] d2.evaluation.evaluator INFO: Inference done 2766/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:39:48
[02/05 01:04:31] d2.evaluation.evaluator INFO: Inference done 2771/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:39:43
[02/05 01:04:37] d2.evaluation.evaluator INFO: Inference done 2776/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:39:37
[02/05 01:04:42] d2.evaluation.evaluator INFO: Inference done 2781/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:39:32
[02/05 01:04:47] d2.evaluation.evaluator INFO: Inference done 2786/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:39:26
[02/05 01:04:53] d2.evaluation.evaluator INFO: Inference done 2791/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:39:21
[02/05 01:04:58] d2.evaluation.evaluator INFO: Inference done 2796/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:39:15
[02/05 01:05:04] d2.evaluation.evaluator INFO: Inference done 2801/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:39:10
[02/05 01:05:09] d2.evaluation.evaluator INFO: Inference done 2806/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:39:04
[02/05 01:05:15] d2.evaluation.evaluator INFO: Inference done 2811/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:38:59
[02/05 01:05:20] d2.evaluation.evaluator INFO: Inference done 2816/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:38:53
[02/05 01:05:25] d2.evaluation.evaluator INFO: Inference done 2821/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:38:48
[02/05 01:05:31] d2.evaluation.evaluator INFO: Inference done 2826/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:38:42
[02/05 01:05:36] d2.evaluation.evaluator INFO: Inference done 2831/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:38:37
[02/05 01:05:42] d2.evaluation.evaluator INFO: Inference done 2836/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:38:31
[02/05 01:05:47] d2.evaluation.evaluator INFO: Inference done 2841/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:38:26
[02/05 01:05:53] d2.evaluation.evaluator INFO: Inference done 2846/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:38:20
[02/05 01:05:58] d2.evaluation.evaluator INFO: Inference done 2851/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:38:15
[02/05 01:06:04] d2.evaluation.evaluator INFO: Inference done 2856/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:38:09
[02/05 01:06:09] d2.evaluation.evaluator INFO: Inference done 2861/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:38:04
[02/05 01:06:14] d2.evaluation.evaluator INFO: Inference done 2866/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:37:58
[02/05 01:06:20] d2.evaluation.evaluator INFO: Inference done 2871/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:37:53
[02/05 01:06:25] d2.evaluation.evaluator INFO: Inference done 2876/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:37:47
[02/05 01:06:31] d2.evaluation.evaluator INFO: Inference done 2881/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:37:42
[02/05 01:06:36] d2.evaluation.evaluator INFO: Inference done 2886/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:37:36
[02/05 01:06:41] d2.evaluation.evaluator INFO: Inference done 2891/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:37:31
[02/05 01:06:47] d2.evaluation.evaluator INFO: Inference done 2896/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:37:25
[02/05 01:06:52] d2.evaluation.evaluator INFO: Inference done 2901/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:37:20
[02/05 01:06:58] d2.evaluation.evaluator INFO: Inference done 2906/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:37:14
[02/05 01:07:03] d2.evaluation.evaluator INFO: Inference done 2911/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:37:09
[02/05 01:07:09] d2.evaluation.evaluator INFO: Inference done 2916/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:37:04
[02/05 01:07:14] d2.evaluation.evaluator INFO: Inference done 2921/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:58
[02/05 01:07:20] d2.evaluation.evaluator INFO: Inference done 2926/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:53
[02/05 01:07:25] d2.evaluation.evaluator INFO: Inference done 2931/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:47
[02/05 01:07:30] d2.evaluation.evaluator INFO: Inference done 2936/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:42
[02/05 01:07:36] d2.evaluation.evaluator INFO: Inference done 2941/4952. Dataloading: 0.0007 s/iter. Inference: 1.0907 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:36
[02/05 01:07:41] d2.evaluation.evaluator INFO: Inference done 2946/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:31
[02/05 01:07:47] d2.evaluation.evaluator INFO: Inference done 2951/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:25
[02/05 01:07:52] d2.evaluation.evaluator INFO: Inference done 2956/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:20
[02/05 01:07:58] d2.evaluation.evaluator INFO: Inference done 2961/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:14
[02/05 01:08:03] d2.evaluation.evaluator INFO: Inference done 2966/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:36:09
[02/05 01:08:09] d2.evaluation.evaluator INFO: Inference done 2971/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:36:03
[02/05 01:08:14] d2.evaluation.evaluator INFO: Inference done 2976/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:58
[02/05 01:08:20] d2.evaluation.evaluator INFO: Inference done 2981/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:53
[02/05 01:08:25] d2.evaluation.evaluator INFO: Inference done 2986/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:47
[02/05 01:08:31] d2.evaluation.evaluator INFO: Inference done 2991/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:42
[02/05 01:08:36] d2.evaluation.evaluator INFO: Inference done 2996/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:36
[02/05 01:08:42] d2.evaluation.evaluator INFO: Inference done 3001/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:31
[02/05 01:08:47] d2.evaluation.evaluator INFO: Inference done 3006/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:25
[02/05 01:08:53] d2.evaluation.evaluator INFO: Inference done 3011/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:20
[02/05 01:08:58] d2.evaluation.evaluator INFO: Inference done 3016/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:35:14
[02/05 01:09:04] d2.evaluation.evaluator INFO: Inference done 3021/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:35:09
[02/05 01:09:09] d2.evaluation.evaluator INFO: Inference done 3026/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:35:04
[02/05 01:09:14] d2.evaluation.evaluator INFO: Inference done 3031/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:58
[02/05 01:09:20] d2.evaluation.evaluator INFO: Inference done 3036/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:53
[02/05 01:09:25] d2.evaluation.evaluator INFO: Inference done 3041/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:47
[02/05 01:09:31] d2.evaluation.evaluator INFO: Inference done 3046/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:42
[02/05 01:09:36] d2.evaluation.evaluator INFO: Inference done 3051/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:36
[02/05 01:09:42] d2.evaluation.evaluator INFO: Inference done 3056/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:34:31
[02/05 01:09:47] d2.evaluation.evaluator INFO: Inference done 3061/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:34:25
[02/05 01:09:53] d2.evaluation.evaluator INFO: Inference done 3066/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:20
[02/05 01:09:58] d2.evaluation.evaluator INFO: Inference done 3071/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:34:14
[02/05 01:10:04] d2.evaluation.evaluator INFO: Inference done 3076/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:34:09
[02/05 01:10:09] d2.evaluation.evaluator INFO: Inference done 3081/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:34:04
[02/05 01:10:15] d2.evaluation.evaluator INFO: Inference done 3086/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:58
[02/05 01:10:20] d2.evaluation.evaluator INFO: Inference done 3091/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:53
[02/05 01:10:26] d2.evaluation.evaluator INFO: Inference done 3096/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:47
[02/05 01:10:31] d2.evaluation.evaluator INFO: Inference done 3101/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:42
[02/05 01:10:37] d2.evaluation.evaluator INFO: Inference done 3106/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:36
[02/05 01:10:42] d2.evaluation.evaluator INFO: Inference done 3111/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:31
[02/05 01:10:48] d2.evaluation.evaluator INFO: Inference done 3116/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:25
[02/05 01:10:53] d2.evaluation.evaluator INFO: Inference done 3121/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:33:20
[02/05 01:10:59] d2.evaluation.evaluator INFO: Inference done 3126/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:14
[02/05 01:11:04] d2.evaluation.evaluator INFO: Inference done 3131/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:09
[02/05 01:11:10] d2.evaluation.evaluator INFO: Inference done 3136/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:33:04
[02/05 01:11:15] d2.evaluation.evaluator INFO: Inference done 3141/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:32:58
[02/05 01:11:20] d2.evaluation.evaluator INFO: Inference done 3146/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:32:53
[02/05 01:11:26] d2.evaluation.evaluator INFO: Inference done 3151/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:47
[02/05 01:11:32] d2.evaluation.evaluator INFO: Inference done 3156/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:42
[02/05 01:11:37] d2.evaluation.evaluator INFO: Inference done 3161/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:36
[02/05 01:11:42] d2.evaluation.evaluator INFO: Inference done 3166/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:31
[02/05 01:11:48] d2.evaluation.evaluator INFO: Inference done 3171/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:25
[02/05 01:11:53] d2.evaluation.evaluator INFO: Inference done 3176/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:20
[02/05 01:11:59] d2.evaluation.evaluator INFO: Inference done 3181/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:15
[02/05 01:12:04] d2.evaluation.evaluator INFO: Inference done 3186/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:09
[02/05 01:12:10] d2.evaluation.evaluator INFO: Inference done 3191/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:32:04
[02/05 01:12:15] d2.evaluation.evaluator INFO: Inference done 3196/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:58
[02/05 01:12:21] d2.evaluation.evaluator INFO: Inference done 3201/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:53
[02/05 01:12:26] d2.evaluation.evaluator INFO: Inference done 3206/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:47
[02/05 01:12:32] d2.evaluation.evaluator INFO: Inference done 3211/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:42
[02/05 01:12:37] d2.evaluation.evaluator INFO: Inference done 3216/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:36
[02/05 01:12:43] d2.evaluation.evaluator INFO: Inference done 3221/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:31
[02/05 01:12:48] d2.evaluation.evaluator INFO: Inference done 3226/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:25
[02/05 01:12:54] d2.evaluation.evaluator INFO: Inference done 3231/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:20
[02/05 01:12:59] d2.evaluation.evaluator INFO: Inference done 3236/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:14
[02/05 01:13:04] d2.evaluation.evaluator INFO: Inference done 3241/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:09
[02/05 01:13:10] d2.evaluation.evaluator INFO: Inference done 3246/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:31:04
[02/05 01:13:15] d2.evaluation.evaluator INFO: Inference done 3251/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:58
[02/05 01:13:21] d2.evaluation.evaluator INFO: Inference done 3256/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:53
[02/05 01:13:26] d2.evaluation.evaluator INFO: Inference done 3261/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:47
[02/05 01:13:32] d2.evaluation.evaluator INFO: Inference done 3266/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:42
[02/05 01:13:37] d2.evaluation.evaluator INFO: Inference done 3271/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:36
[02/05 01:13:43] d2.evaluation.evaluator INFO: Inference done 3276/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:31
[02/05 01:13:48] d2.evaluation.evaluator INFO: Inference done 3281/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:25
[02/05 01:13:54] d2.evaluation.evaluator INFO: Inference done 3286/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:20
[02/05 01:13:59] d2.evaluation.evaluator INFO: Inference done 3291/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:14
[02/05 01:14:05] d2.evaluation.evaluator INFO: Inference done 3296/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:09
[02/05 01:14:10] d2.evaluation.evaluator INFO: Inference done 3301/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:30:03
[02/05 01:14:15] d2.evaluation.evaluator INFO: Inference done 3306/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:58
[02/05 01:14:21] d2.evaluation.evaluator INFO: Inference done 3311/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:52
[02/05 01:14:26] d2.evaluation.evaluator INFO: Inference done 3316/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:47
[02/05 01:14:32] d2.evaluation.evaluator INFO: Inference done 3321/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:42
[02/05 01:14:37] d2.evaluation.evaluator INFO: Inference done 3326/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:36
[02/05 01:14:43] d2.evaluation.evaluator INFO: Inference done 3331/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:31
[02/05 01:14:48] d2.evaluation.evaluator INFO: Inference done 3336/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:25
[02/05 01:14:54] d2.evaluation.evaluator INFO: Inference done 3341/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:20
[02/05 01:14:59] d2.evaluation.evaluator INFO: Inference done 3346/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:14
[02/05 01:15:05] d2.evaluation.evaluator INFO: Inference done 3351/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:09
[02/05 01:15:10] d2.evaluation.evaluator INFO: Inference done 3356/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:29:03
[02/05 01:15:16] d2.evaluation.evaluator INFO: Inference done 3361/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:28:58
[02/05 01:15:21] d2.evaluation.evaluator INFO: Inference done 3366/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:28:52
[02/05 01:15:27] d2.evaluation.evaluator INFO: Inference done 3371/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:28:47
[02/05 01:15:32] d2.evaluation.evaluator INFO: Inference done 3376/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:42
[02/05 01:15:38] d2.evaluation.evaluator INFO: Inference done 3381/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:36
[02/05 01:15:43] d2.evaluation.evaluator INFO: Inference done 3386/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:31
[02/05 01:15:49] d2.evaluation.evaluator INFO: Inference done 3391/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:25
[02/05 01:15:54] d2.evaluation.evaluator INFO: Inference done 3396/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:20
[02/05 01:16:00] d2.evaluation.evaluator INFO: Inference done 3401/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:14
[02/05 01:16:05] d2.evaluation.evaluator INFO: Inference done 3406/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:09
[02/05 01:16:10] d2.evaluation.evaluator INFO: Inference done 3411/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:28:03
[02/05 01:16:16] d2.evaluation.evaluator INFO: Inference done 3416/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:27:58
[02/05 01:16:21] d2.evaluation.evaluator INFO: Inference done 3421/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:52
[02/05 01:16:27] d2.evaluation.evaluator INFO: Inference done 3426/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:47
[02/05 01:16:32] d2.evaluation.evaluator INFO: Inference done 3431/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:41
[02/05 01:16:38] d2.evaluation.evaluator INFO: Inference done 3436/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:36
[02/05 01:16:43] d2.evaluation.evaluator INFO: Inference done 3441/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:30
[02/05 01:16:48] d2.evaluation.evaluator INFO: Inference done 3446/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:25
[02/05 01:16:54] d2.evaluation.evaluator INFO: Inference done 3451/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:19
[02/05 01:16:59] d2.evaluation.evaluator INFO: Inference done 3456/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:14
[02/05 01:17:05] d2.evaluation.evaluator INFO: Inference done 3461/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:09
[02/05 01:17:10] d2.evaluation.evaluator INFO: Inference done 3466/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:27:03
[02/05 01:17:16] d2.evaluation.evaluator INFO: Inference done 3471/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:26:58
[02/05 01:17:21] d2.evaluation.evaluator INFO: Inference done 3476/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:26:52
[02/05 01:17:27] d2.evaluation.evaluator INFO: Inference done 3481/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:47
[02/05 01:17:32] d2.evaluation.evaluator INFO: Inference done 3486/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:41
[02/05 01:17:38] d2.evaluation.evaluator INFO: Inference done 3491/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:36
[02/05 01:17:43] d2.evaluation.evaluator INFO: Inference done 3496/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:30
[02/05 01:17:49] d2.evaluation.evaluator INFO: Inference done 3501/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:25
[02/05 01:17:54] d2.evaluation.evaluator INFO: Inference done 3506/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:20
[02/05 01:18:00] d2.evaluation.evaluator INFO: Inference done 3511/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:14
[02/05 01:18:05] d2.evaluation.evaluator INFO: Inference done 3516/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:09
[02/05 01:18:11] d2.evaluation.evaluator INFO: Inference done 3521/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:26:03
[02/05 01:18:16] d2.evaluation.evaluator INFO: Inference done 3526/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:25:58
[02/05 01:18:22] d2.evaluation.evaluator INFO: Inference done 3531/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:25:52
[02/05 01:18:27] d2.evaluation.evaluator INFO: Inference done 3536/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:25:47
[02/05 01:18:33] d2.evaluation.evaluator INFO: Inference done 3541/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:25:41
[02/05 01:18:38] d2.evaluation.evaluator INFO: Inference done 3546/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:25:36
[02/05 01:18:44] d2.evaluation.evaluator INFO: Inference done 3551/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:25:30
[02/05 01:18:49] d2.evaluation.evaluator INFO: Inference done 3556/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:25:25
[02/05 01:18:55] d2.evaluation.evaluator INFO: Inference done 3561/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:25:20
[02/05 01:19:00] d2.evaluation.evaluator INFO: Inference done 3566/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:25:14
[02/05 01:19:06] d2.evaluation.evaluator INFO: Inference done 3571/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:25:09
[02/05 01:19:11] d2.evaluation.evaluator INFO: Inference done 3576/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:25:03
[02/05 01:19:17] d2.evaluation.evaluator INFO: Inference done 3581/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:58
[02/05 01:19:22] d2.evaluation.evaluator INFO: Inference done 3586/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:52
[02/05 01:19:27] d2.evaluation.evaluator INFO: Inference done 3591/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:47
[02/05 01:19:33] d2.evaluation.evaluator INFO: Inference done 3596/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:41
[02/05 01:19:38] d2.evaluation.evaluator INFO: Inference done 3601/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:36
[02/05 01:19:44] d2.evaluation.evaluator INFO: Inference done 3606/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:30
[02/05 01:19:49] d2.evaluation.evaluator INFO: Inference done 3611/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:25
[02/05 01:19:55] d2.evaluation.evaluator INFO: Inference done 3616/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:19
[02/05 01:20:00] d2.evaluation.evaluator INFO: Inference done 3621/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:14
[02/05 01:20:06] d2.evaluation.evaluator INFO: Inference done 3626/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:09
[02/05 01:20:11] d2.evaluation.evaluator INFO: Inference done 3631/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:24:03
[02/05 01:20:17] d2.evaluation.evaluator INFO: Inference done 3636/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0928 s/iter. ETA=0:23:58
[02/05 01:20:22] d2.evaluation.evaluator INFO: Inference done 3641/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:52
[02/05 01:20:27] d2.evaluation.evaluator INFO: Inference done 3646/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:47
[02/05 01:20:33] d2.evaluation.evaluator INFO: Inference done 3651/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:41
[02/05 01:20:38] d2.evaluation.evaluator INFO: Inference done 3656/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:36
[02/05 01:20:44] d2.evaluation.evaluator INFO: Inference done 3661/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:30
[02/05 01:20:49] d2.evaluation.evaluator INFO: Inference done 3666/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:25
[02/05 01:20:55] d2.evaluation.evaluator INFO: Inference done 3671/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:19
[02/05 01:21:00] d2.evaluation.evaluator INFO: Inference done 3676/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:14
[02/05 01:21:06] d2.evaluation.evaluator INFO: Inference done 3681/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:08
[02/05 01:21:11] d2.evaluation.evaluator INFO: Inference done 3686/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:23:03
[02/05 01:21:17] d2.evaluation.evaluator INFO: Inference done 3691/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:22:57
[02/05 01:21:22] d2.evaluation.evaluator INFO: Inference done 3696/4952. Dataloading: 0.0007 s/iter. Inference: 1.0912 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:22:52
[02/05 01:21:27] d2.evaluation.evaluator INFO: Inference done 3701/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:22:46
[02/05 01:21:33] d2.evaluation.evaluator INFO: Inference done 3706/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0927 s/iter. ETA=0:22:41
[02/05 01:21:38] d2.evaluation.evaluator INFO: Inference done 3711/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:35
[02/05 01:21:44] d2.evaluation.evaluator INFO: Inference done 3716/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:30
[02/05 01:21:49] d2.evaluation.evaluator INFO: Inference done 3721/4952. Dataloading: 0.0007 s/iter. Inference: 1.0911 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:25
[02/05 01:21:54] d2.evaluation.evaluator INFO: Inference done 3726/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:19
[02/05 01:22:00] d2.evaluation.evaluator INFO: Inference done 3731/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:14
[02/05 01:22:05] d2.evaluation.evaluator INFO: Inference done 3736/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:08
[02/05 01:22:11] d2.evaluation.evaluator INFO: Inference done 3741/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:22:03
[02/05 01:22:16] d2.evaluation.evaluator INFO: Inference done 3746/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:57
[02/05 01:22:22] d2.evaluation.evaluator INFO: Inference done 3751/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:52
[02/05 01:22:27] d2.evaluation.evaluator INFO: Inference done 3756/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:46
[02/05 01:22:33] d2.evaluation.evaluator INFO: Inference done 3761/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:41
[02/05 01:22:38] d2.evaluation.evaluator INFO: Inference done 3766/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:35
[02/05 01:22:43] d2.evaluation.evaluator INFO: Inference done 3771/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:30
[02/05 01:22:49] d2.evaluation.evaluator INFO: Inference done 3776/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:24
[02/05 01:22:54] d2.evaluation.evaluator INFO: Inference done 3781/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:21:19
[02/05 01:23:00] d2.evaluation.evaluator INFO: Inference done 3786/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:21:13
[02/05 01:23:05] d2.evaluation.evaluator INFO: Inference done 3791/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:21:08
[02/05 01:23:11] d2.evaluation.evaluator INFO: Inference done 3796/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:21:02
[02/05 01:23:16] d2.evaluation.evaluator INFO: Inference done 3801/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:57
[02/05 01:23:22] d2.evaluation.evaluator INFO: Inference done 3806/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:52
[02/05 01:23:27] d2.evaluation.evaluator INFO: Inference done 3811/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:20:46
[02/05 01:23:33] d2.evaluation.evaluator INFO: Inference done 3816/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:20:41
[02/05 01:23:38] d2.evaluation.evaluator INFO: Inference done 3821/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:20:35
[02/05 01:23:43] d2.evaluation.evaluator INFO: Inference done 3826/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:30
[02/05 01:23:49] d2.evaluation.evaluator INFO: Inference done 3831/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:24
[02/05 01:23:54] d2.evaluation.evaluator INFO: Inference done 3836/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:19
[02/05 01:24:00] d2.evaluation.evaluator INFO: Inference done 3841/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:13
[02/05 01:24:05] d2.evaluation.evaluator INFO: Inference done 3846/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:08
[02/05 01:24:10] d2.evaluation.evaluator INFO: Inference done 3851/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:20:02
[02/05 01:24:16] d2.evaluation.evaluator INFO: Inference done 3856/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:19:57
[02/05 01:24:21] d2.evaluation.evaluator INFO: Inference done 3861/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:19:51
[02/05 01:24:27] d2.evaluation.evaluator INFO: Inference done 3866/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:19:46
[02/05 01:24:32] d2.evaluation.evaluator INFO: Inference done 3871/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:19:40
[02/05 01:24:38] d2.evaluation.evaluator INFO: Inference done 3876/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:19:35
[02/05 01:24:43] d2.evaluation.evaluator INFO: Inference done 3881/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:19:29
[02/05 01:24:49] d2.evaluation.evaluator INFO: Inference done 3886/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:19:24
[02/05 01:24:54] d2.evaluation.evaluator INFO: Inference done 3891/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:19:19
[02/05 01:25:00] d2.evaluation.evaluator INFO: Inference done 3896/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:19:13
[02/05 01:25:05] d2.evaluation.evaluator INFO: Inference done 3901/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:19:08
[02/05 01:25:11] d2.evaluation.evaluator INFO: Inference done 3906/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:19:02
[02/05 01:25:16] d2.evaluation.evaluator INFO: Inference done 3911/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:18:57
[02/05 01:25:21] d2.evaluation.evaluator INFO: Inference done 3916/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:18:51
[02/05 01:25:27] d2.evaluation.evaluator INFO: Inference done 3921/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:18:46
[02/05 01:25:32] d2.evaluation.evaluator INFO: Inference done 3926/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:18:40
[02/05 01:25:38] d2.evaluation.evaluator INFO: Inference done 3931/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:18:35
[02/05 01:25:43] d2.evaluation.evaluator INFO: Inference done 3936/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:18:29
[02/05 01:25:49] d2.evaluation.evaluator INFO: Inference done 3941/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:18:24
[02/05 01:25:54] d2.evaluation.evaluator INFO: Inference done 3946/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:18:18
[02/05 01:25:59] d2.evaluation.evaluator INFO: Inference done 3951/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:18:13
[02/05 01:26:05] d2.evaluation.evaluator INFO: Inference done 3956/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:18:08
[02/05 01:26:10] d2.evaluation.evaluator INFO: Inference done 3961/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:18:02
[02/05 01:26:16] d2.evaluation.evaluator INFO: Inference done 3966/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:57
[02/05 01:26:22] d2.evaluation.evaluator INFO: Inference done 3971/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:51
[02/05 01:26:27] d2.evaluation.evaluator INFO: Inference done 3976/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:46
[02/05 01:26:33] d2.evaluation.evaluator INFO: Inference done 3981/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:40
[02/05 01:26:38] d2.evaluation.evaluator INFO: Inference done 3986/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:35
[02/05 01:26:44] d2.evaluation.evaluator INFO: Inference done 3991/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:29
[02/05 01:26:49] d2.evaluation.evaluator INFO: Inference done 3996/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:24
[02/05 01:26:54] d2.evaluation.evaluator INFO: Inference done 4001/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:18
[02/05 01:27:00] d2.evaluation.evaluator INFO: Inference done 4006/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:13
[02/05 01:27:05] d2.evaluation.evaluator INFO: Inference done 4011/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:08
[02/05 01:27:11] d2.evaluation.evaluator INFO: Inference done 4016/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:17:02
[02/05 01:27:16] d2.evaluation.evaluator INFO: Inference done 4021/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:16:57
[02/05 01:27:22] d2.evaluation.evaluator INFO: Inference done 4026/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:16:51
[02/05 01:27:27] d2.evaluation.evaluator INFO: Inference done 4031/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:16:46
[02/05 01:27:33] d2.evaluation.evaluator INFO: Inference done 4036/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:16:40
[02/05 01:27:38] d2.evaluation.evaluator INFO: Inference done 4041/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:16:35
[02/05 01:27:44] d2.evaluation.evaluator INFO: Inference done 4046/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:16:29
[02/05 01:27:49] d2.evaluation.evaluator INFO: Inference done 4051/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:16:24
[02/05 01:27:55] d2.evaluation.evaluator INFO: Inference done 4056/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:16:18
[02/05 01:28:00] d2.evaluation.evaluator INFO: Inference done 4061/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:16:13
[02/05 01:28:06] d2.evaluation.evaluator INFO: Inference done 4066/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:16:07
[02/05 01:28:11] d2.evaluation.evaluator INFO: Inference done 4071/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:16:02
[02/05 01:28:16] d2.evaluation.evaluator INFO: Inference done 4076/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:15:57
[02/05 01:28:22] d2.evaluation.evaluator INFO: Inference done 4081/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:15:51
[02/05 01:28:27] d2.evaluation.evaluator INFO: Inference done 4086/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:15:46
[02/05 01:28:33] d2.evaluation.evaluator INFO: Inference done 4091/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:15:40
[02/05 01:28:38] d2.evaluation.evaluator INFO: Inference done 4096/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:15:35
[02/05 01:28:44] d2.evaluation.evaluator INFO: Inference done 4101/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:15:29
[02/05 01:28:49] d2.evaluation.evaluator INFO: Inference done 4106/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:15:24
[02/05 01:28:54] d2.evaluation.evaluator INFO: Inference done 4111/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:15:18
[02/05 01:29:00] d2.evaluation.evaluator INFO: Inference done 4116/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:15:13
[02/05 01:29:05] d2.evaluation.evaluator INFO: Inference done 4121/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:15:07
[02/05 01:29:11] d2.evaluation.evaluator INFO: Inference done 4126/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:15:02
[02/05 01:29:16] d2.evaluation.evaluator INFO: Inference done 4131/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:56
[02/05 01:29:21] d2.evaluation.evaluator INFO: Inference done 4136/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:51
[02/05 01:29:27] d2.evaluation.evaluator INFO: Inference done 4141/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:45
[02/05 01:29:32] d2.evaluation.evaluator INFO: Inference done 4146/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:40
[02/05 01:29:38] d2.evaluation.evaluator INFO: Inference done 4151/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:35
[02/05 01:29:43] d2.evaluation.evaluator INFO: Inference done 4156/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:29
[02/05 01:29:49] d2.evaluation.evaluator INFO: Inference done 4161/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:24
[02/05 01:29:54] d2.evaluation.evaluator INFO: Inference done 4166/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:18
[02/05 01:30:00] d2.evaluation.evaluator INFO: Inference done 4171/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:13
[02/05 01:30:05] d2.evaluation.evaluator INFO: Inference done 4176/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:07
[02/05 01:30:10] d2.evaluation.evaluator INFO: Inference done 4181/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:14:02
[02/05 01:30:16] d2.evaluation.evaluator INFO: Inference done 4186/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:13:56
[02/05 01:30:21] d2.evaluation.evaluator INFO: Inference done 4191/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:13:51
[02/05 01:30:27] d2.evaluation.evaluator INFO: Inference done 4196/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:13:45
[02/05 01:30:32] d2.evaluation.evaluator INFO: Inference done 4201/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:13:40
[02/05 01:30:38] d2.evaluation.evaluator INFO: Inference done 4206/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:13:34
[02/05 01:30:43] d2.evaluation.evaluator INFO: Inference done 4211/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:13:29
[02/05 01:30:49] d2.evaluation.evaluator INFO: Inference done 4216/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:13:23
[02/05 01:30:54] d2.evaluation.evaluator INFO: Inference done 4221/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:13:18
[02/05 01:31:00] d2.evaluation.evaluator INFO: Inference done 4226/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:13:13
[02/05 01:31:05] d2.evaluation.evaluator INFO: Inference done 4231/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:13:07
[02/05 01:31:11] d2.evaluation.evaluator INFO: Inference done 4236/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:13:02
[02/05 01:31:16] d2.evaluation.evaluator INFO: Inference done 4241/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:12:56
[02/05 01:31:21] d2.evaluation.evaluator INFO: Inference done 4246/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:12:51
[02/05 01:31:27] d2.evaluation.evaluator INFO: Inference done 4251/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:12:45
[02/05 01:31:32] d2.evaluation.evaluator INFO: Inference done 4256/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:12:40
[02/05 01:31:38] d2.evaluation.evaluator INFO: Inference done 4261/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:12:34
[02/05 01:31:43] d2.evaluation.evaluator INFO: Inference done 4266/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:12:29
[02/05 01:31:49] d2.evaluation.evaluator INFO: Inference done 4271/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0923 s/iter. ETA=0:12:23
[02/05 01:31:54] d2.evaluation.evaluator INFO: Inference done 4276/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:12:18
[02/05 01:32:00] d2.evaluation.evaluator INFO: Inference done 4281/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:12:12
[02/05 01:32:05] d2.evaluation.evaluator INFO: Inference done 4286/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:12:07
[02/05 01:32:11] d2.evaluation.evaluator INFO: Inference done 4291/4952. Dataloading: 0.0007 s/iter. Inference: 1.0908 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:12:02
[02/05 01:32:16] d2.evaluation.evaluator INFO: Inference done 4296/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:11:56
[02/05 01:32:22] d2.evaluation.evaluator INFO: Inference done 4301/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:11:51
[02/05 01:32:27] d2.evaluation.evaluator INFO: Inference done 4306/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:11:45
[02/05 01:32:33] d2.evaluation.evaluator INFO: Inference done 4311/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0924 s/iter. ETA=0:11:40
[02/05 01:32:38] d2.evaluation.evaluator INFO: Inference done 4316/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:34
[02/05 01:32:44] d2.evaluation.evaluator INFO: Inference done 4321/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:29
[02/05 01:32:49] d2.evaluation.evaluator INFO: Inference done 4326/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:23
[02/05 01:32:55] d2.evaluation.evaluator INFO: Inference done 4331/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:18
[02/05 01:33:01] d2.evaluation.evaluator INFO: Inference done 4336/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:13
[02/05 01:33:06] d2.evaluation.evaluator INFO: Inference done 4341/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:07
[02/05 01:33:11] d2.evaluation.evaluator INFO: Inference done 4346/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:11:02
[02/05 01:33:17] d2.evaluation.evaluator INFO: Inference done 4351/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:56
[02/05 01:33:22] d2.evaluation.evaluator INFO: Inference done 4356/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:51
[02/05 01:33:28] d2.evaluation.evaluator INFO: Inference done 4361/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:45
[02/05 01:33:33] d2.evaluation.evaluator INFO: Inference done 4366/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:40
[02/05 01:33:39] d2.evaluation.evaluator INFO: Inference done 4371/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:34
[02/05 01:33:44] d2.evaluation.evaluator INFO: Inference done 4376/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:29
[02/05 01:33:50] d2.evaluation.evaluator INFO: Inference done 4381/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:23
[02/05 01:33:55] d2.evaluation.evaluator INFO: Inference done 4386/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:18
[02/05 01:34:01] d2.evaluation.evaluator INFO: Inference done 4391/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:12
[02/05 01:34:06] d2.evaluation.evaluator INFO: Inference done 4396/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:07
[02/05 01:34:12] d2.evaluation.evaluator INFO: Inference done 4401/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:10:01
[02/05 01:34:17] d2.evaluation.evaluator INFO: Inference done 4406/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:56
[02/05 01:34:22] d2.evaluation.evaluator INFO: Inference done 4411/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:51
[02/05 01:34:28] d2.evaluation.evaluator INFO: Inference done 4416/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:45
[02/05 01:34:33] d2.evaluation.evaluator INFO: Inference done 4421/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:40
[02/05 01:34:39] d2.evaluation.evaluator INFO: Inference done 4426/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:34
[02/05 01:34:44] d2.evaluation.evaluator INFO: Inference done 4431/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:09:29
[02/05 01:34:50] d2.evaluation.evaluator INFO: Inference done 4436/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:23
[02/05 01:34:55] d2.evaluation.evaluator INFO: Inference done 4441/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:18
[02/05 01:35:01] d2.evaluation.evaluator INFO: Inference done 4446/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:12
[02/05 01:35:06] d2.evaluation.evaluator INFO: Inference done 4451/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:07
[02/05 01:35:12] d2.evaluation.evaluator INFO: Inference done 4456/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:09:01
[02/05 01:35:17] d2.evaluation.evaluator INFO: Inference done 4461/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:56
[02/05 01:35:23] d2.evaluation.evaluator INFO: Inference done 4466/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:50
[02/05 01:35:28] d2.evaluation.evaluator INFO: Inference done 4471/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:45
[02/05 01:35:33] d2.evaluation.evaluator INFO: Inference done 4476/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:40
[02/05 01:35:39] d2.evaluation.evaluator INFO: Inference done 4481/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:34
[02/05 01:35:44] d2.evaluation.evaluator INFO: Inference done 4486/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:29
[02/05 01:35:50] d2.evaluation.evaluator INFO: Inference done 4491/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:23
[02/05 01:35:55] d2.evaluation.evaluator INFO: Inference done 4496/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:18
[02/05 01:36:01] d2.evaluation.evaluator INFO: Inference done 4501/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:12
[02/05 01:36:06] d2.evaluation.evaluator INFO: Inference done 4506/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:07
[02/05 01:36:12] d2.evaluation.evaluator INFO: Inference done 4511/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:08:01
[02/05 01:36:17] d2.evaluation.evaluator INFO: Inference done 4516/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:56
[02/05 01:36:23] d2.evaluation.evaluator INFO: Inference done 4521/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:50
[02/05 01:36:28] d2.evaluation.evaluator INFO: Inference done 4526/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:45
[02/05 01:36:33] d2.evaluation.evaluator INFO: Inference done 4531/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:39
[02/05 01:36:39] d2.evaluation.evaluator INFO: Inference done 4536/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:34
[02/05 01:36:44] d2.evaluation.evaluator INFO: Inference done 4541/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:29
[02/05 01:36:50] d2.evaluation.evaluator INFO: Inference done 4546/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:23
[02/05 01:36:55] d2.evaluation.evaluator INFO: Inference done 4551/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:18
[02/05 01:37:01] d2.evaluation.evaluator INFO: Inference done 4556/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:12
[02/05 01:37:06] d2.evaluation.evaluator INFO: Inference done 4561/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:07
[02/05 01:37:12] d2.evaluation.evaluator INFO: Inference done 4566/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:07:01
[02/05 01:37:17] d2.evaluation.evaluator INFO: Inference done 4571/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:56
[02/05 01:37:23] d2.evaluation.evaluator INFO: Inference done 4576/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:50
[02/05 01:37:28] d2.evaluation.evaluator INFO: Inference done 4581/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:45
[02/05 01:37:33] d2.evaluation.evaluator INFO: Inference done 4586/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:39
[02/05 01:37:39] d2.evaluation.evaluator INFO: Inference done 4591/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:34
[02/05 01:37:44] d2.evaluation.evaluator INFO: Inference done 4596/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:28
[02/05 01:37:50] d2.evaluation.evaluator INFO: Inference done 4601/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:23
[02/05 01:37:55] d2.evaluation.evaluator INFO: Inference done 4606/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:17
[02/05 01:38:01] d2.evaluation.evaluator INFO: Inference done 4611/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:12
[02/05 01:38:06] d2.evaluation.evaluator INFO: Inference done 4616/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:07
[02/05 01:38:12] d2.evaluation.evaluator INFO: Inference done 4621/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:06:01
[02/05 01:38:17] d2.evaluation.evaluator INFO: Inference done 4626/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:56
[02/05 01:38:23] d2.evaluation.evaluator INFO: Inference done 4631/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:50
[02/05 01:38:28] d2.evaluation.evaluator INFO: Inference done 4636/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:45
[02/05 01:38:33] d2.evaluation.evaluator INFO: Inference done 4641/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:39
[02/05 01:38:39] d2.evaluation.evaluator INFO: Inference done 4646/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:34
[02/05 01:38:44] d2.evaluation.evaluator INFO: Inference done 4651/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:28
[02/05 01:38:50] d2.evaluation.evaluator INFO: Inference done 4656/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:23
[02/05 01:38:55] d2.evaluation.evaluator INFO: Inference done 4661/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:17
[02/05 01:39:01] d2.evaluation.evaluator INFO: Inference done 4666/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:12
[02/05 01:39:06] d2.evaluation.evaluator INFO: Inference done 4671/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:06
[02/05 01:39:12] d2.evaluation.evaluator INFO: Inference done 4676/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:05:01
[02/05 01:39:17] d2.evaluation.evaluator INFO: Inference done 4681/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:04:56
[02/05 01:39:23] d2.evaluation.evaluator INFO: Inference done 4686/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:04:50
[02/05 01:39:29] d2.evaluation.evaluator INFO: Inference done 4691/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:45
[02/05 01:39:34] d2.evaluation.evaluator INFO: Inference done 4696/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:39
[02/05 01:39:39] d2.evaluation.evaluator INFO: Inference done 4701/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:34
[02/05 01:39:45] d2.evaluation.evaluator INFO: Inference done 4706/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:28
[02/05 01:39:50] d2.evaluation.evaluator INFO: Inference done 4711/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:23
[02/05 01:39:56] d2.evaluation.evaluator INFO: Inference done 4716/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:17
[02/05 01:40:01] d2.evaluation.evaluator INFO: Inference done 4721/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:12
[02/05 01:40:07] d2.evaluation.evaluator INFO: Inference done 4726/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:06
[02/05 01:40:12] d2.evaluation.evaluator INFO: Inference done 4731/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:04:01
[02/05 01:40:18] d2.evaluation.evaluator INFO: Inference done 4736/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:03:55
[02/05 01:40:23] d2.evaluation.evaluator INFO: Inference done 4741/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:03:50
[02/05 01:40:29] d2.evaluation.evaluator INFO: Inference done 4746/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:03:45
[02/05 01:40:34] d2.evaluation.evaluator INFO: Inference done 4751/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:03:39
[02/05 01:40:39] d2.evaluation.evaluator INFO: Inference done 4756/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:03:34
[02/05 01:40:45] d2.evaluation.evaluator INFO: Inference done 4761/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:03:28
[02/05 01:40:50] d2.evaluation.evaluator INFO: Inference done 4766/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:03:23
[02/05 01:40:56] d2.evaluation.evaluator INFO: Inference done 4771/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:03:17
[02/05 01:41:01] d2.evaluation.evaluator INFO: Inference done 4776/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:03:12
[02/05 01:41:07] d2.evaluation.evaluator INFO: Inference done 4781/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:03:06
[02/05 01:41:12] d2.evaluation.evaluator INFO: Inference done 4786/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:03:01
[02/05 01:41:18] d2.evaluation.evaluator INFO: Inference done 4791/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:55
[02/05 01:41:23] d2.evaluation.evaluator INFO: Inference done 4796/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:50
[02/05 01:41:29] d2.evaluation.evaluator INFO: Inference done 4801/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:02:44
[02/05 01:41:34] d2.evaluation.evaluator INFO: Inference done 4806/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:02:39
[02/05 01:41:40] d2.evaluation.evaluator INFO: Inference done 4811/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:34
[02/05 01:41:45] d2.evaluation.evaluator INFO: Inference done 4816/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:28
[02/05 01:41:51] d2.evaluation.evaluator INFO: Inference done 4821/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:23
[02/05 01:41:56] d2.evaluation.evaluator INFO: Inference done 4826/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:17
[02/05 01:42:02] d2.evaluation.evaluator INFO: Inference done 4831/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:12
[02/05 01:42:07] d2.evaluation.evaluator INFO: Inference done 4836/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:06
[02/05 01:42:12] d2.evaluation.evaluator INFO: Inference done 4841/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:02:01
[02/05 01:42:18] d2.evaluation.evaluator INFO: Inference done 4846/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:01:55
[02/05 01:42:23] d2.evaluation.evaluator INFO: Inference done 4851/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0926 s/iter. ETA=0:01:50
[02/05 01:42:29] d2.evaluation.evaluator INFO: Inference done 4856/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:44
[02/05 01:42:34] d2.evaluation.evaluator INFO: Inference done 4861/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:39
[02/05 01:42:39] d2.evaluation.evaluator INFO: Inference done 4866/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:33
[02/05 01:42:45] d2.evaluation.evaluator INFO: Inference done 4871/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:28
[02/05 01:42:50] d2.evaluation.evaluator INFO: Inference done 4876/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:23
[02/05 01:42:56] d2.evaluation.evaluator INFO: Inference done 4881/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:17
[02/05 01:43:01] d2.evaluation.evaluator INFO: Inference done 4886/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:12
[02/05 01:43:07] d2.evaluation.evaluator INFO: Inference done 4891/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:06
[02/05 01:43:12] d2.evaluation.evaluator INFO: Inference done 4896/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:01:01
[02/05 01:43:18] d2.evaluation.evaluator INFO: Inference done 4901/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:55
[02/05 01:43:23] d2.evaluation.evaluator INFO: Inference done 4906/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:50
[02/05 01:43:29] d2.evaluation.evaluator INFO: Inference done 4911/4952. Dataloading: 0.0007 s/iter. Inference: 1.0909 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:44
[02/05 01:43:34] d2.evaluation.evaluator INFO: Inference done 4916/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:39
[02/05 01:43:40] d2.evaluation.evaluator INFO: Inference done 4921/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:33
[02/05 01:43:45] d2.evaluation.evaluator INFO: Inference done 4926/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:28
[02/05 01:43:51] d2.evaluation.evaluator INFO: Inference done 4931/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:22
[02/05 01:43:56] d2.evaluation.evaluator INFO: Inference done 4936/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:17
[02/05 01:44:02] d2.evaluation.evaluator INFO: Inference done 4941/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:12
[02/05 01:44:07] d2.evaluation.evaluator INFO: Inference done 4946/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:06
[02/05 01:44:12] d2.evaluation.evaluator INFO: Inference done 4951/4952. Dataloading: 0.0007 s/iter. Inference: 1.0910 s/iter. Eval: 0.0008 s/iter. Total: 1.0925 s/iter. ETA=0:00:01
[02/05 01:44:14] d2.evaluation.evaluator INFO: Total inference time: 1:30:04.853333 (1.092552 s / iter per device, on 1 devices)
[02/05 01:44:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 1:29:57 (1.090965 s / iter per device, on 1 devices)
[02/05 01:44:14] FCT.evaluation.pascal_voc_evaluation INFO: Evaluating voc_2007_test_all1 using 2007 metric. Note that results do not use the official Matlab API.
[02/05 01:45:02] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate per-class mAP50:
|  aeroplane  |  bicycle  |  boat  |  bottle  |  car   |  cat   |  chair  |  diningtable  |  dog  |  horse  |  person  |  pottedplant  |  sheep  |  train  |  tvmonitor  |  bird  |  bus  |  cow   |  motorbike  |  sofa  |
|:-----------:|:---------:|:------:|:--------:|:------:|:------:|:-------:|:-------------:|:-----:|:-------:|:--------:|:-------------:|:-------:|:-------:|:-----------:|:------:|:-----:|:------:|:-----------:|:------:|
|   24.607    |  24.598   | 17.810 |  25.859  | 34.160 | 11.023 | 17.331  |     9.091     | 9.949 | 11.657  |  25.188  |    17.074     | 33.688  |  6.136  |   18.711    | 2.483  | 0.098 | 23.054 |    0.228    | 0.039  |
[02/05 01:45:02] FCT.evaluation.pascal_voc_evaluation INFO: Evaluate overall bbox:
|  AP   |  AP50  |  AP75  |  bAP   |  bAP50  |  bAP75  |  nAP  |  nAP50  |  nAP75  |
|:-----:|:------:|:------:|:------:|:-------:|:-------:|:-----:|:-------:|:-------:|
| 8.971 | 15.639 | 8.816  | 10.960 | 19.125  | 10.702  | 3.007 |  5.180  |  3.156  |
[02/05 01:45:02] d2.evaluation.testing INFO: copypaste: Task: bbox
[02/05 01:45:02] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,bAP,bAP50,bAP75,nAP,nAP50,nAP75
[02/05 01:45:02] d2.evaluation.testing INFO: copypaste: 8.9714,15.6392,8.8156,10.9595,19.1254,10.7019,3.0072,5.1804,3.1565
